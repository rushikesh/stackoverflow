[{"t":"How do I achieve the theoretical maximum of 4 FLOPs per cycle?","l":"http://stackoverflow.com/questions/8389648/how-do-i-achieve-the-theoretical-maximum-of-4-flops-per-cycle","q":"\n\n<p>How can the theoretical peak performance of 4 floating point operations (double precision) per cycle be achieved on a modern x86-64 Intel cpu?</p>\n\n<p>As far as I understand it take 3 cycles for an sse <code>add</code> and 5 cycles for a <code>mul</code> to complete on most of the modern Intel cpu's (see e.g. <a href=\"http://agner.org/optimize/instruction_tables.pdf\">Agner Fog's 'Instruction Tables'</a> ). Due to pipelining one can get a throughput of 1 <code>add</code> per cycle if the algorithm has at least 3 independent summations. Since that is true for packed <code>addpd</code> as well as the scalar <code>addsd</code> versions and sse registers can contain 2 <code>double</code>'s the throughput can be as much as 2 flops per cycle.\nFurthermore it seems (although I've not seen any proper doc on this) <code>add</code>'s and <code>mul</code>'s can be executed in parallel giving a theoretical max throughput of 4 flops per cycle.</p>\n\n<p>However, I've not been able to replicate that performance with a simple c/c++ programme. My best attempt resulted in about 2.7 flops/cycle. If anyone can contribute a simple c/c++ or assembler programme which demonstrates peak performance that'd be greatly appreciated.</p>\n\n<p>My attempt:</p>\n\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n#include &lt;math.h&gt;\n#include &lt;sys/time.h&gt;\n\ndouble stoptime(void) {\n   struct timeval t;\n   gettimeofday(&amp;t,NULL);\n   return (double) t.tv_sec + t.tv_usec/1000000.0;\n}\n\ndouble addmul(double add, double mul, int ops){\n   // need to initialise differently otherwise compiler might optimise away\n   double sum1=0.1, sum2=-0.1, sum3=0.2, sum4=-0.2, sum5=0.0;\n   double mul1=1.0, mul2= 1.1, mul3=1.2, mul4= 1.3, mul5=1.4;\n   int loops=ops/10;          // we have 10 floating point ops inside the loop\n   double expected = 5.0*add*loops + (sum1+sum2+sum3+sum4+sum5)\n               + pow(mul,loops)*(mul1+mul2+mul3+mul4+mul5);\n\n   for(int i=0; i&lt;loops; i++) {\n      mul1*=mul; mul2*=mul; mul3*=mul; mul4*=mul; mul5*=mul;\n      sum1+=add; sum2+=add; sum3+=add; sum4+=add; sum5+=add;\n   }\n   return  sum1+sum2+sum3+sum4+sum5+mul1+mul2+mul3+mul4+mul5 - expected;\n}\n\nint main(int argc, char** argv) {\n   if(argc!=2) {\n      printf(\"usage: %s &lt;num&gt;\\n\", argv[0]);\n      printf(\"number of operations: &lt;num&gt; millions\\n\");\n      exit(EXIT_FAILURE);\n   }\n   int n=atoi(argv[1])*1000000;\n   if(n&lt;=0) n=1000;\n\n   double x=M_PI;\n   double y=1.0+1e-8;\n   double t=stoptime();\n   x=addmul(x,y,n);\n   t=stoptime()-t;\n   printf(\"addmul:\\t %.3f s, %.3f Gflops, res=%f\\n\",t,(double)n/t/1e9,x);\n\n   return EXIT_SUCCESS;\n}\n</code></pre>\n\n<p>Compiled with</p>\n\n<pre><code>g++ -O2 -march=native addmul.cpp ; ./a.out 1000\n</code></pre>\n\n<p>produces the following output on an Intel Core i5-750, 2.66 GHz</p>\n\n<pre><code>addmul:  0.270 s, 3.707 Gflops, res=1.326463\n</code></pre>\n\n<p>i.e. just about 1.4 flops per cycle. Looking at the assembler code with\n<code>g++ -S -O2 -march=native -masm=intel addmul.cpp</code> the main loop seems kind of\noptimal to me:</p>\n\n<pre><code>.L4:\ninc eax\nmulsd   xmm8, xmm3\nmulsd   xmm7, xmm3\nmulsd   xmm6, xmm3\nmulsd   xmm5, xmm3\nmulsd   xmm1, xmm3\naddsd   xmm13, xmm2\naddsd   xmm12, xmm2\naddsd   xmm11, xmm2\naddsd   xmm10, xmm2\naddsd   xmm9, xmm2\ncmp eax, ebx\njne .L4\n</code></pre>\n\n<p>Changing the scalar versions with packed versions (<code>addpd</code> and <code>mulpd</code>) would double the flop count without changing the execution time and so I'd get just short of 2.8 flops per cycle. Any simple example which achieves 4 flops per cycle?</p>\n\n<p><strong>Edit:</strong></p>\n\n<p>Nice little programme by Mysticial,\nhere are my results (run just for a few seconds though):</p>\n\n<ul>\n<li><code>gcc -O2 -march=nocona</code>: 5.6 Gflops out of 10.66 Gflops (2.1 flops/cycle)</li>\n<li><code>cl /O2</code>, openmp removed: 10.1 Gflops out of 10.66 Gflops (3.8 flops/cycle)</li>\n</ul>\n\n<p>It all seems a bit complex but my conclusions so far:</p>\n\n<ul>\n<li><p><code>gcc -O2</code> changes the order of independent floating point operations with\nthe aim of alternating\n<code>addpd</code> and <code>mulpd</code>'s if possible. Same applies to <code>gcc-4.6.2 -O2 -march=core2</code>.</p></li>\n<li><p><code>gcc -O2 -march=nocona</code> seems to keep the order of fp operations as defined in\nthe C++ source.</p></li>\n<li><p><code>cl /O2</code>, the 64-bit compiler from the\n<a href=\"http://www.microsoft.com/download/en/details.aspx?id=3138\">SDK for Windows 7</a>\ndoes loop-unrolling automatically and seems to try and arrange operations\nso that groups of 3 <code>addpd</code>'s alternate with 3 <code>mulpd</code>'s (well at least on my\nsystem and for my simple programme).</p></li>\n<li><p>My <a href=\"http://en.wikipedia.org/wiki/List_of_Intel_Core_i5_microprocessors#Based_on_Nehalem_microarchitecture\">Core i5 750</a> (<a href=\"http://en.wikipedia.org/wiki/Nehalem_%28microarchitecture%29\">Nahelem architecture</a>)\ndoesn't like alternating add's and mul's and seems unable\nto run both ops in parallel. However, if grouped in 3's it suddenly works like\nmagic.</p></li>\n<li><p>Other architectures (possibly <a href=\"http://en.wikipedia.org/wiki/Sandy_bridge\">Sandy Bridge</a> and others) appear to\nbe able to execute add/mul in parallel without problems \nif they alternate in the assembly code.</p></li>\n<li><p>Although difficult to admit, but on my system <code>cl /O2</code> does a much better job\nat low level optimising operations for my system and achieves close to peak\nperformance for the little c++ example above. I measured between\n1.85-2.01 flops/cycle (have used clock() in Windows which is not that precise\nI guess, need to use a better timer - thanks Mackie Messer).</p></li>\n<li><p>The best I managed  with <code>gcc</code> was to manually loop unroll and arrange\nadditions and multiplications in groups of three. With\n<code>g++ -O2 -march=nocona  addmul_unroll.cpp</code>\nI get at best <code>0.207s, 4.825 Gflops</code> which corresponds to 1.8 flops/cycle\nwhich I'm quite happy with now.</p></li>\n</ul>\n\n<p>In the c++ code I've replaced the <code>for</code> loop with</p>\n\n<pre><code>   for(int i=0; i&lt;loops/3; i++) {\n      mul1*=mul; mul2*=mul; mul3*=mul;\n      sum1+=add; sum2+=add; sum3+=add;\n      mul4*=mul; mul5*=mul; mul1*=mul;\n      sum4+=add; sum5+=add; sum1+=add;\n\n      mul2*=mul; mul3*=mul; mul4*=mul;\n      sum2+=add; sum3+=add; sum4+=add;\n      mul5*=mul; mul1*=mul; mul2*=mul;\n      sum5+=add; sum1+=add; sum2+=add;\n\n      mul3*=mul; mul4*=mul; mul5*=mul;\n      sum3+=add; sum4+=add; sum5+=add;\n   }\n</code></pre>\n\n<p>and the assembly now looks like</p>\n\n<pre><code>.L4:\nmulsd   xmm8, xmm3\nmulsd   xmm7, xmm3\nmulsd   xmm6, xmm3\naddsd   xmm13, xmm2\naddsd   xmm12, xmm2\naddsd   xmm11, xmm2\nmulsd   xmm5, xmm3\nmulsd   xmm1, xmm3\nmulsd   xmm8, xmm3\naddsd   xmm10, xmm2\naddsd   xmm9, xmm2\naddsd   xmm13, xmm2\n...\n</code></pre>\n    ","a":"\n<p>I've done this exact task before. But it was mainly to measure power consumption and CPU temperatures. The following code (which is fairly long) achieves close to optimal on my Core i7 2600K.</p>\n\n<p>The key thing to note here is the massive amount of manual loop-unrolling as well as interleaving of multiplies and adds...</p>\n\n<p>The full project can be found on my GitHub: <a href=\"https://github.com/Mysticial/Flops\">https://github.com/Mysticial/Flops</a></p>\n\n<h1>Warning:</h1>\n\n<p><strong>If you decide to compile and run this, pay attention to your CPU temperatures!!!</strong><br>Make sure you don't overheat it. And make sure CPU-throttling doesn't affect your results!</p>\n\n<p>Furthermore, I take no responsibility for whatever damage that may result from running this code.</p>\n\n<p><strong>Notes:</strong></p>\n\n<ul>\n<li>This code is optimized for x64. x86 doesn't have enough registers for this to compile well.</li>\n<li>This code has been tested to work well on Visual Studio 2010/2012 and GCC 4.6.<br>ICC 11 (Intel Compiler 11) surprisingly has trouble compiling it well.</li>\n<li>These are for pre-FMA processors. In order to achieve peak FLOPS on Intel Haswell and AMD Bulldozer processors (and later), FMA (Fused Multiply Add) instructions will be needed. These are beyond the scope of this benchmark.</li>\n</ul>\n\n<p></p>\n\n<pre><code>#include &lt;emmintrin.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n\ntypedef unsigned long long uint64;\n\ndouble test_dp_mac_SSE(double x,double y,uint64 iterations){\n    register __m128d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;\n\n    //  Generate starting data.\n    r0 = _mm_set1_pd(x);\n    r1 = _mm_set1_pd(y);\n\n    r8 = _mm_set1_pd(-0.0);\n\n    r2 = _mm_xor_pd(r0,r8);\n    r3 = _mm_or_pd(r0,r8);\n    r4 = _mm_andnot_pd(r8,r0);\n    r5 = _mm_mul_pd(r1,_mm_set1_pd(0.37796447300922722721));\n    r6 = _mm_mul_pd(r1,_mm_set1_pd(0.24253562503633297352));\n    r7 = _mm_mul_pd(r1,_mm_set1_pd(4.1231056256176605498));\n    r8 = _mm_add_pd(r0,_mm_set1_pd(0.37796447300922722721));\n    r9 = _mm_add_pd(r1,_mm_set1_pd(0.24253562503633297352));\n    rA = _mm_sub_pd(r0,_mm_set1_pd(4.1231056256176605498));\n    rB = _mm_sub_pd(r1,_mm_set1_pd(4.1231056256176605498));\n\n    rC = _mm_set1_pd(1.4142135623730950488);\n    rD = _mm_set1_pd(1.7320508075688772935);\n    rE = _mm_set1_pd(0.57735026918962576451);\n    rF = _mm_set1_pd(0.70710678118654752440);\n\n    uint64 iMASK = 0x800fffffffffffffull;\n    __m128d MASK = _mm_set1_pd(*(double*)&amp;iMASK);\n    __m128d vONE = _mm_set1_pd(1.0);\n\n    uint64 c = 0;\n    while (c &lt; iterations){\n        size_t i = 0;\n        while (i &lt; 1000){\n            //  Here's the meat - the part that really matters.\n\n            r0 = _mm_mul_pd(r0,rC);\n            r1 = _mm_add_pd(r1,rD);\n            r2 = _mm_mul_pd(r2,rE);\n            r3 = _mm_sub_pd(r3,rF);\n            r4 = _mm_mul_pd(r4,rC);\n            r5 = _mm_add_pd(r5,rD);\n            r6 = _mm_mul_pd(r6,rE);\n            r7 = _mm_sub_pd(r7,rF);\n            r8 = _mm_mul_pd(r8,rC);\n            r9 = _mm_add_pd(r9,rD);\n            rA = _mm_mul_pd(rA,rE);\n            rB = _mm_sub_pd(rB,rF);\n\n            r0 = _mm_add_pd(r0,rF);\n            r1 = _mm_mul_pd(r1,rE);\n            r2 = _mm_sub_pd(r2,rD);\n            r3 = _mm_mul_pd(r3,rC);\n            r4 = _mm_add_pd(r4,rF);\n            r5 = _mm_mul_pd(r5,rE);\n            r6 = _mm_sub_pd(r6,rD);\n            r7 = _mm_mul_pd(r7,rC);\n            r8 = _mm_add_pd(r8,rF);\n            r9 = _mm_mul_pd(r9,rE);\n            rA = _mm_sub_pd(rA,rD);\n            rB = _mm_mul_pd(rB,rC);\n\n            r0 = _mm_mul_pd(r0,rC);\n            r1 = _mm_add_pd(r1,rD);\n            r2 = _mm_mul_pd(r2,rE);\n            r3 = _mm_sub_pd(r3,rF);\n            r4 = _mm_mul_pd(r4,rC);\n            r5 = _mm_add_pd(r5,rD);\n            r6 = _mm_mul_pd(r6,rE);\n            r7 = _mm_sub_pd(r7,rF);\n            r8 = _mm_mul_pd(r8,rC);\n            r9 = _mm_add_pd(r9,rD);\n            rA = _mm_mul_pd(rA,rE);\n            rB = _mm_sub_pd(rB,rF);\n\n            r0 = _mm_add_pd(r0,rF);\n            r1 = _mm_mul_pd(r1,rE);\n            r2 = _mm_sub_pd(r2,rD);\n            r3 = _mm_mul_pd(r3,rC);\n            r4 = _mm_add_pd(r4,rF);\n            r5 = _mm_mul_pd(r5,rE);\n            r6 = _mm_sub_pd(r6,rD);\n            r7 = _mm_mul_pd(r7,rC);\n            r8 = _mm_add_pd(r8,rF);\n            r9 = _mm_mul_pd(r9,rE);\n            rA = _mm_sub_pd(rA,rD);\n            rB = _mm_mul_pd(rB,rC);\n\n            i++;\n        }\n\n        //  Need to renormalize to prevent denormal/overflow.\n        r0 = _mm_and_pd(r0,MASK);\n        r1 = _mm_and_pd(r1,MASK);\n        r2 = _mm_and_pd(r2,MASK);\n        r3 = _mm_and_pd(r3,MASK);\n        r4 = _mm_and_pd(r4,MASK);\n        r5 = _mm_and_pd(r5,MASK);\n        r6 = _mm_and_pd(r6,MASK);\n        r7 = _mm_and_pd(r7,MASK);\n        r8 = _mm_and_pd(r8,MASK);\n        r9 = _mm_and_pd(r9,MASK);\n        rA = _mm_and_pd(rA,MASK);\n        rB = _mm_and_pd(rB,MASK);\n        r0 = _mm_or_pd(r0,vONE);\n        r1 = _mm_or_pd(r1,vONE);\n        r2 = _mm_or_pd(r2,vONE);\n        r3 = _mm_or_pd(r3,vONE);\n        r4 = _mm_or_pd(r4,vONE);\n        r5 = _mm_or_pd(r5,vONE);\n        r6 = _mm_or_pd(r6,vONE);\n        r7 = _mm_or_pd(r7,vONE);\n        r8 = _mm_or_pd(r8,vONE);\n        r9 = _mm_or_pd(r9,vONE);\n        rA = _mm_or_pd(rA,vONE);\n        rB = _mm_or_pd(rB,vONE);\n\n        c++;\n    }\n\n    r0 = _mm_add_pd(r0,r1);\n    r2 = _mm_add_pd(r2,r3);\n    r4 = _mm_add_pd(r4,r5);\n    r6 = _mm_add_pd(r6,r7);\n    r8 = _mm_add_pd(r8,r9);\n    rA = _mm_add_pd(rA,rB);\n\n    r0 = _mm_add_pd(r0,r2);\n    r4 = _mm_add_pd(r4,r6);\n    r8 = _mm_add_pd(r8,rA);\n\n    r0 = _mm_add_pd(r0,r4);\n    r0 = _mm_add_pd(r0,r8);\n\n\n    //  Prevent Dead Code Elimination\n    double out = 0;\n    __m128d temp = r0;\n    out += ((double*)&amp;temp)[0];\n    out += ((double*)&amp;temp)[1];\n\n    return out;\n}\n\nvoid test_dp_mac_SSE(int tds,uint64 iterations){\n\n    double *sum = (double*)malloc(tds * sizeof(double));\n    double start = omp_get_wtime();\n\n#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_SSE(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }\n\n    double secs = omp_get_wtime() - start;\n    uint64 ops = 48 * 1000 * iterations * tds * 2;\n    cout &lt;&lt; \"Seconds = \" &lt;&lt; secs &lt;&lt; endl;\n    cout &lt;&lt; \"FP Ops  = \" &lt;&lt; ops &lt;&lt; endl;\n    cout &lt;&lt; \"FLOPs   = \" &lt;&lt; ops / secs &lt;&lt; endl;\n\n    double out = 0;\n    int c = 0;\n    while (c &lt; tds){\n        out += sum[c++];\n    }\n\n    cout &lt;&lt; \"sum = \" &lt;&lt; out &lt;&lt; endl;\n    cout &lt;&lt; endl;\n\n    free(sum);\n}\n\nint main(){\n    //  (threads, iterations)\n    test_dp_mac_SSE(8,10000000);\n\n    system(\"pause\");\n}\n</code></pre>\n\n<p><strong>Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>\n\n<pre><code>Seconds = 55.5104\nFP Ops  = 960000000000\nFLOPs   = 1.7294e+010\nsum = 2.22652\n</code></pre>\n\n<p>The machine is a Core i7 2600K @ 4.4 GHz. Theoretical SSE peak is 4 flops * 4.4 GHz = <strong>17.6 GFlops</strong>. This code achieves <strong>17.3 GFlops</strong> - not bad.</p>\n\n<p><strong>Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>\n\n<pre><code>Seconds = 117.202\nFP Ops  = 7680000000000\nFLOPs   = 6.55279e+010\nsum = 17.8122\n</code></pre>\n\n<p>Theoretical SSE peak is 4 flops * 4 cores * 4.4 GHz = <strong>70.4 GFlops.</strong> Actual is <strong>65.5 GFlops</strong>.</p>\n\n<hr>\n\n<h2>Let's take this one step further. AVX...</h2>\n\n<pre><code>#include &lt;immintrin.h&gt;\n#include &lt;omp.h&gt;\n#include &lt;iostream&gt;\nusing namespace std;\n\ntypedef unsigned long long uint64;\n\ndouble test_dp_mac_AVX(double x,double y,uint64 iterations){\n    register __m256d r0,r1,r2,r3,r4,r5,r6,r7,r8,r9,rA,rB,rC,rD,rE,rF;\n\n    //  Generate starting data.\n    r0 = _mm256_set1_pd(x);\n    r1 = _mm256_set1_pd(y);\n\n    r8 = _mm256_set1_pd(-0.0);\n\n    r2 = _mm256_xor_pd(r0,r8);\n    r3 = _mm256_or_pd(r0,r8);\n    r4 = _mm256_andnot_pd(r8,r0);\n    r5 = _mm256_mul_pd(r1,_mm256_set1_pd(0.37796447300922722721));\n    r6 = _mm256_mul_pd(r1,_mm256_set1_pd(0.24253562503633297352));\n    r7 = _mm256_mul_pd(r1,_mm256_set1_pd(4.1231056256176605498));\n    r8 = _mm256_add_pd(r0,_mm256_set1_pd(0.37796447300922722721));\n    r9 = _mm256_add_pd(r1,_mm256_set1_pd(0.24253562503633297352));\n    rA = _mm256_sub_pd(r0,_mm256_set1_pd(4.1231056256176605498));\n    rB = _mm256_sub_pd(r1,_mm256_set1_pd(4.1231056256176605498));\n\n    rC = _mm256_set1_pd(1.4142135623730950488);\n    rD = _mm256_set1_pd(1.7320508075688772935);\n    rE = _mm256_set1_pd(0.57735026918962576451);\n    rF = _mm256_set1_pd(0.70710678118654752440);\n\n    uint64 iMASK = 0x800fffffffffffffull;\n    __m256d MASK = _mm256_set1_pd(*(double*)&amp;iMASK);\n    __m256d vONE = _mm256_set1_pd(1.0);\n\n    uint64 c = 0;\n    while (c &lt; iterations){\n        size_t i = 0;\n        while (i &lt; 1000){\n            //  Here's the meat - the part that really matters.\n\n            r0 = _mm256_mul_pd(r0,rC);\n            r1 = _mm256_add_pd(r1,rD);\n            r2 = _mm256_mul_pd(r2,rE);\n            r3 = _mm256_sub_pd(r3,rF);\n            r4 = _mm256_mul_pd(r4,rC);\n            r5 = _mm256_add_pd(r5,rD);\n            r6 = _mm256_mul_pd(r6,rE);\n            r7 = _mm256_sub_pd(r7,rF);\n            r8 = _mm256_mul_pd(r8,rC);\n            r9 = _mm256_add_pd(r9,rD);\n            rA = _mm256_mul_pd(rA,rE);\n            rB = _mm256_sub_pd(rB,rF);\n\n            r0 = _mm256_add_pd(r0,rF);\n            r1 = _mm256_mul_pd(r1,rE);\n            r2 = _mm256_sub_pd(r2,rD);\n            r3 = _mm256_mul_pd(r3,rC);\n            r4 = _mm256_add_pd(r4,rF);\n            r5 = _mm256_mul_pd(r5,rE);\n            r6 = _mm256_sub_pd(r6,rD);\n            r7 = _mm256_mul_pd(r7,rC);\n            r8 = _mm256_add_pd(r8,rF);\n            r9 = _mm256_mul_pd(r9,rE);\n            rA = _mm256_sub_pd(rA,rD);\n            rB = _mm256_mul_pd(rB,rC);\n\n            r0 = _mm256_mul_pd(r0,rC);\n            r1 = _mm256_add_pd(r1,rD);\n            r2 = _mm256_mul_pd(r2,rE);\n            r3 = _mm256_sub_pd(r3,rF);\n            r4 = _mm256_mul_pd(r4,rC);\n            r5 = _mm256_add_pd(r5,rD);\n            r6 = _mm256_mul_pd(r6,rE);\n            r7 = _mm256_sub_pd(r7,rF);\n            r8 = _mm256_mul_pd(r8,rC);\n            r9 = _mm256_add_pd(r9,rD);\n            rA = _mm256_mul_pd(rA,rE);\n            rB = _mm256_sub_pd(rB,rF);\n\n            r0 = _mm256_add_pd(r0,rF);\n            r1 = _mm256_mul_pd(r1,rE);\n            r2 = _mm256_sub_pd(r2,rD);\n            r3 = _mm256_mul_pd(r3,rC);\n            r4 = _mm256_add_pd(r4,rF);\n            r5 = _mm256_mul_pd(r5,rE);\n            r6 = _mm256_sub_pd(r6,rD);\n            r7 = _mm256_mul_pd(r7,rC);\n            r8 = _mm256_add_pd(r8,rF);\n            r9 = _mm256_mul_pd(r9,rE);\n            rA = _mm256_sub_pd(rA,rD);\n            rB = _mm256_mul_pd(rB,rC);\n\n            i++;\n        }\n\n        //  Need to renormalize to prevent denormal/overflow.\n        r0 = _mm256_and_pd(r0,MASK);\n        r1 = _mm256_and_pd(r1,MASK);\n        r2 = _mm256_and_pd(r2,MASK);\n        r3 = _mm256_and_pd(r3,MASK);\n        r4 = _mm256_and_pd(r4,MASK);\n        r5 = _mm256_and_pd(r5,MASK);\n        r6 = _mm256_and_pd(r6,MASK);\n        r7 = _mm256_and_pd(r7,MASK);\n        r8 = _mm256_and_pd(r8,MASK);\n        r9 = _mm256_and_pd(r9,MASK);\n        rA = _mm256_and_pd(rA,MASK);\n        rB = _mm256_and_pd(rB,MASK);\n        r0 = _mm256_or_pd(r0,vONE);\n        r1 = _mm256_or_pd(r1,vONE);\n        r2 = _mm256_or_pd(r2,vONE);\n        r3 = _mm256_or_pd(r3,vONE);\n        r4 = _mm256_or_pd(r4,vONE);\n        r5 = _mm256_or_pd(r5,vONE);\n        r6 = _mm256_or_pd(r6,vONE);\n        r7 = _mm256_or_pd(r7,vONE);\n        r8 = _mm256_or_pd(r8,vONE);\n        r9 = _mm256_or_pd(r9,vONE);\n        rA = _mm256_or_pd(rA,vONE);\n        rB = _mm256_or_pd(rB,vONE);\n\n        c++;\n    }\n\n    r0 = _mm256_add_pd(r0,r1);\n    r2 = _mm256_add_pd(r2,r3);\n    r4 = _mm256_add_pd(r4,r5);\n    r6 = _mm256_add_pd(r6,r7);\n    r8 = _mm256_add_pd(r8,r9);\n    rA = _mm256_add_pd(rA,rB);\n\n    r0 = _mm256_add_pd(r0,r2);\n    r4 = _mm256_add_pd(r4,r6);\n    r8 = _mm256_add_pd(r8,rA);\n\n    r0 = _mm256_add_pd(r0,r4);\n    r0 = _mm256_add_pd(r0,r8);\n\n    //  Prevent Dead Code Elimination\n    double out = 0;\n    __m256d temp = r0;\n    out += ((double*)&amp;temp)[0];\n    out += ((double*)&amp;temp)[1];\n    out += ((double*)&amp;temp)[2];\n    out += ((double*)&amp;temp)[3];\n\n    return out;\n}\n\nvoid test_dp_mac_AVX(int tds,uint64 iterations){\n\n    double *sum = (double*)malloc(tds * sizeof(double));\n    double start = omp_get_wtime();\n\n#pragma omp parallel num_threads(tds)\n    {\n        double ret = test_dp_mac_AVX(1.1,2.1,iterations);\n        sum[omp_get_thread_num()] = ret;\n    }\n\n    double secs = omp_get_wtime() - start;\n    uint64 ops = 48 * 1000 * iterations * tds * 4;\n    cout &lt;&lt; \"Seconds = \" &lt;&lt; secs &lt;&lt; endl;\n    cout &lt;&lt; \"FP Ops  = \" &lt;&lt; ops &lt;&lt; endl;\n    cout &lt;&lt; \"FLOPs   = \" &lt;&lt; ops / secs &lt;&lt; endl;\n\n    double out = 0;\n    int c = 0;\n    while (c &lt; tds){\n        out += sum[c++];\n    }\n\n    cout &lt;&lt; \"sum = \" &lt;&lt; out &lt;&lt; endl;\n    cout &lt;&lt; endl;\n\n    free(sum);\n}\n\nint main(){\n    //  (threads, iterations)\n    test_dp_mac_AVX(8,10000000);\n\n    system(\"pause\");\n}\n</code></pre>\n\n<p><strong>Output (1 thread, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>\n\n<pre><code>Seconds = 57.4679\nFP Ops  = 1920000000000\nFLOPs   = 3.34099e+010\nsum = 4.45305\n</code></pre>\n\n<p>Theoretical AVX peak is 8 flops * 4.4 GHz = <strong>35.2 GFlops</strong>. Actual is <strong>33.4 GFlops</strong>.</p>\n\n<p><strong>Output (8 threads, 10000000 iterations) - Compiled with Visual Studio 2010 SP1 - x64 Release:</strong></p>\n\n<pre><code>Seconds = 111.119\nFP Ops  = 15360000000000\nFLOPs   = 1.3823e+011\nsum = 35.6244\n</code></pre>\n\n<p>Theoretical AVX peak is 8 flops * 4 cores * 4.4 GHz = <strong>140.8 GFlops.</strong> Actual is <strong>138.2 GFlops</strong>.</p>\n\n<hr>\n\n<p><strong>Now for some explanations:</strong></p>\n\n<p>The performance critical part is obviously the 48 instructions inside the inner loop. You'll notice that it's broken into 4 blocks of 12 instructions each. Each of these 12 instructions blocks are completely independent from each other - and take on average 6 cycles to execute.</p>\n\n<p>So there's 12 instructions and 6 cycles between issue-to-use. The latency of multiplication is 5 cycles, so it's just enough to avoid latency stalls.</p>\n\n<p>The normalization step is needed to keep the data from over/underflowing. This is needed since the do-nothing code will slowly increase/decrease the magnitude of the data.</p>\n\n<p>So it's actually possible to do better than this if you just use all zeros and get rid of the normalization step. However, since I wrote the benchmark to measure power consumption and temperature, <strong>I had to make sure the flops were on \"real\" data, rather than zeros</strong> - as the execution units may very well have special case-handling for zeros that use less power and produce less heat.</p>\n\n<hr>\n\n<h2>More Results:</h2>\n\n<ul>\n<li><strong>Intel Core i7 920 @ 3.5 GHz</strong></li>\n<li>Windows 7 Ultimate x64</li>\n<li>Visual Studio 2010 SP1 - x64 Release</li>\n</ul>\n\n<p><strong>Threads: 1</strong></p>\n\n<pre><code>Seconds = 72.1116\nFP Ops  = 960000000000\nFLOPs   = 1.33127e+010\nsum = 2.22652\n</code></pre>\n\n<p>Theoretical SSE Peak: 4 flops * 3.5 GHz = <strong>14.0 GFlops</strong>. Actual is <strong>13.3 GFlops</strong>.</p>\n\n<p><strong>Threads: 8</strong></p>\n\n<pre><code>Seconds = 149.576\nFP Ops  = 7680000000000\nFLOPs   = 5.13452e+010\nsum = 17.8122\n</code></pre>\n\n<p>Theoretical SSE Peak: 4 flops * 4 cores * 3.5 GHz = <strong>56.0 GFlops</strong>. Actual is <strong>51.3 GFlops</strong>.</p>\n\n<p><em><strong>My processor temps hit 76C on the multi-threaded run! If you runs these, be sure the results aren't affected by CPU throttling.</strong></em></p>\n\n<hr>\n\n<ul>\n<li><strong>2 x Intel Xeon X5482 Harpertown @ 3.2 GHz</strong></li>\n<li>Ubuntu Linux 10 x64</li>\n<li>GCC 4.5.2 x64 - (-O2 -msse3 -fopenmp)</li>\n</ul>\n\n<p><strong>Threads: 1</strong></p>\n\n<pre><code>Seconds = 78.3357\nFP Ops  = 960000000000\nFLOPs   = 1.22549e+10\nsum = 2.22652\n</code></pre>\n\n<p>Theoretical SSE Peak: 4 flops * 3.2 GHz = <strong>12.8 GFlops</strong>. Actual is <strong>12.3 GFlops</strong>.</p>\n\n<p><strong>Threads: 8</strong></p>\n\n<pre><code>Seconds = 78.4733\nFP Ops  = 7680000000000\nFLOPs   = 9.78676e+10\nsum = 17.8122\n</code></pre>\n\n<p>Theoretical SSE Peak: 4 flops * 8 cores * 3.2 GHz = <strong>102.4 GFlops</strong>. Actual is <strong>97.9 GFlops</strong>.</p>\n    "},{"t":"How should a model be structured in MVC?","l":"http://stackoverflow.com/questions/5863870/how-should-a-model-be-structured-in-mvc","q":"\n\n<p>I am just getting a grasp on the MVC framework and I often wonder how much code should go in the model. I tend to have a data access class that has methods like this:</p>\n\n<pre><code>public function CheckUsername($connection, $username)\n{\n    try\n    {\n        $data = array();\n        $data['Username'] = $username;\n\n        //// SQL\n        $sql = \"SELECT Username FROM\" . $this-&gt;usersTableName . \" WHERE Username = :Username\";\n\n        //// Execute statement\n        return $this-&gt;ExecuteObject($connection, $sql, $data);\n    }\n    catch(Exception $e)\n    {\n        throw $e;\n    }\n}\n</code></pre>\n\n<p>My models tend to be an entity class that is mapped to the database table.</p>\n\n<p>Should the model object have all the database mapped properties as well as the code above or is it OK to separate that code out that actually does the database work?</p>\n\n<p>Will I end up having four layers?</p>\n    ","a":"\n<blockquote>\n  <p><sub><strong>Disclaimer:</strong> the following is a description of how I understand MVC-like patterns in the context of PHP-based web applications. All the external links that are used in the content are there to explain terms and concepts, and <strong>not</strong> to imply my own credibility on the subject.</sub></p>\n</blockquote>\n\n<p>The first thing that I must clear up is: <strong>the model is a layer</strong>.</p>\n\n<p>Second: there is a difference between <em>classical MVC</em> and what we use in web development. <a href=\"http://stackoverflow.com/a/7622038/727208\">Here's</a> a bit of an older answer I wrote, which briefly describes how they are different.</p>\n\n<h2>What a model is NOT:</h2>\n\n<p>The model is not a class or any single object. It is a very common mistake to make <em>(I did too, though the original answer was written when I began to learn otherwise)</em>, because most frameworks perpetuate this misconception.</p>\n\n<p>Neither is it an Object-Relational Mapping technique (ORM) nor an abstraction of database tables. Anyone who tells you otherwise is most likely trying to <em>'sell'</em> another brand-new ORM or a whole framework.</p>\n\n<h2>What a model is:</h2>\n\n<p>In proper MVC adaptation, the M contains all the domain business logic and the <em>Model Layer</em> is <strong>mostly</strong> made from three types of structures:</p>\n\n<ul>\n<li><p><a href=\"http://c2.com/cgi/wiki?DomainObject\"><em>Domain Objects</em></a></p>\n\n<blockquote>\n  <p>A domain object is a logical container of purely domain information; it usually represents a logical entity in the problem domain space. Commonly referred to as <em>business logic</em>.</p>\n</blockquote>\n\n<p>This would be where you define how to validate data before sending an invoice, or to compute the total cost of an order. At the same time, <em>Domain Objects</em> are completely unaware of storage - neither from <em>where</em> (SQL database, REST API, text file, etc.) nor even <em>if</em> they get saved or retrieved.</p></li>\n<li><p><a href=\"http://martinfowler.com/eaaCatalog/dataMapper.html\"><em>Data Mappers</em></a></p>\n\n<p>These objects are only responsible for the storage. If you store information in a database, this would be where the SQL lives. Or maybe you use an XML file to store data, and your <em>Data Mappers</em> are parsing from and to XML files.</p></li>\n<li><p><a href=\"http://martinfowler.com/eaaCatalog/serviceLayer.html\"><em>Services</em></a></p>\n\n<p>You can think of them as \"higher level Domain Objects\", but instead of business logic, <em>Services</em> are responsible for interaction between <em>Domain Objects</em> and <em>Mappers</em>. These structures end up creating a \"public\" interface for interacting with the domain business logic. You can avoid them, but at the penalty of leaking some domain logic into <em>Controllers</em>.</p>\n\n<p>There is a related answer to this subject in the <a href=\"http://stackoverflow.com/a/9685039/727208\">ACL implementation</a> question - it might be useful.</p></li>\n</ul>\n\n<h2>How to interact with a model?</h2>\n\n<blockquote>\n  <p><sub><em><strong>Prerequisites:</strong> watch lectures <a href=\"http://www.youtube.com/watch?v=-FRm3VPhseI\">\"Global State and Singletons\"</a> and <a href=\"http://www.youtube.com/watch?v=RlfLCWKxHJ0\">\"Don't Look For Things!\"</a> from the Clean Code Talks.</em></sub></p>\n</blockquote>\n\n<p>The communication between the model layer and other parts of the MVC triad should happen only through <em>Services</em>. The clear separation has a few additional benefits:</p>\n\n<ul>\n<li>it helps to enforce the <a href=\"https://en.wikipedia.org/wiki/Single_responsibility_principle\">single responsibility principle</a> (SRP)</li>\n<li>provides additional 'wiggle room' in case the logic changes</li>\n<li>keeps the controller as simple as possible</li>\n<li>gives a clear blueprint, if you ever need an external API</li>\n</ul>\n\n<p>The easiest way to make sure that both <em>View</em> and <em>Controller</em> instances (for that incoming request) have access to the same version of the <em>Model Layer</em> would be to provide them both with the same <code>ServiceFactory</code> instance. I would do it like this:</p>\n\n<pre><code>/*\n * Closure for providing lazy initialization of DB connection\n */\n$dbhProvider = function() {\n    $instance = new \\PDO('mysql:host=localhost;dbname=******;charset=UTF-8', \n    '**username**', '**password**');\n    $instance-&gt;setAttribute(PDO::ATTR_ERRMODE, PDO::ERRMODE_EXCEPTION);\n    $instance-&gt;setAttribute(PDO::ATTR_EMULATE_PREPARES, false);\n    return $instance;\n};\n\n/* \n * Creates basic structures, which will be used for \n * interaction with model layer\n */\n$serviceFactory = new ServiceFactory(\n    new DataMapperFactory($dbhProvider),\n    new DomainObjectFactory\n    );\n$serviceFactory-&gt;setDefaultNamespace('Application\\\\Service');\n\n/*\n * Initializes the routing mechanism\n */\n$configuration = json_decode(\n    file_get_contents(__DIR__ . '/config/routes.json'), true);\n$router = new Router(new RouteBuilder);\n$router-&gt;import($configuration);\n\n/*\n * Gets the part of URI after the \"?\" symbol\n */\n$uri = isset($_SERVER['REQUEST_URI']) \n           ? $_SERVER['REQUEST_URI'] \n           : '/';\n\n/*\n * Initializes the request abstraction and \n * apply routing pattens to that instance\n */\n$request = new Request($uri);\n$router-&gt;route($request);\n\n/* \n * Initialization of View \n */\n$class = '\\\\Application\\\\View\\\\' . $request-&gt;getResourceName();\n$view = new $class($serviceFactory);\n$view-&gt;setDefaultTemplateLocation(__DIR__ . '/templates');\n\n/*\n * Initialization of Controller\n */\n$class = '\\\\Application\\\\Controller\\\\' . $request-&gt;getResourceName();\n$controller = new $class($serviceFactory, $view);\n\n/*\n * Execute the necessary command on the controller\n */\n$command = $request-&gt;getCommand();\n$controller-&gt;{$command}($request);\n\n/*\n * Produces the response\n */\necho $view-&gt;render();\n</code></pre>\n\n<p>This would let you initialize a not-too-complicated MVC application (notice that there is no caching nor authentication/authorization included). As you can see, the <code>$serviceFactory</code> object is shared between both the <em>View</em> object and <em>Controller</em> object, and keeps track of initialized services.</p>\n\n<p>Also, you might notice that the anonymous <code>$dbhProvider</code> function is passed only to the <code>DataMapperFactory</code> instance, which would be creating all the <em>Data Mappers</em> within any given service.</p>\n\n<p>With this given code, the <em>Controller</em> instance would change the state of the <em>Model Layer</em>, and the <em>View</em> instance (as per Model2 MVC) would request data from the <em>Model Layer</em>.</p>\n\n<h2>How to build the model?</h2>\n\n<p>Since there is not a single \"Model\" class (as explained above), you really do not \"build the model\". Instead you start from making <em>Services</em>, which are able to perform certain methods. And then implement <em>Domain Objects</em> and <em>Mappers</em>.</p>\n\n<h3>An example of a service method:</h3>\n\n<p>This might be a simplified authentication method in a recognition service (something that ascertains a user's identity).</p>\n\n<p>But you should <strong>not</strong> think of this example as directly related to the one above, because as part of the authentication process, it should happen right after the <code>$serviceFactory</code> was created (the check-if-logged-in part), while the <code>authenticate()</code> method would be called from within the controller. And the authentication would closely interact with (but be separate from) the authorization service.</p>\n\n<pre><code>namespace Service;\n\nclass Recognitions\n{\n    // -- snip --\n\n    /* This is an EXAMPLE, not a production-level code.\n       Do not copy-paste! */\n    public function authenticate( $username, $password )\n    {\n        $account = $this-&gt;domainObjectFactory-&gt;build('User');\n        $mapper  = $this-&gt;dataMapperFactory-&gt;build('User');\n\n        $account-&gt;setUsername( $username );\n        $mapper-&gt;fetch( $account );\n\n        if ( $account-&gt;matchPassword($password) )\n        {\n            $state = $this-&gt;dataMapperFactory-&gt;build('Cookie');\n        }\n        else\n        {\n            $state = $this-&gt;dataMapperFactory-&gt;build('Session');\n        }\n\n        $state-&gt;store($account);\n\n    }\n    // -- snip --\n}\n</code></pre>\n\n<p>As you can see, at this level of abstraction, there is no indication of where the data was fetched from. It might be a database, but it also might be just a mock object for testing purposes.</p>\n\n<p>P.S. This would also be the part where caching is introduced. For example, as an additional <em>Mapper</em>.</p>\n\n<h2>Some additional comments:</h2>\n\n<ol>\n<li><p><strong>Database tables and model</strong></p>\n\n<p>While sometimes there is a direct 1:1:1 relationship between a database table, <em>Domain Object</em>, and <em>Mapper</em>, in larger projects it might be less common than you expect:</p>\n\n<ul>\n<li><p>Information used by a single <em>Domain Object</em> might be mapped from different tables, while the object itself has no persistence in the database.</p>\n\n<p><em>Example:</em> if you are generating a monthly report. This would collect information from different of tables, but there is no magical <code>MonthlyReport</code> table in the database.</p></li>\n<li><p>A single <em>Mapper</em> can affect multiple tables.</p>\n\n<p><em>Example:</em> when you are storing data from the <code>User</code> object, this <em>Domain Object</em> could contain collection of other domain objects - <code>Group</code> instances. If you alter them and store the <code>User</code>, the <em>Data Mapper</em> will have to update and/or insert entries in multiple tables.</p></li>\n<li><p>Data from a single <em>Domain Object</em> is stored in more than one table.</p>\n\n<p><em>Example:</em> in large systems (think: a medium-sized social network), it might be pragmatic to store user authentication data and often-accessed data separately from larger chunks of content, which is rarely required. In that case you might still have a single <code>User</code> class, but the information it contains would depend of whether full details were fetched.</p></li>\n</ul></li>\n<li><p><strong>A view is not a template</strong></p>\n\n<p><em>View</em> instances in MVC (if you are not using the MVP variation of the pattern) are responsible for the presentational logic. This means that each <em>View</em> will usually juggle at least a few templates. It acquires data from the <em>Model Layer</em> and then, based on the received information, chooses a template and sets values.</p>\n\n<p>One of the benefits you gain from this is re-usability. If you create a <code>ListView</code> class, then, with well-written code, you can have the same class handing the presentation of user-list and comments below an article. Because they both have the same presentation logic. You just switch templates.</p>\n\n<p>You can use either <a href=\"http://codeangel.org/articles/simple-php-template-engine.html\">native PHP templates</a> or use some third-party templating engine. There also might be some third-party libraries, which are able to fully replace <em>View</em> instances.</p></li>\n<li><p><strong>What about the old version of the answer?</strong></p>\n\n<p>The only major change is that, what is called <em>Model</em> in the old version, is actually a <em>Service</em>. The rest of the \"library analogy\" keeps up pretty well.</p>\n\n<p>The only flaw that I see is that this would be a really strange library, because it would return you information from the book, but not let you touch the book itself, because otherwise the abstraction would start to \"leak\". I might have to think of a more fitting analogy.</p></li>\n<li><p><strong>What is the relationship between <em>View</em> and <em>Controller</em> instances?</strong></p>\n\n<p>The MVC structure is composed of two layers: presentation and model. The main structures in the <em>Presentation layer</em> are views and controller. </p>\n\n<p>When you are dealing with websites that use MVC design pattern, the best way is to have 1:1 relation between views and controllers. Each view represents a whole page in your website and it has a dedicated controller to handle all the incoming requests for that particular view.</p>\n\n<p>For example, to represent an opened article, you would have <code>\\Application\\Controller\\Document</code> and <code>\\Application\\View\\Document</code>. This would contain all the main functionality for presentation layer, when it comes to dealing with articles <em>(of course you might have some <a href=\"https://developer.mozilla.org/en/xmlhttprequest\">XHR</a> components that are not directly related to articles)</em>.</p></li>\n</ol>\n    "},{"t":"Component based game engine design [closed]","l":"http://stackoverflow.com/questions/1901251/component-based-game-engine-design","q":"\n\n<p>I have been looking at game engine design (specifically focused on 2d game engines, but also applicable to 3d games), and am interested in some information on how to go about it.  I have heard that many engines are moving to a component based design nowadays rather than the traditional deep-object hierarchy.</p>\n\n<p>Do you know of any good links with information on how these sorts of designs are often implemented?  I have seen <a href=\"http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy/\">evolve your hierarchy</a>, but I can't really find many more with detailed information (most of them just seem to say \"use components rather than a hierarchy\" but I have found that it takes a bit of effort to switch my thinking between the two models).</p>\n\n<p>Any good links or information on this would be appreciated, and even books, although links and detailed answers here would be preferred.  </p>\n    ","a":"\n<p><strong>Update 2013-01-07</strong>: <em>If you want to see a good mix of component-based game engine with the (in my opinion) superior approach of reactive programming take a look at the <a href=\"http://v-play.net\">V-Play engine</a>. It very well integrates QTs <a href=\"http://v-play.net/doc/index.html#qml-introduction\">QML property binding</a> functionality.</em></p>\n\n<p>We did some research on CBSE in games at our university and I collected some material over the years:</p>\n\n<p>CBSE in games literature:</p>\n\n<ul>\n<li>Game Engine Architecture</li>\n<li>Game Programming Gems 4: A System for Managin Game Entities Game</li>\n<li>Game Programming Gems 5: Component Based Object Management</li>\n<li>Game Programming Gems 5: A Generic Component Library</li>\n<li>Game Programming Gems 6: Game Object Component System</li>\n<li>Object-Oriented Game Development</li>\n<li>Architektur des Kerns einer Game-Engine und Implementierung mit Java (german)</li>\n</ul>\n\n<p>A very good and clean example of a component-based game-engine in C# is the <a href=\"http://www.codeplex.com/elephant\">Elephant game framework</a>.</p>\n\n<p>If you really want to know what components are read: Component-based Software Engineering!\nThey define a component as:</p>\n\n<blockquote>\n  <p>A <em>software component</em> is a software element that conforms to a component model and can be independently deployed and composed without modification according to a composition standard.</p>\n  \n  <p>A <em>component model</em> <strong>defines specific interaction</strong> and composition standards. A <em>component model implementation</em> is the dedicated set of executable software elements required to support the execution of components that conform to the model.</p>\n  \n  <p>A <em>software component infrastructure</em> is a set of interacting software components designed to ensure that a software system or subsystem constructed using those components and interfaces will satisfy clearly defined performance specifications.</p>\n</blockquote>\n\n<p><strong>My opinions after 2 years of experience</strong> with CBSE in games thought are that object-oriented programming is simply a dead-end. Remember my warning as you watch your components become smaller and smaller, and more like functions packed in components with a lot of useless overhead. Use <a href=\"http://stackoverflow.com/questions/1028250/what-is-functional-reactive-programming\">functional-reactive programming</a> instead. Also take a look at my fresh blog post (which lead me to this question while writing it :)) about <strong><a href=\"http://lambdor.net/?p=171\">Why I switched from component-based game engine architecture to FRP</a></strong>.</p>\n\n<p>CBSE in games papers:</p>\n\n<ul>\n<li><a href=\"http://books.google.at/books?id=G1jQpyZI2JgC&amp;lpg=PP1&amp;pg=PA66#v=onepage&amp;q=&amp;f=false\">Component Based Game Development – A Solution to Escalating Costs and Expanding Deadlines?</a> </li>\n<li><s><a href=\"http://www.acims.arizona.edu/PUBLICATIONS/PDF/JeffPlummerMSthesis_wo_Appendix.pdf\">A Flexible And Expandable Architecture For Computer Games</a></s> (404)</li>\n<li><a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.89.2884&amp;rep=rep1&amp;type=pdf\">A Software Architecture for Games</a></li>\n<li><a href=\"http://mi-lab.org/wp-content/blogs.dir/1/files/publications/Haller%20et%20al%20-%20ACM%20SIGGRAPH%20Campfire%202002%20-%20A%20generic%20framework%20for%20game%20development.pdf\">A Generic Framework For Game Development</a></li>\n<li><a href=\"http://portal.acm.org/ft_gateway.cfm?id=1658872&amp;type=pdf&amp;coll=portal&amp;dl=ACM&amp;CFID=575755565&amp;CFTOKEN=575755565\">Smart Composition Of Game Objects Using Dependency Injection</a></li>\n</ul>\n\n<p>CBSE in games web-links (sorted by relevancy):</p>\n\n<ul>\n<li><a href=\"http://www.oddrosemedia.com/wiki/index.php\">Component based objects Wiki</a></li>\n<li><a href=\"http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy\">Evolve Your Hierachy</a></li>\n<li><a href=\"http://www.gamearchitect.net/Articles/GameObjects1.html\">Game Object Structure: Inheritance vs. Aggregation</a></li>\n<li><a href=\"http://scottbilas.com/files/2002/gdc_san_jose/game_objects_paper.pdf\">A Data-Driven Game Object System (PDF)</a></li>\n<li><a href=\"http://scottbilas.com/files/2002/gdc_san_jose/game_objects_slides.ppt\">A Data-Driven Game Object System (PPT)</a></li>\n<li><a href=\"http://blog.scrambled-egg.net\">Component-based prototyping tool for flash</a></li>\n<li><s><a href=\"http://cmpmedia.vo.llnwd.net/o1/vault/gdccanada09/slides/marcinchadyGDCCanada.ppt\">Theory and Practice of Game Object Component Architecture</a></s> (404)</li>\n<li><a href=\"http://t-machine.org/index.php/2007/09/03/entity-systems-are-the-future-of-mmog-development-part-1\">Entity Systems are the Future of MMOs</a></li>\n<li><a href=\"http://www.ogre3d.org/forums/viewtopic.php?f=1&amp;t=36015\">ogre3d.org forum: Component Based Objects</a></li>\n<li><a href=\"http://www.gamedev.net/community/forums/topic.asp?topic_id=463508\">gamedev.net: Outboard component-based entity system architecture</a></li>\n<li><a href=\"http://www.gamedev.net/community/forums/topic.asp?topic_id=489703\">gamedev.net: Entity System question</a></li>\n<li><a href=\"http://www.brainfold.org/blog/tag/entity-system\">Brainfold entity-system blog</a></li>\n</ul>\n    "},{"t":"INotifyPropertyChanged vs. DependencyProperty in ViewModel","l":"http://stackoverflow.com/questions/291518/inotifypropertychanged-vs-dependencyproperty-in-viewmodel","q":"\n\n<p>When implementing the ViewModel in a Model-View-ViewModel architecture WPF application there seem to be two major choices how to make it databindable. I have seen implementations that use DependencyProperty for properties the View is going to bind against and I have seen the ViewModel implementing INotifyPropertyChanged instead. </p>\n\n<p>My question is when should I prefer one over the other? Are there any performance differences? Is it really a good idea to give the ViewModel dependencies to WPF? What else do I need to consider when make the design decision?</p>\n    ","a":"\n<p>Kent wrote an interesting blog about this topic: <a href=\"http://kentb.blogspot.com/2009/03/view-models-pocos-versus.html\">View Models: POCOs versus DependencyObjects</a>.</p>\n\n<p><strong>Short summary:</strong></p>\n\n<ol>\n<li>DependencyObjects are not marked as\nserializable</li>\n<li>The DependencyObject class overrides and seals the Equals() and\nGetHashCode() methods</li>\n<li>A DependencyObject has thread affinity – it can only be accessed\non the thread on which it was\ncreated</li>\n</ol>\n\n<p>I prefer the POCO approach. A base class for PresentationModel (aka ViewModel) which implements INotifyPropertyChanged interface can be found here: <a href=\"http://compositeextensions.codeplex.com\">http://compositeextensions.codeplex.com</a></p>\n    "},{"t":"When to Redis? When to MongoDB?","l":"http://stackoverflow.com/questions/5400163/when-to-redis-when-to-mongodb","q":"\n\n<p>What I want is not a comparison between Redis and MongoDB. I know they are different; the performance and the API is totally different.</p>\n\n<p>Redis is very fast, but the API is very 'atomic'. MongoDB will eat more resources, but the API is very very easy to use, and I am very happy with it.</p>\n\n<p>They're both awesome, and I want to use Redis in deployment as much as I can, but it is hard to code. I want to use MongoDB in development as much as I can, but it needs an expensive machine.</p>\n\n<p>So what do you think about the use of both of them? When to pick Redis? When to pick MongoDB?</p>\n    ","a":"\n<p>I would say, it depends on kind of dev team you are and your application needs.</p>\n\n<p>For example if there are more <strong>querying</strong> required, it mostly means more work in Redis, where you can use different data structures to suit your queries. Same is easier in MongoDB. On other hand this is often extra work in Redis would most likely to pay off with <strong>sheer speed</strong>. </p>\n\n<p>MongoDB offers simplicity, much smaller learning for guys with SQL experience. Whereas Redis offers non-traditional approach hence more learning but huge flexibility.</p>\n\n<p>Eg. A <strong>cache</strong> layer can probably be better implemented in Redis, and as for a more schema-able data MongoDB might be better.  <em>[Note: mongodb is schemaless]</em></p>\n\n<p>If you ask me my personal choice is Redis for most requirements.</p>\n\n<p>Lastly, I hope by now you have seen <a href=\"http://antirez.com/post/MongoDB-and-Redis.html\">http://antirez.com/post/MongoDB-and-Redis.html</a> </p>\n    "},{"t":"Undefined symbols for architecture armv7","l":"http://stackoverflow.com/questions/6429494/undefined-symbols-for-architecture-armv7","q":"\n\n<p>This problem has been driving me crazy, and i can't work out how to fix it...</p>\n\n<pre><code>    Undefined symbols for architecture armv7:\n  \"_deflateEnd\", referenced from:\n      -[ASIDataCompressor closeStream] in ASIDataCompressor.o\n  \"_OBJC_CLASS_$_ASIDataDecompressor\", referenced from:\n      objc-class-ref in ASIHTTPRequest.o\n  \"_deflate\", referenced from:\n      -[ASIDataCompressor compressBytes:length:error:shouldFinish:] in ASIDataCompressor.o\n  \"_deflateInit2_\", referenced from:\n      -[ASIDataCompressor setupStream] in ASIDataCompressor.o\nld: symbol(s) not found for architecture armv7\ncollect2: ld returned 1 exit status\nCommand /Developer/Platforms/iPhoneOS.platform/Developer/usr/bin/gcc-4.2 failed with exit code 1\n</code></pre>\n\n<p>I think it has to do with:</p>\n\n<pre><code>ld: symbol(s) not found for architecture armv7\n</code></pre>\n\n<p>but I have added: libz.1.2.3.dylib\nand it's not helping, anyone got any ideas?</p>\n    ","a":"\n<h3>Common Causes</h3>\n\n<p>The common causes for \"Undefined symbols for architecture armv7\" are:</p>\n\n<ol>\n<li><p>You <strong>import a header and do not link against the correct library</strong>. This is common, especially for headers for libraries like QuartzCore since it is not included in projects by default. To resolve:</p>\n\n<ul>\n<li><p>Add the correct libraries in the <strong><em><code>Link Binary With Libraries</code></em></strong> section of the <strong><em><code>Build Phases</code></em>.</strong></p></li>\n<li><p>If you want to add a library outside of the default search path you can include the path in the <strong><em><code>Library Search Paths</code></em></strong> value in the Build Settings and add <br><code>-l{library_name_without_lib_and_suffix}</code> (eg. for libz.a use <code>-lz</code>) to the <strong><em><code>Other Linker Flags</code></em></strong> section of <strong><em><code>Build Settings</code></em></strong>.<br><br></p></li>\n</ul></li>\n<li><p>You <strong>copy files into your project but forgot to check the target to add the files to</strong>. To resolve:</p>\n\n<ul>\n<li>Open the <strong><em><code>Build Phases</code></em></strong> for the correct target, expand <strong><em><code>Compile Sources</code></em></strong> and add the missing <code>.m</code> files. If this is your issue please upvote <a href=\"http://stackoverflow.com/a/10170293/418715\">Cortex's answer below</a> as well.<br><br></li>\n</ul></li>\n<li><p>You <strong>include a static library that is built for another architecture</strong> like i386, the simulator on your host machine. To resolve:</p>\n\n<ul>\n<li><p>If you have multiple library files from your libraries vendor to include in the project you need to include the one for the simulator (i386) and the one for the device (armv7 for example).</p></li>\n<li><p>Optionally, you could create a <a href=\"http://stackoverflow.com/questions/3520977/build-fat-static-library-device-simulator-using-xcode-and-sdk-4\">fat static library</a> that contains both architectures.</p></li>\n</ul></li>\n</ol>\n\n<p><br></p>\n\n<hr>\n\n<h3>Original Answer:</h3>\n\n<p>You have not linked against the correct libz file. If you right click the file and reveal in finder its path should be somewhere in an iOS sdk folder. Here is mine for example</p>\n\n<blockquote>\n  <p>/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS4.3.sdk/usr/lib</p>\n</blockquote>\n\n<p>I recommend removing the reference and then re-adding it back in the Link Binary With Libraries section Build Phases of your target.</p>\n    "},{"t":"Software Design vs. Software Architecture [closed]","l":"http://stackoverflow.com/questions/704855/software-design-vs-software-architecture","q":"\n\n<p>Could someone explain the difference between Software Design and Software Architecture?</p>\n\n<p>More specifically; if you tell someone to present you the 'design' - what would you expect them to present? Same goes for 'architecture'. </p>\n\n<p>My current understanding is:  </p>\n\n<ul>\n<li>Design: UML diagram/flow chart/simple wireframes (for UI) for a specific module/part of the system</li>\n<li>Architecture: component diagram (showing how the different modules of the system communicates with each other and other systems), what language is to be used, patterns...? </li>\n</ul>\n\n<p>Correct me if I'm wrong. I have referred Wikipedia has articles on <a href=\"http://en.wikipedia.org/wiki/Software_design\">http://en.wikipedia.org/wiki/Software_design</a> and <a href=\"http://en.wikipedia.org/wiki/Software_architecture\">http://en.wikipedia.org/wiki/Software_architecture</a>, but I'm not sure if I have understood them correctly.</p>\n    ","a":"\n<p>You're right yes. The architecture of a system is its 'skeleton'. It's the highest level of abstraction of a system. What kind of data storage is present, how do modules interact with each other, what recovery systems are in place. Just like design patterns, there are architectural patterns: MVC, 3-tier layered design, etc. </p>\n\n<p>Software design is about designing the individual modules / components. What are the responsibilities, functions, of module x? Of class Y? What can it do, and what not? What design patterns can be used?</p>\n\n<p>So in short, Software architecture is more about the design of the entire system, while software design emphasizes on module / component / class level.</p>\n    "},{"t":"How is Node.js inherently faster when it still relies on Threads internally?","l":"http://stackoverflow.com/questions/3629784/how-is-node-js-inherently-faster-when-it-still-relies-on-threads-internally","q":"\n\n<p>I just watched the following video: <a href=\"http://www.yuiblog.com/blog/2010/05/20/video-dahl/\">Introduction to Node.js</a> and still don't understand how you get the speed benefits.</p>\n\n<p>Mainly, at one point Ryan Dahl (Node.js' creator) says that Node.js is event-loop based instead of thread-based.  Threads are expensive and should only be left to the experts of concurrent programming to be utilized.  </p>\n\n<p>Later, he then shows the architecture stack of Node.js which has an underlying C implementation which has its own Thread pool internally.  So obviously Node.js developers would never kick off their own threads or use the thread pool directly...they use async call-backs.  That much I understand.</p>\n\n<p>What I don't understand is the point that Node.js still is using threads...it's just hiding the implementation so how is this faster if 50 people request 50 files (not currently in memory) well then aren't 50 threads required?</p>\n\n<p>The only difference being that since it's managed internally the Node.js developer doesn't have to code the threaded details but underneath it's still using the threads to process the IO (blocking) file requests.</p>\n\n<p>So aren't you really just taking one problem (threading) and hiding it while that problem still exists: mainly multiple threads, context switching, dead-locks...etc?  </p>\n\n<p>There must be some detail I still do not understand here.</p>\n    ","a":"\n<p>There are actually a few different things being conflated here.  But it starts with the meme that threads are just really hard.  So if they're hard, you are more likely, when using threads to 1) break due to bugs and 2) not use them as efficiently as possible.  (2) is the one you're asking about.</p>\n\n<p>Think about one of the examples he gives, where a request comes in and you run some query, and then do something with the results of that.  If you write it in a standard procedural way, the code might look like this:</p>\n\n<pre><code>result = query( \"select smurfs from some_mushroom\" );\n// twiddle fingers\ngo_do_something_with_result( result );\n</code></pre>\n\n<p>If the request coming in caused you to create a new thread that ran the above code, you'll have a thread sitting there, doing nothing at all while while <code>query()</code> is running.  (Apache, according to Ryan, is using a single thread to satisfy the original request whereas nginx is outperforming it in the cases he's talking about because it's not.)</p>\n\n<p>Now, if you were really clever, you would express the code above in a way where the environment could go off and do something else while you're running the query:</p>\n\n<pre><code>query( statement: \"select smurfs from some_mushroom\", callback: go_do_something_with_result() );\n</code></pre>\n\n<p>This is basically what node.js is doing.  You're basically decorating -- in a way that is convenient because of the language and environment, hence the points about closures -- your code in such a way that the environment can be clever about what runs, and when.  In that way, node.js isn't <em>new</em> in the sense that it invented asynchronous I/O (not that anyone claimed anything like this), but it's new in that the way it's expressed is a little different.  </p>\n\n<p>Note: when I say that the environment can be clever about what runs and when, specifically what I mean is that the thread it used to start some I/O can now be used to handle some other request, or some computation that can be done in parallel, or start some other parallel I/O.  (I'm not certain node is sophisticated enough to start more work for the same request, but you get the idea.)</p>\n    "},{"t":"What's the difference between REST & RESTful","l":"http://stackoverflow.com/questions/1568834/whats-the-difference-between-rest-restful","q":"\n\n<p>What's the difference between a REST system and a system that is RESTful?</p>\n\n<p>From a few things I've <a href=\"http://www.infoq.com/articles/subbu-allamaraju-rest\">read</a> most so called REST services are actually RESTful services. So what is the difference between the two.  </p>\n    ","a":"\n<p><a href=\"http://en.wikipedia.org/wiki/Representational%5FState%5FTransfer\">Representational state transfer (REST)</a> is a style of software architecture. As described in a dissertation by Roy Fielding, REST is an \"architectural style\" that basically exploits the existing technology and protocols of the Web.</p>\n\n<p>RESTful is typically used to refer to web services implementing such an architecture. </p>\n    "},{"t":"Best way to allow plugins for a PHP application","l":"http://stackoverflow.com/questions/42/best-way-to-allow-plugins-for-a-php-application","q":"\n\n<p>I am starting a new web application in PHP and this time around I want to create something that people can extend by using a plugin interface. How does one go about writing 'hooks' into their code so that plugins can attach to specific events?</p>\n    ","a":"\n<p>You could use an Observer pattern.  A simple functional way to accomplish this:</p>\n\n<pre><code>&lt;?php<br><br>/** Plugin system **/<br><br>$listeners = array();<br><br>/* Create an entry point for plugins */<br>function hook(){<br>  global $listeners;<br><br>  $num_args = func_num_args();<br>  $args = func_get_args();<br><br>  if($num_args &lt; 2)<br>    trigger_error(\"Insufficient arguments\", E_USER_ERROR);<br><br>  // Hook name should always be first argument<br>  $hook_name = array_shift($args);<br><br>  if(!isset($listeners[$hook_name]))<br>    return; // No plugins have registered this hook<br><br>  foreach($listeners[$hook_name] as $func){<br>    $args = $func($args); <br>  }<br><br>  return $args;<br>}<br><br>/* Attach a function to a hook */<br>function add_listener($hook, $function_name){<br>  global $listeners;<br><br>  $listeners[$hook][] = $function_name;<br>}<br><br><br>/////////////////////////<br><br>/** Sample Plugin **/<br>add_listener('a_b', 'my_plugin_func1');<br>add_listener('str', 'my_plugin_func2');<br><br>function my_plugin_func1($args){<br>  return array(4, 5);<br>}<br>function my_plugin_func2($args){<br>  return str_replace('sample', 'CRAZY', $args[0]);<br>}<br><br>/////////////////////////<br><br>/** Sample Application **/<br><br>$a = 1;<br>$b = 2;<br><br>list($a, $b) = hook('a_b', $a, $b);<br><br>$str  = \"This is my sample application\\n\";<br>$str .= \"$a + $b = \".($a+$b).\"\\n\";<br>$str .= \"$a * $b = \".($a*$b).\"\\n\";<br><br>$str = hook('str', $str);<br><br>echo $str;<br><br>?&gt;<br></code></pre>\n\n<p><strong>Output:</strong></p>\n\n<pre><code>This is my CRAZY application<br>4 + 5 = 9<br>4 * 5 = 20<br></code></pre>\n\n<p><strong>Notes:</strong></p>\n\n<p>For this example source code, you must declare all your plugins before the actual source code that you want to be extendable.  I've included an example of how to handle single or multiple values being passed to the plugin.  The hardest part of this is writing the actual documentation which lists what arguments get passed to each hook.</p>\n\n<p>This is just one method of accomplishing a plugin system in PHP.  There are better alternatives, I suggest you check out the WordPress Documentation for more information.</p>\n\n<p><em>Sorry, it appears underscore characters are replaced by HTML entities by Markdown?  I can re-post this code when this bug gets fixed.</em></p>\n\n<p><em>Edit: Nevermind, it only appears that way when you are editing</em></p>    "},{"t":"C state-machine design","l":"http://stackoverflow.com/questions/1647631/c-state-machine-design","q":"\n\n<p>I am crafting a small project in mixed C and C++.  I am building one small-ish state-machine at the heart of one of my worker thread.</p>\n\n<p>I was wondering if you gurus on SO would share your state-machine design techniques.</p>\n\n<p><strong>NOTE:</strong> I am primarily after tried &amp; tested implementation techniques.</p>\n\n<p><strong>UPDATED:</strong> Based on all the great input gathered on SO, I've settled on this architecture:</p>\n\n<p><img src=\"http://www.gliffy.com/pubdoc/1876140/L.jpg\" alt=\"alt text\"></p>\n    ","a":"\n<p>State machines that I've designed before (C, not C++) have all come down to a <code>struct</code> array and a loop. The structure basically consists of a state and event (for lookup) and a function that returns the new state, something like:</p>\n\n<pre><code>typedef struct {\n    int st;\n    int ev;\n    int (*fn)(void);\n} tTransition;\n</code></pre>\n\n<p>Then you define your states and events with simple defines (the <code>ANY</code> ones are special markers, see below):</p>\n\n<pre><code>#define ST_ANY              -1\n#define ST_INIT              0\n#define ST_ERROR             1\n#define ST_TERM              2\n: :\n#define EV_ANY              -1\n#define EV_KEYPRESS       5000\n#define EV_MOUSEMOVE      5001\n</code></pre>\n\n<p>Then you define all the functions that are called by the transitions:</p>\n\n<pre><code>static int GotKey (void) { ... };\nstatic int FsmError (void) { ... };\n</code></pre>\n\n<p>All these function are written to take no variables and return the new state for the state machine. Because they all follow the same form and take no parameters, there's use made of \"global\" variables for information passing where necessary. This isn't as bad as it sounds since the FSM is usually locked up inside a single compilation unit and all variables are static to that unit (which is why I used quotes around \"global\" above - they're more shared than truly global). As with all globals, it requires care.</p>\n\n<p>The transitions array then defines all possible transitions and the functions that get called for those transitions (including the catch-all last one):</p>\n\n<pre><code>tTransition trans[] = {\n    { ST_INIT, EV_KEYPRESS, &amp;GotKey},\n    : :\n    { ST_ANY, EV_ANY, &amp;FsmError}\n};\n#define TRANS_COUNT (sizeof(trans)/sizeof(*trans))\n</code></pre>\n\n<p>The workings of the FSM then become a relatively simple loop:</p>\n\n<pre><code>state = ST_INIT;\nwhile (state != ST_TERM) {\n    event = GetNextEvent();\n    for (i = 0; i &lt; TRANS_COUNT; i++) {\n        if ((state == trans[i].st) || (ST_ANY == trans[i].st)) {\n            if ((event == trans[i].ev) || (EV_ANY == trans[i].ev)) {\n                state = (trans[i].fn)();\n                break;\n            }\n        }\n    }\n}\n</code></pre>\n\n<p>As alluded to above, note the use of <code>ST_ANY</code> and <code>EV_ANY</code> as wildcards, allowing an event to call a function no matter the current state, and guaranteeing that, if you reach the end of the transitions array, you get an error stating your FSM hasn't been built correctly.</p>\n\n<p>I've used code similar for this on a great many communications projects, such as an early implementation of the OSI layered model and protocols for embedded systems. It's big advantage was its simplicity and relative ease in changing the transitions array.</p>\n\n<p>I've no doubt there will be higher-level abstractions which may be more suitable nowadays but I suspect they'll all boil down to this same sort of structure. </p>\n\n<hr>\n\n<p>As <code>ldog</code> states in a comment, you can avoid the globals altogether by passing a structure pointer to all functions (and using that in the event loop). This will allow multiple state machines to run side-by-side without interference.</p>\n\n<p>Just create a structure type which holds the machine-specific data (state at a bare minimum) and use that instead of the globals.</p>\n\n<p>The reason I've rarely done that is simply because most of the state machines I've written have been singleton types (one-off, at-process-start, configuration file reading for example), not needing to run more than one instance. But it has value if you need to run more than one.</p>\n    "},{"t":"I just discovered why all ASP.Net websites are slow, and I am trying to work out what to do about it","l":"http://stackoverflow.com/questions/3629709/i-just-discovered-why-all-asp-net-websites-are-slow-and-i-am-trying-to-work-out","q":"\n\n<p>I just discovered that every request in an ASP.Net web application gets a Session lock at the beginning of a request, and then releases it at the end of the request!</p>\n\n<p>In case the implications of this are lost on you, as it was for me at first, this basically means the following:</p>\n\n<ul>\n<li><p>Anytime an ASP.Net webpage is taking a long time to load (maybe due to a slow database call or whatever), and the user decides they want to navigate to a different page because they are tired of waiting, THEY CANT! The ASP.Net session lock forces the new page request to wait until the original request has finished its painfully slow load. Arrrgh.</p></li>\n<li><p>Anytime an UpdatePanel is loading slowly, and the user decides to navigate to a different page before the UpdadePanel has finished updating... THEY CANT! The ASP.Net session lock forces the new page request to wait until the original request has finished its painfully slow load. Double Arrrgh!</p></li>\n</ul>\n\n<p>So what are the options?  So far I have come up with:</p>\n\n<ul>\n<li>Implement a Custom SessionStateDataStore, which ASP.Net supports.  I haven't found too many out there to copy, and it seems kind of high risk and easy to mess up.</li>\n<li>Keep track of all requests in progress, and if a request comes in from the same user, cancel the original request.  Seems kind of extreme, but it would work (I think).</li>\n<li>Don't use Session!  When I need some kind of state for the user, I could just use Cache instead, and key items on the authenticated user's name, or some such thing. Again seems kind of extreme.</li>\n</ul>\n\n<p>I really can't believe that the ASP.Net Microsoft team would have left such a huge performance bottleneck in the framework at version 4.0! Am I missing something obvious? How hard would it be to use a ThreadSafe collection for the Session?</p>\n    ","a":"\n<p>OK, so big Props to Joel Muller for all his input. My ultimate solution was to use the Custom SessionStateModule detailed at the end of this MSDN article: </p>\n\n<p><a href=\"http://msdn.microsoft.com/en-us/library/system.web.sessionstate.sessionstateutility.aspx\">http://msdn.microsoft.com/en-us/library/system.web.sessionstate.sessionstateutility.aspx</a> </p>\n\n<p>This was:</p>\n\n<ul>\n<li>Very quick to implement (actually seemed easier than going the provider route)</li>\n<li>Used a lot of the standard ASP.Net session handling out of the box (via the SessionStateUtility class)</li>\n</ul>\n\n<p>This has made a HUGE difference to the feeling of \"snapiness\" to our application.  I still can't believe the custom implementation of ASP.Net Session locks the session for the whole request.  This adds such a huge amount of sluggishness to websites.  Judging from the amount of online research I had to do (and conversations with several really experienced ASP.Net developers), a lot of people have experienced this issue, but very few people have ever got to the bottom of the cause.  Maybe I will write a letter to Scott Gu...</p>\n\n<p>I hope this helps a few people out there! </p>\n    "},{"t":"Should everything really be a bundle in Symfony 2.x?","l":"http://stackoverflow.com/questions/9999433/should-everything-really-be-a-bundle-in-symfony-2-x","q":"\n\n<p>I'm aware of questions like <a href=\"http://stackoverflow.com/questions/7958346/an-exact-description-of-a-symfony-bundle-in-a-complex-web-application\">this</a>, where people tend to discuss the general Symfony 2 concept of bundle.</p>\n\n<p>The thing is, in a specific application, like, for instance, a twitter-like application, should everything really be inside a generic bundle, like the <a href=\"http://symfony.com/doc/current/book/page_creation.html#page-creation-bundles\">official docs</a> say? </p>\n\n<p>The reason I'm asking this is because when we develop applications, in general, we don't want to highly couple our code to some full-stack glue framework.</p>\n\n<p>If I develop a Symfony 2 based application and, at some point, I decide Symfony 2 is not really the best choice to <em>keep the development going</em>, will that be a problem for me?</p>\n\n<p>So the general question is: why is everything being a bundle a good thing? </p>\n\n<p><strong>EDIT#1</strong></p>\n\n<p>Almost a year now since I asked this question I wrote an <a href=\"http://blog.danielribeiro.org/yes-you-can-have-low-coupling-in-a-symfony-standard-edition-application\">article</a> to share my knowledge on this topic.</p>\n    ","a":"\n<p>I've written a more thorough and updated blog post on this topic: <a href=\"http://elnur.pro/symfony-without-bundles/\">http://elnur.pro/symfony-without-bundles/</a></p>\n\n<hr>\n\n<p>No, not everything has to be in a bundle. You could have a structure like this:</p>\n\n<ul>\n<li><code>src/Vendor/Model</code> — for models,</li>\n<li><code>src/Vendor/Controller</code> — for controllers,</li>\n<li><code>src/Vendor/Service</code> — for services,</li>\n<li><code>src/Vendor/Bundle</code> — for bundles, like <code>src/Vendor/Bundle/AppBundle</code>,</li>\n<li>etc.</li>\n</ul>\n\n<p>This way, you would put in the <code>AppBundle</code> only that stuff that is really Symfony2 specific. If you decide to switch to another framework later, you would get rid of the <code>Bundle</code> namespace and replace it with the chosen framework stuff.</p>\n\n<p><em>Please note that what I'm suggesting here is for <strong>app</strong> specific code. For reusable bundles, I still suggest using <a href=\"http://symfony.com/doc/master/cookbook/bundles/best_practices.html\">the best practices</a>.</em></p>\n\n<h1>Keeping entities out of bundles</h1>\n\n<p>To keep entities in <code>src/Vendor/Model</code> outside of any bundle, I've changed the <code>doctrine</code> section in <code>config.yml</code> from</p>\n\n<pre><code>doctrine:\n    # ...\n    orm:\n        # ...\n        auto_mapping: true\n</code></pre>\n\n<p>to</p>\n\n<pre><code>doctrine:\n    # ...\n    orm:\n        # ...\n        mappings:\n            model:\n                type: annotation\n                dir: %kernel.root_dir%/../src/Vendor/Model\n                prefix: Vendor\\Model\n                alias: Model\n                is_bundle: false\n</code></pre>\n\n<p>Entities's names — to access from Doctrine repositories — begin with <code>Model</code> in this case, for example, <code>Model:User</code>.</p>\n\n<p>You can use subnamespaces to group related entities together, for example, <code>src/Vendor/User/Group.php</code>. In this case, the entity's name is <code>Model:User\\Group</code>.</p>\n\n<h1>Keeping controllers out of bundles</h1>\n\n<p>First, you need to tell <a href=\"https://github.com/schmittjoh/JMSDiExtraBundle\">JMSDiExtraBundle</a> to scan the <code>src</code> folder for services by adding this to <code>config.yml</code>:</p>\n\n<pre><code>jms_di_extra:\n    locations:\n        directories: %kernel.root_dir%/../src\n</code></pre>\n\n<p>Then you <a href=\"http://symfony.com/doc/master/cookbook/controller/service.html\">define controllers as services</a> and put them under the <code>Controller</code> namespace:</p>\n\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\nnamespace Vendor\\Controller;\n\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpFoundation\\RedirectResponse;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Route;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\Configuration\\Template;\nuse JMS\\DiExtraBundle\\Annotation\\Service;\nuse JMS\\DiExtraBundle\\Annotation\\InjectParams;\nuse JMS\\SecurityExtraBundle\\Annotation\\Secure;\nuse Elnur\\AbstractControllerBundle\\AbstractController;\nuse Vendor\\Service\\UserService;\nuse Vendor\\Model\\User;\n\n/**\n * @Service(\"user_controller\", parent=\"elnur.controller.abstract\")\n * @Route(service=\"user_controller\")\n */\nclass UserController extends AbstractController\n{\n    /**\n     * @var UserService\n     */\n    private $userService;\n\n    /**\n     * @InjectParams\n     *\n     * @param UserService $userService\n     */\n    public function __construct(UserService $userService)\n    {\n        $this-&gt;userService = $userService;\n    }\n\n    /**\n     * @Route(\"/user/add\", name=\"user.add\")\n     * @Template\n     * @Secure(\"ROLE_ADMIN\")\n     *\n     * @param Request $request\n     * @return array\n     */\n    public function addAction(Request $request)\n    {\n        $user = new User;\n        $form = $this-&gt;formFactory-&gt;create('user', $user);\n\n        if ($request-&gt;getMethod() == 'POST') {\n            $form-&gt;bind($request);\n\n            if ($form-&gt;isValid()) {\n                $this-&gt;userService-&gt;save($user);\n                $request-&gt;getSession()-&gt;getFlashBag()-&gt;add('success', 'user.add.success');\n\n                return new RedirectResponse($this-&gt;router-&gt;generate('user.list'));\n            }\n        }\n\n        return ['form' =&gt; $form-&gt;createView()];\n    }\n\n    /**\n     * @Route(\"/user/profile\", name=\"user.profile\")\n     * @Template\n     * @Secure(\"ROLE_USER\")\n     *\n     * @param Request $request\n     * @return array\n     */\n    public function profileAction(Request $request)\n    {\n        $user = $this-&gt;getCurrentUser();\n        $form = $this-&gt;formFactory-&gt;create('user_profile', $user);\n\n        if ($request-&gt;getMethod() == 'POST') {\n            $form-&gt;bind($request);\n\n            if ($form-&gt;isValid()) {\n                $this-&gt;userService-&gt;save($user);\n                $request-&gt;getSession()-&gt;getFlashBag()-&gt;add('success', 'user.profile.edit.success');\n\n                return new RedirectResponse($this-&gt;router-&gt;generate('user.view', [\n                    'username' =&gt; $user-&gt;getUsername()\n                ]));\n            }\n        }\n\n        return [\n            'form' =&gt; $form-&gt;createView(),\n            'user' =&gt; $user\n        ];\n    }\n}\n</code></pre>\n\n<p>Note that I'm using my <a href=\"https://github.com/elnur/ElnurAbstractControllerBundle\">ElnurAbstractControllerBundle</a> to simplify defining controllers as services.</p>\n\n<p>The last thing left is to tell Symfony to look for templates without bundles. I do this by overriding the template guesser service, but since the approach is different between Symfony 2.0 and 2.1, I'm providing versions for both of them.</p>\n\n<h3>Overriding the Symfony 2.1+ template guesser</h3>\n\n<p>I've created a <a href=\"https://github.com/elnur/ElnurTemplateGuesserBundle\">bundle</a> that does that for you.</p>\n\n<h3>Overriding the Symfony 2.0 template listener</h3>\n\n<p>First, define the class:</p>\n\n<pre class=\"lang-php prettyprint-override\"><code>&lt;?php\nnamespace Vendor\\Listener;\n\nuse InvalidArgumentException;\nuse Symfony\\Bundle\\FrameworkBundle\\Templating\\TemplateReference;\nuse Symfony\\Component\\HttpFoundation\\Request;\nuse Symfony\\Component\\HttpKernel\\Bundle\\Bundle;\nuse Sensio\\Bundle\\FrameworkExtraBundle\\EventListener\\TemplateListener as FrameworkExtraTemplateListener;\nuse JMS\\DiExtraBundle\\Annotation\\Service;\n\nclass TemplateListener extends FrameworkExtraTemplateListener\n{\n    /**\n     * @param array   $controller\n     * @param Request $request\n     * @param string  $engine\n     * @throws InvalidArgumentException\n     * @return TemplateReference\n     */\n    public function guessTemplateName($controller, Request $request, $engine = 'twig')\n    {\n        if (!preg_match('/Controller\\\\\\(.+)Controller$/', get_class($controller[0]), $matchController)) {\n            throw new InvalidArgumentException(sprintf('The \"%s\" class does not look like a controller class (it must be in a \"Controller\" sub-namespace and the class name must end with \"Controller\")', get_class($controller[0])));\n\n        }\n\n        if (!preg_match('/^(.+)Action$/', $controller[1], $matchAction)) {\n            throw new InvalidArgumentException(sprintf('The \"%s\" method does not look like an action method (it does not end with Action)', $controller[1]));\n        }\n\n        $bundle = $this-&gt;getBundleForClass(get_class($controller[0]));\n\n        return new TemplateReference(\n            $bundle ? $bundle-&gt;getName() : null,\n            $matchController[1],\n            $matchAction[1],\n            $request-&gt;getRequestFormat(),\n            $engine\n        );\n    }\n\n    /**\n     * @param string $class\n     * @return Bundle\n     */\n    protected function getBundleForClass($class)\n    {\n        try {\n            return parent::getBundleForClass($class);\n        } catch (InvalidArgumentException $e) {\n            return null;\n        }\n    }\n}\n</code></pre>\n\n<p>And then tell Symfony to use it by adding this to <code>config.yml</code>:</p>\n\n<pre><code>parameters:\n    jms_di_extra.template_listener.class: Vendor\\Listener\\TemplateListener\n</code></pre>\n\n<h3>Using templates without bundles</h3>\n\n<p>Now, you can use templates out of bundles. Keep them under the <code>app/Resources/views</code> folder. For example, templates for those two actions from the example controller above are located in:</p>\n\n<ul>\n<li><code>app/Resources/views/User/add.html.twig</code></li>\n<li><code>app/Resources/views/User/profile.html.twig</code></li>\n</ul>\n\n<p>When referring to a template, just omit the bundle part:</p>\n\n<pre><code>{% include ':Controller:view.html.twig' %}\n</code></pre>\n    "},{"t":"Logout: GET or POST?","l":"http://stackoverflow.com/questions/3521290/logout-get-or-post","q":"\n\n<p><strong>This question is not about when to use GET or POST in general;</strong> it is about which is the recommended one for handling logging out of a web application. I have found plenty of information on the differences between GET and POST in the general sense, but I did not find a definite answer for this particular scenario.</p>\n\n<p>As a pragmatist, I'm inclined to use GET, because implementing it is way simpler than POST; just drop a simple link and you're done. This seems to be case with the vast majority of websites I can think of, at least from the top of my head. Even Stack Overflow handles logging out with GET.</p>\n\n<p>The thing making me hesitate is the (albeit old) argument that some web accelerators/proxies pre-cache pages by going and retrieving every link they find in the page, so the user gets a faster response when she clicks on them. I'm not sure if this still applies, but if this was the case, then in theory a user with one of these accelerators would get kicked out of the application as soon as she logs in, because her accelerator would find and retrieve the logout link even if she never clicked on it.</p>\n\n<p>Everything I have read so far suggest that <em>POST should be used for \"destructive actions\", whereas actions that do not alter the internal state of the application -like querying and such- should be handled with GET</em>. Based on this, the real question here is:</p>\n\n<p>Is logging out of an application considered a destructive action/does it alter the internal state of the application?</p>\n    ","a":"\n<p>Use <code>POST</code>.</p>\n\n<p>In 2010, using <code>GET</code> was probably an acceptable answer. But today (in 2013), browsers will pre-fetch pages they \"think\" you will visit next.</p>\n\n<p>Here is one of the StackOverflow developers talking about this issue on twitter:</p>\n\n<blockquote>\n  <p></p><p>I'd like to thank my bank for making log off a GET request, and the Chrome team for handy URL prefetching.- Nick Craver (<a href=\"https://twitter.com/Nick_Craver\">@Nick_Craver</a>) <a href=\"https://twitter.com/Nick_Craver/status/296281730984316928\">January 29, 2013</a></p>\n</blockquote>\n\n<p><em>fun fact: StackOverflow used to handle log-out via GET, but not anymore.</em></p>\n    "},{"t":"How do I prevent site scraping?","l":"http://stackoverflow.com/questions/3161548/how-do-i-prevent-site-scraping","q":"\n\n<p>I have a fairly large music website with a large artist database.  I've been noticing other music sites scraping our site's data (I enter dummy Artist names here and there and then do google searches for them).  </p>\n\n<p>How can I prevent screen scraping?  Is it even possible?</p>\n    ","a":"\n<p>I will presume that you have set up <code>robots.txt</code>.</p>\n\n<p>As others have mentioned, scrapers can fake nearly every aspect of their activities, and it is probably very difficult to identify the requests that are coming from the bad guys.</p>\n\n<p>What I would consider doing is:</p>\n\n<ol>\n<li>Set up a page <code>/jail.html</code></li>\n<li>Disallow access to the page in <code>robots.txt</code> (so the respectful spiders will never visit)</li>\n<li>Place a link on one of your pages, hiding it with CSS (<code>display: none</code>).</li>\n<li>Record IPs of visitors to <code>/jail.html</code></li>\n</ol>\n\n<p>This might help you to quickly identify requests from scrapers that are flagrantly disregarding your <code>robots.txt</code>.</p>\n\n<p>You might also want to make your <code>/jail.html</code> a whole entire website that has the same, exact markup as normal pages, but with fake data (<code>/jail/album/63ajdka</code>, <code>/jail/track/3aads8</code>, etc.). This way, the bad scrapers won't be alerted to \"unusual input\" until you have the chance to block them entirely.</p>\n    "},{"t":"How do you design object oriented projects?","l":"http://stackoverflow.com/questions/1100819/how-do-you-design-object-oriented-projects","q":"\n\n<p>I'm working on a large project (for me) which will have many classes and will need to be extensible, but I'm not sure how to plan out my program and how the classes need to interact.</p>\n\n<p>I took an OOD course a few semesters back and learned a lot from it; like writing UML, and translating requirements documents into objects and classes. We learned sequence diagrams too but somehow I missed the lecture or something, they didn't really stick with me.</p>\n\n<p>With previous projects I've tried using methods I learned from the course but usually end up with code that as soon as I can say \"yeah that looks something like what I had in mind\" i have no desire to dig through the muck to add new features.</p>\n\n<p>I've got a copy of Steve McConnell's <em>Code Complete</em> which I continually hear is amazing, here and elsewhere. I read the chapter on design and didn't seem to come out with the information I'm looking for. I know he says that it's not a cut and dried process, that it's mostly based on heuristics, but I can't seem to take all his information and apply it to my projects.</p>\n\n<p>So <strong>what are things you do during the high level design phase (before you begin programming) to determine what are the classes you need (especially ones not based on any 'real world objects') and how will they interact with each other</strong>?</p>\n\n<p>Specifically I'm interested in what are the methods you use? What is the process you follow that usually yeilds a good, clean design that will closely represent the final product?</p>\n    ","a":"\n<p>The steps that I use for initial design (getting to a class diagram), are:</p>\n\n<ol>\n<li><p>Requirements gathering.  Talk to the client and factor out the use cases to define what functionality the software should have.</p></li>\n<li><p>Compose a narrative of the individual use cases.</p></li>\n<li><p>Go through the narrative and highlight nouns (person, place, thing), as candidate classes and verbs (actions), as methods / behaviors.</p></li>\n<li><p>Discard duplicate nouns and factor out common functionality.</p></li>\n<li><p>Create a class diagram.  If you're a Java developer, NetBeans 6.7 from Sun has a UML module that allows for diagramming as well as round-trip engineering and it's FREE.  Eclipse (an open  source Java IDE), also has a modeling framework, but I have no experience with it.  You may also want to try out ArgoUML, an open source tool.</p></li>\n<li><p>Apply OOD principles to organize your classes (factor out common functionality, build hierarchies, etc.)</p></li>\n</ol>\n    "},{"t":"Websites like projecteuler.net [closed]","l":"http://stackoverflow.com/questions/662283/websites-like-projecteuler-net","q":"\n\n<p>Sometimes I'm solving problems on projecteuler.net.  Almost all problems are solvable with programs, but these tasks are more mathematical than programmatical.</p>\n\n<p>Maybe someone knows similar sites with:</p>\n\n<ul>\n<li>design tasks,</li>\n<li>architecture tasks,</li>\n<li>something like \"find most elegant C++ solution\"?</li>\n</ul>\n    ","a":"\n<p>I keep a few bookmarked along with <a href=\"http://projecteuler.net/\" rel=\"nofollow\">Project Euler</a>.</p>\n\n<ul>\n<li><a href=\"http://www.topcoder.com/tc\" rel=\"nofollow\">TopCoder</a></li>\n<li><a href=\"http://uva.onlinejudge.org/\" rel=\"nofollow\">UVa Online Judge</a></li>\n<li><a href=\"http://www.pythonchallenge.com/\" rel=\"nofollow\">Python Challenge</a></li>\n<li><a href=\"http://codegolf.com/\" rel=\"nofollow\">Code Golf</a></li>\n<li><a href=\"http://www.gowrikumar.com/c/index.php\" rel=\"nofollow\">C Puzzles</a></li>\n<li><a href=\"http://rubyquiz.com/\" rel=\"nofollow\">Ruby Quiz</a></li>\n</ul>\n\n<h3>Update:</h3>\n\n<p>I've collected these and links to several other puzzle sites in a blog post: <a href=\"http://www.billthelizard.com/2009/06/programming-and-logic-puzzles.html\" rel=\"nofollow\">Programming and Logic Puzzles</a>.</p>\n\n<h3>Update:</h3>\n\n<p><a href=\"http://www.mindcipher.com/\" rel=\"nofollow\">MindCipher</a> recently re-launched and has all of the original content.</p>\n    "},{"t":"What's the difference between “Layers” and “Tiers”?","l":"http://stackoverflow.com/questions/120438/whats-the-difference-between-layers-and-tiers","q":"\n\n<p>What's the difference between \"Layers\" and \"Tiers\"?</p>\n    ","a":"\n<blockquote>\n  <p>Logical <strong>layers</strong> are merely a way of\n  organizing your code. Typical layers\n  include Presentation, Business and\n  Data – the same as the traditional\n  3-tier model. But when we’re talking\n  about layers, we’re only talking about\n  logical organization of code. In no\n  way is it implied that these layers\n  might run on different computers or in\n  different processes on a single\n  computer or even in a single process\n  on a single computer. All we are doing\n  is discussing a way of organizing a\n  code into a set of layers defined by\n  specific function.</p>\n  \n  <p>Physical <strong>tiers</strong> however, are only about\n  where the code runs. Specifically,\n  tiers are places where layers are\n  deployed and where layers run. In\n  other words, tiers are the physical\n  deployment of layers.</p>\n</blockquote>\n\n<p><em>Source: Rockford Lhotka, <a href=\"http://www.lhotka.net/weblog/ShouldAllAppsBeNtier.aspx\">Should all apps be n-tier?</a></em></p>\n    "},{"t":"Why is Linux called a monolithic kernel?","l":"http://stackoverflow.com/questions/1806585/why-is-linux-called-a-monolithic-kernel","q":"\n\n<p>I read that Linux is a monolithic kernel. Does monolithic kernel mean compiling and linking the complete kernel code into an executable?</p>\n\n<p>If Linux is able to support modules, why not break all the subsystems into modules and load them when necessary? In that case, the kernel doesn't have to load all modules initially and could maintain an index of the functions in the module and load them when necessary.</p>\n    ","a":"\n<p>A monolithic kernel is a kernel where all services (file system, VFS, device drivers, etc) as well as core functionality (scheduling, memory allocation, etc.) are a tight knit group sharing the same space. This directly opposes a <em>microkernel</em>.</p>\n\n<p>A microkernel prefers an approach where core functionality is isolated from system services and device drivers (which are basically just system services). For instance, VFS (virtual file system) and block device file systems (i.e. minixfs) are separate processes that run outside of the kernel's space, using IPC to communicate with the kernel, other services and user processes. In short, if it's a <em>module</em> in Linux, it's a <em>service</em> in a microkernel, indicating an isolated process.</p>\n\n<p>Do not confuse the term <em>modular</em> kernel to be anything but monolithic. Some monolithic kernels can be compiled to be modular (e.g Linux), what matters is that the module is inserted to and runs from the same space that handles core functionality.</p>\n\n<p>The advantage to a microkernel is that any failed service can be easily restarted, for instance, there is no kernel halt if the root file system throws an abort.</p>\n\n<p>The disadvantage to a microkernel is that asynchronous IPC messaging can become very difficult to debug, especially if <a href=\"http://lwn.net/Articles/219954/\">fibrils</a> are implemented. Additionally, just tracking down a FS/write issue means examining the user space process, the block device service, VFS service, file system service and (possibly) the PCI service. If you get a blank on that, its time to look at the IPC service. This is often easier in a monolithic kernel. <a href=\"http://www.gnu.org/software/hurd/\">GNU Hurd</a> suffers from these debugging problems (<a href=\"http://www.gnu.org/software/hurd/open_issues/bash.html\">reference</a>). I'm not even going to go into checkpointing when dealing with complex message queues. Microkernels are not for the faint of heart.</p>\n\n<p>The shortest path to a working, stable kernel is the monolithic approach. Either approach can offer a POSIX interface, where the design of the kernel becomes of little interest to someone simply wanting to write code to run on any given design.</p>\n\n<p>I use Linux (monolithic) in production. However, most of my learning, hacking or tinkering with kernel development goes into a microkernel, specifically <a href=\"http://helenos.org\">HelenOS</a>.</p>\n\n<p><strong>Edit</strong></p>\n\n<p>If you got this far through my very long-winded answer, you will probably have some fun reading the '<a href=\"http://oreilly.com/catalog/opensources/book/appa.html\">Great Torvalds-Tanenbaum debate on kernel design</a>'. It's even funnier to read in 2013, more than 20 years after it transpired. The funniest part was Linus' signature in one of the last messages:</p>\n\n<pre><code>Linus \"my first, and hopefully last flamefest\" Torvalds\n</code></pre>\n\n<p>Obviously, that did not come true any more than Tanenbaum's prediction that x86 would soon be obsolete.</p>\n\n<p><strong>NB:</strong></p>\n\n<p>When I say \"Minix\", I do not imply Minix 3. Additionally, when I mention The HURD, I am referencing (mostly) the Mach microkernel. It is not my intent to disparage the recent work of others. </p>\n    "},{"t":"Facebook Architecture [closed]","l":"http://stackoverflow.com/questions/3533948/facebook-architecture","q":"\n\n<p>I have been scrounging for articles/info about the architecture at Facebook, the challenges &amp; ways they tackle them. What they use &amp; why they use. How do they scale &amp; what are the design decisions for what they do etc. Main underpinning being to learn. Knowing about sites which handles such massive traffic gives lots of pointers for architects etc. to keep in mind certain stuff while designing new sites. I am sharing what I found.</p>\n\n<ol>\n<li><a href=\"http://www.infoq.com/presentations/Facebook-Software-Stack\"><strong>Facebook Science &amp; Social Graph (Video)</strong></a></li>\n<li><a href=\"http://www.infoq.com/presentations/Scale-at-Facebook\"><strong>Scale at Facebook</strong></a></li>\n<li><a href=\"http://www.infoq.com/news/2008/05/facebookchatarchitecture\"><strong>Facebook Chat Architecture</strong></a></li>\n<li><a href=\"http://developers.facebook.com/blog/\"><strong>Facebook Blog</strong></a></li>\n<li><a href=\"http://perspectives.mvdirona.com/2009/02/07/FacebookCassandraArchitectureAndDesign.aspx\"><strong>Facebook Cassandra Architecture and Design</strong></a></li>\n<li><a href=\"http://www.facebook.com/notes.php?id=9445547199\"><strong>Facebook Engineering Notes</strong></a></li>\n<li><a href=\"http://www.quora.com/What-is-Facebooks-architecture\"><strong>Quora - Facebook Architecture</strong></a></li>\n<li><a href=\"http://www.slideshare.net/mozion/facebook-architecture-for-600m-users\"><strong>Facebook for 600M users</strong></a></li>\n<li><a href=\"http://www.infoq.com/news/2008/05/facebookchatarchitecture\"><strong>Facebook Chat Architecture</strong></a></li>\n<li><a href=\"http://borthakur.com/ftp/hadoopmicrosoft.pdf\"><strong>Hadoop &amp; its usage at Facebook</strong></a></li>\n<li><a href=\"http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf\"><strong>Erlang at Facebook: Chat Architecture</strong></a></li>\n<li><a href=\"http://sizzo.org/wp/wp-content/uploads/2007/09/facebook_performance_caching.pdf\"><strong>Facebook Performance Caching</strong></a></li>\n<li><a href=\"http://www.bestechvideos.com/2009/04/07/facebook-tech-talks-the-architecture-of-facebook-connect\"><strong>Facebook Connect Architecture</strong></a></li>\n</ol>\n\n<p>I have 2 more links but unable to post due to restrictions at this site. Also, please share if anyone has anything better (need not be related to Facebook only).</p>\n\n<p><strong>P.S. -</strong> I wasn't able to find good places to share this research, hence this initiative. Hope this helps someone.</p>\n    ","a":"\n<p>Well Facebook has undergone MANY many changes and it wasn't originally designed to be efficient. It was designed to do it's job. I have absolutely no idea what the code looks like and you probably won't find much info about it (for obvious security and copyright reasons), but just take a look at the API. Look at how often it changes and how much of it doesn't work properly, anymore, or at all.</p>\n\n<p>I think the biggest ace up their sleeve is the Hiphop. \n<a href=\"http://developers.facebook.com/blog/post/358\">http://developers.facebook.com/blog/post/358</a>\nYou can use HipHop yourself:\n<a href=\"http://wiki.github.com/facebook/hiphop-php\">http://wiki.github.com/facebook/hiphop-php</a></p>\n\n<p>But if you ask me it's a very ambitious and probably time wasting task. Hiphop only supports so much, it can't simply convert everything to C++. So what does this tell us? Well, it tells us that Facebook is NOT fully taking advantage of the PHP language. It's not using the latest 5.3 and I'm willing to bet there's still a lot that is PHP 4 compatible. Otherwise, they couldn't use HipHop. HipHop IS A GOOD IDEA and needs to grow and expand, but in it's current state it's not really useful for that many people who are building NEW PHP apps.</p>\n\n<p>There's also PHP to JAVA via things like Resin/Quercus. Again, it doesn't support everything...</p>\n\n<p>Another thing to note is that if you use any non-standard PHP module, you aren't going to be able to convert that code to C++ or Java either. However...Let's take a look at PHP modules. They are ARE compiled in C++. So if you can build PHP modules that do things (like parse XML, etc.) then you are basically (minus some interaction) working at the same speed. Of course you can't just make a PHP module for every possible need and your entire app because you would have to recompile and it would be much more difficult to code, etc.</p>\n\n<p>However...There are some handy PHP modules that can help with speed concerns.\nThough at the end of the day, we have this awesome thing known as \"the cloud\" and with it, we can scale our applications (PHP included) so it doesn't matter as much anymore. Hardware is becoming cheaper and cheaper. Amazon just lowered it's prices (again) speaking of.</p>\n\n<p>So as long as you code your PHP app around the idea that it will need to one day scale...Then I think you're fine and I'm not really sure I'd even look at Facebook and what they did because when they did it, it was a completely different world and now trying to hold up that infrastructure and maintain it...Well, you get things like HipHop. </p>\n\n<p>Now how is HipHop going to help you? It won't. It can't. You're starting fresh, you can use PHP 5.3. I'd highly recommend looking into PHP 5.3 frameworks and all the new benefits that PHP 5.3 brings to the table along with the SPL libraries and also think about your database too. You're most likely serving up content from a database, so check out MongoDB and other types of databases that are schema-less and document-oriented. They are much much faster and better for the most \"common\" type of web site/app. </p>\n\n<p>Look at NEW companies like Foursquare and Smugmug and some other companies that are utilizing NEW technology and HOW they are using it. For as successful as Facebook is, I honestly would not look at them for \"how\" to build an efficient web site/app. I'm not saying they don't have very (very) talented people that work there that are solving (their) problems creatively...I'm also not saying that Facebook isn't a great idea in general and that it's not successful and that you shouldn't get ideas from it....I'm just saying that if you could view their entire source code, you probably wouldn't benefit from it.</p>\n    "},{"t":"Domain Driven Design: Domain Service, Application Service","l":"http://stackoverflow.com/questions/2268699/domain-driven-design-domain-service-application-service","q":"\n\n<p>Can someone explain the difference between domain and application services by providing some examples? And, if a service is a domain service, would I put the actual implementation of this service within the domain assembly and if so, would I also inject repositories into that domain service? Some info would be really helpful.</p>\n    ","a":"\n<p>Services come in 3 flavours: <strong>Domain Services</strong>, <strong>Application Services</strong>, and <strong>Infrastructure Services</strong></p>\n\n<ul>\n<li><strong>Domain Services</strong> : Encapsulates\n<em>business logic</em> that doesn't naturally\nfit within a domain object, and are <strong>NOT</strong> typical CRUD operations - those would belong to a <em>Repository</em>.</li>\n<li><strong>Application Services</strong> : Used by\nexternal consumers to talk to your\nsystem (think <em>Web Services</em>).  If consumers need access to CRUD operations, they would be exposed here.</li>\n<li><strong>Infrastructure Services</strong> : Used to\nabstract technical concerns (e.g.\nMSMQ, email provider, etc)</li>\n</ul>\n\n<p>Keeping Domain Services along with your Domain Objects is sensible - they are all focused on domain logic.  And yes, you can inject Repositories into your Services.</p>\n\n<p>Application Services will typically use both Domain Services <em>and</em> Repositories to deal with external requests.</p>\n\n<p>Hope that helps!</p>\n    "},{"t":"Advantage of creating a generic repository vs. specific repository for each object?","l":"http://stackoverflow.com/questions/1230571/advantage-of-creating-a-generic-repository-vs-specific-repository-for-each-obje","q":"\n\n<p>We are developing an ASP.NET MVC application, and are now building the repository/service classes.  I'm wondering if there are any major advantages to creating a generic IRepository interface that all repositories implement, vs. each Repository having its own unique interface and set of methods.</p>\n\n<p>For example: a generic IRepository interface might look like (taken from <a href=\"http://stackoverflow.com/questions/291344/repository-pattern-vs-dal\">this answer</a>):</p>\n\n<pre><code>public interface IRepository : IDisposable\n{\n    T[] GetAll&lt;T&gt;();\n    T[] GetAll&lt;T&gt;(Expression&lt;Func&lt;T, bool&gt;&gt; filter);\n    T GetSingle&lt;T&gt;(Expression&lt;Func&lt;T, bool&gt;&gt; filter);\n    T GetSingle&lt;T&gt;(Expression&lt;Func&lt;T, bool&gt;&gt; filter, List&lt;Expression&lt;Func&lt;T, object&gt;&gt;&gt; subSelectors);\n    void Delete&lt;T&gt;(T entity);\n    void Add&lt;T&gt;(T entity);\n    int SaveChanges();\n    DbTransaction BeginTransaction();\n}\n</code></pre>\n\n<p>Each Repository would implement this interface, for example:</p>\n\n<ul>\n<li>CustomerRepository:IRepository</li>\n<li>ProductRepository:IRepository</li>\n<li>etc.</li>\n</ul>\n\n<p>The alternate that we've followed in prior projects would be:</p>\n\n<pre><code>public interface IInvoiceRepository : IDisposable\n{\n    EntityCollection&lt;InvoiceEntity&gt; GetAllInvoices(int accountId);\n    EntityCollection&lt;InvoiceEntity&gt; GetAllInvoices(DateTime theDate);\n    InvoiceEntity GetSingleInvoice(int id, bool doFetchRelated);\n    InvoiceEntity GetSingleInvoice(DateTime invoiceDate, int accountId); //unique\n    InvoiceEntity CreateInvoice();\n    InvoiceLineEntity CreateInvoiceLine();\n    void SaveChanges(InvoiceEntity); //handles inserts or updates\n    void DeleteInvoice(InvoiceEntity);\n    void DeleteInvoiceLine(InvoiceLineEntity);\n}\n</code></pre>\n\n<p>In the second case, the expressions (LINQ or otherwise) would be entirely contained in the Repository implementation, whoever is implementing the service just needs to know which repository function to call.  </p>\n\n<p>I guess I don't see the advantage of writing all the expression syntax in the service class and passing to the repository.  Wouldn't this mean easy-to-messup LINQ code is being duplicated in many cases?  </p>\n\n<p>For example, in our old invoicing system, we call</p>\n\n<pre><code>InvoiceRepository.GetSingleInvoice(DateTime invoiceDate, int accountId)\n</code></pre>\n\n<p>from a few different services (Customer, Invoice, Account, etc).  That seems much cleaner than writing the following in multiple places:</p>\n\n<pre><code>rep.GetSingle(x =&gt; x.AccountId = someId &amp;&amp; x.InvoiceDate = someDate.Date);\n</code></pre>\n\n<p>The only disadvantage I see to using the specific approach is that we could end up with many permutations of Get* functions, but this still seems preferable to pushing the expression logic up into the Service classes.</p>\n\n<p>What am I missing?</p>\n    ","a":"\n<p>This is an issue as old as the Repository pattern itself. The recent introduction of LINQ's <code>IQueryable</code>, a uniform representation of a query, has caused a lot of discussion about this very topic.</p>\n\n<p>I prefer specific repositories myself, after having worked very hard to build a generic repository framework. No matter what clever mechanism I tried, I always ended up at the same problem: a repository is a part of the domain being modeled, and that domain is not generic. Not every entity can be deleted, not every entity can be added, not every entity has a repository. Queries vary wildly; the repository API becomes as unique as the entity itself.</p>\n\n<p>A pattern I often use is to have specific repository interfaces, but a base class for the implementations. For example, using LINQ to SQL, you could do:</p>\n\n<pre><code>public abstract class Repository&lt;TEntity&gt;\n{\n    private DataContext _dataContext;\n\n    protected Repository(DataContext dataContext)\n    {\n        _dataContext = dataContext;\n    }\n\n    protected IQueryable&lt;TEntity&gt; Query\n    {\n        get { return _dataContext.GetTable&lt;TEntity&gt;(); }\n    }\n\n    protected void InsertOnCommit(TEntity entity)\n    {\n        _dataContext.GetTable&lt;TEntity&gt;().InsertOnCommit(entity);\n    }\n\n    protected void DeleteOnCommit(TEntity entity)\n    {\n        _dataContext.GetTable&lt;TEntity&gt;().DeleteOnCommit(entity);\n    }\n}\n</code></pre>\n\n<p>Replace <code>DataContext</code> with your unit-of-work of choice. An example implementation might be:</p>\n\n<pre><code>public interface IUserRepository\n{\n    User GetById(int id);\n\n    IQueryable&lt;User&gt; GetLockedOutUsers();\n\n    void Insert(User user);\n}\n\npublic class UserRepository : Repository&lt;User&gt;, IUserRepository\n{\n    public UserRepository(DataContext dataContext) : base(dataContext)\n    {}\n\n    public User GetById(int id)\n    {\n        return Query.Where(user =&gt; user.Id == id).SingleOrDefault();\n    }\n\n    public IQueryable&lt;User&gt; GetLockedOutUsers()\n    {\n        return Query.Where(user =&gt; user.IsLockedOut);\n    }\n\n    public void Insert(User user)\n    {\n        InsertOnCommit(user);\n    }\n}\n</code></pre>\n\n<p>Notice the public API of the repository does not allow users to be deleted. Also, exposing <code>IQueryable</code> is a whole other can of worms - there are as many opinions as belly buttons on that topic. </p>\n    "},{"t":"Building a minimal plugin architecture in Python","l":"http://stackoverflow.com/questions/932069/building-a-minimal-plugin-architecture-in-python","q":"\n\n<p>I have an application, written in Python, which is used by a fairly technical audience (scientists). </p>\n\n<p>I'm looking for a good way to make the application extensible by the users, i.e. a scripting/plugin architecture. </p>\n\n<p>I am looking for something <strong>extremely lightweight</strong>. Most scripts, or plugins, are not going to be developed and distributed by a third-party and installed, but are going to be something whipped up by a user in a few minutes to automate a repeating task, add support for a file format, etc. So plugins should have the absolute minimum boilerplate code, and require no 'installation' other than copying to a folder (so something like setuptools entry points, or the Zope plugin architecture seems like too much.)</p>\n\n<p>Are there any systems like this already out there, or any projects that implement a similar scheme that I should look at for ideas / inspiration?</p>\n    ","a":"\n<p>Mine is, basically, a directory called \"plugins\" which the main app can poll and then use <a href=\"https://docs.python.org/library/imp.html#imp.load_module\">imp.load_module</a> to pick up files, look for a well-known entry point possibly with module-level config params, and go from there. I use file-monitoring stuff for a certain amount of dynamism in which plugins are active, but that's a nice-to-have.</p>\n\n<p>Of course, any requirement that comes along saying \"I don't need [big, complicated thing] X; I just want something lightweight\" runs the risk of re-implementing X one discovered requirement at a time. But that's not to say you can't have some fun doing it anyway :)</p>\n    "},{"t":"Thread vs ThreadPool","l":"http://stackoverflow.com/questions/230003/thread-vs-threadpool","q":"\n\n<p>What is the difference between using a new thread and using a thread from the thread pool? What performance benefits are there and why should I consider using a thread from the pool rather than one I've explicitly created? I'm thinking specifically of .NET here, but general examples are fine.</p>\n    ","a":"\n<p>Thread pool will provide benefits for frequent and relatively short operations by</p>\n\n<ul>\n<li>Reusing threads that have already been created instead of creating new ones (an expensive process)</li>\n<li><p>Throttling the rate of thread creation when there is a burst of requests for new work items (I believe this is only in .NET 3.5)</p>\n\n<ul>\n<li><p>If you queue 100 thread pool tasks, it will only use as many threads as have already been created to service these requests (say 10 for example). The thread pool will make frequent checks (I believe every 500ms in 3.5 SP1) and if there are queued tasks, it will make one new thread. If your tasks are quick, then the number of new threads will be small and reusing the 10 or so threads for the short tasks will be faster than creating 100 threads up front.</p></li>\n<li><p>If your workload consistently has large numbers of thread pool requests coming in, then the thread pool will tune itself to your workload by creating more threads in the pool by the above process so that there are a larger number of thread available to process requests</p></li>\n<li><p>check <a href=\"http://blogs.msdn.com/pedram/archive/2007/08/05/dedicated-thread-or-a-threadpool-thread.aspx\">Here</a> for more in depth info on how the thread pool functions under the hood</p></li>\n</ul></li>\n</ul>\n\n<p>Creating a new thread yourself would be more appropriate if the job were going to be relatively long running (probably around a second or two, but it depends on the specific situation)</p>\n\n<p>@Krzysztof - Thread Pool threads are background threads that will stop when the main thread ends. Manually created threads are foreground by default (will keep running after the main thread has ended), but can be set to background before calling Start on them.</p>\n    "},{"t":"Describe the architecture you use for Java web applications?","l":"http://stackoverflow.com/questions/286846/describe-the-architecture-you-use-for-java-web-applications","q":"\n\n<p><strong>Let's share Java based web application architectures!</strong></p>\n\n<p>There are lots of different architectures for web applications which are to be implemented using Java. The answers to this question may serve as a library of various web application designs with their pros and cons. While I realize that the answers will be subjective, let's try to be as objective as we can and motivate the pros and cons we list.</p>\n\n<p>Use the detail level you prefer for describing your architecture. For your answer to be of any value you'll at least have to describe the major technologies and ideas used in the architecture you describe. And last but not least, <em>when</em> should we use your architecture?</p>\n\n<p>I'll start...</p>\n\n<p></p><hr><p></p>\n\n<h1>Overview of the architecture</h1>\n\n<p>We use a 3-tier architecture based on open standards from Sun like Java EE, Java Persistence API, Servlet and Java Server Pages.</p>\n\n<ul>\n<li>Persistence</li>\n<li>Business</li>\n<li>Presentation</li>\n</ul>\n\n<p>The possible communication flows between the layers are represented by:</p>\n\n<pre><code>Persistence &lt;-&gt; Business &lt;-&gt; Presentation\n</code></pre>\n\n<p>Which for example means that the presentation layer never calls or performs persistence operations, it always does it through the business layer. This architecture is meant to fulfill the demands of a high availability web application.</p>\n\n<h2>Persistence</h2>\n\n<p>Performs create, read, update and delete (<a href=\"http://en.wikipedia.org/wiki/Create,_read,_update_and_delete\">CRUD</a>) persistence operations. In our case we are using (<a href=\"http://java.sun.com/javaee/technologies/persistence.jsp\">Java Persistence API</a>) JPA and we currently use <a href=\"http://www.hibernate.org/\">Hibernate</a> as our persistence provider and use <a href=\"http://www.hibernate.org/397.html\">its EntityManager</a>.</p>\n\n<p>This layer is divided into multiple classes, where each class deals with a certain type of entities (i.e. entities related to a shopping cart might get handled by a single persistence class) and is <em>used</em> by one and only one <em>manager</em>.</p>\n\n<p>In addition this layer also stores <a href=\"http://en.wikipedia.org/wiki/Java_Persistence_API#Entities\">JPA entities</a> which are things like <code>Account</code>, <code>ShoppingCart</code> etc.</p>\n\n<h2>Business</h2>\n\n<p>All logic which is tied to the web application functionality is located in this layer. This functionality could be initiating a money transfer for a customer who wants to pay for a product on-line using her/his credit card. It could just as well be creating a new user, deleting a user or calculating the outcome of a battle in a web based game.</p>\n\n<p>This layer is divided into multiple classes and each of these classes is annotated with <code>@Stateless</code> to become a <a href=\"http://en.wikipedia.org/wiki/Session_Beans\">Stateless Session Bean</a> (SLSB). Each SLSB is called a <em>manager</em> and for instance a manager could be a class annotated as mentioned called <code>AccountManager</code>.</p>\n\n<p>When <code>AccountManager</code> needs to perform CRUD operations it makes the appropriate calls to an instance of <code>AccountManagerPersistence</code>, which is a class in the persistence layer. A rough sketch of two methods in <code>AccountManager</code> could be:</p>\n\n<pre><code>...\npublic void makeExpiredAccountsInactive() {\n    AccountManagerPersistence amp = new AccountManagerPersistence(...)\n    // Calls persistence layer\n    List&lt;Account&gt; expiredAccounts = amp.getAllExpiredAccounts();\n    for(Account account : expiredAccounts) {\n        this.makeAccountInactive(account)\n    }\n}\npublic void makeAccountInactive(Account account) {\n    AccountManagerPersistence amp = new AccountManagerPersistence(...)\n    account.deactivate();\n    amp.storeUpdatedAccount(account); // Calls persistence layer\n}\n</code></pre>\n\n<p>We use <a href=\"http://java.sun.com/javaee/5/docs/tutorial/doc/bncij.html\">container manager transactions</a> so we don't have to do transaction demarcation our self's. What basically happens under the hood is we initiate a transaction when entering the SLSB method and commit it (or rollback it) immediately before exiting the method. It's an example of convention over configuration, but we haven't had a need for anything but the default, Required, yet.</p>\n\n<p>Here is how The Java EE 5 Tutorial from Sun explains the <a href=\"http://java.sun.com/javaee/5/docs/tutorial/doc/bncij.html\">Required transaction attribute</a> for Enterprise JavaBeans (EJB's):</p>\n\n<blockquote>\n  <p>If the client is running within a\n  transaction and invokes the enterprise\n  bean’s method, the method executes\n  within the client’s transaction. If\n  the client is not associated with a\n  transaction, the container starts a\n  new transaction before running the\n  method.</p>\n  \n  <p>The Required attribute is the implicit\n  transaction attribute for all\n  enterprise bean methods running with\n  container-managed transaction\n  demarcation. You typically do not set\n  the Required attribute unless you need\n  to override another transaction\n  attribute. Because transaction\n  attributes are declarative, you can\n  easily change them later.</p>\n</blockquote>\n\n<h2>Presentation</h2>\n\n<p>Our presentation layer is in charge of... presentation! It's responsible for the user interface and shows information to the user by building HTML pages and receiving user input through GET and POST requests. We are currently using the old <a href=\"http://java.sun.com/products/servlet/\">Servlet</a>'s + Java Server Pages (<a href=\"http://java.sun.com/products/jsp/\">JSP</a>) combination.</p>\n\n<p>The layer calls methods in <em>managers</em> of the business layer to perform operations requested by the user and to receive information to show in the web page. Sometimes the information received from the business layer are less complex types as <code>String</code>'s and <code>int</code>egers, and at other times <a href=\"http://en.wikipedia.org/wiki/Java_Persistence_API#Entities\">JPA entities</a>.</p>\n\n<h1>Pros and cons with the architecture</h1>\n\n<h2>Pros</h2>\n\n<ul>\n<li>Having everything related to a specific way of doing persistence in this layer only means we can swap from using JPA into something else, without having to re-write anything in the business layer.</li>\n<li>It's easy for us to swap our presentation layer into something else, and it's likely that we will if we find something better.</li>\n<li>Letting the EJB container manage transaction boundaries is nice.</li>\n<li>Using Servlet's + JPA is easy (to begin with) and the technologies are widely used and implemented in lots of servers.</li>\n<li>Using Java EE is supposed to make it easier for us to create a high availability system with <a href=\"http://en.wikipedia.org/wiki/Load_balancing_(computing)\">load balancing</a> and <a href=\"http://en.wikipedia.org/wiki/Failover\">fail over</a>. Both of which we feel that we must have.</li>\n</ul>\n\n<h2>Cons</h2>\n\n<ul>\n<li>Using JPA you may store often used queries as named queries by using the <code>@NamedQuery</code> annotation on the JPA entity class. If you have as much as possible related to persistence in the persistence classes, as in our architecture, this will spread out the locations where you may find queries to include the JPA entities as well. It will be harder to overview persistence operations and thus harder to maintain.</li>\n<li>We have JPA entities as part of our persistence layer. But <code>Account</code> and <code>ShoppingCart</code>, aren't they really business objects? It is done this way as you have to touch these classes and turn them into entities which JPA knows how to handle.</li>\n<li>The JPA entities, which are also our business objects, are created like Data Transfer Objects (<a href=\"http://en.wikipedia.org/wiki/Data_Transfer_Object\">DTO</a>'s), also known as Value Objects (VO's). This results in an <a href=\"http://en.wikipedia.org/wiki/Anemic_Domain_Model\">anemic domain model</a> as the business objects have no logic of their own except accessor methods. All logic is done by our managers in the business layer, which results in a more procedural programming style. It's not good object oriented design, but maybe that's not a problem? (After all object orientation isn't the only programming paradigm which has delivered results.)</li>\n<li>Using EJB and Java EE introduces a bit of complexity. And we can't use purely Tomcat (adding an EJB micro-container isn't <em>purely</em> Tomcat).</li>\n<li>There are lots of issues with using Servlet's + JPA. Use Google for more information about these issues.</li>\n<li>As the transactions are closed when exiting the business layer we can't load any information from JPA entities which is configured to be loaded from the database when it's needed (using <code>fetch=FetchType.LAZY</code>) from inside the presentation layer. It will trigger an exception. Before returning an entity containing these kinds of fields we have to be sure to call the relevant getter's. Another option is to use Java Persistence Query Language (<a href=\"http://java.sun.com/javaee/5/docs/tutorial/doc/bnbtg.html\">JPQL</a>) and do a <code>FETCH JOIN</code>. However both of these options are a little bit cumbersome.</li>\n</ul>\n    ","a":"\n<p>Ok I'll do a (shorter) one:</p>\n\n<ul>\n<li>Frontend : Tapestry (3 for older projects, 5 for newer projects)</li>\n<li>Business layer: Spring</li>\n<li>DAO's : Ibatis</li>\n<li>Database : Oracle</li>\n</ul>\n\n<p>We use Sping transaction support, and start transactions upon entering the service layer, propagating down to the DAO call's. The Service layer has the most bussines model knowledge, and the DAO's do relatively simple CRUD work.</p>\n\n<p>Some more complicated query stuff is handled by more complicated queries in the backend for performance reasons.</p>\n\n<p>Advantages of using Spring in our case is that we can have country/language dependant instances, which are behind a Spring Proxy class. Based on the user in the session, the correct country/language implementation is used when doing a call.</p>\n\n<p>Transaction management is nearly transparent, rollback on runtime exceptions. We use unchecked exceptions as much as possible. We used to do checked exceptions, but with the introduction of Spring I see the benefits of unchecked exceptions, only handling exceptions when you can. It avoids a lot of boilerplate \"catch/rethrow\" or \"throws\" stuff.</p>\n\n<p>Sorry it's shorter than your post, hope you find this interesting...</p>\n    "},{"t":"What is N-Tier architecture?","l":"http://stackoverflow.com/questions/312187/what-is-n-tier-architecture","q":"\n\n<p>I've seen quite a few developer job postings recently that include a sentence that reads more or less like this: \"Must have experience with N-Tier architecture\", or \"Must be able to develop N-Tier apps\".</p>\n\n<p>This leads me to ask, what is N-Tier architecture? How does one gain experience with it?</p>\n    ","a":"\n<p><a href=\"http://en.wikipedia.org/wiki/Multitier_architecture\">Wikipedia</a>:</p>\n\n<blockquote>\n  <p>In software engineering, multi-tier\n  architecture (often referred to as\n  n-tier architecture) is a\n  client-server architecture in which,\n  the presentation, the application\n  processing and the data management are\n  logically separate processes. For\n  example, an application that uses\n  middleware to service data requests\n  between a user and a database employs\n  multi-tier architecture. The most\n  widespread use of \"multi-tier\n  architecture\" refers to three-tier\n  architecture.</p>\n</blockquote>\n\n<p>It's debatable what counts as \"tiers,\" but in my opinion it needs to at least cross the process boundary. Or else it's called layers. But, it does not need to be in physically different machines. Although I don't recommend it, you <em>can</em> host logical tier and database on the same box.</p>\n\n<p><img src=\"http://upload.wikimedia.org/wikipedia/en/6/66/Overview_of_a_three-tier_application.png\" alt=\"alt text\"></p>\n\n<p><strong>Edit</strong>: One implication is that presentation tier and the logic tier (sometimes called Business Logic Layer) needs to cross machine boundaries \"across the wire\" sometimes over unreliable, slow, and/or insecure network. This is very different from simple Desktop application where the data lives on the same machine as files or Web Application where you can hit the database directly.</p>\n\n<p>For n-tier programming, you need to package up the data in some sort of transportable form called \"dataset\" and fly them over the wire. .NET's <a href=\"http://msdn.microsoft.com/en-us/library/system.data.dataset.aspx\">DataSet</a> class or Web Services protocol like <a href=\"http://www.w3.org/TR/soap/\">SOAP</a> are few of such attempts to fly objects over the wire.</p>\n    "},{"t":"Why is IoC / DI not common in Python?","l":"http://stackoverflow.com/questions/2461702/why-is-ioc-di-not-common-in-python","q":"\n\n<p>In Java <a href=\"http://en.wikipedia.org/wiki/Inversion_of_Control\">IoC</a> / <a href=\"http://en.wikipedia.org/wiki/Dependency_Injection\">DI</a> is a very common practice which is extensively used in web applications, nearly all available frameworks and Java EE. On the other hand, there are also lots of big Python web applications, but beside of Zope (which I've heard should be really horrible to code) IoC doesn't seem to be very common in the Python world. (Please name some examples if you think that I'm wrong).</p>\n\n<p>There are of course several clones of popular Java IoC frameworks available for Python, <a href=\"http://springpython.webfactional.com/\">springpython</a> for example. But none of them seems to get used practically. At least, I've never stumpled upon a <a href=\"http://www.djangoproject.com/\">Django</a> or <a href=\"http://www.sqlalchemy.org/\">sqlalchemy</a>+<code>&lt;insert your favorite wsgi toolkit here&gt;</code> based web application which uses something like that.</p>\n\n<p>In my opinion IoC has reasonable advantages and would make it easy to replace the django-default-user-model for example, but extensive usage of interface classes and IoC in Python looks a bit odd and not »pythonic«. But maybe someone has a better explanation, why IoC isn't widely used in Python.</p>\n    ","a":"\n<p>I don't actually think that DI/IoC are <em>that</em> uncommon in Python. What <em>is</em> uncommon, however, are DI/IoC <em>frameworks/containers</em>.</p>\n\n<p>Think about it: what does a DI container do? It allows you to </p>\n\n<ol>\n<li>wire together independent components into a complete application ...</li>\n<li>... at runtime.</li>\n</ol>\n\n<p>We have names for \"wiring together\" and \"at runtime\":</p>\n\n<ol>\n<li>scripting</li>\n<li>dynamic</li>\n</ol>\n\n<p>So, a DI container is nothing but an interpreter for a dynamic scripting language. Actually, let me rephrase that: a typical Java/.NET DI container is nothing but a crappy interpreter for a really bad dynamic scripting language with butt-ugly, often XML-based, syntax.</p>\n\n<p>When you program in Python, why would you want to use an ugly, bad scripting language when you have a beautiful, brilliant scripting language at your disposal? Actually, that's a more general question: when you program in pretty much any language, why would you want to use an ugly, bad scripting language when you have Jython and IronPython at your disposal?</p>\n\n<p>So, to recap: the <em>practice</em> of DI/IoC is just as important in Python as it is in Java, for exactly the same reasons. The <em>implementation</em> of DI/IoC however, is built into the language and often so lightweight that it completely vanishes. </p>\n\n<p>(Here's a brief aside for an analogy: in assembly, a subroutine call is a pretty major deal - you have to save your local variables and registers to memory, save your return address somewhere, change the instruction pointer to the subroutine you are calling, arrange for it to somehow jump back into your subroutine when it is finished, put the arguments somewhere where the callee can find them, and so on. IOW: in assembly, \"subroutine call\" is a Design Pattern, and before there were languages like Fortran which had subroutine calls built in, people were building their own \"subroutine frameworks\". Would you say that subroutine calls are \"uncommon\" in Python, just because you don't use subroutine frameworks?)</p>\n\n<p>BTW: for an example of what it looks like to take DI to its logical conclusion, take a look at <a href=\"http://GBracha.BlogSpot.Com/\">Gilad Bracha</a>'s <a href=\"http://NewspeakLanguage.Org/\">Newspeak Programming Language</a> and his writings on the subject:</p>\n\n<ul>\n<li><a href=\"http://GBracha.BlogSpot.Com/2007/06/constructors-considered-harmful.html\">Constructors Considered Harmful</a></li>\n<li><a href=\"http://GBracha.BlogSpot.Com/2007/12/some-months-ago-i-wrote-couple-of-posts.html\">Lethal Injection</a></li>\n<li><a href=\"http://GBracha.BlogSpot.Com/2009/06/ban-on-imports.html\">A Ban on Imports</a> (<a href=\"http://GBracha.BlogSpot.Com/2009/07/ban-on-imports-continued.html\">continued</a>)</li>\n</ul>\n    "},{"t":"Architecture for merging multiple user accounts together","l":"http://stackoverflow.com/questions/6666267/architecture-for-merging-multiple-user-accounts-together","q":"\n\n<p>Okay, I got a website where you can register yourself and login. You can also login with your facebook, twitter or linkedin account.</p>\n\n<p>It is important that users only have one account registered. So somehow, I want to merge the accounts of users if they use different methods to login. What is the best solution to solve this?</p>\n\n<p>For instance, the user logs in with his Facebook account. I use the data to register an account for him automatically. Should I sent an e-mail with an username and password of our website? (If this is okay with the policy of Facebook). Should I give them a second screen where they can fill in an username and password? But that's not the idea behind logging in with your Facebook account. It should simplify your procedure to participate.</p>\n\n<p>It's also possible the user has registered himself on our website and the next time he logs in with his twitter account. How can I merge these 2 accounts as one? What's the best way?</p>\n\n<p>So basically my question is: I got 4 different ways a user becomes a member of our website. How can I make sure all these 4 ways only create one account if a user decides to use multiple ways? What's the best flow to make sure that it doesn't become a hassle for the user himself?</p>\n\n<hr>\n\n<p>Edit: </p>\n\n<p>3 years after I asked this question, I am giving the answer myself in a series of articles: <a href=\"http://www.sitepoint.com/series/using-social-networks-as-a-login-system/\">http://www.sitepoint.com/series/using-social-networks-as-a-login-system/</a></p>\n    ","a":"\n<p>I am faced with the exact same task at the moment.  The design I worked out is rather simple, but it works well.</p>\n\n<p>The core idea is that models for a local site identity and the third-party site identities are kept isolated, but are later linked.  So every user that logs into the site has a local identity which maps to any number of third-party site identities.</p>\n\n<p>A local identity record contains a minimum of information - it could even be a single field - just a primary key.  (For my application, I don't care about the user's email, name, or birth date - I just want to know they're the person who has been logging into this account all along.)</p>\n\n<p>The third-party identities contain information relevant only to authenticating with a third-party.  For OAuth, this typically means a user identifier (like an id, email, or username) and a service identifier (indicating what site or service was authenticated with).  In other parts of the application, outside of the database, that service identifier is paired with a method for retrieving the relevant user identifier from that service, and that is how authentication is performed.  For OpenID, we employ the same approach, except the method for authenticating is more generalized (because we can almost always perform the exact same protocol - except we use a different identity URL, and that is our service identifier). </p>\n\n<p>Finally, I keep a records of which third-party identities are paired to what local identity.  To generate these records, the flow looks like this:</p>\n\n<ul>\n<li>A user logs in for the first time using a third-party identity.  A local identity record is created, then a third-party identity record, and then they are paired.</li>\n<li>In a control panel, the user is offered the opportunity to link an account by logging in to third-party services.  (Pretty straightforward how this works.)</li>\n<li>In the scenario where the user unwittingly makes multiple accounts, the solution is pretty simple.  While the user is logged in on one of the accounts, he logs into another which he previously used to log into the site (via the control panel feature above).  The web service detects this collision (that the local identity of the logged-in user differs from the local identity that is linked to the third-party identity that just logged in) and the user is prompted with an account merge.</li>\n</ul>\n\n<p>Merging accounts is a matter of merging each individual field of the local identity (which will vary from application to application, and should be easy if you have only a couple fields in your local identity records), and then ensuring the linked third-party identities are linked to the resultant local identity.</p>\n    "},{"t":"Architecture of a single-page JavaScript web application?","l":"http://stackoverflow.com/questions/3050869/architecture-of-a-single-page-javascript-web-application","q":"\n\n<p>How should a complex single-page JS web application be structured on the client-side? Specifically I'm curious about how to cleanly structure the application in terms of its model objects, UI components, any controllers, and objects handling server persistence.</p>\n\n<p>MVC seemed like a fit at first. But with UI components nested at various depths (each with their own way of acting on/reacting to model data, and each generating events which they themselves may or may not handle directly), it doesn't seem like MVC can be cleanly applied. (But please correct me if that's not the case.)</p>\n\n<p>--</p>\n\n<p>(<a href=\"http://stackoverflow.com/questions/2529722/suggestions-for-single-page-web-application-design\">This question</a> resulted in two suggestions of using ajax, which is obviously needed for anything other than the most trivial one-page app.)</p>\n    ","a":"\n<p>MVC architecture of <a href=\"https://github.com/PureMVC/puremvc-js-multicore-framework/wiki\" rel=\"nofollow\">PureMVC/JS</a> is the most elegant IMO. I learned a lot from it. I also found <a href=\"http://www.youtube.com/watch?v=vXjVFPosQHw\" rel=\"nofollow\">Scalable JavaScript Application Architecture</a> by Nicholas Zakas helpful in researching client side architecture options.</p>\n\n<p>Two other tips </p>\n\n<ol>\n<li>I've found view, focus, and input management are areas that need special attention in single page web apps </li>\n<li>I also found it helpful to abstract away the JS library, leaving door open to change mind on what you use, or mix &amp; match should the need arise.</li>\n</ol>\n    "},{"t":"What is opinionated software?","l":"http://stackoverflow.com/questions/802050/what-is-opinionated-software","q":"\n\n<p>I often see people saying that certain software is \"very opinionated\" or that Microsoft tends to write \"un-opinionated\" frameworks. What does this actually mean?</p>\n    ","a":"\n<p>If a framework is opinionated, it lock or guides you into their way of doing things.</p>\n\n<p>For example: some people believe that a template system shouldn't provide access to user defined methods and functions as it leaves the system open to returning raw HTML. So an opinionated framework developer only allows access to data structures. By design, the software is limiting and encourages the designer into doing things their way.</p>\n\n<p>Another example (<a href=\"http://gettingreal.37signals.com/ch04%5FMake%5FOpinionated%5FSoftware.php\">taken from the signals link</a>) is that of <a href=\"http://c2.com/cgi/wiki\">wiki</a>. The designers of wiki had a lot of opinions. They thought HTML was too complicated for people to write, so they came up with what they felt was a more natural way to update content. They also stripped it of fancy design because they felt the focus ought to be more on content than design.</p>\n\n<p>Apple has strong opinions when it designs its products.</p>\n\n<p><strong><em>Un-opinionated software design</em></strong> is more like PERL/PHP. It allows the developer and trusts the developer to make the right decisions and puts more control in their hands. </p>\n\n<p>I would also place Microsoft in the non-opinionated column. A good example of a Microsoft framework which is un-opininated: <code>.NET</code>. By opening the CLR and the specs, it opened it to all sorts of languages and styles of implementations. </p>\n    "},{"t":"How to version control a record in a database","l":"http://stackoverflow.com/questions/323065/how-to-version-control-a-record-in-a-database","q":"\n\n<p>Let's say that I have a record in the database and that both admin and normal users can do updates. </p>\n\n<p>Can anyone suggest a good approach/architecture how to version control every change in this table so it's possible to rollback a record to a previous revision.</p>\n    ","a":"\n<p>Let's say you have a <code>FOO</code> table that admins and users can update.  Most of the time you can write queries against the FOO table.  Happy days.</p>\n\n<p>Then, I would create a <code>FOO_HISTORY</code> table.  This has all the columns of the <code>FOO</code> table.  The primary key is the same as FOO plus a RevisionNumber column.  There is a foreign key from <code>FOO_HISTORY</code> to <code>FOO</code>.  You might also add columns related to the revision such as the UserId and RevisionDate.  Populate the RevisionNumbers in an ever-increasing fashion across all the <code>*_HISTORY</code> tables (ie. from an Oracle sequence or equivalent).  Do not rely on there only being one change in a second. ie. do not put <code>RevisionDate</code> into the primary key.</p>\n\n<p>Now, everytime you update <code>FOO</code>, just before you do the update you insert the old values into <code>FOO_HISTORY</code>.  You do this at some fundamental level in your design so that programmers can't accidently miss this step.</p>\n\n<p>If you want to delete a row from <code>FOO</code> you have some choices.  Either cascade and delete all the history, or perform a logical delete by flagging <code>FOO</code> as deleted.</p>\n\n<p>This solution is good when you are largely interested in the current values and only occasionally in the history.  If you always need the history then you can put effective start and end dates and keep all the records in FOO intself.  Every query then needs to check those dates.</p>\n    "},{"t":"Exotic architectures the standards committees care about","l":"http://stackoverflow.com/questions/6971886/exotic-architectures-the-standards-committees-care-about","q":"\n\n<p>I know that the C and C++ standards leave many aspects of the language implementation-defined just because if there is an architecture with other characteristics, it would be very difficult or impossible to write a standard conforming compiler for it.</p>\n\n<p>I know that 40 years ago any computer had its own unique specification. However, I don't know of any architectures used today where:</p>\n\n<ul>\n<li><code>CHAR_BIT != 8</code></li>\n<li><code>signed</code> is not two's complement (I heard Java had problems with this one).</li>\n<li>Floating point is not IEEE 754 compliant (Edit: I meant \"not in IEEE 754 binary encoding\").</li>\n</ul>\n\n<p>The reason I'm asking is that I often explain to people that it's good that C++ doesn't mandate any other low-level aspects like fixed sized types<sup>†</sup>. It's good because unlike 'other languages' it makes your code portable when used correctly. But I feel bad that I cannot point to any specific architecture myself.</p>\n\n<p>So the question is: what architectures exhibit the above properties?</p>\n\n<p>† <code>uint*_t</code>s are optional.</p>\n    ","a":"\n<p>Take a look at this one</p>\n\n<p><a href=\"http://www.unisys.com/unisys/product/productdetail.jsp?id=1120000970004210128&amp;pid=16000034\">Unisys ClearPath Dorado Servers</a></p>\n\n<p>offering backward compatibility for people who have not yet migrated all their Univac software.</p>\n\n<p>Key points:</p>\n\n<ul>\n<li>36 bit words</li>\n<li>CHAR_BIT == 9</li>\n<li>ones complement</li>\n<li>72 bit non-IEEE floating point</li>\n<li>separate address space for code and data</li>\n<li><strike>sizeof(char*) != sizeof(int*)</strike>[maybe not]</li>\n<li>word addressed</li>\n</ul>\n\n<p>Don't know if they offer a C++ compiler though, but they <strong>could</strong>.</p>\n    "},{"t":"AngularJS: Understanding design pattern","l":"http://stackoverflow.com/questions/20286917/angularjs-understanding-design-pattern","q":"\n\n<p><a href=\"https://plus.google.com/110323587230527980117\">AngularJS</a>:  Shared publicly  -  <a href=\"https://plus.google.com/110323587230527980117/posts/aZNVhj355G2\">Jul 19, 2012</a></p>\n\n<blockquote>\n  <p><strong>MVC vs MVVM vs MVP</strong>. What a controversial topic that many developers\n  can spend hours and hours debating and arguing about.</p>\n  \n  <p>For several years AngularJS was closer to MVC (or rather one of its\n  client-side variants), but over time and thanks to many refactorings\n  and api improvements, it's now closer to <strong>MVVM</strong> – the <strong><em>$scope</em></strong> object\n  could be considered the <strong>ViewModel</strong> that is being decorated by a\n  function that we call a <strong>Controller</strong>.</p>\n  \n  <p>Being able to categorize a framework and put it into one of the MV* buckets has some advantages.\n  It can help developers get more comfortable with its apis by making it\n  easier to create a mental model that represents the application that\n  is being built with the framework. It can also help to establish\n  terminology that is used by developers.</p>\n  \n  <p>Having said, I'd rather see developers build kick-ass apps that are\n  well-designed and follow separation of concerns, than see them waste\n  time arguing about MV* nonsense. And for this reason, I hereby declare\n  <strong>AngularJS</strong> to be <strong>MVW framework - Model-View-Whatever</strong>. Where Whatever\n  stands for \"<strong>whatever works for you</strong>\".</p>\n  \n  <p>Angular gives you a lot of flexibility to nicely separate presentation\n  logic from business logic and presentation state. Please use it fuel\n  your productivity and application maintainability rather than heated\n  discussions about things that at the end of the day don't matter that\n  much.</p>\n</blockquote>\n\n<h2>Are there any recommendations or guidelines for implementing AngularJS MVW (Model View Whatever) design pattern in client-side applications?</h2>\n    ","a":"\n<p>Thanks to a huge amount of valuable sources I've got some general recommendations for implementing components in AngularJS apps:</p>\n\n<hr>\n\n<h1>Controller</h1>\n\n<ul>\n<li><p>Controller should be just an <strong>interlayer</strong> between model and view. Try to make it as <strong>thin</strong> as possible.</p></li>\n<li><p>It is highly recommended to <strong>avoid business logic</strong> in controller. It should be moved to model.</p></li>\n<li><p>Controller may communicate with other controllers using method invocation (possible when children wants to communicate with parent) or <em>$emit</em>, <em>$broadcast</em> and <em>$on</em> methods. The emitted and broadcasted messages should be kept to a minimum. </p></li>\n<li><p>Controller should <strong>not care about presentation</strong> or DOM manipulation.</p></li>\n<li><p>Try to <strong>avoid nested controllers</strong>. In this case parent controller is interpreted as model. Inject models as shared services instead.</p></li>\n<li><p><strong>Scope</strong> in controller should be used for <strong>binding</strong> model with view and<br>\nencapsulating <strong>View Model</strong> as for <strong>Presentation Model</strong> design pattern.</p></li>\n</ul>\n\n<hr>\n\n<h1>Scope</h1>\n\n<p>Treat scope as <strong>read-only in templates</strong> and <strong>write-only in controllers</strong>. The purpose of the scope is to refer to model, not to be the model.</p>\n\n<p>When doing bidirectional binding (ng-model) make sure you don't bind directly to the scope properties.</p>\n\n<hr>\n\n<h1>Model</h1>\n\n<p>Model in AngularJS is a <strong>singleton</strong> defined by <strong>service</strong>.</p>\n\n<p>Model provides an excellent way to separate data and display.</p>\n\n<p>Models are prime candidates for unit testing, as they typically have exactly one dependency (some form of event emitter, in common case the <em>$rootScope</em>) and contain highly testable <strong>domain logic</strong>.</p>\n\n<ul>\n<li><p>Model should be considered as an implementation of particular unit.\nIt is based on single-responsibility-principle. Unit is an instance that is responsible for its own scope of related logic that may represent single entity in real world and describe it in programming world in terms of <strong>data and state</strong>.</p></li>\n<li><p>Model should encapsulate your application’s data and provide an <strong>API</strong>\nto access and manipulate that data.</p></li>\n<li><p>Model should be <strong>portable</strong> so it can be easily transported to similar\napplication.</p></li>\n<li><p>By isolating unit logic in your model you have made it easier to\nlocate, update, and maintain.</p></li>\n<li><p>Model can use methods of more general global models that are common\nfor the whole application.</p></li>\n<li><p>Try to avoid composition of other models into your model using dependency injection if it is not really dependent to decrease components coupling and increase unit <strong>testability</strong> and <strong>usability</strong>.</p></li>\n<li><p>Try to avoid using event listeners in models. It makes them harder to test and generally kills models in terms of single-responsibility-principle.</p></li>\n</ul>\n\n<h2>Model Implementation</h2>\n\n<p>As model should encapsulate some logic in terms of data and state, it should architecturally restrict access to its members thus we can guarantee loose coupling.</p>\n\n<p>The way to do it in AngularJS application is to define it using <em>factory</em> service type. This will allow us to define private properties and methods very easy and also return publically accessible ones in single place that will make it really readable for developer.</p>\n\n<p><strong>An example</strong>:</p>\n\n<pre><code>angular.module('search')\n.factory( 'searchModel', ['searchResource', function (searchResource) {\n\n  var itemsPerPage = 10,\n  currentPage = 1,\n  totalPages = 0,\n  allLoaded = false,\n  searchQuery;\n\n  function init(params) {\n    itemsPerPage = params.itemsPerPage || itemsPerPage;\n    searchQuery = params.substring || searchQuery;\n  }\n\n  function findItems(page, queryParams) {\n    searchQuery = queryParams.substring || searchQuery;\n\n    return searchResource.fetch(searchQuery, page, itemsPerPage).then( function (results) {\n      totalPages = results.totalPages;\n      currentPage = results.currentPage;\n      allLoaded = totalPages &lt;= currentPage;\n\n      return results.list\n    });\n  }\n\n  function findNext() {\n    return findItems(currentPage + 1);\n  }\n\n  function isAllLoaded() {\n    return allLoaded;\n  }\n\n  // return public model API  \n  return {\n    /**\n     * @param {Object} params\n     */\n    init: init,\n\n    /**\n     * @param {Number} page\n     * @param {Object} queryParams\n     * @return {Object} promise\n     */\n    find: findItems,\n\n    /**\n     * @return {Boolean}\n     */\n    allLoaded: isAllLoaded,\n\n    /**\n     * @return {Object} promise\n     */\n    findNext: findNext\n  };\n});\n</code></pre>\n\n<h2>Creating new instances</h2>\n\n<p>Try to avoid having a factory that returns a new able function as this begins to break down dependency injection and the library will behave awkwardly, especially for third parties.</p>\n\n<p>A better way to accomplish the same thing is to use the factory as an API to return a collection of objects with getter and setter methods attached to them.</p>\n\n<pre><code>angular.module('car')\n .factory( 'carModel', ['carResource', function (carResource) {\n\n  function Car(data) {\n    angular.extend(this, data);\n  }\n\n  Car.prototype = {\n    save: function () {\n      // TODO: strip irrelevant fields\n      var carData = //...\n      return carResource.save(carData);\n    }\n  };\n\n  function getCarById ( id ) {\n    return carResource.getById(id).then(function (data) {\n      return new Car(data);\n    });\n  }\n\n  // the public API\n  return {\n    // ...\n    findById: getCarById\n    // ...\n  };\n});\n</code></pre>\n\n<h2>Global Model</h2>\n\n<p>In general try to avoid such situations and design your models properly thus it can be injected into controller and used in your view. </p>\n\n<p>In particular case some methods require global accessibility within application.\nTo make it possible you can define ‘<em>common</em>’ property in <em>$rootScope</em> and bind it to <em>commonModel</em> during application bootstrap:</p>\n\n<pre><code>angular.module('app', ['app.common'])\n.config(...)\n.run(['$rootScope', 'commonModel', function ($rootScope, commonModel) {\n  $rootScope.common = 'commonModel';\n}]);\n</code></pre>\n\n<p>All your global methods will live within ‘<em>common</em>’ property. This is some kind of <strong>namespace</strong>.</p>\n\n<p>But do not define any methods directly in your <em>$rootScope</em>. This can lead to <a href=\"http://stackoverflow.com/a/18128502/2230007\">unexpected behavior</a> when used with ngModel directive within your view scope, generally littering your scope and leads to scope methods overriding issues.</p>\n\n<hr>\n\n<h1>Resource</h1>\n\n<p>Resource lets you interact with different <strong>data sources</strong>. </p>\n\n<p>Should be implemented using <strong>single-responsibility-principle</strong>.</p>\n\n<p>In particular case it is a <strong>reusable</strong> proxy to HTTP/JSON endpoints.</p>\n\n<p>Resources are injected in models and provide possibility to send/retrieve data.</p>\n\n<h2>Resource implementation</h2>\n\n<p>A factory which creates a resource object that lets you interact with RESTful server-side data sources.</p>\n\n<p>The returned resource object has action methods which provide high-level behaviors without the need to interact with the low level $http service.</p>\n\n<hr>\n\n<h1>Services</h1>\n\n<p><strong>Both model and resource are services</strong>.</p>\n\n<p>Services are unassociated, <strong>loosely coupled</strong> units of functionality that are self-contained.</p>\n\n<p>Services are a feature that Angular brings to client-side web apps from the server side, where services have been commonly used for a long time.</p>\n\n<p>Services in Angular apps are substitutable objects that are wired together using dependency injection.</p>\n\n<p>Angular comes with different types of services. Each one with its own use cases. Please read <a href=\"http://angular-tips.com/blog/2013/08/understanding-service-types/\">Understanding Service Types</a> for details.</p>\n\n<p>Try to consider <a href=\"http://en.wikipedia.org/wiki/Service-oriented_architecture#Principles\">main principles of service architecture</a> in your application.</p>\n\n<p>In general according to <a href=\"http://www.w3.org/TR/ws-gloss/#service\">Web Services Glossary</a>:</p>\n\n<blockquote>\n  <p>A service is an abstract resource that represents a capability of\n  performing tasks that form a coherent functionality from the point of\n  view of providers entities and requesters entities. To be used, a\n  service must be realized by a concrete provider agent.</p>\n</blockquote>\n\n<hr>\n\n<h1>Client-side structure</h1>\n\n<p>In general client side of the application is splitted into <strong>modules</strong>. Each module should be <strong>testable</strong> as a unit.</p>\n\n<p>Try to define modules depending on <strong>feature/functionality</strong> or <strong>view</strong>, not by type. \nSee <a href=\"http://www.youtube.com/watch?v=ZhfUv0spHCY&amp;feature=share&amp;t=34m19s\">Misko’s presentation</a> for details.</p>\n\n<p>Module components may be conventionally grouped by types such as controllers, models, views, filters, directives etc.</p>\n\n<p>But module itself remains <strong>reusable</strong>, <strong>transferable</strong> and <strong>testable</strong>.</p>\n\n<p>It is also much easier for developers to find some parts of code and all its dependencies. </p>\n\n<p>Please refer to <a href=\"http://cliffmeyers.com/blog/2013/4/21/code-organization-angularjs-javascript\">Code Organization in Large AngularJS and JavaScript Applications</a> for details.</p>\n\n<p><strong>An example of folders structuring</strong>:</p>\n\n<pre><code>|-- src/\n|   |-- app/\n|   |   |-- app.js\n|   |   |-- home/\n|   |   |   |-- home.js\n|   |   |   |-- homeCtrl.js\n|   |   |   |-- home.spec.js\n|   |   |   |-- home.tpl.html\n|   |   |   |-- home.less\n|   |   |-- user/\n|   |   |   |-- user.js\n|   |   |   |-- userCtrl.js\n|   |   |   |-- userModel.js\n|   |   |   |-- userResource.js\n|   |   |   |-- user.spec.js\n|   |   |   |-- user.tpl.html\n|   |   |   |-- user.less\n|   |   |   |-- create/\n|   |   |   |   |-- create.js\n|   |   |   |   |-- createCtrl.js\n|   |   |   |   |-- create.tpl.html\n|   |-- common/\n|   |   |-- authentication/\n|   |   |   |-- authentication.js\n|   |   |   |-- authenticationModel.js\n|   |   |   |-- authenticationService.js\n|   |-- assets/\n|   |   |-- images/\n|   |   |   |-- logo.png\n|   |   |   |-- user/\n|   |   |   |   |-- user-icon.png\n|   |   |   |   |-- user-default-avatar.png\n|   |-- index.html\n</code></pre>\n\n<p>Good example of angular application structuring is implemented by <em>angular-app</em> - <a href=\"https://github.com/angular-app/angular-app/tree/master/client/src\">https://github.com/angular-app/angular-app/tree/master/client/src</a></p>\n\n<p>This is also considered by modern application generators - <a href=\"https://github.com/yeoman/generator-angular/issues/109\">https://github.com/yeoman/generator-angular/issues/109</a></p>\n    "},{"t":"How To Create a Flexible Plug-In Architecture?","l":"http://stackoverflow.com/questions/2768104/how-to-create-a-flexible-plug-in-architecture","q":"\n\n<p>A repeating theme in my development work has been the use of or creation of an in-house plug-in architecture.  I've seen it approached many ways - configuration files (XML, .conf, and so on), inheritance frameworks, database information, libraries, and others.  In my experience:</p>\n\n<ul>\n<li>A database isn't a great place to store your configuration information, especially co-mingled with data</li>\n<li>Attempting this with an inheritance hierarchy requires knowledge about the plug-ins to be coded in, meaning the plug-in architecture isn't all that dynamic</li>\n<li>Configuration files work well for providing simple information, but can't handle more complex behaviors</li>\n<li>Libraries seem to work well, but the one-way dependencies have to be carefully created.</li>\n</ul>\n\n<p>As I seek to learn from the various architectures I've worked with, I'm also looking to the community for suggestions.  How have you implemented a solid plug-in architecture?  What was your worst failure (or the worst failure you've seen)?  What would you do if you were going to implement a new plug-in architecture?  What SDK or open source project that you've worked with has the best example of a good architecture?</p>\n\n<p>A few examples I've been finding on my own:</p>\n\n<ul>\n<li>Perl's <a href=\"http://search.cpan.org/~simonw/Module-Pluggable-3.9/lib/Module/Pluggable.pm\" rel=\"nofollow\">Module::Plugable</a> and <a href=\"http://www.drdobbs.com/web-development/184416179\" rel=\"nofollow\">IOC</a> for dependency injection in Perl</li>\n<li><a href=\"http://www.springsource.org/\" rel=\"nofollow\">The various Spring frameworks</a> (Java, .NET, Python) for dependency injection.</li>\n<li>An <a href=\"http://stackoverflow.com/questions/1613935/java-plugin-framework-choice\">SO question</a> with a list for Java (including <a href=\"http://en.wikipedia.org/wiki/Service_Provider_Interface\" rel=\"nofollow\">Service Provider Interfaces</a>)</li>\n<li>An <a href=\"http://stackoverflow.com/questions/43322/whats-safe-for-a-c-plug-in-system\">SO question</a> for C++ pointing to a <a href=\"http://www.drdobbs.com/cpp/204202899;jsessionid=2P021EF4CUUAFQE1GHPSKH4ATMY32JVN?cid=RSSfeed%255FDDJ%255FCpp\" rel=\"nofollow\">Dr. Dobbs article</a></li>\n<li>An <a href=\"http://stackoverflow.com/questions/340183/plug-in-architecture-for-asp-net-mvc\">SO question</a> regarding a specific plugin idea for ASP.NET MVC</li>\n</ul>\n\n<p>These examples seem to play to various language strengths.  Is a good plugin architecture necessarily tied to the language?  Is it best to use tools to create a plugin architecture, or to do it on one's own following models?</p>\n    ","a":"\n<p>This is not an <em>answer</em> as much as a bunch of potentially useful remarks/examples. </p>\n\n<ul>\n<li><p>One effective way to make your application extensible is to expose its internals as a scripting language and write all the top level stuff in that language. This makes it quite modifiable and practically future proof (if your primitives are well chosen and implemented). A success story of this kind of thing is Emacs. I prefer this to the eclipse style plugin system because if I want to extend functionality, I don't have to learn the API and write/compile a separate plugin. I can write a 3 line snippet in the current buffer itself, evaluate it and use it. Very smooth learning curve and very pleasing results. </p></li>\n<li><p>One application which I've extended a little is <a href=\"http://trac.edgewall.org/wiki/TracDev/ComponentArchitecture\" rel=\"nofollow\">Trac</a>. It has a component architecture which in this situation means that tasks are delegated to modules that advertise extension points. You can then implement other components which would fit into these points and change the flow. It's a little like Kalkie's suggestion above. </p></li>\n<li><p>Another one that's good is <a href=\"http://pytest.org/latest/index.html\" rel=\"nofollow\">py.test</a>. It follows the \"best API is no API\" philosophy and relies purely on hooks being called at every level. You can override these hooks in files/functions named according to a convention and alter the behaviour. You can see the list of plugins on the site to see how quickly/easily they can be implemented. </p></li>\n</ul>\n\n<p>A few general points. </p>\n\n<ul>\n<li>Try to keep your non-extensible/non-user-modifiable core as small as possible. Delegate everything you can to a higher layer so that the extensibility increases. Less stuff to correct in the core then in case of bad choices. </li>\n<li>Related to the above point is that you shouldn't make too many decisions about the direction of your project at the outset. Implement the smallest needed subset and then start writing plugins. </li>\n<li>If you are embedding a scripting language, make sure it's a full one in which you can write general programs and not a toy language <em>just</em> for your application. </li>\n<li>Reduce boilerplate as much as you can. Don't bother with subclassing, complex APIs, plugin registration and stuff like that. Try to keep it simple so that it's <em>easy</em> and not just <em>possible</em> to extend. This will let your plugin API be used more and will encourage end users to write plugins. Not just plugin developers. py.test does this well. Eclipse as far as I know, <a href=\"http://help.eclipse.org/help33/index.jsp?topic=/org.eclipse.platform.doc.isv/reference/api/org/eclipse/core/runtime/Plugin.html\" rel=\"nofollow\">does not</a>. </li>\n</ul>\n    "},{"t":"In Flux architecture, how do you manage Store lifecycle?","l":"http://stackoverflow.com/questions/23591325/in-flux-architecture-how-do-you-manage-store-lifecycle","q":"\n\n<p>I'm reading about <a href=\"https://facebook.github.io/flux/docs/overview.html\" rel=\"nofollow\">Flux</a> but the <a href=\"https://github.com/facebook/flux/tree/master/examples/flux-todomvc\" rel=\"nofollow\">example Todo app</a> is too simplistic for me to understand some key points.</p>\n\n<p>Imagine a single-page app like Facebook that has <strong>user profile pages</strong>. On each user profile page, we want to show some user info and their last posts, with infinite scroll. We can navigate from one user profile to another one.</p>\n\n<p>In Flux architecture, how would this correspond to Stores and Dispatchers?  </p>\n\n<p>Would we use one <code>PostStore</code> per user, or would we have some kind of a global store?  What about dispatchers, would we create  a new Dispatcher for each “user page”, or would we use a singleton? Finally, what part of the architecture is responsible for managing the lifecycle of “page-specific” Stores in response to route change?</p>\n\n<p>Moreover, a single pseudo-page may have several lists of data of the same type. For example, on a profile page, I want to show both <em>Followers</em> and <em>Follows</em>. How can a singleton <code>UserStore</code> work in this case? Would <code>UserPageStore</code> manage <code>followedBy: UserStore</code> and <code>follows: UserStore</code>?</p>\n    ","a":"\n<p>In a Flux app there should only be one Dispatcher.  All data flows through this central hub.  Having a singleton Dispatcher allows it to manage all Stores.  This becomes important when you need Store #1 update itself, and then have Store #2 update itself based on both the Action and on the state of Store #1.  Flux assumes this situation is an eventuality in a large application.  Ideally this situation would not need to happen, and developers should strive to avoid this complexity, if possible.  But the singleton Dispatcher is ready to handle it when the time comes.</p>\n\n<p>Stores are singletons as well.  They should remain as independent and decoupled as possible -- a self-contained universe that one can query from a Controller-View.  The only road into the Store is through the callback it registers with the Dispatcher.  The only road out is through getter functions.  Stores also publish an event when their state has changed, so Controller-Views can know when to query for the new state, using the getters.</p>\n\n<p>In your example app, there would be a single <code>PostStore</code>.  This same store could manage the posts on a \"page\" (pseudo-page) that is more like FB's Newsfeed, where posts appear from different users.  Its logical domain is the list of posts, and it can handle any list of posts.  When we move from pseudo-page to pseudo-page, we want to reinitialize the state of the store to reflect the new state.  We might also want to cache the previous state in localStorage as an optimization for moving back and forth between pseudo-pages, but my inclination would be to set up a <code>PageStore</code> that waits for all other stores, manages the relationship with localStorage for all the stores on the pseudo-page, and then updates its own state.  Note that this <code>PageStore</code> would store nothing about the posts -- that's the domain of the <code>PostStore</code>.  It would simply know whether a particular pseudo-page has been cached or not, because pseudo-pages are its domain.</p>\n\n<p>The <code>PostStore</code> would have an <code>initialize()</code> method.  This method would always clear the old state, even if this is the first initialization, and then create the state based on the data it received through the Action, via the Dispatcher.  Moving from one pseudo-page to another would probably involve a <code>PAGE_UPDATE</code> action, which would trigger the invocation of <code>initialize()</code>.  There are details to work out around retrieving data from the local cache, retrieving data from the server, optimistic rendering and XHR error states, but this is the general idea.</p>\n\n<p>If a particular pseudo-page does not need all the Stores in the application, I'm not entirely sure there is any reason to destroy the unused ones, other than memory constraints.  But stores don't typically consume a great deal of memory.  You just need to make sure to remove the event listeners in the Controller-Views you are destroying.  This is done in React's <code>componentWillUnmount()</code> method.</p>\n    "},{"t":"How to learn “good software design/architecture”? [closed]","l":"http://stackoverflow.com/questions/268231/how-to-learn-good-software-design-architecture","q":"\n\n<p>I just listened to a discussion about a project drifting away from the direction it's supposed to go. The problem was \"bad software design\".</p>\n\n<p>Components are not designed to be re-used; the software is hard to maintain, test, extense, and scales poorly.</p>\n\n<p>What did the programmers do wrong? Where/how to learn better techniques?</p>\n\n<p>Of course, there are the GoF patterns... but that's not all, is it?</p>\n    ","a":"\n<p>The quality of software design will improve with real world industry experience.</p>\n\n<p>No university and college degree is a substitute for working in a real job developing real software.</p>\n\n<p>Books such as <a href=\"http://cc2e.com\">Code Complete</a> by Steve McConnell are also invaluable resources.</p>\n    "},{"t":"How do you plan an application's architecture before writing any code? [closed]","l":"http://stackoverflow.com/questions/292463/how-do-you-plan-an-applications-architecture-before-writing-any-code","q":"\n\n<p>One thing I struggle with is planning an application's architecture before writing any code.</p>\n\n<p>I don't mean gathering requirements to narrow in on what the application needs to do, but rather effectively thinking about a good way to lay out the overall class, data and flow structures, and iterating those thoughts so that I have a credible plan of action in mind before even opening the IDE. At the moment it is all to easy to just open the IDE, create a blank project, start writing bits and bobs and let the design 'grow out' from there.</p>\n\n<p>I gather UML is one way to do this but I have no experience with it so it seems kind of nebulous.</p>\n\n<p>How do <strong>you</strong> plan an application's architecture before writing any code? If UML is the way to go, can you recommend a concise and practical introduction for a developer of smallish applications?</p>\n\n<p>I appreciate your input.</p>\n    ","a":"\n<p>I really find that a first-off of writing on paper or whiteboard is really crucial. Then move to UML if you want, but nothing beats the flexibility of just drawing it by hand at first.</p>\n    "},{"t":"C Macro definition to determine big endian or little endian machine?","l":"http://stackoverflow.com/questions/2100331/c-macro-definition-to-determine-big-endian-or-little-endian-machine","q":"\n\n<p>Is there a one line macro definition to determine the endianness of the machine. I am using the following code but converting it to macro would be too long.</p>\n\n<pre><code>unsigned char test_endian( void )\n{\n    int test_var = 1;\n    unsigned char test_endian* = (unsigned char*)&amp;test_var;\n\n    return (test_endian[0] == NULL);\n}\n</code></pre>\n    ","a":"\n<p>Code supporting arbitrary byte orders, ready to be put into a file called <code>order32.h</code>:</p>\n\n<pre><code>#ifndef ORDER32_H\n#define ORDER32_H\n\n#include &lt;limits.h&gt;\n#include &lt;stdint.h&gt;\n\n#if CHAR_BIT != 8\n#error \"unsupported char size\"\n#endif\n\nenum\n{\n    O32_LITTLE_ENDIAN = 0x03020100ul,\n    O32_BIG_ENDIAN = 0x00010203ul,\n    O32_PDP_ENDIAN = 0x01000302ul\n};\n\nstatic const union { unsigned char bytes[4]; uint32_t value; } o32_host_order =\n    { { 0, 1, 2, 3 } };\n\n#define O32_HOST_ORDER (o32_host_order.value)\n\n#endif\n</code></pre>\n\n<p>You would check for little endian systems via</p>\n\n<pre><code>O32_HOST_ORDER == O32_LITTLE_ENDIAN\n</code></pre>\n    "},{"t":"Why do we need RESTful Web Services?","l":"http://stackoverflow.com/questions/1368014/why-do-we-need-restful-web-services","q":"\n\n<p>I'm going to learn RESTful web services (it's better to say that I'll have to do this because it's a part of CS master degree program). </p>\n\n<p>I've read some info in Wikipedia and I've also read an article about REST at Sun Developer Network and I see that it's not easy technology, there are special frameworks for building RESTful apps, and it's often being compared to SOAP web services and programmer should understand when to use SOAP and when REST could be nice approach.</p>\n\n<p>I remember that several years ago SOAP was very popular (fashionable?) and item 'SOAP' had to be present in every good CV. But in practice it was used very rarely and for achieving very simple purposes.</p>\n\n<p>It seems to me that REST is another 'last word of fashion' (or I can be totally wrong because I haven't ever seen REST in practice).</p>\n\n<p>Can you give me some examples were REST should be used and why we can't do the same without REST (or why we should spend much more time to do the same without REST)?  </p>\n\n<p><strong>UPD</strong>: Unfortunatelly I can't see any concrete arguments which can blow my mind in first comments. Make me think that REST is awesome technology!</p>\n\n<p>I'd like to see answers like this:</p>\n\n<blockquote>\n  <p>I was developing another complex\n  HelloWorld application and we need to \n  transfer lots of / tiny data and I\n  proposed REST solution to my workmate:</p>\n  \n  <p>– Oh, damn! Jonny, we should\n  certainly use REST for implementing\n  this app!<br> – Yes, Billy, we\n  can use REST, but we would better use\n  SOAP. Trust me 'cause I know something\n  about developing HelloWorld\n  applications.<br> – But SOAP is\n  old-fashioned technology from the last\n  century and we can use better\n  one.<br> – Billy, are you ready\n  to spent 3 days for experimenting with\n  REST? We can do this with SOAP in 2\n  hours..<br> – Yes, I'm sure\n  that we'll spent even more time to\n  achieve the same security/performance/\n  /scalability/whatever else with SOAP.\n  I'm sure that HelloWorld applications\n  should be developed only with REST\n  from now.</p>\n</blockquote>\n    ","a":"\n<p>REST should be used if it is very important for you to <strong>minimize the coupling</strong> between client and server components in a distributed application.</p>\n\n<p>This may be the case if your server is going to be used by <strong>many different clients</strong> that you do not have control over.  It may also be the case if you want to be able to <strong>update the server regularly</strong> without needing to update the client software.</p>\n\n<p>I can assure you that achieving this low level of coupling is <strong>not easy to do</strong>.  It is critical to follow all of the constraints of REST to succeed.  Maintaining a purely stateless connection is difficult.  Picking the right media-types and squeezing your data into the formats is tricky.  Creating your own media types can be even harder. </p>\n\n<p>Adapting rich server behaviour into the uniform HTTP interface can be confusing and at times appears pedantic in comparison to the relatively straightforward RPC approach.</p>\n\n<p>Despite the difficulties, the benefits are that you have a service that a client developer should be able to easily understand due to the consistent use of the HTTP protocol.  The service should be <strong>easily discoverable due to hypermedia</strong> and the client should be extremely <strong>resilient to changes on the server</strong>.</p>\n\n<p>The benefits of hypermedia and the avoidance of session state makes load balancing simple and <strong>service partitioning feasible</strong>.  The strict conformance to HTTP rules make the availability of tools like debuggers and caching proxies wonderful thing. </p>\n\n<p><strong>Update</strong></p>\n\n<blockquote>\n  <p>It seems to me that REST is another\n  'last word of fashion' (or I can be\n  totally wrong because I haven't ever\n  seen REST in practice).</p>\n</blockquote>\n\n<p>I think REST has become fashionable because people attempting to do SOA type projects have found that using the SOAP stack they are not realizing the benefits that were promised.  People keep turning back to the web as an example of simple integration methodologies.  Unfortunately, I think people underestimate the amount of planning and foresight that went into creating the web and they oversimplify what needs to be done to allow the kind of serendipitous reuse that does occur on the web.</p>\n\n<p>You say that you have never seen REST in practice, but that cannot possibly be true if you ever use a web browser.  The web browser is a REST client.</p>\n\n<ul>\n<li>Why do you not need to do a browser\nupdate when someone changes some html\non a web site?</li>\n<li>Why can I add a complete new set of\npages to a web site and the \"client\"\ncan still access those new pages\nwithout an update?</li>\n<li>Why do I not need to provide a\n\"service-description-language\" to the\nweb browser to tell it when it goes\nto <em><a href=\"http://example.org/images/cat\">http://example.org/images/cat</a></em> that\nthe return type will be a jpeg image\nand when you go to\n<em><a href=\"http://example.org/description/cat\">http://example.org/description/cat</a></em>\nthe return type will be text/html?</li>\n<li>Why can I use a web browser to visit\nsites that did not exist when the\nbrowser was released?  How can the\nclient know about these sites?</li>\n</ul>\n\n<p>These may sound like inane questions, but if you know the answer, then you can start to see what REST is all about.\nLook at StackOverflow for more benefits of REST.  When I am looking at a question, I can bookmark that page or <strong>send the url to a friend</strong> and he can see the same information.  He doesn't have to navigate through the site to find that question.  </p>\n\n<p>StackOverflow uses a variety of OpenId services for authentication, gravatar.com for avatar images, google-analytics and Quantserve for analytical information.   This kind of multi-company integration is the type of thing the <strong>SOAP world only dreams of</strong>.  One of the best examples is the fact that the jQuery libraries that are used to drive the StackOverflow UI are retrieved from Google's Content Delivery Network.  The fact that SO could direct the client (i.e. your web browser) to download code from a third-party site to improve performance is testament to the low coupling between web client and server.</p>\n\n<p>These are examples of a REST architecture at work.  </p>\n\n<p>Now some web sites / applications do <strong>break the rules of REST</strong> and then the browser does not work as expected.  </p>\n\n<ul>\n<li>The infamous <strong>back button problem</strong>\nis caused by using server side\nsession state.</li>\n<li>Load balancing can become a pain when\nyou have server side session state.</li>\n<li>Flash applications often prevent the\nURL from specifically identifying a\nrepresentation.</li>\n<li>The other problem that breaks web\nbrowsers is poor conformance to\nmedia-type standards. We hear all of\nthe time about how IE6 needs to be\nkilled.  The problem there is that\nstandards were not properly followed,\nor were ignored for whatever reason.</li>\n<li>The use of login sessions are the\nsource of many security holes.</li>\n</ul>\n\n<p>REST is everywhere.  It is the part of the web that makes it work well.  If you want to build distributed applications that can scale like the web, be resilient to change like the web and promote re-use as the web has done, then follow the same rules they did when building web browsers.</p>\n    "},{"t":"Java getter chaining bad or good? [closed]","l":"http://stackoverflow.com/questions/8744668/java-getter-chaining-bad-or-good","q":"\n\n<p>To prevent monster constructors and monster interfaces with oversized delegating classes, I use alot of classes that hold other objects which again hold other objects. Therefore my code looks like this alot.</p>\n\n<pre><code>this.mainObject.getA().getAB().getABA().getABAC().doSomething();\n</code></pre>\n\n<p>The style checking packages don't compain about this and metrics on loose coupling are OK. I know there is <a href=\"http://stackoverflow.com/questions/1103985/method-chaining-why-is-it-a-good-practice-or-not\">this question</a> on method chaining, but it is not quite the same as getter chaining, on which I can find little guidance. Is my way \"correct\", or is there a better design pattern? Or is the truth somewhere in between and one should use chained getters only if their length is smaller than e.g. 5?</p>\n\n<p>I'm looking for a best pratice style or even some style standard if such exists.</p>\n    ","a":"\n<p>Aside from what others have said about null references, you of course have the Law of Demeter. Other answers have done a pretty good job of describing the Law of Demeter, but I think its worth clarifying some exceptions as called out in <a href=\"http://rads.stackoverflow.com/amzn/click/0132350882\">Clean Code</a>.</p>\n\n<p>According to Martin, the law of demeter doesn't apply in purely data/structural (ie \"struct like\") relationships. IE <code>Student.GetAddress().GetStreetName()</code> is perfectly acceptable. Martin actually advocates using plain structs for these kinds of relationships, but alas this is Java. The Law of Demeter however, would apply if you involved mutators, or provided writable access to an internal class with mutators  ie <code>Student.GetLastTest().ChangeGradeToA()</code> becomes more problematic because you are probably intending to perform an operation on Student that could easily have a better name. Moreover you are tightly coupling the client of Student to whatever GetLastTest returns.</p>\n\n<p>As I <a href=\"http://ilearnstuff.blogspot.com/2011/04/just-facts-maam.html\">advocate</a> its always advisable to cleanly separate data/structural relationships from relationships where one class is attempting to act on another.</p>\n    "},{"t":"Why should I isolate my domain entities from my presentation layer?","l":"http://stackoverflow.com/questions/821276/why-should-i-isolate-my-domain-entities-from-my-presentation-layer","q":"\n\n<p>One part of domain-driven design that there doesn't seem to be a lot of detail on, is how and why you should isolate your domain model from your interface. I'm trying to convince my colleagues that this is a good practice, but I don't seem to be making much headway...</p>\n\n<p>They use domain entities where ever they please in the presentation and interface layers. When I argue to them that they should be using display models or DTOs to insulate the Domain layer from the interface layer, they counter that they don't see the business value in doing something like that, because now you have a UI object to maintain as well as the original domain object.  </p>\n\n<p>So I'm looking for some concrete reasons I can use to back this up. Specifically:</p>\n\n<ol>\n<li>Why should we not use domain objects in our presentation layer?<br>\n(if the answer is the obvious one, 'decoupling', then please explain why this is important in this context)</li>\n<li>Should we use additional objects or constructs to isolate our domain objects from the interface?</li>\n</ol>\n    ","a":"\n<p>Quite simply, the reason is one of implementation and drift.  Yes, your presentation layer needs to know about your business objects to be able to represent them properly.  Yes, initially it looks like there is a lot of overlap between the implementation of the two types of objects.  The problem is, as time goes on, things get added on both sides.  Presentation changes, and the needs of the presentation layer evolve to include things that are completely independent of your business layer (color, for example).  Meanwhile, your domain objects change over time, and if you don't have appropriate decoupling from your interface, you run the risk of screwing up your interface layer by making seemingly benign changes to your business objects.</p>\n\n<p>Personally, I believe the best way to approach things is through the strictly enforced interface paradigm; that is, your business object layer exposes an interface that is the only way that it can be communicated with; no implementation details (i.e. domain objects) about the interface are exposed.  Yes, this means that you have to implement your domain objects in two locations; your interface layer and in your BO layer.  But that reimplementation, while it may initially seem like extra work, helps enforce the decoupling that will save TONS of work at some point in the future.</p>\n    "},{"t":"what is Data Transfer Object?","l":"http://stackoverflow.com/questions/1051182/what-is-data-transfer-object","q":"\n\n<p>what is a Data Transfer Object?</p>\n\n<p>In MVC are the model classes DTO, and if not what are the differences and do we need both?</p>\n    ","a":"\n<p>A Data Transfer Object is an object that is used to encapsulate data, and send it from one subsystem of an application to another.</p>\n\n<p>DTOs are most commonly used by the Services layer in an N-Tier application to transfer data between itself and the UI layer. The main benefit here is that it reduces the amount of data that needs to be sent across the wire in distributed applications. They also make great models in the MVC pattern.</p>\n\n<p>Another use for DTOs can be to encapsulate parameters for method calls. This can be useful if a method takes more than 4 or 5 parameters.</p>\n\n<p>When using the DTO pattern, you would also make use of DTO assemblers. The assemblers are used to create DTOs from Domain Objects, and vice versa.</p>\n\n<p>The conversion from Domain Object to DTO and back again can be a costly process. If you're not creating a distributed application, you probably won't see any great benefits from the pattern, as <a href=\"http://martinfowler.com/bliki/LocalDTO.html\">Martin Fowler explains here</a></p>\n    "},{"t":"Fat model / thin controller vs. Service layer [closed]","l":"http://stackoverflow.com/questions/8735466/fat-model-thin-controller-vs-service-layer","q":"\n\n<p>I have been developing enterprise applications for many years using .Net \nMy apps usually have a domain model containing entities mapping to SQL DB tables.\nI use a Repository pattern, Dependency injection and a service layer.</p>\n\n<p>Recently we started working on MVC 3 projects and we had a debate where to put which logic.\nI came accross thin Controller / FAT Model architecture and was wondering how the service layer would fit in</p>\n\n<h2>Option 1 - Model talks to services</h2>\n\n<p>Controller is thin, calls methods on the models. The models \"know\" how to load themselfs from the DB and talk to repositories or services.\nE.g. customerModel has a Load(id) method and loads the customer and some child objects like GetContracts().</p>\n\n<h2>Option 2 - Controller talks to services</h2>\n\n<p>Controller asks Services to retrieve model objects. The logic of loading / storing etc. Is in the service layer. The model is a pure entity model with data only.</p>\n\n<p>Why would option 1 be a better choice especially when we talk about enterprise applictions my experience tells me to separate concerns, keep models AND Controllers as thin as possible and have specialized services doing the Business logic (imcl. The DB interaction)</p>\n\n<p>Thanks for all advices and references to good resources.</p>\n    ","a":"\n<p>All of this depends on the intention and requirements of your application. </p>\n\n<p>That said, here's my suggestion for \"mid scale\" (not a local restaurant, and not Twitter/Facebook) web applications.</p>\n\n<ol>\n<li><p><strong>Lean Domain Modeling</strong></p>\n\n<p>Dry POCO style objects, preferably ignorant to the MVC architecture of your web application to remain as loosely coupled from your particular implementation as possible.perhaps even class library repack-able for use in an external application, say a REST API via a WCF Web Service).</p>\n\n<p>\"Model\" in MVC most accurately means <em>the model the Controller is aware of</em> and thus the <em>the model intended for the View</em>. </p>\n\n<p>In smaller (often Tutorial) applications the entity models of your \"Application/Domain Model Layer\" are often the same instantiated objects the controller ships off to a View. </p>\n\n<p>In larger applications developers often employ the tenets of MVVM architecture and begin using separate View Model objects. The controllers often call middle-tier services that work with the unseen entities below. In this scenario, the M in MVC most accurately means the View Model.</p></li>\n<li><p><strong>Robust Service Layer</strong></p>\n\n<p>This does not mean <em>obese</em> logic, but well-written single purpose services. While coding your business logic in services outside of the model is a bit more \"procedural\" than it is pure \"OOP\", it helps a lot with loose coupling, testing, and flexible deployment (ex. n-tier deployment).</p>\n\n<p>In my personal practice, I code services both down at the data layer, which I consider my behavioral modeling of the POCO objects (persistence mechanics, low level validation, etc.), and higher level services (business/workflow function) up closer to the MVC mechanics.</p></li>\n<li><p><strong>Lean Controllers</strong> </p>\n\n<p>I make sure my controller is merely <em>the coach</em>, in that it is neither the <em>play</em> (services) or the <em>player</em> (entity model or view model), but simply decides who plays what position and what play to make. My controllers do two things:</p>\n\n<ol>\n<li><p>Call services that interact with the entity/domain Models</p></li>\n<li><p>Prepare a View Model for the appropriate View. </p></li>\n</ol>\n\n<p>Even authenticated/authorized controller actions are done via injected services/attributes.</p></li>\n</ol>\n\n<hr>\n\n<p><strong>EDIT 1:</strong> </p>\n\n<p>Keep in mind, that this does not mean your Entity/Domain Model is or must be anemic. ORMs, repositories and factories, validation or state mechanics are welcome. It only means for applications of moderate scale, the <em>Model</em> in MVC represents <em>the model meant for the controller, to hand off to your View</em>.</p>\n\n<p>Hopefully this point will calm Fowler apostles who believe the <em>anemic data model</em> to be an <em>anti-pattern</em>. At the same time, it <em>does</em> reflect a slightly more procedural angle than OOP where it is more pure to include behavior in the modeled classes.</p>\n\n<p>There is no \"ultimate truth\", but using this pattern you'll find it easy to build, test, and deploy your applications - while maintaining a lot of re-usability and scalability.</p>\n\n<hr>\n\n<p><strong>EDIT 2:</strong></p>\n\n<p>That said, even for modestly sized applications, over architecting (that a word nerds made up?) a system is much too common. For instance, wrapping an ORM with a repository pattern, and then writing services to use the repository... all this is good for separation of concern and such, but if your project doesn't require (and is not very likely to <em>soon</em> require) such things, don't build it. There is nothing wrong with skipping the repository all together, writing thin business services (ex. query classes) against an ORM, or even having your controller talk directly to it. It all depends on scale.</p>\n\n<hr>\n\n<p><strong>EDIT 3:</strong></p>\n\n<p>I wanted to note that this explanation and advice is for the context of server-side MVC architecture like ASP.Net, not for clent-side frameworks like Knockout or Backbone.</p>\n    "},{"t":"When are you truly forced to use UUID as part of the design?","l":"http://stackoverflow.com/questions/703035/when-are-you-truly-forced-to-use-uuid-as-part-of-the-design","q":"\n\n<p>I don't really see the point of <a href=\"http://en.wikipedia.org/wiki/UUID\">UUID</a>.  I know the probability of a collision is <em>effectively nil</em>, but <em>effectively nil</em> is not even close to impossible.</p>\n\n<p>Can somebody give an example where you have no choice but to use UUID?  From all the uses I've seen, I can see an alternative design without UUID.  Sure the design might be slightly more complicated, but at least it doesn't have a non-zero probability of failure.</p>\n\n<p>UUID smells like global variables to me.  There are many ways global variables make for simpler design, but its just lazy design.</p>\n    ","a":"\n<p>I wrote the UUID generator/parser for Ruby, so I consider myself to be reasonably well-informed on the subject. There are four major UUID versions:</p>\n\n<p>Version 4 UUIDs are essentially just 16 bytes of randomness pulled from a cryptographically secure random number generator, with some bit-twiddling to identify the UUID version and variant. These are extremely unlikely to collide, but it could happen if a PRNG is used or if you just happen to have really, really, really, really, really bad luck.</p>\n\n<p>Version 5 and Version 3 UUIDs use the SHA1 and MD5 hash functions respectively, to combine a namespace with a piece of already unique data to generate a UUID. This will, for example, allow you to produce a UUID from a URL. Collisions here are only possible if the underlying hash function also has a collision.</p>\n\n<p>Version 1 UUIDs are the most common. They use the network card's MAC address (which unless spoofed, should be unique), plus a timestamp, plus the usual bit-twiddling to generate the UUID. In the case of a machine that doesn't have a MAC address, the 6 node bytes are generated with a cryptographically secure random number generator. If two UUIDs are generated in sequence fast enough that the timestamp matches the previous UUID, the timestamp is incremented by 1. Collisions should not occur unless one of the following happens: The MAC address is spoofed; One machine running two different UUID generating applications produces UUIDs at the exact same moment; Two machines without a network card or without user level access to the MAC address are given the same random node sequence, and generate UUIDs at the exact same moment; We run out of bytes to represent the timestamp and rollover back to zero.</p>\n\n<p>Realistically, none of these events occur by accident within a single application's ID space. Unless you're accepting IDs on, say, an Internet-wide scale, or with an untrusted environment where malicious individuals might be able to do something bad in the case of an ID collision, it's just not something you should worry about. It's critical to understand that if you happen to generate the same version 4 UUID as I do, in most cases, it doesn't matter. I've generated the ID in a completely different ID space from yours. My application will never know about the collision so the collision doesn't matter. Frankly, in a single application space without malicious actors, the extinction of all life on earth will occur long before you have a collision, even on a version 4 UUID, even if you're generating quite a few UUIDs per second.</p>\n\n<p>Also, 2^64 * 16 is 256 exabytes. As in, you would need to store 256 exabytes worth of IDs before you had a 50% chance of an ID collision in a single application space.</p>\n    "},{"t":"Fowler's “Patterns of Enterprise Application Architecture” still relevant? [closed]","l":"http://stackoverflow.com/questions/692241/fowlers-patterns-of-enterprise-application-architecture-still-relevant","q":"\n\n<p>I'm thinking of buying Martin Fowler's \"Patterns of Enterprise Application Architecture\".</p>\n\n<p>From what I can see it seems like a great book, an architectural book with bias towards enterprise Java -- just what I need.</p>\n\n<p>However, in computer years, it is quite old. 2003 was a long time ago, and things have moved on quite a bit since that time.</p>\n\n<p>So I'm wondering if anyone can tell me: is this book still relevant, and worth the read?</p>\n    ","a":"\n<p>Yes, it is still very relevant and an excellent resource.</p>\n    "},{"t":"What's the difference between “Solutions Architect” and “Applications Architect”? [closed]","l":"http://stackoverflow.com/questions/524941/whats-the-difference-between-solutions-architect-and-applications-architect","q":"\n\n<p>As far as I can see <strong>Solutions Architect</strong> is just a different \"marketing\" term for <strong>Applications Architect</strong>. Is that correct or are the roles actually different somehow? If so, how?</p>\n\n<p>And yes, I have searched for this both on StackOverflow and on Google.</p>\n    ","a":"\n<p>For people who have never worked in a very large organization (or have, but it was a dysfunctional one), \"architect\" may have left a bad taste in their mouth. However, it is  not only a legitimate role, but a highly strategic one for smart companies.</p>\n\n<ul>\n<li><p>When an application becomes so vast and complex that dealing with the overall technical vision and planning, and translating business needs into technical strategy becomes a full-time job, that is an <strong>application architect</strong>. Application architects also often mentor and/or lead developers, and know the code of their responsible application(s) well.</p></li>\n<li><p>When an organization has so many applications and infrastructure inter-dependencies that it is a full-time job to ensure their alignment and strategy without being involved in the code of any of them, that is a <strong>solution architect</strong>. Solution architect can sometimes be similar to an application architect, but over a suite of especially large applications that comprise a logical solution for a business.</p></li>\n<li><p>When an organization becomes so large that it becomes a full-time job to coordinate the high-level planning for the solution architects, and frame the terms of the business technology strategy, that role is an <strong>enterprise architect</strong>. Enterprise architects typically work at an executive level, advising the CxO office and its support functions as well as the business as a whole.</p></li>\n</ul>\n\n<p><em>There are also infrastructure architects, information architects, and a few others, but in terms of total numbers these comprise a smaller percentage than the \"big three\".</em></p>\n\n<p><strong>Note</strong>: numerous other answers have said there is \"no standard\" for these titles. That is not true. Go to any Fortune 1000 company's IT department and you will find these titles used consistently.</p>\n\n<p>The two most common <strong>misconceptions</strong> about \"architect\" are:</p>\n\n<ul>\n<li>An architect is simply a more senior/higher-earning developer with a fancy title</li>\n<li>An architect is someone who is technically useless, hasn't coded in years but still throws around their weight in the business, making life difficult for developers</li>\n</ul>\n\n<p>These misconceptions come from a lot of architects doing a pretty bad job, and organizations doing a terrible job at understanding what an architect is for. It is common to promote the top programmer into an architect role, but that is not right. They have some overlapping but <em>not</em> identical skillsets. The best programmer may often be, but is not always, an ideal architect. A good architect has a <strong>good</strong> understanding of many <strong>technical</strong> aspects of the IT industry; a <strong>better</strong> understanding of <strong>business needs and strategies</strong> than a developer needs to have; excellent <strong>communication skills</strong> and often some project management and business analysis skills. It is essential for architects to keep their hands dirty with code and to stay sharp technically. Good ones do.</p>\n    "},{"t":"Repository pattern vs. “smart” business objects [closed]","l":"http://stackoverflow.com/questions/888911/repository-pattern-vs-smart-business-objects","q":"\n\n<p>I see two main \"schools of thoughts\" when it comes to creating larger-scale enterprise-wide apps on .NET (Winforms, WPF, ASP.NET).</p>\n\n<p>Some folks use the \"repository pattern\" which uses a repository that knows how to fetch, insert, update and delete objects. Those objects are rather \"dumb\" in that they don't necessarily contain a whole lot of logic - e.g. they're more or less data-transfer objects.</p>\n\n<p>The other camp uses what I call \"smart\" business objects that know how to load themselves, and they typically have a Save(), possibly Update() or even Delete() method. Here you really don't need any repository - the objects themselves know how to load and save themselves.</p>\n\n<p><strong>Big question is</strong>: which do you use or prefer? And why? </p>\n\n<p>Do you use the same approach in all your apps, or do you have any particular criteria when to choose one approach over the other? If so - what are those criteria?</p>\n\n<p>I'm not trying to start a flame-war here - just trying to find out what everyone thinks about this and what your opinion is, and why you use one (or both) patterns over the other.</p>\n\n<p>Thanks for any constructive input!</p>\n    ","a":"\n<p>I use the repository pattern because of the Single Responsibility Principle.  I don't want each individual object to have to know how to save, update, delete itself, when this can be handled by one single generic repository </p>\n    "},{"t":"Explaining why “Just add another column to the DB” is a bad idea, to non programmers","l":"http://stackoverflow.com/questions/1724381/explaining-why-just-add-another-column-to-the-db-is-a-bad-idea-to-non-program","q":"\n\n<p>I have sales people and bean counters who are trying to sell customizations to clients, which is fine.  But when a complex change request comes in that I send back a large estimate for, they get confused.  Often they come back at me with \"Why can't you just add another column?\" which by another, they mean a dozen or so custom columns PER client.</p>\n\n<p>So far all I can come back with is \"We are trying to keep the database well normalized\" which means nothing to them.  I tell them I can create a system of tables that allows each client to define their own set of custom fields, but of course that takes more time and money than \"just adding a few columns\".  And of course they want to have their cake and eat it too.</p>\n\n<p>So how can I make them understand?</p>\n    ","a":"\n<p>The best way I've found is to show how you can create a new <em>feature</em> out of what they're asking for that you couldn't add with just a couple customized columns.  Features are better than customizations, especially when you can charge someone for it.  </p>\n\n<p>Try to make a good business case for your side before you get into the technical stuff.</p>\n    "},{"t":"iOS app submission : missing 64-bit support","l":"http://stackoverflow.com/questions/26790554/ios-app-submission-missing-64-bit-support","q":"\n\n<p>I sent an app yesterday for review, with no problem. I then realized that I had a very little fix to do (changing the max zoom level of a map from 19 to 18, nothing else), so I removed the binary from iTunes Connect, and tried to resubmit.</p>\n\n<p>Now I'm having this warning :</p>\n\n<p><img src=\"http://i.stack.imgur.com/TXpQT.png\" alt=\"warning_xcode\"></p>\n\n<p>I don't understand why, as my architectures are :</p>\n\n<ul>\n<li>architectures : armv7</li>\n<li>valid architectures : armv6, armv7, armv7s, arm64</li>\n</ul>\n\n<p>The app runs fine in the simulator. If I try to use the standard architectures (armv7, arm64) as recommended in the warning, then the app won't build and I get :</p>\n\n<ul>\n<li>Undefined symbols for architecture x86_64</li>\n<li>ld: symbol(s) not found for architecture x86_64</li>\n</ul>\n\n<p>I'm using the lib route-me, and I set the same architecture settings.</p>\n\n<p>Any clue ?</p>\n    ","a":"\n<p>Please, read again the warning :) </p>\n\n<p>Use \"<code>Standard architectures</code>\" like this:</p>\n\n<ul>\n<li>Architecture: \"Standard architectures\" arm7, <strong>arm64</strong></li>\n<li>Valid Architectures: \"<strong>arm64</strong>\" , armv7...</li>\n<li>Build Active Architecture Only -  <strong>NO</strong> (specially... if your connected device is not arm64 compatible)</li>\n</ul>\n\n<p>like this:</p>\n\n<p><img src=\"http://i.stack.imgur.com/kbPz5.jpg\" alt=\"enter image description here\"></p>\n    "},{"t":"ASP.NET MVC3 and Entity Framework Code first architecture","l":"http://stackoverflow.com/questions/5609508/asp-net-mvc3-and-entity-framework-code-first-architecture","q":"\n\n<p><a href=\"http://stackoverflow.com/q/5609473/671686\">My previous question</a> made me think again about layers, repository, dependency injection and architectural stuff like this.  </p>\n\n<p>My architecture now looks like this:<br>\nI am using EF code first, so I just made POCO classes, and context. That creates db and model.<br>\nLevel higher are business layer classes (Providers). I am using different provider for each domain... like MemberProvider, RoleProvider, TaskProvider etc. and I am making new instance of my DbContext in each of these providers.<br>\nThen I instantiate these providers in my controllers, get data and send them to Views.</p>\n\n<p>My initial architecture included repository, which I got rid of because I was told that it just adds complexity, so why I don't just use EF only. I wanted to did that.. working with EF directly from controllers, but I have to write tests and it was a bit complicate with real database. I had to fake - mock data somehow. So I made an interface for each provider and made fake providers with hardcoded data in lists. And with this I got back to something, where I am not sure how to proceed correctly.</p>\n\n<p>These things starts to be overcomplicated too quickly... many approaches and \"pattterns\"... it creates just too much noise and useless code.</p>\n\n<p><strong>Is there any SIMPLE and testable architecture for creating and ASP.NET MVC3 application with Entity Framework?</strong></p>\n    ","a":"\n<p>If you want to use TDD (or any other testing approach with high test coverage) and EF together you must write integration or end-to-end tests. The problem here is that any approach with mocking either context or repository just creates test which can test your upper layer logic (which uses those mocks) but not your application.</p>\n\n<p>Simple example:</p>\n\n<p>Let's define generic repository:</p>\n\n<pre><code>public interface IGenericRepository&lt;TEntity&gt; \n{\n    IQueryable&lt;TEntity&gt; GetQuery();\n    ...\n}\n</code></pre>\n\n<p>And lets write some business method:</p>\n\n<pre><code>public IEnumerable&lt;MyEntity&gt; DoSomethingImportant()\n{\n    var data = MyEntityRepo.GetQuery().Select((e, i) =&gt; e);\n    ...\n}\n</code></pre>\n\n<p>Now if you mock the repository you will use Linq-To-Objects and you will have a green test but if you run the application with Linq-To-Entities you will get an exception because select overload with indexes is not supported in L2E.</p>\n\n<p>This was simple example but same can happen with using methods in queries and other common mistakes. Moreover this also affects methods like Add, Update, Delete usually exposed on repository. If you don't write a mock which will exactly simulate behavior of EF context and referential integrity you will not test your implementation. </p>\n\n<p>Another part of story are problems with Lazy loading which can also hardly be detected with unit tests against mocks.</p>\n\n<p>Because of that you should also introduce integration or end-to-end tests which will work against real database using real EF context ane L2E. Btw. using end-to-end tests is required to use TDD correctly. For writing end-to-end tests in ASP.NET MVC you can <a href=\"http://watin.org/\">WatiN</a> and possibly also <a href=\"http://www.specflow.org/\">SpecFlow</a> for BDD but this will really add a lot of work  but you will have your application really tested. If you want to read more about TDD I recommend <a href=\"http://www.growing-object-oriented-software.com/\">this book</a> (the only disadvantage is that examples are in Java).</p>\n\n<p>Integration tests make sense if you don't use generic repository and you hide your queries in some class which will not expose <code>IQueryable</code> but returns directly data.</p>\n\n<p>Example:</p>\n\n<pre><code>public interface IMyEntityRepository\n{\n    MyEntity GetById(int id);\n    MyEntity GetByName(string name); \n}\n</code></pre>\n\n<p>Now you can just write integration test to test implementation of this repository because queries are hidden in this class and not exposed to upper layers. But this type of repository is somehow considered as old implementation used with stored procedures. You will lose a lot of ORM features with this implementation or you will have to do a lot of additional work - for example add <a href=\"http://en.wikipedia.org/wiki/Specification_pattern\">specification pattern</a> to be able to define query in upper layer. </p>\n\n<p>In ASP.NET MVC you can partially replace end-to-end tests with integration tests on controller level.</p>\n\n<p><strong>Edit based on comment:</strong></p>\n\n<p>I don't say that you need unit tests, integration tests and end-to-end tests. I say that making tested applications require much more effort. The amount and types of needed tests is dependent on the complexity of your application, expected future of the application, your skills and skills of other team members. </p>\n\n<p>Small straighforward projects can be created without tests at all (ok, it is not a good idea but we all did it and at the end it worked) but once a project passes some treshold you can find that introducing new features or maintaining the project is very hard because you are never sure if it breaks something which already worked - that is called regression. The best defence against regression is good set of automated tests. </p>\n\n<ul>\n<li>Unit tests help you to test method. Such tests should ideally cover all execution paths in the method. These tests should be very short and easy to write - to complicated part can be to set up dependencies (mocks, faktes, stubs). </li>\n<li>Integration tests help you to test functionality accross multiple layers and usually accross multiple processes (application, database). You don't need to have them for everything, it is more about experience to select where they are helpful. </li>\n<li>End-to-end tests are something like validation of use case / user story / feature. They should cover whole flow of the requirement. </li>\n</ul>\n\n<p>It is not needed to test a feture multiple times - if you know that the feature is tested in end-to-end test you don't need to write integration test for the same code. Also if you know that method has only single execution path which is covered by integration test you don't need to write unit test for it. This works much better with TDD approach where you start with a big test (end-to-end or integration) and go deeper to unit tests.</p>\n\n<p>Depending on your developement approach you don't have to start with multiple types of test from beginning but you can introduce them later as your application will become more complex. The exception is TDD/BDD where you should start to use at least end-to-end and unit tests before you even write single line of other code.</p>\n\n<p>So you are asking the wrong question. The question is not what is simpler? The question is what will help you at the end and what complexity fits your application? If you want to have easily unit tested application and business logic you should wrap EF code to some other classes which can be mocked. But in the same time you must introduce other type of tests to ensure that EF code works.</p>\n\n<p>I can't say you what approach will fit your environment / project / team / etc. But I can explain example from my past project:</p>\n\n<p>I worked on the project for about 5-6 months with two collegues. The project was based on  ASP.NET MVC 2 + jQuery + EFv4 and it was developed in incremental and iterative way. It had a lot of complicated business logic and a lot of complicated database queries. We started with generic repositories and high code coverage with unit tests + integration tests to validate mapping (simple tests for inserting, deleting, updating and selecting entity). After few months we found that our approach doesn't work. We had more then 1.200 unit tests, code coverage about 60% (that is not very good) and a lot of regression problems. Changing anything in EF model could introduce unexpected problems in parts which were not touched for several weeks. We found that we are missing integration tests or end-to-end tests for our application logic. The same conclusion was made on a parallel team worked on another project and using integration tests was considered as recommendation for new projects.</p>\n    "},{"t":"Coupling and cohesion","l":"http://stackoverflow.com/questions/39946/coupling-and-cohesion","q":"\n\n<p>I'm trying to boil down the concepts of coupling and cohesion to a concise definition. Can someone give me a short and understandable explanation (shorter than the definitions on Wikipedia <a href=\"http://en.wikipedia.org/wiki/Coupling_%28computer_science%29\">here</a> and <a href=\"http://en.wikipedia.org/wiki/Cohesion_%28computer_science%29\">here</a>)? How do they interact?</p>\n\n<p>Thanks.</p>\n\n<p>Anybody have a good, short example?</p>\n    ","a":"\n<p><strong>Coupling</strong></p>\n\n<ul>\n<li><p>Loose: You and the guy at the convenience store. You communicate through a well-defined protocol to achieve your respective goals - you pay money, he lets you walk out with the bag of Cheetos. Either one of you can be replaced without disrupting the system.</p></li>\n<li><p>Tight: You and your wife.</p></li>\n</ul>\n\n<p><strong>Cohesion</strong></p>\n\n<ul>\n<li><p>Low: The convenience store. You go there for everything from gas to milk to ATM banking. Products and services have little in common, and the convenience of having them all in one place may not be enough to offset the resulting increase in cost and decrease in quality.</p></li>\n<li><p>High: The cheese store. They sell cheese. Nothing else. Can't beat 'em when it comes to cheese though. </p></li>\n</ul>\n    "},{"t":"DAO and Service layers (JPA/Hibernate + Spring)","l":"http://stackoverflow.com/questions/3882108/dao-and-service-layers-jpa-hibernate-spring","q":"\n\n<p>I'm designing a new app based on JPA/Hibernate, Spring and Wicket. The distinction between the DAO and Service layers isn't that clear to me though. According to Wikipedia, DAO is </p>\n\n<blockquote>\n  <p>an object that provides an abstract\n  interface to some type of database or\n  persistence mechanism, providing some\n  specific operations without exposing\n  details of the database.</p>\n</blockquote>\n\n<p>I was wondering whether a DAO could contain methods that don't really have to do much with data access, but are way easier executed using a query? For example \"get a list of all airlines that operate on a certain set of airports\"? It sounds to me to be more of a service-layer method, but I'm not sure if using JPA EntityManager in the service layer is an example of good practice?</p>\n    ","a":"\n<p>A DAO should provide access to a single <em>related</em> source of data and, depending on how complicated your business model, will return either full fledged Business objects, or simple Data objects.  Either way, the DAO methods should reflect the database somewhat closely.</p>\n\n<p>A Service can provide a higher level interface to not only process your business objects, but to get access to them in the first place.  If I get a business object from a Service, that object may be created from different databases (and different DAO's), it could be decorated with information made from an HTTP request.  It may have certain business logic that converts several data objects into a single, robust, business object.</p>\n\n<p>I generally create a DAO thinking that it will be used by anyone who is going to use that database, or set of business related data, it is literally the lowest level code besides triggers, functions and stored procedures within the database.  </p>\n\n<p><strong>Answers to specific questions:</strong></p>\n\n<blockquote>\n  <p>I was wondering whether a DAO could\n  contain methods that don't really have\n  to do much with data access, but are\n  way easier executed using a query?</p>\n</blockquote>\n\n<p>for most cases no, you would want your more complicated business logic in your service layer, the assembly of data from separate queries.  However, if you're concerned about processing speed, a service layer may delegate an action to a DAO even though it breaks the beauty of the model, in much the same way that a C++ programmer may write assembler code to speed up certain actions.</p>\n\n<blockquote>\n  <p>It sounds to me to be more of a\n  service-layer method, but I'm not sure\n  if using JPA EntityManager in the\n  service layer is an example of good\n  practice?</p>\n</blockquote>\n\n<p>If you're going to use your entity manager in your service, then think of the entity manager as your DAO, because that's exactly what it is.  If you need to remove some redundant query building, don't do so in your service class, extract it into a class that utilized the entity manager and make that your DAO.  If your use case is really simple, you could skip the service layer entirely and use your entity manager, or DAO in controllers because all your service is going to do is pass off calls to <code>getAirplaneById()</code> to the DAO's <code>findAirplaneById()</code></p>\n\n<p>UPDATE - To clarify with regard to the discussion below, using an entity manager in a service is likely not the best decision in most situations where there is also a DAO layer for various reasons highlighted in the comments.  But in my opinion it would be perfectly reasonable given:</p>\n\n<ol>\n<li>The service needs to interact with different sets of data</li>\n<li>At least one set of data already has a DAO</li>\n<li>The service class resides in a module that requires some persistence which is simple enough to not warrant it's own DAO</li>\n</ol>\n\n<p>example.</p>\n\n<pre><code>//some system that contains all our customers information\nclass PersonDao {\n   findPersonBySSN( long ssn )\n}\n\n//some other system where we store pets\nclass PetDao {\n   findPetsByAreaCode()\n   findCatByFullName()\n}\n\n//some web portal your building has this service\nclass OurPortalPetLostAndFoundService {\n\n   notifyOfLocalLostPets( Person p ) {\n      Location l = ourPortalEntityManager.findSingle( PortalUser.class, p.getSSN() )\n        .getOptions().getLocation();\n      ... use other DAO's to get contact information and pets...\n   }\n}\n</code></pre>\n    "},{"t":"When to rewrite a code base from scratch","l":"http://stackoverflow.com/questions/1064403/when-to-rewrite-a-code-base-from-scratch","q":"\n\n<p>I think back to Joel Spolsky's article about never rewriting code from scratch.  To sum up his argument:  The code doesn't get rusty, and while it may not look pretty after many maintenance releases, if it works, it works.  The end user doens't care how pretty the code is.</p>\n\n<p>You can read the article here: <a href=\"http://www.joelonsoftware.com/articles/fog0000000069.html\">Things You Should Never Do</a></p>\n\n<p>I've recently taken over a project and after looking through their code, it's pretty awful.  I immediately thought of prototypes I had built before, and explicitly stated that it should not be used for any production environment.  But of course, people don't listen.</p>\n\n<p>The code is built as a website, has no separation of concerns, no unit testing, and code duplication everywhere. No Data layer, no real business logic, unless you count a bunch of classes in App_Code.</p>\n\n<p>I've made the recommendation to the stake holders that, while we should keep the existing code, and do bug fix releases, and some minor feature releases, we should start rewriting it immediately with Test Driven Development in mind and with clear separation of concerns.  I'm thinking of going the ASP.NET MVC route.</p>\n\n<p>My only concern is of course, the length of time it might take to rewrite from scratch.  It's not entirely complicated, pretty run of the mill web application with membership, etc..</p>\n\n<p>Have any of you come across a similar problem?  Any particular steps you took?</p>\n\n<p>Thanks a bunch!</p>\n\n<p><strong>UPDATE:</strong></p>\n\n<p>So.. What did I end up deciding to do?  I took Matt's approach and decided to refactor many areas. </p>\n\n<ul>\n<li>Since App_Code was getting rather\nlarge and thus slowing down the build\ntime, I removed many of the classes\nand converted them into a Class\nLibrary.</li>\n<li><p>I created a very simple Data Access\nLayer, which contained all of the ADO\ncalls, and created a SqlHelper object\nto execute these calls.</p></li>\n<li><p>I implemented a cleaner logging<br>\nsolution, which is much more concise.</p></li>\n</ul>\n\n<p>While I no longer work on this project [funding, politics, blah blah], I think it gave me some enormous insight into how bad some projects can be written, and steps one developer can take to make things a lot cleaner, readable and just flat out better with small, incremental steps over time.</p>\n\n<p>Thanks again to everyone who commented.</p>\n    ","a":"\n<p>Just because it has all those problems now doesn't mean it has to continue to have them.  If you find yourself making a specific bug fix in the system that could benefit from, say, a new data layer, then create a new data layer.  Just because the whole site doesn't use it doesn't mean you can't start using one.  Refactor as you need to during your bug fixes.  And make sure you understand exactly what the code is doing before you change it.</p>\n\n<p>Problem with code duplication?  Pull it out into a class or utility library, in a central location next time you have to fix a bug in the duplicated code.</p>\n\n<p>And, as already mentioned by other responders - start writing tests now.  It may be hard if the code is a coupled as it sounds, but you can probably start somewhere.</p>\n\n<p>There is no good reason to rewrite working code.  However, if you are already fixing a bug, there is no reason you can't rework that specific part of the code with a \"better\" design.</p>\n    "},{"t":"NOT using repository pattern, use the ORM as is (EF)","l":"http://stackoverflow.com/questions/14110890/not-using-repository-pattern-use-the-orm-as-is-ef","q":"\n\n<p>I always used Repository pattern but for my latest project I wanted to see if I could perfect the use of it and my implementation of “Unit Of Work”. The more I started digging I started asking myself the question: <strong>\"Do I really need it?\"</strong></p>\n\n<p>Now this all starts with a couple of comments on Stackoverflow with a trace to Ayende Rahien's post on his blog, with 2 specific,</p>\n\n<ul>\n<li><a href=\"http://ayende.com/blog/3955/repository-is-the-new-singleton\">repository-is-the-new-singleton</a></li>\n<li><a href=\"http://ayende.com/blog/153701/ask-ayende-life-without-repositories-are-they-worth-living\">ask-ayende-life-without-repositories-are-they-worth-living</a></li>\n</ul>\n\n<p>This could probably be talked about forever and ever and it depends on different applications. Whats I like to know,</p>\n\n<ol>\n<li>would this approach be suited for a Entity Framework project?</li>\n<li>using this approach is the business logic still going in a service layer, or extension methods (as explained below, I know, the extension method is using NHib session)?</li>\n</ol>\n\n<p><strong>That's easily done using extension methods. Clean, simple and reusable.</strong></p>\n\n<pre><code>public static IEnumerable GetAll(\n    this ISession instance, Expression&lt;Func&lt;T, bool&gt;&gt; where) where T : class\n{\n    return instance.QueryOver().Where(where).List();\n}\n</code></pre>\n\n<p>Using this approach and <code>Ninject</code> as DI, do I need to make the <code>Context</code> a interface and inject that in my controllers?</p>\n    ","a":"\n<p>I've gone down many paths and created many implementations of repositories on different projects and... I've thrown the towel in and given up on it, here's why. </p>\n\n<p><strong>Coding for the exception</strong></p>\n\n<p>Do you code for the 1% chance your database is going to change from one technology to another? If you're thinking about your business's future state and say yes that's a possibility then a) they must have a lot of money to afford to do a migration to another DB technology or b) you're choosing a DB technology for fun or c) something has gone horribly wrong with the first technology you decided to use.</p>\n\n<p><strong>Why throw away the rich LINQ syntax?</strong></p>\n\n<p>LINQ and EF were developed so you could do neat stuff with it to read and traverse object graphs. Creating and maintain a repository that can give you the same flexibility to do that is a monstrous task. In my experience any time I've created a repository I've <strong>ALWAYS</strong> had business logic leak into the repository layer to either make queries more perform-ant and/or reduce the number of hits to the database.</p>\n\n<p>I don't want to create a method for every single permutation of a query that I have to write. I might as well write stored procedures. I don't want GetOrder, GetOrderWithOrderItem, GetOrderWithOrderItemWithOrderActivity, GetOrderByUserId, and so on... I just want to get the main entity and traverse and include the object graph as I so please.</p>\n\n<p><strong>Most examples of repositories are bullshit</strong> </p>\n\n<p>Unless you are developing something REALLY bare-bones like a blog or something your queries are never going to be as simple as 90% of the examples you find on the internet surrounding the repository pattern. I cannot stress this enough! This is something that one has to crawl through the mud to figure out. There will always be that one query that breaks your perfectly thought out repository/solution that you've created, and its not until that point where you 2nd guess yourself and the technical debt/erosion begins.</p>\n\n<p><strong>Don't unit test me bro</strong></p>\n\n<p>But what about unit testing if I don't have a repository? How will I mock? Simple you don't. Lets look at it from both angles:</p>\n\n<p>No repository - You can mock the DbContext using an IDbContext or some other tricks but then you're really unit testing LINQ to Objects and not LINQ to Entities because the query is determined at runtime... OK so that's not good! So now its up to the integration test to cover this.</p>\n\n<p>With repository - You can now mock your repositories and unit test the layer(s) in between. Great right? Well not really... In the cases above where you have to leak logic into the repository layer to make queries more perform-ant and/or less hits to the database, how can your unit tests cover that? It's now in the repo layer and you don't want to test IQueryable right? Also lets be honest, your unit tests aren't going to cover the queries that have a 20 line <code>.Where()</code> clause and <code>.Include()</code>'s a bunch of relationships and hits the database again to do all this other stuff, blah, blah, blah anyway's because the query is generated at runtime. Also since you created a repository to keep the upper layers persistence ignorant, if you now you want to change your database technology, sorry your unit tests are defiantly not going to guarantee the same results at runtime, back to integration tests. So the whole point of the repository seems weird..</p>\n\n<p><strong>2 cents</strong></p>\n\n<p>We already lose a lot of functionality and syntax when using EF over plain stored procedures (bulk inserts, bulk deletes, CTE's, etc.) but I also code in C# so I don't have to type binary. We use EF so we can have the possibility of using different providers and to work with object graphs in a nice related way amongst many things. Certain abstractions are useful and some are not.</p>\n\n<p>I hope this helps someone on the internets somewhere...</p>\n    "},{"t":"Using Entity Framework entities as business objects?","l":"http://stackoverflow.com/questions/217655/using-entity-framework-entities-as-business-objects","q":"\n\n<p>I'm using Entity Framework O/R mapper from Microsoft and using entity classes (generated classes that are mapped to DB objects) as a business objects. \nIs this OK? Please state your cons or pros. What to do in a case of WCF communication between business layer and presentation, how to send those objects as data members?</p>\n    ","a":"\n<p>I am using EF in this fashion and one nice feature is that generated entities are partial classes, allowing them to be extended in a way that is fairly protected from regeneration issues.</p>\n\n<p>Also take a look at <a href=\"http://msdn.microsoft.com/en-us/library/cc716789.aspx\">this link on MSDN</a> which describes some common usage scenarios with EF in regards to Business Logic.</p>\n    "},{"t":"Why do stacks typically grow downwards?","l":"http://stackoverflow.com/questions/2035568/why-do-stacks-typically-grow-downwards","q":"\n\n<p>I know that in the architectures I'm personally familiar with (x86, 6502, etc), the stack typically grows downwards (i.e. every item pushed onto the stack results in a decremented SP, not an incremented one). </p>\n\n<p>I'm wondering about the historical rationale for this. I know that in a unified address space, it's convenient to start the stack on the opposite end of the data segment (say) so there's only a problem if the two sides collide in the middle. But why does the stack traditionally get the top part? Especially given how this is the opposite of the \"conceptual\" model?</p>\n\n<p>(And note that in the 6502 architecture, the stack also grows downwards, even though it is bounded to a single 256-byte page, and this direction choice seems arbitrary.)</p>\n    ","a":"\n<p>As to the historic rationale, I can't say for certain (because I didn't design them). My <em>thoughts</em> on the matter are that early CPUs got their original program counter set to 0 and it was a natural desire to start the stack at the other end and grow downwards, since their code naturally grows upward.</p>\n\n<p>Note that this setting of the program counter to 0 on reset is not the case for <em>all</em> early CPUs.</p>\n\n<p>One of the first things some historical CPUs would do would be to scan memory from the top until it found a location that would read back the same value written, so that it would know the actual RAM installed (e.g., a z80 with 64K address space didn't necessarily have 64K or RAM, in fact 64K would have been <em>massive</em> in my early days). Once it found the top actual address, it would set the stack pointer appropriately and could then start calling subroutines.</p>\n\n<p>With regard to the stacks growth, not all of them grow downwards, see <a href=\"http://stackoverflow.com/questions/664744/what-is-the-direction-of-stack-growth-in-most-modern-systems/664779#664779\">this answer</a> for details.</p>\n    "},{"t":"optimal architecture for multitenant application on django","l":"http://stackoverflow.com/questions/7194341/optimal-architecture-for-multitenant-application-on-django","q":"\n\n<p>I've been brooding over the right/optimal way to create a multitenancy application based\non Django.</p>\n\n<p>Some explanation:</p>\n\n<ul>\n<li><p>Application can be used by several tenants (tenant1, tenant2, ...,). </p></li>\n<li><p>All tenant-individual data has to be secured against access of other tenants (and their users).</p></li>\n<li><p>Optionally tenants can create additional custom-fields for application-objects.</p></li>\n<li><p>Of course, underlying hardware limits number of tenants on one \"system\".</p></li>\n</ul>\n\n<p>1) Separating each tenant by e.g. sub-domain and using tenant-specific databases in the underlying layer</p>\n\n<p>2) Using some tenant-ID in the model to separate the tenant-data in the database</p>\n\n<p>I am thinking about deployment-processes, performance of the system-parts (web-server(s), database-server(s), working-node(s),...)</p>\n\n<p>What would be the best setup ?  Where are the pro's and con's?</p>\n\n<p>What do you think?</p>\n    ","a":"\n<p>We built a multitenancy <a href=\"https://www.atizo.com/\" rel=\"nofollow\">platform</a> using the following architecture. I hope you can find some useful hints.</p>\n\n<ul>\n<li>Each tenant gets sub-domain (t1.example.com)</li>\n<li>Using url rewriting the requests for the Django application are rewritten to something like example.com/t1</li>\n<li>All url definitions are prefixed with something like <code>(r'^(?P&lt;tenant_id&gt;[\\w\\-]+)</code></li>\n<li>A <a href=\"https://docs.djangoproject.com/en/1.3/topics/http/middleware/#writing-your-own-middleware\" rel=\"nofollow\">middleware</a> processes and consumes the tenant_id and adds it to the request (e.g. request.tenant = 't1')</li>\n<li>Now you have the current tenant available in each view without specifying the tenant_id argument every view</li>\n<li>In some cases you don't have the request available. I solved this issue by binding the tenant_id to the current thread (similar to the <a href=\"https://github.com/django/django/blob/master/django/utils/translation/trans_real.py\" rel=\"nofollow\">current language</a> using <code>threading.local</code> )</li>\n<li>Create decorators (e.g a tenant aware <code>login_required</code>), middlewares or factories to protect views and select the right models</li>\n<li>Regarding to the databases I used two different scenarios:\n<ul>\n<li>Setup multiple databases and configure a <a href=\"https://docs.djangoproject.com/en/dev/topics/db/multi-db/#automatic-database-routing\" rel=\"nofollow\">routing</a> according to current tenant. I used this first but switched to one database after about one year. The reasons were the following:\n<ul>\n<li>We didn't need a high secure solution to separate the data</li>\n<li>The different tenants used almost all the same models</li>\n<li>We had to manage a lot of databases (and didn't built an easy update/migration process)</li>\n</ul></li>\n<li>Use one database with some simple mapping tables for i.e. users and different models. To add additional and tenant specific model fields we use <a href=\"https://docs.djangoproject.com/en/dev/topics/db/models/#model-inheritance\" rel=\"nofollow\">model inheritance</a>.</li>\n</ul></li>\n</ul>\n\n<p>Regarding the environment we use the following setup:</p>\n\n<ul>\n<li><a href=\"http://wiki.nginx.org/\" rel=\"nofollow\">Nginx</a>  </li>\n<li><a href=\"http://projects.unbit.it/uwsgi/\" rel=\"nofollow\">uWSGI</a></li>\n<li>PostgreSQL</li>\n<li><a href=\"http://memcached.org/\" rel=\"nofollow\">Memcached</a></li>\n</ul>\n\n<p>From my point of view this setup has the following pro's and con's:</p>\n\n<p>Pro:</p>\n\n<ul>\n<li>One application instance knowing the current tenant</li>\n<li>Most parts of the project don't have to bother with tenant specific issues</li>\n<li>Easy solution for sharing entities between all tenants (e.g. messages)</li>\n</ul>\n\n<p>Contra:</p>\n\n<ul>\n<li>One quite large database</li>\n<li>Some very similar tables due to the model inheritance</li>\n<li>Not secured on the database layer</li>\n</ul>\n\n<p>Of course the best architecture strongly depends on your requirements as number of tenants, the delta of your models, security requirements and so on.</p>\n\n<p><strong>Update</strong>: As we reviewed our architecture, I suggest to <em>not</em> rewrite the URL as indicated in point 2-3. I think a better solutions is to put the <code>tenant_id</code> as a Request Header and extract (point 4) the <code>tenant_id</code> out of the request with something like <code>request.META.get('TENANT_ID', None)</code>. This way you get neutral URLs and it's much easier to use Django built-in functions (e.g. <code>{% url ...%}</code> or <code>reverse()</code>) or external apps.</p>\n    "},{"t":"How does a site like kayak.com aggregate content?","l":"http://stackoverflow.com/questions/4607141/how-does-a-site-like-kayak-com-aggregate-content","q":"\n\n<p>Greetings,\nI've been toying with an idea for a new project and was wondering if anyone has any idea on how a service like Kayak.com is able to aggregate data from so many sources so quickly and accurately. More specifically, do you think Kayak.com is interacting with APIs or are they crawling/scraping airline and hotel websites in order to fulfill user requests? I know there isn't one right answer for this sort of thing but I'm curious to know what others think would be a good way to go about this. If it helps, pretend you are going to create kayak.com tomorrow ... where is your data coming from?</p>\n    ","a":"\n<p>I'm working in travel industry as a software architect / project lead on the precisely kind of project you describe - in our region we work with suppliers directly, but for outgoing we connect to several aggregators.</p>\n\n<p>To answer your question... some data you have, some you get in various ways, and some you have to torture and twist until it confesses.</p>\n\n<h2>What's your angle?</h2>\n\n<p>The questions you have to ask are... Do you want to sell advertising like Kayak or do you take a cut like Expedia? Are you into search or into selling travel services? Do you target niche (for example, just air travel) or everything (accommodation, airlines, rent-a-car, additional services like transport/sightseeing/conferences etc)? Do you target region (US or part of US) or the world? How deep do you go - do you just show several sites on a single screen, or do you bundle different services together and package them dynamically?</p>\n\n<h2>Getting the data</h2>\n\n<p>If you're going with Kayak business model, you technically don't need site's permission... but a lot of sites have affiliate programs with IFrames or other simple ways to direct the customer to their site. On the plus side, you don't have to deal with payments/complaints and travelers themselves. As for the cons... if you want to compare prices yourself and present the cheapest option to the user, you'll have to integrate on a deeper level, and that means APIs and web scraping.</p>\n\n<p>As for web scraping... avoid it. It sucks. Really. Just don't do it. Trust me on this one. For example, some things like lowcosters you can't get without web scraping. Low cost airlines live from value added services. If the user doesn't see their website, they don't sell extra stuff, and they don't earn anything. Therefore, they don't have affiliates, they don't offer APIs, and they change their site layout almost constantly. However, there are companies which earn a living by web scraping lowcoster's sites and wrapping them into nice APIs. If you can afford them, you can give your users cost-comparison of low cost flights and that's huge.</p>\n\n<p>On the other hand, there are \"normal\" carriers which offer APIs. It's not that big of a problem to get to airlines since they're all united under <a href=\"http://www.iata.org/\">IATA</a>; basically, you buy from IATA, and IATA distributes the money to carriers. However, you probably don't want to connect directly to carrier network. They have web services and SOAP these days, but believe me when I say that there are SOAP protocols which are just an insanely thin wrappers around a text prompt through which you can interact with a mainframe with an 80es-style protocol (think of a Unix prompt where you're billed per command; and it takes about 20 commands to do one search). That's why you probably want to connect to somebody a bit more down the food chain, with a better API.</p>\n\n<p>Airlines are thus on both extremes of Gaussian curve; on one side are individual suppliers, and on the other highly centralized systems where you implement one API and you're able to fly anywhere in the world. Accommodation and the rest of travel products are in between. There are several big players which aggregate hotels, and a ton of small suppliers with a lot of aggregators which cover only part of a spectrum. For example, you can rent a lighthouse and it's even not that expensive - but you won't be able to compare the prices of different lighthouses in one place.</p>\n\n<p>If you're into Kayak business model, you'll probably end up scraping websites. If you're into integrating different providers, you'll often work with APIs, some of which are pretty good, and most of which are tolerable. I haven't worked with RSS but there's not a lot of difference between RSS and web scraping. There is also a fourth option not mentioned in Jeff's answer... the one where you get your data nightly, for example .CSV files through FTP and similar.</p>\n\n<h2>Life sucks (mini-rant)</h2>\n\n<p>And then there's complexity. The more value you want to add, the more complexity you'll have to handle. Can you search accommodations which allow pets? For a hostel which is located less than 5 km from the town center? Are you combining flights, and are you able to guarantee that the traveler will have enough time to get from one airport to another... can you sell the transport in advance? A famous cellist doesn't want to part from his precious 18th century cello; can you sell him another seat for the cello (yep, not making this one up)?</p>\n\n<p>Want to compare prices? Sure, the room is EUR 30 per night. But you can either get one double for 30 and one single for 20, or you can get one extra bed in a double and get 70% off for third person. But only if it's a child under 12 years of age; our extra beds are not for adults. And you don't get the price for extra bed in search results - only when you calculate the final price.</p>\n\n<p>And don't even get me started on dynamic packaging. Want to sell accommodation + rent-a-car? No problem; integrate with two different providers, and off you go... manually updating list of locations in the city (from rent-a-car provider) to match with hotels (from accommodation provider, who gives you only the city for each hotel). Of course, provided that you've already matched the list of cities from the two, since there is no international standard for city codes.</p>\n\n<p>Unlike a lot of other industries which have many products, travel industry has many very complex products. Amazon has it easy; selling books and selling potatoes, it's the same thing; you can even ship them in the same box. They combine easily and aren't assembled from many parts. :)</p>\n    "},{"t":"Business Logic in Database versus Code? [closed]","l":"http://stackoverflow.com/questions/1473624/business-logic-in-database-versus-code","q":"\n\n<p>As a software engineer, I have a strong bias towards writing business logic in the application layer, while typically relying on the database for little more than CRUD (Create Retrieve Update and Delete) operations. On the other hand, I have run across applications (typically older ones) where a large amount of the business logic was written in stored procedures, so there are people out there that prefer to write business logic in the database layer.</p>\n\n<p>For the people that have and/or enjoy written/writing business logic in a stored procedure, what were/are your reasons for using this method?</p>\n    ","a":"\n<p>I try to seriously limit my business logic in the DB to only procs that have to do alot of querying and updating to perform a single application operation. Some may argue that even that should be in the app, but I like to keep the IO down if I can.</p>\n\n<p>Databases are great for CRUD but if they get bloated with logic:</p>\n\n<ol>\n<li>It becomes confusing where the logic is, \n</li><li>Typically databases are a silo and do not scale horizontally nearly as well as the app servers.\n</li><li>t_sql/PLsql is hard to read and procedural in nature\n</li><li>You forfeit all of the benefits of OOAD.\n</li></ol>\n    "},{"t":"Single Page Application: advantages and disadvantages","l":"http://stackoverflow.com/questions/21862054/single-page-application-advantages-and-disadvantages","q":"\n\n<p>I've read about SPA and it advantages. I find most of them unconvincing. There are 3 advantages that arouse my doubts.</p>\n\n<p><em><strong>Question:</strong></em> <em>Can you act as advocate of SPA and prove that I am wrong about first three statements?</em></p>\n\n<pre><code>                              === ADVANTAGES ===\n</code></pre>\n\n<p><em><strong>1. SPA is extremely good for very responsive sites:</strong></em></p>\n\n<blockquote>\n  <p>Server-side rendering is hard to implement for all the intermediate\n  states - small view states do not map well to URLs.</p>\n  \n  <p>Single page apps are distinguished by their ability to redraw any part\n  of the UI without requiring a server roundtrip to retrieve HTML. This\n  is achieved by separating the data from the presentation of data by\n  having a model layer that handles data and a view layer that reads\n  from the models.</p>\n</blockquote>\n\n<p><em>What is wrong with holding a model layer for non-SPA? Does SPA the only compatible architecture with MVC on client side?</em></p>\n\n<p><em><strong>2. With SPA we don't need to use extra queries to the server to download pages.</strong></em></p>\n\n<p><em>Hah, and how many pages user can download during visiting your site? Two, three? Instead there appear another security problems and you need to separate your login page, admin page etc into separate pages. In turn it conflicts with SPA architecture.</em></p>\n\n<p><em><strong>3.May be any other advantages? Don't hear about any else..</strong></em></p>\n\n<pre><code>                            === DISADVANTAGES ===\n</code></pre>\n\n<ol>\n<li>Client must enable javascript.</li>\n<li>Only one entry point to the site.</li>\n<li>Security.</li>\n</ol>\n\n<p><em><strong>P.S.</strong></em> I've worked on SPA and non-SPA projects. And I'm asking those questions because I need to deepen my understanding. No mean to harm SPA supporters. Don't ask me to read a bit more about SPA. I just want to hear your considerations about that.</p>\n    ","a":"\n<p>Let's look at one of the most popular SPA sites, GMail.</p>\n\n<p><strong><em>1. SPA is extremely good for very responsive sites:</em></strong></p>\n\n<p>Server-side rendering is not as hard as it used to be with simple techniques like keeping a #hash in the URL, or more recently <a href=\"https://developer.mozilla.org/en-US/docs/Web/Guide/API/DOM/Manipulating_the_browser_history\">HTML5 <code>pushState</code></a>. With this approach the exact state of the web app is embedded in the page URL. As in GMail every time you open a mail a special hash tag is added to the URL. If copied and pasted to other browser window can open the exact same mail (provided they can authenticate). This approach maps directly to a more traditional query string, the difference is merely in the execution.  With HTML5 pushState() you can eliminate the <code>#hash</code> and use completely classic URLs which can resolve on the server on the first request and then load via ajax on subsequent requests.</p>\n\n<p><strong><em>2. With SPA we don't need to use extra queries to the server to download pages.</em></strong></p>\n\n<p>The number of pages user downloads during visit to my web site?? really how many mails some reads when he/she opens his/her mail account. i read &gt;50 at one go. now the structure of the mails is almost the same. if you will use a server side rendering scheme the server would then render it on every request(typical case). \n    - security concern - you should/ should not keep separate pages for the admins/login that entirely depends upon the structure of you site take paytm.com for example also making a web site SPA does not mean that you open all the endpoints for all the users i mean i use forms auth with my spa web site. \n   - in the probably most used spa framework angular js the dev can load the entire html temple from the web site so that can be done depending on the users authentication level. pre loading html for all the auth types isnt SPA. </p>\n\n<p><strong><em>3. May be any other advantages? Don't hear about any else..</em></strong></p>\n\n<ul>\n<li>these days you can safely assume the client will have javascript enabled browsers. </li>\n<li>only one entry point of the site. As i mentioned earlier maintenance of state is possible you can have any number of entry points as you want but you should have one for sure. </li>\n<li>even in an SPA user only see to what he has proper rights. you dont have to inject every thing at once. loading diff html templates and javascript async is also a valid part of SPA. </li>\n</ul>\n\n<p><strong><em>Advantages that I can think of are:</em></strong></p>\n\n<ol>\n<li>rendering html obviously takes some resources now every user visiting you site is doing this. also not only rendering major logics are now done client side instead of server side.</li>\n<li>date time issues - i just give the client utc time is a pre set format and done even care about the time zones i let javascript handle it. this is great advantage to where i had to guess time zones based on location derived from users IP. </li>\n<li>to me state is more nicely maintained in an SPA because once you have set a variable you know it will be there. this gives a feel of developing an app rather than a web page. this helps a lot typically in making sites like foodpanda, flipkart, amazon. because if you are not using client side state you are using expensive sessions.</li>\n<li>websites surely are extremely responsive - ill take an extreme example for this try making a calculator in a non SPA website(i know its weird).</li>\n</ol>\n    "},{"t":"Writing Maintainable Event-Driven Code","l":"http://stackoverflow.com/questions/5597512/writing-maintainable-event-driven-code","q":"\n\n<p>I have just recently started playing with event-driven architectures, coming from a pretty standard object-oriented mindset.</p>\n\n<p>The first thing I noticed was that the difficulty in understanding and tracing through programs seems to increase exponentially with the size of the program. While small pet projects are easy to follow, it feels like the code will rapidly turn to spaghetti.</p>\n\n<p>I understand that I am new to this development mindset and not all of my object oriented worries carry over. Are there any resources on writing maintainable, understandable event-driven code? What do people who use node.js or Twisted or Event Machine do about this?</p>\n    ","a":"\n<p>I'll use Python as an example as that is what I am using to build huge distributed applications right now.</p>\n\n<p>Twisted python allows for a very imperative style using either inlinecallbacks or (slightly uglier) deferredGenerator styles. These methods allow you to write procedures that use event driven callback code that is much easier to read and understand. The implementation turns your function into a lazy sequence that yields a sequence of deferreds. </p>\n\n<p>Specifically, you don't have to build a deeply nested set of callback functions/lambdas/closures, and can instead yield control of a function back to the event loop at arbitrary points. You can mentally re-label this as coroutines or cooperative multitasking if you like. It gets the job done. An example would be (using the uglier deferredGenerator style) like this:</p>\n\n<pre><code>@defer.deferredGenerator\ndef foo(arg):\n    bar = nonBlockingFunction(foo)\n    baz = waitForDeferred(aFunctionThatReturnsADeferredToo(bar))\n    yield baz #Returns control to the event loop\n    output = baz.getResult() #This gets the output of aFunctionThat...Too above\n    yield output #This is how we return a result instead of using return\n\n@defer.deferredGenerator\ndef aFunctionThatReturnsADeferredToo(put_bar_here):\n    \"\"\"Stuff happens here....\"\"\"\n    ...etc...\n</code></pre>\n\n<p>There is another post here that shows the inlineCallbacks method, which is cleaner, but requires python 2.5 or newer (meaning not under Centos/RHEL 5 series, which I am sadly stuck with for my app). If you can use it DO SO. </p>\n\n<p>As you can see, this looks like the old school python imperative stuff you know and love, but is WAY easier to maintain without a ton of nested functions and lambdas. I still wish python had blocks though.</p>\n\n<p>As for debugging, you can turn on twisted reactor debugging using the defer.setDebugging(True) call somewhere in your initialization code. This will attach the original traceback that raised an exception in your code, so that you can trivially see where the error ACTUALLY occurred. Just remember to redact the setDebugging statement before going production, because it results in a HUGE amount of extra introspection (watch it in strace if you want to be utterly horrified).</p>\n    "},{"t":"Difference between frontend, backend, and middleware in web development","l":"http://stackoverflow.com/questions/636689/difference-between-frontend-backend-and-middleware-in-web-development","q":"\n\n<p>I was wondering if anyone can compare/contrast the differences between frontend, backend, and middleware (\"middle-end\"?) succinctly.</p>\n\n<p>Are there cases where they overlap?\nAre there cases where they MUST overlap, and frontend/backend cannot be separated?\nIn terms of bottlenecks, which end is associated with which type of bottlenecks?</p>\n    ","a":"\n<p>Here is one breakdown:</p>\n\n<p>Front-end tier -&gt; User Interface layer usually consisting of a mix of HTML, Javascript, CSS, Flash, and various server-side code like ASP.Net, classic ASP, PHP, etc.  Think of this as being closest to the user in terms of code.</p>\n\n<p>Middleware, middle-tier -&gt; One tier back, generally referred to as the \"plumbing\" part of a system.  Java and C# are common languages for writing this part that could be viewed as the glue between the UI and the data and can be webservices or WCF components or other SOA components possibly.</p>\n\n<p>Back-end tier -&gt; Databases and other data stores are generally at this level.  Oracle, MS-SQL, MySQL, SAP, and various off-the-shelf pieces of software come to mind for this piece of software that is the final processing of the data.</p>\n\n<p>Overlap can exist between any of these as you could have everything poured into one layer like an ASP.Net website that uses the built-in AJAX functionality that generates Javascript while the code behind may contain database commands making the code behind contain both middle and back-end tiers.  Alternatively, one could use VBScript to act as all the layers using ADO objects and merging all three tiers into one.</p>\n\n<p>Similarly, taking middleware and either front or back-end can be combined in some cases.</p>\n\n<p>Bottlenecks generally have a few different levels to them:</p>\n\n<p>1) Database or back-end processing -&gt; This can vary from payroll or sales or other tasks where the throughput to the database is bogging things down.</p>\n\n<p>2) Middleware bottlenecks -&gt; This would be where some web service may be hitting capacity but the front and back ends have bandwidth to handle more traffic.  Alternatively, there may be some server that is part of a system that isn't quite the UI part or the raw data that can be a bottleneck using something like Biztalk or MSMQ.</p>\n\n<p>3) Front-end bottlenecks -&gt; This could client or server-side issues.  For example, if you took a low-end PC and had it load a web page that consisted of a lot of data being downloaded, the client could be where the bottleneck is.  Similarly, the server could be queuing up requests if it is getting hammered with requests like what Amazon.com or other high-traffic websites may get at times.</p>\n\n<p>Some of this is subject to interpretation, so it isn't perfect by any means and YMMV.</p>\n\n<hr>\n\n<p>EDIT: Something to consider is that some systems can have multiple front-ends or back-ends.  For example, a content management system will likely have a way for site visitors to view the content that is a front-end but what about how content editors are able to change the data on the site?  The ability to pull up this data could be seen as front-end since it is a UI component or it could be seen as a back-end since it is used by internal users rather than the general public viewing the site.  Thus, there is something to be said for context here.</p>\n    "},{"t":"WPF/Silverlight - Prism - Resources for beginners","l":"http://stackoverflow.com/questions/1097582/wpf-silverlight-prism-resources-for-beginners","q":"\n\n<p><strong>Official Websites</strong></p>\n\n<ul>\n<li><a href=\"http://msdn.microsoft.com/en-us/library/dd458809.aspx\">Composite Application Guidance for WPF and Silverlight</a></li>\n<li><a href=\"http://compositewpf.codeplex.com/\">patterns &amp; practices: Composite WPF and Silverlight</a></li>\n</ul>\n\n<p><strong>Articles</strong></p>\n\n<ul>\n<li><a href=\"http://msdn.microsoft.com/en-us/magazine/dd943055.aspx\">Composite Web Apps With Prism</a></li>\n</ul>\n\n<p><strong>Podcasts</strong></p>\n\n<ul>\n<li><a href=\"http://www.connectedshow.com/default.aspx?Episode=10\">PRISM for Silverlight - Connected Show</a></li>\n</ul>\n\n<p><strong>Videocasts</strong></p>\n\n<ul>\n<li><a href=\"http://www.slickthought.net/category/WPF-Composite-App.aspx\">SlickThought.Net - Jeff Brand</a></li>\n</ul>\n\n<p><strong>dnrTV</strong></p>\n\n<ul>\n<li><a href=\"http://www.dnrtv.com/default.aspx?showNum=124\">Brian Noyes on Prism</a></li>\n<li><a href=\"http://www.dnrtv.com/default.aspx?showNum=132\">Brian Noyes on Prism Events and Commands</a></li>\n</ul>\n\n<p><strong>Channel 9</strong></p>\n\n<ul>\n<li><a href=\"http://channel9.msdn.com/posts/akMSFT/What-is-Prism-v2/\">What is Prism v2?</a></li>\n<li><a href=\"http://channel9.msdn.com/posts/ContinuumNews/When-to-use-Prism-for-Silverlight-or-WPF-apps-podcast/\">When to use Prism for Silverlight or WPF apps podcast</a></li>\n<li><a href=\"http://channel9.msdn.com/shows/Continuum/Prismv2/\">Prism v2 - Composite Application Guidance for WPF and Silverlight</a></li>\n<li><a href=\"http://channel9.msdn.com/posts/akMSFT/Creating-a-modular-application-using-Prism-V2-Part-1-of-4--Creating-a-shell-and-modules/\">1/4 - Creating a shell and modules</a></li>\n<li><a href=\"http://channel9.msdn.com/posts/akMSFT/Creating-a-modular-application-using-Prism-V2-Screencast-24--Visual-Composition/\">2/4 - Visual Composition</a></li>\n<li><a href=\"http://channel9.msdn.com/posts/akMSFT/Creating-a-modular-application-using-Prism-V2-Screencast-34--Implementing-views-and-services/\">3/4 - Implementing views and services</a></li>\n<li><a href=\"http://channel9.msdn.com/posts/akMSFT/Creating-a-modular-application-using-Prism-v2-Screencast-44--Decoupled-Communication/\">4/4 - Decoupled Communication</a></li>\n</ul>\n\n<p></p><hr><p></p>\n\n<p><strong>Have you some recommendation to other resources for Prism?</strong></p>\n    ","a":"\n<p>I've been creating Prism (Silverlight slant but most applies to WPF as well) resources:</p>\n\n<p><strong>If you have 5 minutes</strong>: <a href=\"http://www.sparklingclient.com/prism-silverlight/\">10 Things to Know About Prism</a></p>\n\n<p><strong>If you have 20 minutes</strong>: <a href=\"http://development-guides.silverbaylabs.org/Video/Silverlight-Prism\">Prism Basics Video</a></p>\n\n<p><strong>videos</strong></p>\n\n<p><a href=\"http://development-guides.silverbaylabs.org/Video/Silverlight-Prism\">Intro to Silverlight Prism</a></p>\n\n<p><a href=\"http://development-guides.silverbaylabs.org/Video/Modularity-in-Prism\">Testing/Module Catalog/Unity</a></p>\n\n<p><a href=\"http://development-guides.silverbaylabs.org/Video/Prism-Regions\">Regions (including Region Scope, Region Adapter and Region Context)</a></p>\n\n<p><a href=\"http://development-guides.silverbaylabs.org/Video/Prism-Commands\">Commanding (including creating new commands)</a></p>\n\n<p><a href=\"http://www.sparklingclient.com/prism-in-silverlight/\">Eventing</a></p>\n\n<p><strong>podcast interviews with the Prism Team</strong></p>\n\n<p><a href=\"http://www.sparklingclient.com/prism-in-silverlight/\">What is Prism</a> </p>\n\n<p><a href=\"http://www.sparklingclient.com/modularity-in-prism/\">Modularity in Prism</a> </p>\n\n<p><a href=\"http://www.sparklingclient.com/when-to-use-prism/\">When to use Prism</a> </p>\n\n<p><a href=\"http://www.sparklingclient.com/which-comes-first-the-view-or-the-viewmodel/\">View or Presenter First?</a> </p>\n\n<p><a href=\"http://www.sparklingclient.com/commanding-in-prism/\">Commanding</a>  </p>\n\n<p><a href=\"http://www.sparklingclient.com/prisms-event-aggregator/\">Event Aggregator</a>  </p>\n\n<p><strong>blog posts</strong></p>\n\n<p><a href=\"http://www.sparklingclient.com/prism-silverlight/\">10 Things to Know about Silverlight Prism (overview of all resources)</a> </p>\n\n<p><a href=\"http://www.sparklingclient.com/downloading-and-building-prism/\">Downloading and Building Prism</a>  </p>\n    "},{"t":"ASP.NET MVC & Web Services","l":"http://stackoverflow.com/questions/118931/asp-net-mvc-web-services","q":"\n\n<p>Does adding a Web Service to my ASP.NET MVC project break the whole concept of MVC?</p>\n\n<p>That Web Service (WCF) depends on the Model layer from my MVC project to communicate with the back-end (so it looks to me like it needs to be part of the MVC solution).</p>\n\n<p>Should I add this to the Controller or Model layer?</p>\n    ","a":"\n<p>It sounds like you should split out your model into its own assembly and reference it from your MVC-application and WCF-application.</p>\n\n<ul>\n<li>YourApp.Data -- Shared model and data access maybe</li>\n<li>YourApp.Web -- If you want to share more across your web-apps</li>\n<li>YourApp.Web.Mvc</li>\n<li>YourApp.Web.WebService</li>\n</ul>\n\n<p>If you want to do WebServices MVC-style maybe you should use MVC to build your own REST-application.</p>\n    "},{"t":"Dynamic Database Schema","l":"http://stackoverflow.com/questions/66385/dynamic-database-schema","q":"\n\n<p>What is a recommended architecture for providing storage for a dynamic logical database schema?</p>\n\n<p>To clarify: Where a system is required to provide storage for a model whose schema may be extended or altered by its users once in production, what are some good technologies, database models or storage engines that will allow this? </p>\n\n<p>A few possibilities to illustrate:</p>\n\n<ul>\n<li>Creating/altering database objects via dynamically generated DML</li>\n<li>Creating tables with large numbers of sparse physical columns and using only those required for the 'overlaid' logical schema</li>\n<li>Creating a 'long, narrow' table that stores dynamic column values as rows that then need to be pivoted to create a 'short, wide' rowset containing all the values for a specific entity</li>\n<li>Using a BigTable/SimpleDB PropertyBag type system</li>\n</ul>\n\n<p>Any answers based on real world experience would be greatly appreciated</p>\n    ","a":"\n<p>What you are proposing is not new. Plenty of people have tried it... most have found that they chase \"infinite\" flexibility and instead end up with much, much less than that. It's the \"roach motel\" of database designs -- data goes in, but it's almost impossible to get it out. Try and conceptualize writing the code for ANY sort of constraint and you'll see what I mean.</p>\n\n<p>The end result typically is a system that is MUCH more difficult to debug, maintain, and full of data consistency problems. This is not <em>always</em> the case, but more often than not, that is how it ends up. Mostly because the programmer(s) don't see this train wreck coming and fail to defensively code against it. Also, often ends up the case that the \"infinite\" flexibility really isn't that necessary; it's a very bad \"smell\" when the dev team gets a spec that says \"Gosh I have no clue what sort of data they are going to put here, so let 'em put WHATEVER\"... and the end users are just fine having pre-defined attribute types that they can use (code up a generic phone #, and let them create any # of them -- this is trivial in a nicely normalized system and maintains flexibility and integrity!)</p>\n\n<p>If you have a very good development team and are <strong>intimately aware</strong> of the problems you'll have to overcome with this design, you can successfully code up a well designed, not terribly buggy system. Most of the time. </p>\n\n<p>Why start out with the odds stacked so much against you, though?</p>\n\n<p>Don't believe me? Google \"One True Lookup Table\" or \"single table design\". Some good results:\n<a href=\"http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:10678084117056\">http://asktom.oracle.com/pls/asktom/f?p=100:11:0::::P11_QUESTION_ID:10678084117056</a></p>\n\n<p><a href=\"http://thedailywtf.com/Comments/Tom_Kyte_on_The_Ultimate_Extensibility.aspx?pg=3\">http://thedailywtf.com/Comments/Tom_Kyte_on_The_Ultimate_Extensibility.aspx?pg=3</a></p>\n\n<p><a href=\"http://www.dbazine.com/ofinterest/oi-articles/celko22\">http://www.dbazine.com/ofinterest/oi-articles/celko22</a></p>\n\n<p><a href=\"http://thedailywtf.com/Comments/The_Inner-Platform_Effect.aspx?pg=2\">http://thedailywtf.com/Comments/The_Inner-Platform_Effect.aspx?pg=2</a></p>\n    "},{"t":"List, IList, IEnumerable, IQueryable, ICollection, which is most flexible return type?","l":"http://stackoverflow.com/questions/3559868/list-ilist-ienumerable-iqueryable-icollection-which-is-most-flexible-return","q":"\n\n<p>I've seen this question posted here previously but I'm not satisfied that I understand the complete ramifications. The problem is what return type should a data layer that uses linq-to-sql return for maximum flexibility and query ability. This is what I've read/found:</p>\n\n<ol>\n<li><p>IEnumerable is limited and only allows for read forward operation. IEnumerable is the most generic. What I've found is that IEnumerable does allow query operations vs the extension syntax.</p></li>\n<li><p>List allows for most flexibility because of insert operations.</p></li>\n<li><p>Collections should be used instead of list to enable read only collections.</p></li>\n<li><p>IQueryable should never be used, it should be \"used and turned off\". IQueryable doesn't return a list but generates a query syntax for database.</p></li>\n</ol>\n\n<p>I feel I have a better feel for the trade offs but still not sure about a few things:</p>\n\n<ol>\n<li><p>Why would I choose the interface variants over the concrete types? I.e IList or ICollection vs List or Collection. What benefit would I get?</p></li>\n<li><p>I see that the extension operations work but will the expanded query syntax work as well?</p></li>\n<li><p>Someone suggested I use AsQueryable() before. But, why would I do this if I don't have connection to the database? It seems the extension methods work regardless.</p></li>\n</ol>\n    ","a":"\n<p>Collections are not generally very useful for DAL returns, because a collection does not implicitly guarantee order. It's just a bucket of items. An IList, on the other hand, does implicitly guarantee order. So we're down to IEnumerable or IList. The next question would be: is the List object \"live\"? i.e., is it connected to the data backing so that when you add an item to the IList, it will be reflected in the DB? For LINQ-to-SQL, this is not the case. Rather, you're supposed to attach entities to the tables. So unless you supply this additional wiring, a List is superfluous. Stick with IEnumerable.</p>\n    "},{"t":"How to expose a collection property?","l":"http://stackoverflow.com/questions/35007/how-to-expose-a-collection-property","q":"\n\n<p>Every time I create an object that has a collection property I go back and forth on the best way to do it?</p>\n\n<ol>\n<li>public property with a getter that\nreturns a reference to private variable</li>\n<li>explicit get_ObjList and set_ObjList\nmethods that return and create new or cloned\nobjects every time</li>\n<li>explicit get_ObjList that returns an\nIEnumerator and a set_ObjList that\ntakes IEnumerator</li>\n</ol>\n\n<p>Does it make a difference if the collection is an array (i.e., objList.Clone()) versus a List?</p>\n\n<p>If returning the actual collection as a reference is so bad because it creates dependencies, then why return any property as a reference? Anytime you expose an child object as a reference the internals of that child can be changed without the parent \"knowing\" unless the child has a property changed event.  Is there a risk for memory leaks?</p>\n\n<p>And, don't options 2 and 3 break serialization? Is this a catch 22 or do you have to implement custom serialization anytime you have a collection property?</p>\n\n<p>The generic ReadOnlyCollection seems like a nice compromise for general use. It wraps an IList and restricts access to it.  Maybe this helps with memory leaks and serialization.  However it still has <a href=\"http://www.coversant.net/Coversant/Blogs/tabid/88/EntryID/34/Default.aspx\">enumeration concerns</a> </p>\n\n<p>Maybe it just depends.  If you don't care that the collection is modified, then just expose it as a public accessor over a private variable per #1. If you don't want other programs to modify the collection then #2 and/or #3 is better.</p>\n\n<p>Implicit in the question is why should one method be used over another and what are the ramifications on security, memory, serialization, etc.?</p>\n    ","a":"\n<p>How you expose a collection depends entirely on how users are intended to interact with it.</p>\n\n<p><strong>1)</strong> If users will be adding and removing items from an object's collection, then a simple get-only collection property is best (option #1 from the original question):</p>\n\n<pre><code>private readonly Collection&lt;T&gt; myCollection_ = new ...;\npublic Collection&lt;T&gt; MyCollection {\n  get { return this.myCollection_; }\n}\n</code></pre>\n\n<p>This strategy is used for the <code>Items</code> collections on the WindowsForms and WPF <code>ItemsControl</code> controls, where users add and remove items they want the control to display. These controls publish the actual collection and use callbacks or event listeners to keep track of items.</p>\n\n<p>WPF also exposes some settable collections to allow users to display a collection of items they control, such as the <code>ItemsSource</code> property on <code>ItemsControl</code> (option #3 from the original question). However, this is not a common use case.</p>\n\n<p><br>\n<strong>2)</strong> If users will only be reading data maintained by the object, then you can use a readonly collection, as <a href=\"http://stackoverflow.com/questions/35007/how-to-expose-a-collection-property#35065\">Quibblesome</a> suggested:</p>\n\n<pre><code>private readonly List&lt;T&gt; myPrivateCollection_ = new ...;\nprivate ReadOnlyCollection&lt;T&gt; myPrivateCollectionView_;\npublic ReadOnlyCollection&lt;T&gt; MyCollection {\n  get {\n    if( this.myPrivateCollectionView_ == null ) { /* lazily initialize view */ }\n    return this.myPrivateCollectionView_;\n  }\n}\n</code></pre>\n\n<p>Note that <code>ReadOnlyCollection&lt;T&gt;</code> provides a live view of the underlying collection, so you only need to create the view once.</p>\n\n<p>If the internal collection does not implement <code>IList&lt;T&gt;</code>, or if you want to restrict access to more advanced users, you can instead wrap access to the collection through an enumerator:</p>\n\n<pre><code>public IEnumerable&lt;T&gt; MyCollection {\n  get {\n    foreach( T item in this.myPrivateCollection_ )\n      yield return item;\n  }\n}\n</code></pre>\n\n<p>This approach is simple to implement and also provides access to all the members without exposing the internal collection. However, it does require that the collection remain unmodfied, as the BCL collection classes will throw an exception if you try to enumerate a collection after it has been modified. If the underlying collection is likely to change, you can either create a light wrapper that will enumerate the collection safely, or return a copy of the collection.</p>\n\n<p><br>\n<strong>3)</strong> Finally, if you need to expose arrays rather than higher-level collections, then you should return a copy of the array to prevent users from modifying it (option #2 from the orginal question):</p>\n\n<pre><code>private T[] myArray_;\npublic T[] GetMyArray( ) {\n  T[] copy = new T[this.myArray_.Length];\n  this.myArray_.CopyTo( copy, 0 );\n  return copy;\n  // Note: if you are using LINQ, calling the 'ToArray( )' \n  //  extension method will create a copy for you.\n}\n</code></pre>\n\n<p>You should not expose the underlying array through a property, as you will not be able to tell when users modify it. To allow modifying the array, you can either add a corresponding <code>SetMyArray( T[] array )</code> method, or use a custom indexer:</p>\n\n<pre><code>public T this[int index] {\n  get { return this.myArray_[index]; }\n  set {\n    // TODO: validate new value; raise change event; etc.\n    this.myArray_[index] = value;\n  }\n}\n</code></pre>\n\n<p>(of course, by implementing a custom indexer, you will be duplicating the work of the BCL classes :)</p>\n    "},{"t":"Better to have huge Controllers, or many controllers, in MVC?","l":"http://stackoverflow.com/questions/1197908/better-to-have-huge-controllers-or-many-controllers-in-mvc","q":"\n\n<p>We are building a fairly large HR application in ASP.NET MVC, and so far our controllers are becoming quite large.  For example, we have an Employee controller, and all employee views are included (Personal info, employee deductions, dependents, etc).  Each of these views might have multiple actions or subviews (e.g. CRUD).  Each action is relatively small, but the controllers might have dozens of functions.</p>\n\n<p>Are there any best practices for splitting controllers?  Instead of having an Employee controller with dozens of views, would it be better too have one controller for each subtype (i.e. EmployeePersonalInfoController, EmployeeDeductionController, EmployeeDependentController)?  </p>\n\n<p>And finally, does it even matter?</p>\n\n<p><strong>Updated Clarification</strong></p>\n\n<p>My original concern was with CRUD actions.  For example, let's consider Create and Delete ... </p>\n\n<p><em>Current Actions in EmployeeController</em>:</p>\n\n<pre><code>  CreateEmployee()\n  DeleteEmployee()\n  CreateEmployeeDeduction()\n  DeleteEmployeeDeduction()\n  CreateDependent()\n  DeleteDependent()\n  etc.\n</code></pre>\n\n<p>If the controllers were split:</p>\n\n<pre><code>  EmployeeController\n    Create()\n    Delete()\n  EmployeeDeductionController\n    Create()\n    Delete()\n  EmployeeDependentController\n    Create()\n    Delete()\n  EmployeeBenefitController\n    Create()\n    Delete()\n  etc.\n</code></pre>\n\n<p>In the 1st scenario, our ~100 screens get split into 8-10 large controllers.  In the second, I'd probably have ~50 controllers.</p>\n    ","a":"\n<p>In my humble opinion, if you are keeping the code in your controllers down then it doesn't really matter.</p>\n\n<p>Most of your code would be happening in a business layer somewhere right?  If that's the case then all you are really doing in your controller is returning data to the view.  As it should be.</p>\n\n<p>Not really sure if I'm a fan of seperating the controllers into subtypes.  Whilst you should maintain seperation of concerns I think subtypes is going a little too far.</p>\n\n<p>You could take a look at this post to see if it helps.  <a href=\"http://stackoverflow.com/questions/1169622/asp-net-mvc-same-view-name-different-paths/1169647#1169647\">Same View Different Paths</a></p>\n\n<p>That may be a better solution than using a subtype approach that you suggested.</p>\n    "},{"t":"What is SOA (Service Oriented Architecture)?","l":"http://stackoverflow.com/questions/1093204/what-is-soa-service-oriented-architecture","q":"\n\n<p>Call me a troll if you want, but I'm serious -- how exactly is the new SOA trend any different than the client-service architecture that I was building 15 years ago? I keep hearing SOA but I don't see how it's different than what we've always done. Back 10 years ago, ,y company had multiple clients (in multiple languages) which talked to the same service. It wasn't XML (it was a binary protocol called Microsoft DCOM) and there wasn't auto-discovery through WSDL but that's OK since reading the docs was just as easy. Our system was even \"open\" in the sense we documented it enough to allow 3rd parties to talk to our services. We were not pioneers -- every other company I knew 10 years ago was doing the same thing.\n   The ONLY difference I see between then and now is that now there's a single service available on the internet, whereas 10 years ago, each customer would host his own instance of the service. But that's not an architecture issue -- where the service physically lives is transparent to anyone using the service. </p>\n\n<p>So what exactly is SOA that's different than what we've been doing for years? Is SOA simply a marketing term representing a best practice that actually became common a long long time ago? Or am I missing some subtely to SOA that's different than what we've been doing all along? </p>\n    ","a":"\n<p>Forget about XML. Forget about WSDL. SOA is not a technology you can buy, though it's often marketed that way.</p>\n\n<p>The real point of SOA is all about IT <em>organization</em>. The point of SOA is to avoid having a huge bunch of \"applications\" that have isolated data pools and either don't talk to each other at all (and thus often duplicate data), or only in an inefficient, buggy way through adapter layers or EAI systems.</p>\n\n<p>For large companies, this is a serious problem - they have literally hundreds of separate apps that are insufficiently integrated. There's duplicate and inconsistent data everywhere and the result is that customers get pissed off and real money is lost because the billing department keeps sending invoices for a cancelled order and the customer service rep can't even find the order because it's cancelled in the order tracking system, but not the billing system.</p>\n\n<p>SOA is supposed to solve this by designing every app from the ground up to publish its services in a standardized, cross-platfrom manner so that other apps can access the data and don't have to duplicate it.</p>\n\n<p>From a business perspective, this is highly desirable. The buzzword hype and the acronym soup is just IT companies' attempts to cash in on that desirability. Unfortunately, this has (mis)led many people, including CEOs into believing that SOA is a product you can buy and it will magically make your IT more efficient, without realizing that this will only happen if you also reorganize your entire IT (and quite possibly your business units as well) to be SOA-compatible.</p>\n    "},{"t":"Core Data on client (iOS) to cache data from a server Strategy","l":"http://stackoverflow.com/questions/4878586/core-data-on-client-ios-to-cache-data-from-a-server-strategy","q":"\n\n<p>I have written many iOS apps that was communicating with the backend. Almost every time, I used HTTP cache to cache queries and parse the response data (JSON) into objective-C objects. For this new project, I'm wondering if a Core Data approach would make sense.</p>\n\n<p>Here's what I thought: </p>\n\n<p>The iOS client makes request to the server and parse the objects from JSON to CoreData models.</p>\n\n<p>Every time I need a new object, instead of fetching the server directly, I parse CoreData to see if I already made that request. If that object exists and hasn't expired, I use the fetched object.</p>\n\n<p>However, if the object doesn't exist or has expired (Some caching logic would be applied here), I would fetch the object from the server and update CoreData accordingly.</p>\n\n<p>I think having such an architecture could help with the following:\n1. Avoid unnecessary queries to the backend\n2. Allow a full support for offline browsing (You can still make relational queries with DataCore's RDBMS)</p>\n\n<p>Now here's my question to SO Gods: </p>\n\n<ol>\n<li>I know this kinda requires to code the backend logic a second time (Server + CoreData) but is this overkill?</li>\n<li>Any limitation that I have under estimated?</li>\n<li>Any other idea?</li>\n</ol>\n    ","a":"\n<p>First of all, If you're a registered iOS Dev, you should have access to the WWDC 2010 Sessions. One of those sessions covered a bit of what you're talking about: \"Session 117, Building a Server-driven User Experience\". You should be able to <a href=\"http://developer.apple.com/videos/wwdc/2010/\">find it on iTunes</a>.</p>\n\n<p>A smart combination of REST / JSON / Core Data works like a charm and is a huge time-saver if you plan to reuse your code, but will require knowledge about HTTP (and knowledge about Core Data, if you want your apps to perform well and safe).</p>\n\n<p>So the key is to understand REST and Core Data.</p>\n\n<ul>\n<li><p>Understanding <a href=\"http://en.wikipedia.org/wiki/Representational_State_Transfer\">REST</a> means Understanding HTTP Methods (GET, POST, PUT, DELETE, ...HEAD ?) and Response-Codes (2xx, 3xx, 4xx, 5xx) and Headers (Last-Modified, If-Modified-Since, Etag, ...)</p></li>\n<li><p>Understanding Core Data means knowing how to design your Model, setting up relations, handling time-consuming operations (deletes, inserts, updates), and how to make things happen in the background so your UI keeps responsive. And of course how to query locally on sqlite (eg. for prefetching id's so you can update objects instead of create new ones once you get their server-side equivalents).</p></li>\n</ul>\n\n<p>If you plan to implement a reusable API for the tasks you mentioned, you should make sure you understand REST and Core Data, because that's where you will probably do the most coding. (Existing API's - <a href=\"http://allseeing-i.com/ASIHTTPRequest/\">ASIHttpRequest</a> for the network layer (or any other) and any good JSON lib (eg. <a href=\"http://code.google.com/p/json-framework/\">SBJSON</a>) for parsing will do the job.</p>\n\n<p>The key to make such an API simple is to have your server provide a RESTful Service, and your Entities holding the required attributes (dateCreated, dateLastModified, etc.) so you can create Requests (easily done with ASIHttpRequest, be they GET, PUT, POST, DELETE) and add the appropriate Http-Headers, e.g. for a Conditional GET: If-Modified-Since.</p>\n\n<p>If you already feel comfortable with Core Data and can handle JSON and can easily do HTTP Request and handle Responses (again, ASIHttpRequest helps a lot here, but there are others, or you can stick to the lower-level Apple NS-Classes and do it yourself), then all you need is to set the correct HTTP Headers for your Requests, and handle the Http-Response-Codes appropriately (assuming your Server is REST-ful).</p>\n\n<p>If your primary goal is to avoid to re-update a Core-Data entity from a server-side equivalent, just make sure you have a \"last-modified\" attribute in your entity, and do a conditional GET to the server (setting the \"If-Modified-Since\" Http-Header to your entities \"last-modified\" date. The server will respond with Status-Code 304 (Not-Modified) if that resource didn't change (assuming the server is REST-ful). If it changed, the server will set the \"Last-Modified\" Http-Header to the date the last change was made, will respond with Status-Code 200 and deliver the resource in the body (eg. in JSON format).</p>\n\n<p>So, as always, the answer is to your question is as always probably 'it depends'. \nIt mostly depends what you'd like to put in your reusable do-it-all core-data/rest layer.</p>\n\n<p>To tell you numbers: It took me 6 months (in my spare time, at a pace of 3-10 hours per week) to have mine where I wanted it to be, and honestly I'm still refactoring, renaming, to let it handle special use-cases (cancellation of requests, roll-backs etc) and provide fine-grained call-backs (reachability, network-layer, serialization, core data saving...), . But it's pretty clean and elaborate and optimized and hopefully fits my employer's general needs (an online market-place for classifieds with multiple iOS apps).  That time included doing learning, testing, optimizing, debugging and constantly changing my API (First adding functionality, then improving it, then radically simplifying it, and debugging it again).</p>\n\n<p>If time-to-market is your priority, you're better off with a simple and pragmatic approach: Nevermind reusability, just keep the learnings in mind, and refactor in the next project, reusing and fixing code here and there. In the end, the sum of all experiences might materialize in a clear vision of HOW your API works and WHAT it provides. If you're not there yet, keep your hands of trying to make it part of project budget, and just try to reuse as much of stable 3'rd-Party API's out there.</p>\n\n<p>Sorry for the lenghty response, I felt you were stepping into something like building a generic API or even framework. Those things take time, knowledge, housekeeping and long-term commitment, and most of the time, they are a waste of time, because you never finish them.</p>\n\n<p>If you just want to handle specific caching scenarios to allow offline usage of your app and minimize network traffic, then you can of course just implement those features. Just set if-modified-since headers in your request, inspect last-modified headers or etags, and keep that info persistent in your persistet entities so you can resubmit this info in later requests. Of course I'd also recommend caching (persistently) resources such as images locally, using the same HTTP headers.</p>\n\n<p>If you have the luxury of modifying (in a REST-ful manner) the server-side service, then you're fine, provided you implement it well (from experience, you can save as much as 3/4 of network/parsing code iOS-side if the service behaves well (returns appropriate HTTP status codes, avoids checks for nil, number transformations from strings, dates, provide lookup-id's instead of implicit strings etc...).</p>\n\n<p>If you don't have that luxury, then either that service is at least REST-ful (which helps a lot), or you'll have to fix things client-side (which is a pain, often).</p>\n    "},{"t":"What is Cyclomatic Complexity?","l":"http://stackoverflow.com/questions/911637/what-is-cyclomatic-complexity","q":"\n\n<p>A term that I see every now and then is \"Cyclomatic Complexity\". Here on SO I saw some Questions about \"how to calculate the CC of Language X\" or \"How do I do Y with the minimum amount of CC\", but I'm not sure I really understand what it is.</p>\n\n<p>On the <a href=\"http://www.ndepend.com/Metrics.aspx#CC\">NDepend Website</a>, I saw an explanation that basically says \"The number of decisions in a method. Each if, for, &amp;&amp; etc. adds +1 to the CC \"score\"). Is that really it? If yes, why is this bad? I can see that one might want to keep the number of if-statements fairly low to keep the code easy to understand, but is this really everything to it?</p>\n\n<p>Or is there some deeper concept to it?</p>\n    ","a":"\n<p>I'm not aware of a deeper concept.  I believe it's generally considered in the context of a maintainability index.  The more branches there are within a particular method, the more difficult it is to maintain a mental model of that method's operation (generally).  </p>\n\n<p>Methods with higher cyclomatic complexity are also more difficult to obtain full code coverage on in unit tests.  (Thanks <a href=\"http://stackoverflow.com/users/102529/marc-w\">Mark W</a>!)</p>\n\n<p>That brings all the other aspects of maintainability in, of course.  Likelihood of errors/regressions/so forth.  The core concept is pretty straight-forward, though.</p>\n    "},{"t":"Detecting CPU architecture compile-time","l":"http://stackoverflow.com/questions/152016/detecting-cpu-architecture-compile-time","q":"\n\n<p>What is the most reliable way to find out CPU architecture when compiling C or C++ code? As far as I can tell, different compilers have their own set of non-standard preprocessor definitions (<code>_M_X86</code> in MSVS, <code>__i386__</code>, <code>__arm__</code> in GCC, etc).</p>\n\n<p>Is there a <em>standard</em> way to detect the architecture I'm building for? If not, is there a source for a comprehensive list of such definitions for various compilers, such as a header with all the boilerplate <code>#ifdef</code>s?</p>\n    ","a":"\n<p>Here is some information about <a href=\"http://sourceforge.net/p/predef/wiki/Architectures/\">Pre-defined Architecture Macros</a> and other types of pre-defined macros.</p>\n    "},{"t":"Recommended scalable AngularJS project structure?","l":"http://stackoverflow.com/questions/13522246/recommended-scalable-angularjs-project-structure","q":"\n\n<p>I have seen several AngularJS project templates: the <a href=\"https://github.com/angular/angular-seed\">seed project</a> at the official website, <a href=\"http://yeoman.io/\">Yeoman</a>'s generated, and <a href=\"https://github.com/CaryLandholt/AngularFun\">AngularFun</a>. </p>\n\n<p>Are there any other (un)opinionated templates I should take a look at, or any related pattern you would suggest for a scalable AngularJS project?</p>\n\n<p>By scalable I mean</p>\n\n<ul>\n<li>being able to split controllers, directives, filters, etc. in their own files; </li>\n<li>being able to load these files on demand rather than making the browser load everything;</li>\n<li>being able to have common, cross-project components (e.g. common directives, filters or services).</li>\n</ul>\n    ","a":"\n<p>You can take a look at a demo application that Pawel Kozlowski and I are putting together: \n<a href=\"https://github.com/angular-app/angular-app\">https://github.com/angular-app/angular-app</a>.</p>\n\n<p>It doesn't provide any support for loading files on demand but you can see we spit modules up into separate files and set up testing as a first class component.  We have a build process (using Grunt) that concatenates (and minifies on release) the js files and can run unit and end to end tests.</p>\n\n<p>We have chosen to split our modules into two groups functional application areas and common cross cutting library code, rather than a simple split into directives, filter, services and so on.  In side a functional area we might have some service, directives, controllers and templates.</p>\n\n<p>This makes developing against a functional area easier as all the relevant items are in one place.</p>\n\n<p>The project relies on a simple nodeJS server to deliver the files (supporting HTML5 mode deep linking) and also to provide authentication and authorization services.</p>\n    "},{"t":"How to organize a Swing GUI application?","l":"http://stackoverflow.com/questions/6269851/how-to-organize-a-swing-gui-application","q":"\n\n<p>I've written a few GUI's using Swing and I know about MVC, but I never found a good way to really organize my code somehow. What I am looking for is something like the folder structure that maven introduces for each new project. Another example is rails, where MVC is introduced through the folder structure automatically. Is there something similar for Swing?</p>\n\n<p>It would also be nice to see a book that describes the development of a larger Swing Application. All I find are books about design-guidelines where design refers to the look of the application. Other Swing books (like O'Reilly) describe in detail all the swing components, but where is any information about the big picture?</p>\n\n<p>Are there any good examples of a swing gui, where you'd say \"That's how you organize code/folders/packages for swing!\"?</p>\n\n<p>EDIT: I found the following site <a href=\"http://www.ibm.com/developerworks/java/tutorials/j-springswing/section7.html\">http://www.ibm.com/developerworks/java/tutorials/j-springswing/section7.html</a> which describes the usage of spring while creating a GUI. It is a quite old example and it doesn't answer my question, but it is a step into the right direction. It also mentions Spring RCP, but I'm not sure if it could be the solution.</p>\n\n<p>EDIT2: I still didn't find any better answers. Does anybody know an example for a ideally structured Swing GUI which is Open Source? Does anybody know a book, which describes it? And if not for Swing, then maybe for GUI's in general?</p>\n    ","a":"\n<p>Although it is <strong>Groovy</strong>, not <strong>Java</strong>, I would advise you take a look at <a href=\"http://griffon.codehaus.org/\">Griffon</a>, which is a \"<em>Grails for Swing</em>\".</p>\n\n<p>It enforces a given structure (in terms of directories and patterns, <strong>MVC</strong> in particular) to all applications you build with it.</p>\n\n<p>I think it can give you good ideas in general, although you would have to perform some little adaptation to Java.</p>\n\n<p>Besides, please note that Griffon also supports Application building in Java, and it may also provide \"archetypes\" for that, so you could check that as well.</p>\n    "},{"t":"Why is number of bits always(?) a power of two?","l":"http://stackoverflow.com/questions/1606827/why-is-number-of-bits-always-a-power-of-two","q":"\n\n<p>We have 8-bit, 16-bit, 32-bit and 64-bit hardware architectures and operating systems. But not, say, 42-bit or 69-bit ones.</p>\n\n<p>Why? Is it something fundamental that makes 2^n bits a better choice, or is just about compatibility with existing systems? (It's obviously convenient that a 64-bit register can hold two 32-bit pointers, or that a 32-bit data unit can hold 4 bytes.)</p>\n    ","a":"\n<p>That's mostly a matter of tradition. It is not even always true. For example, floating-point units in processors (even contemporary ones) have 80-bits registers. And there's nothing that would force us to have 8-bit bytes instead of 13-bit bytes.</p>\n\n<p>Sometimes this has mathematical reasoning. For example, if you decide to have an N bits byte and want to do integer multiplication you need exactly 2N bits to store the results. Then you also want to add/subtract/multiply those 2N-bits integers and now you need 2N-bits general-purpose registers for storing the addition/subtraction results and 4N-bits registers for storing the multiplication results.</p>\n    "},{"t":"What is the best resource for learning Scrum? [closed]","l":"http://stackoverflow.com/questions/87513/what-is-the-best-resource-for-learning-scrum","q":"\n\n<p>What is the best resource for learning Scrum?</p>\n    ","a":"\n<p>Best video for learning Scrum: <a href=\"http://www.youtube.com/watch?v=Q5k7a9YEoUI&amp;fmt=22\">http://www.youtube.com/watch?v=Q5k7a9YEoUI&amp;fmt=22</a></p>\n    "},{"t":"Why is CommonJS only said to be suitable for non-browser apps?","l":"http://stackoverflow.com/questions/4773298/why-is-commonjs-only-said-to-be-suitable-for-non-browser-apps","q":"\n\n<p>Why not use it as a general component pattern for Javascript, including browser-executed Javascript?</p>\n\n<p>At a glance, it seems to be a good way to modularize the project I'm currently working on, which consists of a large Javascript code-base, with lots of components, some of which interact with eachother.</p>\n    ","a":"\n<p>CommonJS is definitely suitable for the browser, with some caveats. The CommonJS module pattern is quite nice (in my biased opinion), and is also a good stepping stone to the module system proposed for ECMAScript Harmony (the planned next release of the JavaScript language). Specifically, Harmony modules won't have access to the global (\"window\") object.</p>\n\n<p>The reason that some people claim CommonJS modules are not suitable for the browser is that they can't be loaded via a &lt;script&gt; tag without some server-side assistance. For example, imagine you have a markdown library that exports a \"convertToHTML\" function. You could then make a module that looks like this:</p>\n\n<pre><code>var convertToHTML = require(\"markdown\").convertToHTML;\nexports.mangleSomeText = function() {\n    // do something then call convertToHTML\n}\n</code></pre>\n\n<p>This doesn't work via a script tag for a few reasons (the scope isn't wrapped, so convertToHTML would get attached to window, require wouldn't typically be defined and exports needs to be created separately for each module).</p>\n\n<p>A client side library with a tiny bit of server side help could allow this to load via script tags easily. Or, a client side library that loads the script via XMLHttpRequest and does an eval() would also work, though the debugging experience is often not as good.</p>\n\n<p>A fairly reasonable solution right now, though one that is also the subject of contentious debate among CommonJS members, is <a href=\"http://requirejs.org\">RequireJS</a>. Using RequireJS, you can write your module like this:</p>\n\n<pre><code>define(function(require, exports, module) {\n\nvar convertToHTML = require(\"markdown\").convertToHTML;\nexports.mangleSomeText = function() {\n    // do something then call convertToHTML\n}\n\n});\n</code></pre>\n\n<p>All we did was add that define() bit around the module. (You could likely make a server do that pretty easily as well, so that you don't even need to manually type the define part).</p>\n\n<p>I've personally used RequireJS on a couple of projects now and find it an easy way to make use of CommonJS modules without a server-side bit. There are <em>many</em> other solutions and if you aren't reliant on running static JS files, standard CommonJS modules are a great way to go.</p>\n\n<p>(ObDisclaimer: I started the CommonJS project, so I am clearly biased.)</p>\n    "},{"t":"Using Dependency Injection with Roboguice?","l":"http://stackoverflow.com/questions/6245722/using-dependency-injection-with-roboguice","q":"\n\n<p>I'm working on an Android project and I would like to know any recommendations about what's a good architecture to build an android application.</p>\n\n<p>I want to use dependency injection using Roboguice and I've been reading about MVVM pattern or MVC pattern (<a href=\"http://stackoverflow.com/questions/4972927/android-mvvm-design-pattern-examples\">Android MVVM Design Pattern Examples</a>).</p>\n\n<p>Also I know that roboguice have a pretty cool Context-Based Event's raising and handling feature that could be very testable as the code is decoupled.</p>\n\n<p>Any recommendations on a working design pattern? a testable and scalable architecture you have worked with or developed?</p>\n    ","a":"\n<p>The Android platform provides a common set of design patterns, and with the limited hardware resources you get compared to Web-apps it is still often best to stick with using these directly in production code. There are other frameworks that sort of \"wrap\" the base platform; these are worth looking into if you have a specific purpose (or perhaps for prototyping/experimenting), but for the best level of support you are generally best sticking with the standard components.</p>\n\n<p>This is a great resource when working on UI solutions: <a href=\"http://www.androidpatterns.com/\">http://www.androidpatterns.com/</a></p>\n\n<p>Specifically for DI: There is a <a href=\"http://www.springsource.org/spring-android\">Spring framework for Android</a>, I've had a play with it and it looks quite promising. You've already mentioned Roboguice as another alternative to this. However, to avoid performance and library overhead, I still find the easiest approach is to write a simple reflection-based class that registers and injects dependencies within my own code. Similar to <a href=\"http://ralfoide.blogspot.com/2011/03/diy-dependency-injection.html\">this approach</a>, except I usually move the injection code into a separate singleton and reference it from there.</p>\n\n<p>In my experience most of the third-party offerings are not yet mature enough to rely on right now, and don't really give you much on top of what the base platform provides. They are constantly progressing, however, so be sure to experiment with the big names from time-to-time.</p>\n    "},{"t":"Is NodeJS really Single-Threaded?","l":"http://stackoverflow.com/questions/7018093/is-nodejs-really-single-threaded","q":"\n\n<p>Node.js solves \"One Thread per Connection Problem\" by putting the event-based model at its core, using an event loop instead of threads. \nAll the expensive I/O operations are always executed asynchronously with a callback that gets executed when the initiated operation completes.</p>\n\n<p>The Observation IF any Operation occures is handled by multiplexing mechanisms like epoll().</p>\n\n<p>My Question is now:</p>\n\n<ul>\n<li><p>Why doesnt NodeJS Block while using the blocking Systemcalls\nselect/epoll/kqueue? </p></li>\n<li><p>Or isnt NodeJS Single Threaded at all, so that a second Thread is<br>\nnecessary to observe all the I/O-Operations with select/epoll/kqueue?</p></li>\n</ul>\n    ","a":"\n<p>NodeJS is <em>evented</em> (2nd line from the <a href=\"http://nodejs.org/\">website</a>), not single-threaded. It internally handles threading needed to do select/epoll/kqueue handling without the user explicitly having to manage that, but that doesn't mean there is no thread usage within it.</p>\n    "},{"t":"Architecture more suitable for web apps than MVC?","l":"http://stackoverflow.com/questions/7621832/architecture-more-suitable-for-web-apps-than-mvc","q":"\n\n<p>I've been learning Zend and its MVC application structure for my new job, and found that working with it just bothered me for reasons I couldn't quite put my finger on.  Then during the course of my studies I came across articles such as <a href=\"http://wardley.org/computers/web/mvc.html\">MVC: No Silver Bullet</a> and <a href=\"http://devzone.zend.com/article/12997\">this podcast</a> on the topic of MVC and web applications.  The guy in the podcast made a very good case against MVC as a web application architecture and nailed a lot of what was bugging me on the head.  </p>\n\n<p>However, the question remains, if MVC isn't really a good fit for web applications, what is?  </p>\n    ","a":"\n<p>It all depends on your coding style. Here's the secret: <strong>It is impossible to write classical MVC in PHP.</strong></p>\n\n<p>Any framework which claims you can is lying to you. The reality is that frameworks themselves cannot even implement MVC -- your code can. But that's not as good a marketing pitch, I guess. </p>\n\n<p>To implement a classical MVC it would require for you to have persistent Models to begin with. Additionally, Model should inform View about the changes (observer pattern), which too is impossible in your vanilla PHP page (you can do something close to classical MVC, if you use sockets, but that's impractical for real website).</p>\n\n<p>In web development you actually have 4 other MVC-inspired solutions:</p>\n\n<ul>\n<li><p><strong>Model2 MVC</strong>: View is requesting data from the Model and then deciding how to render it and which templates to use. Controller is responsible for changing the state of both View and Model.</p></li>\n<li><p><strong>MVVM</strong>: Controller is swapped out for a ViewModel, which is responsible for the translation between View's expectations and Models's logic. View requests data from controller, which translates the request so that Model can understand it. </p>\n\n<p>Most often you would use this when you have no control over either views or the model layer. </p></li>\n<li><p><strong>MVP</strong> (what php frameworks call \"MVC\"): Presenter requests information from Model, collects it, modifies it, and passes it to the passive View.</p>\n\n<p>To explore this pattern, I would recommend for you begin with <a href=\"http://www.wildcrest.com/Potel/Portfolio/mvp.pdf\">this publication</a>. It will explain it in detail.</p></li>\n<li><p><strong>HMVC</strong> (or PAC): differs from Model2 with ability of a controller to execute sub-controllers. Each with own triad of M, V and C. You gain modularity and maintainability, but pay with some hit in performance. </p></li>\n</ul>\n\n<p>Anyway. The bottom line is: you haven't really used MVC.</p>\n\n<p>But if you are sick of all the MVC-like structures, you can look into:</p>\n\n<ul>\n<li>event driven architectures</li>\n<li>n-Tier architecture</li>\n</ul>\n\n<p>And then there is always the <a href=\"http://en.wikipedia.org/wiki/Data,_Context_and_Interaction\">DCI</a> paradigm, but it has some issues when applied to PHP (you cannot cast to a class in PHP .. not without ugly hacks).</p>\n    "},{"t":"Do you know any alternative to NDepend for architects? [closed]","l":"http://stackoverflow.com/questions/996758/do-you-know-any-alternative-to-ndepend-for-architects","q":"\n\n<p>do you know any software similar to NDepend? I've got it just recently, and found it very useful. It helped me a lot, but for now i don't have a possibility to buy a professional version. </p>\n\n<p>So, is there any alternative (maybe, open-source)? Preferably, free. But not necessarily. Maybe, with a little bit more fitting price for a single-developer, not a team.</p>\n\n<p>Requirements for this software:\nBuild dependency diagrams\nRetrieve code metrics\nDisplay comments coverage \n(so far)</p>\n    ","a":"\n<p>Nitriq is a free static code analysis tool for .net. They don't have graphs, but they do have a treemap and instead of having to learn CQL, you use LINQ to do all of your querying. You can find it at <a href=\"http://www.nitriq.com\">www.nitriq.com</a></p>\n    "},{"t":"Multiple routers vs single router in BackboneJs","l":"http://stackoverflow.com/questions/8362230/multiple-routers-vs-single-router-in-backbonejs","q":"\n\n<p>All example on backbone using one router for the whole application. But wouldn't it make sense to have a router for single part of your app (header, footer, stage, sidebar). So my question is has anyone build apps with more than one router and what are experience.</p>\n\n<p>Lets think about a complex app with nested views. Wouldn't it be better when a view have an own router that handle the display of the subviews, than having one big router that have to inform the main view to change his sub views?</p>\n\n<p>The background of this question: I've see a lot of parallels of the router in backbone and the ActivityMapper in GWT. The ActivityMapper is only responsible to get the right presenter for a given route and a given container in the DOM. </p>\n    ","a":"\n<p>i wrote an app (still writing) with multiple routers in it.\nhowever it is not like you think, it is more module based and not a router per view or anything like that.</p>\n\n<p>for example,\nsay i got two big modules in my app,  1 handling all books, and 1 for the users.\nbooks have multiple views (as do users), a list view, detail view, edit view, etc etc...\nso each module has its own router,\nwhich stands for its own set of urls:</p>\n\n<pre><code>// user module...\nvar userRouter = Backbone.Router.extend({\n    routes: {\n        \"users\": \"loadUsers\",\n        \"users/add\": \"addUser\",\n        \"user/:id\": \"loadUser\",\n        \"user/:id/edit\": \"editUser\"\n    }\n\n// ... rest dropped to save the trees (you never know if someone prints this out)\n});\n\n\n// book module\nvar bookRouter = Backbone.Router.extend({\n    routes: {\n        \"books\": \"loadBooks\",\n        \"books/add\": \"addBook\",\n        \"book/:name\": \"loadBook\",\n        \"book/:name/edit\": \"editBook\"\n    }\n\n// ... rest dropped to save the trees (you never know if someone prints this out)\n});\n</code></pre>\n\n<p>so, it is not like my two routers are competing for the same route, they each handle their own set of routes.</p>\n\n<p><strong>edit</strong>\nnow that I had more info via Elf Sternberg, I know it isn't possible by default to have multiple routers match on the same route. without a workaround like overriding the backbone history or using namespaces in routes and regexes to match these routes. \nmore info here: <a href=\"http://stackoverflow.com/questions/5223251/multiple-matching-routes/\">multiple matching routes</a> \nthanks Elf Sternberg for the link.</p>\n    "},{"t":"Android application architecture - what is the suggested model?","l":"http://stackoverflow.com/questions/3320534/android-application-architecture-what-is-the-suggested-model","q":"\n\n<p>In the same way a web or desktop app might have three or n tiers - UI, Business, Data for example - what is the suggested structure for an Android application? How do you group classes together, what layers do you have etc? </p>\n\n<p>I'm just starting Android dev (an internet-based app that must respond to incoming notifications) and have no real feel for the structure I'm aiming at. Suggestions appreciated.</p>\n    ","a":"\n<p>The actions, views and activies in Android are the baked in way of working with the Android UI and are an implementation of a model-view-viewmodel pattern, which is structurally similar (in the same family as) model view controller.</p>\n\n<p>To the best of my knoweledge, there is no way to break out of this model. It can probably be done, but you would likely lose all the benefit that the existing model has, and have to rewrite your own UI layer to make it work.</p>\n\n<p><strong>You can find MVC in the followings:</strong></p>\n\n<ul>\n<li>You define your <a href=\"http://developer.android.com/intl/de/guide/topics/ui/index.html\">user interface</a> in  various XML files by resolution/hardware etc.</li>\n<li>You define your <a href=\"http://developer.android.com/intl/de/guide/topics/resources/index.html\">resources</a> in various XML files by locale etc.</li>\n<li>You store data in <a href=\"http://developer.android.com/intl/de/reference/android/database/sqlite/SQLiteDatabase.html\">SQLite</a> or your custom data in /assets/ folder, read more about <a href=\"http://www.wiseandroid.com/post/2010/06/14/Android-Beginners-Intro-to-Resources-and-Assets.aspx\">resources and assets</a></li>\n<li>You extend clases like <a href=\"http://developer.android.com/intl/de/reference/android/app/ListActivity.html\">ListActivity</a>, <a href=\"http://developer.android.com/intl/de/reference/android/app/TabActivity.html\">TabActivity</a> and make use of the XML file by <a href=\"http://developer.android.com/intl/de/reference/android/view/LayoutInflater.html\">inflaters</a></li>\n<li>You can create as many classes as you wish for your model, and have your own packages, that will act as a structure</li>\n<li>A lot of <a href=\"http://developer.android.com/intl/de/reference/android/util/package-summary.html\">Utils</a> have been already written for you. DatabaseUtils, Html, </li>\n</ul>\n\n<p>There is no single MVC Pattern you could obey to. MVC just states more or less that you don't should mingle data and view, so that e.g. views are responsible for holding data or classes which are processing data are directly affecting the view.</p>\n\n<p>But nevertheless, the way Android deals with classes and resources, you're sometimes even forced to follow the MVC pattern. More complicated in my oppinion are the activites which are responsible sometimes for the view but nevertheless act as an controller in the same time.</p>\n\n<p>If you define your views and layouts in the xml files, load your resources from the res folder, and if you avoid more or less to mingle this things in your code, then your anyway following a MVC pattern.</p>\n    "},{"t":"Best Practices - Design before coding","l":"http://stackoverflow.com/questions/373988/best-practices-design-before-coding","q":"\n\n<p>I'm curious How do you people think ? (I mean a way of thinking) about design architecture of your Libraries, Systems, Frameworks, etc. before start coding it.</p>\n\n<p>I recently find my self feeling pain in what I've done, and practically every time I want to start everything from scratch..</p>\n\n<p>I do design before, painting some schemes on the paper and imagine how it will work, but maybe I do it in a wrong way ?</p>\n\n<p>For example how do you decide what Interfaces you will need, or how everything will be connected in a best way ? </p>\n\n<p>(I had a problem some day ago, my friend asked me a library what I've done some time ago, and instead of giving him just one file, I had to give him about 3-4 files, and that's because they're connected in some way.. but not in the right one I think :) so it was my mistake in design..)</p>\n    ","a":"\n<p>I usually do enough analysis of the problem domain on paper/white board to get a good enough understanding of the problem domain to start writing code. I rarely draw implementation or class diagrams on paper. A key technique I've found to achieve better design is to not get too attached to the code you write. If I don't like it, I delete, rename, move and shuffle it around until it expresses a good enough solution to what I'm trying to solve. Sounds easy? Not at all! But with good \"coding\" tools, actually writing the code is not the major effort. Write some, refactor, delete, write again...</p>\n\n<p>Good design almost never start out good. <strong>It evolves to good.</strong> Accepting this makes it easier to work in small steps without getting frustrated why the design isn't \"perfect\". In order for this process to work you have to posses good design skills though. The point being, even excellent designers don't get it right the first time.</p>\n\n<p>Many times, I thought I understood the problem domain when I started, but I didn't. I then go back to the white board, talk to someone or read up on the problem domain if I realize I don't understand it well enough. I then go back to the code.</p>\n\n<p>It is a very iterative processes.</p>\n\n<p>An interesting question to ask when dealing with how programmers think, is how they developed their way of thinking. Personally, my way of thinking has evolved over the years, but a few events have had profound influence on the way I develop software. The most important among them have been to design software with people who are expert designers. Nothing has influenced me more than spending iterations with great designers. Another event that has, and still do, affect the way I think is going back and look at software I wrote some time back.</p>\n    "},{"t":"Have you ever derived a programming solution from nature? [closed]","l":"http://stackoverflow.com/questions/712769/have-you-ever-derived-a-programming-solution-from-nature","q":"\n\n<p>When you step back and look at ... </p>\n\n<ul>\n<li>the nature of animals, insects, plants and the problems they have organically solved</li>\n<li>perhaps even the nature and balance of the universe</li>\n</ul>\n\n<p>Have you ever been able to solve a problem by deriving an approach from nature?</p>\n\n<p>I've heard of <a href=\"http://en.wikipedia.org/wiki/Ant%5Fcolony%5Foptimization\" rel=\"nofollow\">Ant Colony Algorithms</a> being able to optimize supply chain amongst other things.  Also <a href=\"http://en.wikipedia.org/wiki/Fractal\" rel=\"nofollow\">Fractal</a>'s being the \"geometry of nature\" have been applied to a wide range of problems.</p>\n\n<p>Now that spring is here again and the world is coming back to life I'm wondering if anybody has some experiences they can share.</p>\n\n<p>Thanks</p>\n\n<p>PS I would recommend watching the \"<a href=\"http://www.pbs.org/wgbh/nova/fractals/\" rel=\"nofollow\">Hunting the Hidden Dimension</a>\" Nova episode on fractals.</p>\n    ","a":"\n<p>I remember reading a book by a mathematician about the field of mathematics, and he mentioned an example from nature. His example from nature helped me improve a design I was working on.</p>\n\n<p>His example was this: he was driving and he saw some birds on a telephone wire. The birds were spaced evenly apart. This happened not because there was some all-ruling bird that was telling each one where to sit. Rather, each bird had within itself a certain \"algorithm\" for deciding what to do when another bird came by. Birds prefer to maximize their free space, I guess.</p>\n\n<p>This helped me at a point when I was fairly new to OO. I kept tending to make things procedural and have centralized intelligence in \"god-objects\". I read this and realized that individual objects could focus only on the things they needed to know and care about, and yet that the result at the big picture level could still be what you want. That the right result can \"emerge\" without being \"controlled\".</p>\n    "},{"t":"Is it a good idea to use MySQL and Neo4j together?","l":"http://stackoverflow.com/questions/2541891/is-it-a-good-idea-to-use-mysql-and-neo4j-together","q":"\n\n<p>I will make an application with a lot of similar items (millions), and I would like to store them in a MySQL database, because I would like to do a lot of statistics and search on specific values for specific columns.</p>\n\n<p>But at the same time, I will store relations between all the items, that are related in many connected binary-tree-like structures (transitive closure), and relation databases are not good at that kind of structures, so I would like to store all relations in Neo4j which have good performance for this kind of data.</p>\n\n<p>My plan is to have all data except the relations in the MySQL database and all relations with <code>item_id</code> stored in the Neo4j database. When I want to lookup a tree, I first search the Neo4j for all the <code>item_id</code>:s in the tree, then I search the MySQL-database for all the specified items in a query that would look like:</p>\n\n<p><code>SELECT * FROM items WHERE item_id = 45 OR item_id = 345435 OR item_id = 343 OR item_id = 78 OR item_id = 4522 OR item_id = 676 OR item_id = 443 OR item_id = 4255 OR item_id = 4345</code></p>\n\n<p><b>Is this a good idea, or am I very wrong?</b> I haven't used graph-databases before. Are there any better approaches to my problem? How would the MySQL-query perform in this case?</p>\n    ","a":"\n<p>Few thoughts on this:</p>\n\n<p>I would try modelling your Neo4j domain model to include the attributes of each node in the graph. By separating your data into two different data stores you might limit some operations that you might want to do.</p>\n\n<p>I guess it comes down to what you will be doing with your graph? If for example want to find all the nodes connected to a specific node, whose attributes (ie name, age.. whatever) are certain values, would you first have to find the correct node ID in your MySQL database and then go into Neo4j. This just seems slow and overly complicated when you could do all this in Neo4j. So the question is will you need the attributes of a node when you traversing the graph? </p>\n\n<p>Will your data change or is it static? By having two separate data stores it will complicate matters.</p>\n\n<p>Whilst generating statistics using a MySQL database might be easier than doing everything in Neo4j, the code required to traverse a graph to find all the nodes that meet a defined criteria isn't overly difficult. What these stats are should drive your solution.</p>\n\n<p>I can't comment on the performance of the MySQL query to select node ids. I guess that comes down to how many nodes you will need to select and your indexing strategy. I agree about the performance side of things when it comes to traversing a graph though.</p>\n\n<p>This is a good article on just this: <a href=\"http://java.dzone.com/articles/mysql-vs-neo4j-large-scale\">MySQL vs. Neo4j on a Large-Scale Graph Traversal</a> and in this case, when they say large, they only mean a million vertices/nodes and four million edges. So it wasn't even a particularly dense graph.</p>\n    "},{"t":"ASP.NET MVC Architecture : ViewModel by composition, inheritance or duplication?","l":"http://stackoverflow.com/questions/6954102/asp-net-mvc-architecture-viewmodel-by-composition-inheritance-or-duplication","q":"\n\n<p>I'm using ASP.NET MVC 3 and Entity Framework 4.1 Code First.</p>\n\n<p>Let's say I have a <code>User</code> entity :</p>\n\n<pre><code>public class User\n{\n    public int Id { get; set; }\n    public string Name { get; set; }\n    public string Email { get; set; }\n    public string Password { get; set; }        \n}\n</code></pre>\n\n<p>When editing it in my <code>UserController</code> I want to add a <code>PasswordConfirmation</code> field and verify that <code>PasswordConfirmation == Password</code> </p>\n\n<h2>1. By composition</h2>\n\n<p>My first try was :</p>\n\n<pre><code>public class EditUserModel\n{\n    [Required]\n    public User User { get; set; }\n\n    [Compare(\"User.Password\", ErrorMessage = \"Passwords don't match.\")]\n    public string PasswordConfirmation { get; set; }\n}\n</code></pre>\n\n<p>In this case the client side validation <del>works but</del> (<strong>Edit:</strong> client side validation working was a coincidence.) <strong>doesn't work</strong> and the <strong>server side validation fails</strong> with the following message : <em>Could not find a property named User.Password</em></p>\n\n<p><strong>Edit:</strong> I think the best solution, in this case, would be to create a custom  <code>CompareAttribute</code></p>\n\n<p><strong>Implementing <code>IValidatableObject</code></strong></p>\n\n<pre><code>public class EditUserModel : IValidatableObject\n{\n    [Required]\n    public User User { get; set; }\n    public string PasswordConfirmation { get; set; }\n\n    public IEnumerable&lt;ValidationResult&gt; Validate(ValidationContext validationContext)\n    {\n        if(this.PasswordConfirmation != this.User.Password)\n            return new[] { new ValidationResult(\"Passwords don't match\", new[] { \"PasswordConfirmation \" }) };\n\n        return new ValidationResult[0];\n    }\n}\n</code></pre>\n\n<p>In this case the <strong>server side validation works</strong> but the <strong>client side validation doesn't work</strong> anymore. Implementing <code>IClientValidatable</code> seems a bit too complicated and I prefer not having client side validation in this case.</p>\n\n<h2>2. By inheritance</h2>\n\n<pre><code>public class EditUserModel : User\n{\n    [Compare(\"Password\", ErrorMessage = \"Passwords don't match.\")]\n    public string PasswordConfirmation  { get; set; }\n}\n</code></pre>\n\n<p>When trying to directly save <code>EditUserModel</code> using EF it doesn't work, I get some some error message about the <code>EditUserModel</code> metadata so I'm using <em>AutoMapper</em> to convert from <code>User</code> to <code>EditUserModel</code> and backwards.\nThis solution <strong>works</strong> but it more complex because I have to convert from the model to the view model and backwards.</p>\n\n<h2>3. By duplication</h2>\n\n<p><em>(Suggested by Malte Clasen)</em></p>\n\n<p>The view model would have all the properties of the model plus additional ones. <em>AutoMapper</em> can be used to convert from one to another.</p>\n\n<pre><code>public class EditUserModel {    \n  public string Name { get; set; }    \n  public string Email { get; set; }    \n  public string Password { get; set; }   \n  [Compare(\"Password\", ErrorMessage = \"Passwords don't match.\")]     \n  public string ConfirmPassword { get; set; }        \n}\n</code></pre>\n\n<p>This is the solution I like the least because of code duplication (DRY) </p>\n\n<p><strong>Questions</strong></p>\n\n<p>What are the pros and cons of inheritance, composition and duplication in this case ?</p>\n\n<p>Is there a simple way to have both client side and server side validation without having to convert the model to the view model and backwards ?</p>\n    ","a":"\n<p>Having struggled with this question before, I have in various instances gone with all three. In general, most of the opinions I've seen favor duplication in an MVC project, with a ViewModel constructed specifically for each view. In this manner the convention you'd use is something like <code>UserDetailsViewModel</code> and <code>UserCreateViewModel</code>. As you said, at that point AutoMapper or some other auto mapping tool would be used to convert from your domain objects to these flat ViewModels.</p>\n\n<p>While I, too, don't like repeating code, I also don't like polluting my domain objects with validation or other view-specific attributes. Another advantage, though admittedly one almost nobody would ever have to contend with (regardless of what all the pros say), is that you can manipulate your domain objects in some ways without necessarily manipulating your ViewModels. I mention that because it's commonly cited, not because it carries much weight for me.</p>\n\n<p>Lastly, using a truly flat ViewModel makes for cleaner markup. When I've used composition, I've often made errors creating HTML elements with names that are something like <code>User.Address.Street</code>. A flat ViewModel reduces at least my likelihood of doing that (I know, I could always use HtmlHelper routines to create elements, but that's not always feasible).</p>\n\n<p>My recent projects have also pretty much required separate ViewModels these days anyway. They've all been NHibernate-based, and the use of proxies on NHibernate objects makes it not possible to use them directly for views.</p>\n\n<p><strong>Update</strong> - here's a good article I've referred to in the past: <a href=\"http://geekswithblogs.net/michelotti/archive/2009/10/25/asp.net-mvc-view-model-patterns.aspx\">http://geekswithblogs.net/michelotti/archive/2009/10/25/asp.net-mvc-view-model-patterns.aspx</a></p>\n    "},{"t":"Onion archicecture dependencies in the same layer: Infrastructure and Web communicating","l":"http://stackoverflow.com/questions/2336273/onion-archicecture-dependencies-in-the-same-layer-infrastructure-and-web-commun","q":"\n\n<p>I am designing an ASP.NET MVC application using the <a href=\"http://jeffreypalermo.com/blog/the-onion-architecture-part-1/\">Onion Architecture</a> described by Jeffrey Palermo.</p>\n\n<p>It is an ASP.NET MVC 2.0 project, where I am requiring that all views be strongly typed using dedicated View Models -- we will not be passing domain models to our views. We are using AutoMapper to do the translation -- AutoMapper is isolated in the infrastructure, Web does not know or care that AutoMapper is being used.</p>\n\n<p>Currently, I am defining the IViewModelMapping interfaces in the Web project -- simply because this service will be used by the Controllers and it has direct access to its own View Models. This way the interface can access both the Domain Models (in Core) and the View Models (in Web). </p>\n\n<p>In order to provide the actual implementation of the IViewModelMapping interfaces, I created an ObjectMapping namespace in the Infrastructure project, which will isolate the actual mapping implementation to the Intrastructure of the onion. In doing so, this will require Infrastructure to have a dependency on BOTH Core AND Web. </p>\n\n<p>My question is: since both of these projects are technically on the outskirts of the onion (in the same layer) -- is one project allowed to have a dependency on another project in that layer? Does anyone notice any potential pitfalls with this design?</p>\n\n<p>An alternative design would be moving the IViewMapper interfaces into Core -- but this would be impossible because Core does not have access to the ViewModel classes. I could also move the view models into Core, but I feel like they would not belong there, since they are specific to the UI layer.</p>\n\n<p>The proposed architecture is as follows -- notice that Infrastructure has a dependency on Core AND Web. Web remains isolated and only has access to the Core business logic.</p>\n\n<p><img src=\"http://www.matthidinger.com/images/onion-arch.png\"></p>\n    ","a":"\n<p>You are correct that you don't want Infrastructure to depend on UI(Web), but I break that rule sometimes.</p>\n\n<p>I would think instead of IViewModelMapping, create IMapper with method Map().  Then, the interface can have implementations that might have to do with view model mapping, or maybe just regular mapping.  Either way, that interface can be in Core because it is not semantically bound to any type of model.</p>\n\n<p>Great graphic.  I hope I answered the meat of your question.  The overall philosophy of the Onion Architecture is to keep your business logic and model in the middle (Core) of your application and push your dependencies as far outward as possible.</p>\n    "},{"t":"Pros & Cons of putting all code in Header files in C++?","l":"http://stackoverflow.com/questions/193864/pros-cons-of-putting-all-code-in-header-files-in-c","q":"\n\n<p>You can structure a C++ program so that (almost) all the code resides in Header files. It essentially looks like a C# or Java program. However, you do need at least one <code>.cpp</code> file to pull in all the header files when compiling. Now I know some people would absolutely detest this idea. But I haven't found any convincing downsides of doing this. I can list some advantages:</p>\n\n<p>[1] Faster compile times. All header files only get parsed once, because there is only one .cpp file. Also, one header file cannot be included more than once, otherwise you will get a build break. There are other ways of achieving faster compiles when using the alternate approach, but this is so simple.</p>\n\n<p>[2] It avoids circular dependencies, by making them absolutely clear. If <code>ClassA</code> in <code>ClassA.h</code> has a circular dependency on <code>ClassB</code> in <code>ClassB.h</code>, I have to put a forward reference &amp; it sticks out. (Note that this is unlike C# &amp; Java where the compiler automatically resolves circular dependencies. This encourages bad coding practices IMO). Again, you can avoid circular dependencies if your code was in <code>.cpp</code> files, but in a real-world project, <code>.cpp</code> files tend to include random headers until you can't figure out who depends on whom.</p>\n\n<p>Your thoughts?</p>\n    ","a":"\n<h2>Reason [1] Faster compile times</h2>\n\n<p>Not in my projects: source files (CPP) only include the headers (HPP) they need. So when I need to recompile only one CPP because of a tiny change, I have ten times the same number of files that are not recompiled.</p>\n\n<p>Perhaps you should break down your project in more logical sources/headers: A modification in class A's implementation should NOT need the recompilation of  implementations of class B, C, D, E, etc..</p>\n\n<h2>Reason[2] It avoids circular dependencies</h2>\n\n<p>Circular dependencies in code?</p>\n\n<p>Sorry, but I have yet to have this kind of problem being a real problem: Let's say A depends on B, and B depends on A:</p>\n\n<pre><code>struct A\n{\n   B * b ;\n   void doSomethingWithB() ;\n} ;\n\nstruct B\n{\n   A * a ;\n   void doSomethingWithA() ;\n} ;\n\nvoid A::doSomethingWithB() { /* etc. */ }\nvoid B::doSomethingWithA() { /* etc. */ }\n</code></pre>\n\n<p>A good way to resolve the problem would be to break down this source into at least one source/header per class (in a way similar to the Java way, but with one source and one header per class):</p>\n\n<pre><code>// A.hpp\n\nstruct B ;\n\nstruct A\n{\n   B * b ;\n   void doSomethingWithB() ;\n} ;\n</code></pre>\n\n<p>.</p>\n\n<pre><code>// B.hpp\n\nstruct A ;\n\nstruct B\n{\n   A * a ;\n   void doSomethingWithA() ;\n} ;\n</code></pre>\n\n<p>.</p>\n\n<pre><code>// A.cpp\n#include \"A.hpp\"\n#include \"B.hpp\"\n\nvoid A::doSomethingWithB() { /* etc. */ }\n</code></pre>\n\n<p>.</p>\n\n<pre><code>// B.cpp\n#include \"B.hpp\"\n#include \"A.hpp\"\n\nvoid B::doSomethingWithA() { /* etc. */ }\n</code></pre>\n\n<p>Thus, no dependency problem, and still fast compile times.</p>\n\n<p>Did I miss something?</p>\n\n<h2>When working on \"real-world\" projects</h2>\n\n<blockquote>\n  <p>in a real-world project, cpp files tend to include random headers until you can't figure out who depends on whom</p>\n</blockquote>\n\n<p>Of course. But then if you have time to reorganize those files to build your \"one CPP\" solution, then you have time to clean those headers. My rules for headers are:</p>\n\n<ul>\n<li>break down header to make them as modular as possible</li>\n<li>Never include headers you don't need</li>\n<li>If you need a symbol, forward-declare it</li>\n<li>only if the above failed, include the header</li>\n</ul>\n\n<p>Anyway, all headers must be self-sufficient, which means:</p>\n\n<ul>\n<li>An header include all needed headers (and only needed headers - see above)</li>\n<li>an empty CPP file including one header must compile without needing to include anything else</li>\n</ul>\n\n<p>This will remove ordering problems and circular dependencies.</p>\n\n<h2>Is compile times an issue? Then...</h2>\n\n<p>Should compile time be really an issue, I would consider either:</p>\n\n<ul>\n<li>Using precompiled headers (this is quite useful for STL and BOOST)</li>\n<li>Decrease coupling through the PImpl idiom, as explained in <a href=\"http://en.wikipedia.org/wiki/Opaque_pointer\">http://en.wikipedia.org/wiki/Opaque_pointer</a></li>\n<li>Use network shared compilation</li>\n</ul>\n\n<h2>Conclusion</h2>\n\n<p>What you are doing is not putting everything in headers.</p>\n\n<p>You are basically including all your files into one and only one final source.</p>\n\n<p>Perhaps you are winning in terms of full-project compilation.</p>\n\n<p>But when compiling for one small change, you'll always lose.</p>\n\n<p>When coding, I know I compile often small changes (if only to have the compiler validate my code), and then one final time, do a full project change.</p>\n\n<p><strong>I would lose a lot of time if my project was organized your way.</strong></p>\n    "},{"t":"Should I use a single or multiple database setup for a multi-client application?","l":"http://stackoverflow.com/questions/255616/should-i-use-a-single-or-multiple-database-setup-for-a-multi-client-application","q":"\n\n<p>I am working on a PHP application that intends to ease company workflow and project management, let's say something like <a href=\"http://www.basecamphq.com/\">Basecamp</a> and <a href=\"http://goplan.org\">GoPlan</a>.</p>\n\n<p>I am not sure on what the best approach is, database-wise. Should I use a single database and add client-specific columns to each of the tables, or should I create a database for each new client? An important factor is automation: I want it to be dead simple to create a new client (and perhaps opening the possibility to signing up for yourself).</p>\n\n<p>Possible cons I can think of using one database:</p>\n\n<ul>\n<li>Lack of extensibility</li>\n<li>Security problems (although bugs <em>shouldn't be there in the first place</em>)</li>\n</ul>\n\n<p>What are your thoughts on this? Do you have any ideas what solution the above companies are most likely to have chosen? </p>\n    ","a":"\n<p>I usually add ClientID to all tables and go with one database.\nBut since the database is usually hard to scale I will also make it possible to run on different database instances for some or all clients.</p>\n\n<p>That way you can have a bunch of small clients in one database and the big ones on separate servers.</p>\n\n<p>A key factor for maintainability though, is that you keep the schema identical in all databases. There will be headache enough to manage the versioning without introducing client specific schemas.</p>\n    "},{"t":"Good STL-like library for C [closed]","l":"http://stackoverflow.com/questions/2540/good-stl-like-library-for-c","q":"\n\n<p>What are good libraries for C with datastructures like vectors, deques, stacks, hashmaps, treemaps, sets, etc.? Plain C, please, and platform-independent.</p>    ","a":"\n<p>The <a href=\"http://library.gnome.org/devel/glib/stable/\" rel=\"nofollow\">Glib</a> library used on the Gnome project may also be some use. Moreover it is pretty well tested.</p>\n\n<p>IBM developer works has a good tutorial on its use: <a href=\"https://www.ibm.com/developerworks/linux/tutorials/l-glib/\" rel=\"nofollow\">Manage C data using the GLib collections</a></p>\n    "},{"t":"Fat models and skinny controllers sounds like creating God models [closed]","l":"http://stackoverflow.com/questions/14044681/fat-models-and-skinny-controllers-sounds-like-creating-god-models","q":"\n\n<p>I've been reading a lot of blogs which advocate the <em>fat models and skinny controllers</em> approach, esp. the Rails camp. As a result the routers is basically just figuring out what method to call on what controller and all the controller method does is call the corresponding method on the model and then bring up the view. So I've two concerns here which I don't understand:</p>\n\n<ol>\n<li>The controller and router are really not doing much different tasks other than just calling a method on the God-like model based on the route.</li>\n<li>Models are doing too much. Sending emails, creating relationships, deleting and modifying other models, queuing tasks, etc. Basically now you have God-like objects that are supposed to do everything that may or may not concern with modeling and dealing with data.</li>\n</ol>\n\n<p>Where do you draw the line? Isn't this just falling into the God pattern?</p>\n    ","a":"\n<blockquote>\n  <p><sub>It might not be the best idea to look at Rails as a staple of MVC design pattern. Said framework was made with some inherit shortcomings (I kinda elaborated on it in a <a href=\"http://stackoverflow.com/a/11984678/727208\">different post</a>) and community only just now has begun addressing the fallout. You could look at DataMapper2 <a href=\"http://www.youtube.com/watch?v=MU4RvuvpT8w\">development</a> as first major step.</sub></p>\n</blockquote>\n\n<h3>Some theory</h3>\n\n<p>People giving that advice seem to be afflicted by quite common misconception. So let me begin by clearing it up: <strong>Model, in modern MVC design pattern, is NOT a class or object.</strong> Model is a layer.</p>\n\n<p>The core idea behind MVC pattern is <a href=\"https://en.wikipedia.org/wiki/Separation_of_concerns\"><em>Separation of Concerns</em></a> and first step in it is the division between presentation layer and model layers. Just like presentation layer breaks down in controllers (instances, responsible for dealing with user input), views (instances, responsible for UI logic) and templates/layouts, so does the model layer.</p>\n\n<p>The major part that model layer consists of are:</p>\n\n<ul>\n<li><p><a href=\"http://c2.com/cgi/wiki?DomainObject\">Domain Objects</a></p>\n\n<p>Also know as domain entities, business objects or model objects (I dislike that latter name because it just ads to the confusion). There structures are what people usually mistakenly call \"models\". The are responsible for containing business rules (all the math and validation for specific unit of domain logic).</p></li>\n<li><p>Storage Abstractions:</p>\n\n<p>Usually implemented using <a href=\"http://martinfowler.com/eaaCatalog/dataMapper.html\">data mapper</a> pattern (do not confuse with ORMs, which have abuse this name). These instances usually are tasked with information storage-from and retrieval-into the domain objects. Each domain object can have several mappers, just like there are several forms of storage (DB, cache, session, cookies, /dev/null).</p></li>\n<li><p>Services:</p>\n\n<p>Structures responsible for application logic (that is, interaction between domain objects and interaction between domain objects and storage abstractions. They should act like the \"interface\" through which the presentation layer interacts with model layer This is usually what in Rails-like code ends up in the controllers.</p></li>\n</ul>\n\n<p>There are also Several structures that might be in the spaces between these groups: <a href=\"http://www.oracle.com/technetwork/java/dataaccessobject-138824.html\">DAOs</a>, <a href=\"http://martinfowler.com/eaaCatalog/unitOfWork.html\">units of work</a> and <a href=\"http://martinfowler.com/eaaCatalog/repository.html\">repositories</a>. </p>\n\n<blockquote>\n  <p><sub>Oh ... and when we talk (in context of web) about <em>user</em>, that interacts with MVC application, it is not a human being. The \"user\" is actually your web browser.</sub></p>\n</blockquote>\n\n<h3>So what about deities?</h3>\n\n<p>Instead of having some scary and monolithic model to work with, controllers should interact with services. You pass data from user input in specific service (for example <code>MailService</code> or <code>RecognitionService</code>). This way controller changes the state of model layer, but it is done by using clear API. And with no messing with internal structures, that would cause a leaky abstraction.</p>\n\n<p>Such change can either cause some immediate reaction or only affect the data that view instance requests from model layer or both.</p>\n\n<p>Each service can interact with any number (though, it's usually only handful) domain object and storage abstractions. For example, the <code>RecogitionService</code> could not care less about storage abstractions for the articles. </p>\n\n<h3>Closing notes</h3>\n\n<p>This way you get an application that can be unit-tested at any level, has low coupling (if correctly implemented) and has clearly understandable architecture.</p>\n\n<p>Though, keep in mind: MVC is not meant for small applications. If you are writing a guestbook page using MVC pattern, you are doing it wrong. This pattern is meant for enforcing <em>law and order</em> on large scale applications.</p>\n\n<blockquote>\n  <p><sub>For people who are using PHP as primary language, <a href=\"http://stackoverflow.com/a/5864000/727208\">this post</a> might be relevant. It's a bit longer description of model layer with few snippets of code</sub></p>\n</blockquote>\n    "},{"t":"Service Layer vs Business Layer in architecting web applications?","l":"http://stackoverflow.com/questions/4108824/service-layer-vs-business-layer-in-architecting-web-applications","q":"\n\n<p>I know this might sound silly but I am finding it hard to understand the need of a service layer and its differences with business layer. </p>\n\n<p>So, we are using asp.net mvc 2 and have Data Access layer which does all the querying with the database and then we have the Business Layer which has the business logic and validations needed to be done. Finally we have the Presentation Layer which basically has all the views. In addition we also have some helpers,DTOs and viewmodel classes in different folders as a part of our libraries. But I have tried to read about architecture and it seems that service layer is an important part of an architecture.</p>\n\n<p>All I understand is that a service layer is something that calls all the functions.\nBut I can't really see the need of Service layer in our application ? Or it might be already there and I can't see it... Can anyone explain with an example how a service layer is important ? How it is different from a business layer because from what I have read seem pretty similar? \nIf its in the first needed at all ? All we trying to do is architect our application in the best possible way what are your thoughts and experience on it ?</p>\n    ","a":"\n<p><strong>It is all about decoupling your app into self contained pieces, each one defined by the requirement to do one job really well.</strong>  </p>\n\n<p><strong>This allows you to apply specialised design patterns and best practices to each component.</strong>  </p>\n\n<p>For example, the business layer's job is to implement the business logic.  Full stop.  Exposing an API designed to be consumed by the presentation layer is not its \"concern\".  </p>\n\n<p>This role of the go between is best performed by a service layer.  Factoring out this specialised layer allows you to apply much more specialised patterns to each individual component.</p>\n\n<p>There is no need to do design things this way, but the accumulated experience of the community indicates that it results in an application that is much easier to develop and maintain because you know exactly what each component is expected to do, even before you start coding the app.</p>\n\n<p>Each layer should do one job really well.  The role of go between that the service layer performs is one such well defined job and that is the reason for its existence:  it is a unit of complexity that is designed in the same way over and over again, rather than having to reinvent the wheel each time, to mangle this role with the business logic where it does not belong.  Think of the service layer as a mapping component.  It is external to the business logic and does not belong in its classes, or in the controllers either.</p>\n\n<p>Also, as a result of being factored out of the business logic, you get simpler business objects that are easier to use by other applications and services that the \"business\" consumes.</p>\n\n<p>ASP.NET MVC is nothing if not a platform to enable you to write your apps as specialised components.</p>\n\n<p>As a result of this increasing understanding of how to specialise components, programs are evolving from a primordial bowl of soup and spaghetti into something different and strange.  The complexity they can address, whilst still using simple structures, is increasing.  Evolution is getting going.  If life is anything to go by, this has to be good, so keep the ball rolling.</p>\n    "},{"t":"How to structure an enterprise MVC app, and where does Business Logic go?","l":"http://stackoverflow.com/questions/2568010/how-to-structure-an-enterprise-mvc-app-and-where-does-business-logic-go","q":"\n\n<p>I am an MVC newbie.  As far as I can tell:</p>\n\n<ul>\n<li><strong>Controller</strong>: deals with routing requests</li>\n<li><strong>View</strong>: deals with presentation of data</li>\n<li><strong>Model</strong>: looks a whole lot like a Data Access layer</li>\n</ul>\n\n<p>Where does the Business Logic go?  </p>\n\n<p>Take a large enterprise application with:</p>\n\n<ul>\n<li>Several different sources of data (WCF, WebServices and ADO) tied together in a data access layer (useing multiple different DTOs).</li>\n<li>A lot business logic segmented over several dlls. </li>\n</ul>\n\n<p>What is an appropriate way for an MVC web application to sit on top of this (in terms of code and project structure)?  </p>\n\n<p>The example I have seen where everything just goes in the Model folder don't seem like they are appropriate for very large applications.</p>\n\n<p>Thanks for any advice!</p>\n    ","a":"\n<p>In my apps, I usually create a \"Core\" project separate from the web project. </p>\n\n<p><strong>Core project contains</strong>:</p>\n\n<ol>\n<li>Business objects, such as entities and such</li>\n<li>Data access</li>\n<li>Anything that is <em>not</em> specifically designed for web</li>\n</ol>\n\n<p><strong>Web project contains</strong>:</p>\n\n<ol>\n<li><em>Controllers</em>, which route requests from the UI to the core logic</li>\n<li><em>Views</em>, which focus on presenting data in HTML</li>\n<li><em><strong>View</strong> Models</em>, which flatten/transform core business objects into simpler structures designed to support specific views</li>\n</ol>\n\n<p>The key point here is that the web-based Models folder/namespace is ONLY used for presentation-specific models that document the specific variables needed for a given view. As much \"business logic\" as possible goes into the core project.</p>\n    "},{"t":"When NOT to use the Entity Framework","l":"http://stackoverflow.com/questions/517600/when-not-to-use-the-entity-framework","q":"\n\n<p>I have been playing around with the EF to see what it can handle. Also many articles and posts explain the various scenarios in which the EF can be used, however if miss the \"con\" side somehow. Now my question is, <strong>in what kind of scenarios should I stay away from the Entity Framework</strong> ?</p>\n\n<p>If you have some experience in this field, tell me what scenarios don't play well with the EF. Tell me about some downsides you experienced where you whished you would have chosen a different technology.</p>\n    ","a":"\n<p>I'm also just at the 'playing around' stage, and although I was worried about the lack of built-in persistence agnosticism, I was sure there would be a \"work-around\".  </p>\n\n<p>In fact, not even a work-around in an n-tier architecture.</p>\n\n<p><strong>WCF + EF</strong></p>\n\n<p>If I've read the <a href=\"http://msdn.microsoft.com/en-us/magazine/cc700340.aspx\" rel=\"nofollow\">article</a> correctly, then I don't see any problem serializing entities across the wire (using WCF) and also the persistence ignorance isn't a problem. </p>\n\n<p>This is because I'd use PI mainly for unit-testing. </p>\n\n<p><strong>Unit Testing <em>is</em> possible! (i think)</strong></p>\n\n<p>In this system, we could simply use a mock service (by wrapping up the call to the service in ANOTHER interface based class which could be produced from a factory, for example).  This would test OUR presenter code (there's no need to unit-test the EF/DAL - that's Microsoft's job!)  Of course, integration tests would still be required to achieve full confidence.</p>\n\n<p>If you wanted to write to a separate database, this would be done in the DAL layer, easily achieved via the config file.</p>\n\n<p><strong>My Tuppence Worth</strong></p>\n\n<p>My opinion - make up your own mind about the EF and don't be put off by all the doom and gloom regarding it that's doing the rounds.  I'd guess that it's going to be around for a while and MS will iron out the faults in the next year or so.  PI is definitely coming in according to Dan Simmons. </p>\n\n<p><strong>EDIT</strong>: I've just realised I jumped the gun and like a good politician didn't actually answer the question that was asked.  Oops.  But I'll leave this in in case anyone else finds it useful.</p>\n    "},{"t":"Software Design vs. Software Architecture [closed]","l":"http://stackoverflow.com/questions/1958732/what-is-the-difference-between-design-and-architecture","q":"\n\n<p>Could someone explain the difference between Software Design and Software Architecture?</p>\n\n<p>More specifically; if you tell someone to present you the 'design' - what would you expect them to present? Same goes for 'architecture'. </p>\n\n<p>My current understanding is:  </p>\n\n<ul>\n<li>Design: UML diagram/flow chart/simple wireframes (for UI) for a specific module/part of the system</li>\n<li>Architecture: component diagram (showing how the different modules of the system communicates with each other and other systems), what language is to be used, patterns...? </li>\n</ul>\n\n<p>Correct me if I'm wrong. I have referred Wikipedia has articles on <a href=\"http://en.wikipedia.org/wiki/Software_design\">http://en.wikipedia.org/wiki/Software_design</a> and <a href=\"http://en.wikipedia.org/wiki/Software_architecture\">http://en.wikipedia.org/wiki/Software_architecture</a>, but I'm not sure if I have understood them correctly.</p>\n    ","a":"\n<p>You're right yes. The architecture of a system is its 'skeleton'. It's the highest level of abstraction of a system. What kind of data storage is present, how do modules interact with each other, what recovery systems are in place. Just like design patterns, there are architectural patterns: MVC, 3-tier layered design, etc. </p>\n\n<p>Software design is about designing the individual modules / components. What are the responsibilities, functions, of module x? Of class Y? What can it do, and what not? What design patterns can be used?</p>\n\n<p>So in short, Software architecture is more about the design of the entire system, while software design emphasizes on module / component / class level.</p>\n    "},{"t":"Design Patterns - Architecture Astronaut [closed]","l":"http://stackoverflow.com/questions/404210/design-patterns-architecture-astronaut","q":"\n\n<p>Perhaps my question is similar in nature to this one: <a href=\"http://stackoverflow.com/questions/11586/do-you-use-design-patterns\">Do you use design patterns?</a></p>\n\n<p>The programs that I write are small 50-75 K line programs mostly using <a href=\"http://en.wikipedia.org/wiki/Windows_Forms\" rel=\"nofollow\">Windows Forms</a> and <a href=\"http://en.wikipedia.org/wiki/ASP.NET\" rel=\"nofollow\">ASP.NET</a>.  These programs are GUI intensive allowing the design and layout of various graphics and graphics processing.</p>\n\n<p>I consider myself good at OOP and practiced at balancing OOP and traditional procedural methods to create maintainable code.</p>\n\n<p>The problem comes in when I consider design patterns.  The linked to thread has an interesting comment that design patterns may be used but not intentionally.  When I want to intentionally use a design pattern (in the design of my program), it feels like I'm going above and beyond what is needed, that I'm in the realm of \"<a href=\"http://www.joelonsoftware.com/articles/fog0000000018.html\" rel=\"nofollow\">architecture astronaut</a>\" so I fall back to my traditional methods and everything goes along smoothly (i.e. normally).</p>\n\n<p>Take the MVC pattern as an example.  If I want to implement this pattern using Windows Forms or ASP.NET (Visual Studio 2005) then I have to write a \"Framework\" and writing frameworks seems to be more trouble than it's worth for the size of the application.</p>\n\n<p>Perhaps my applications are too small to justify the use of some of these patterns.\nPerhaps I just don't know the patterns well enough or need to study them more.</p>\n\n<p>Does anyone else experience this \"architecture astronaut\" feeling?</p>\n\n<p>How do you go about intentionally using design patterns without going \"overboard?\"</p>\n    ","a":"\n<p>When it comes to smaller applications of this nature, I generally worry more about <a href=\"http://c2.com/cgi/wiki?AntiPattern\">anti-patterns</a> than I do about design patterns. That said, it's really two sides to the same coin: the power of a design pattern for me is being familiar with them so as to recognize the less-than-obvious pros and cons of whatever solution I'm thinking of. I rarely if ever go out of my way to actually fully implement a complete design pattern (unless I actually need all the functionality); however, I have often saved myself a lot of future re-work by recognizing the path I'm on and looking at the common pitfalls or drawbacks to that solution, which I can then check against my future uses to see if it's going to be a relevant concern for me or not. Thus, the power of a design pattern is that you can easily predict the future consequences of your current solution against your potential needs, without worrying that you might be missing some less-than-obvious caveat or special case that you haven't considered.</p>\n    "},{"t":"What are the architectural limitations of PHP? [closed]","l":"http://stackoverflow.com/questions/5823310/what-are-the-architectural-limitations-of-php","q":"\n\n<p>I was reading the article <a href=\"http://www.codinghorror.com/blog/2008/05/php-sucks-but-it-doesnt-matter.html\">\"PHP Sucks, But It Doesn't Matter\"</a> by Jeff Atwood.</p>\n\n<p>In the comments he writes:</p>\n\n<blockquote>\n  <p>That said, I absolutely think it's important for PHP devs to be aware of the architectural limitations of PHP, and understand the alternatives.</p>\n</blockquote>\n\n<p>What are those limitations and how do they compare with other scripting / weakly typed languages?</p>\n\n<p>Also, what are the alternatives in those conditions where limitations need to be avoided?</p>\n    ","a":"\n<p>There are basically two real limitations I see:</p>\n\n<p><strong>PHP is a fully synchronous language</strong>. This has impact on which things you can easily implement in PHP and which not. For example implementing a <a href=\"http://en.wikipedia.org/wiki/Push_technology#Long_polling\">Long Polling</a> driven chat application isn't trivial, because PHP would need block one process per chatter. I'm not saying it's impossible, you can hack around this limitation using some PHP Daemon library. I'm just saying that this is one of the cases where other languages, like JavaScript, are more appropriate (<a href=\"http://nodejs.org/\">NodeJS</a>).</p>\n\n<p><strong>PHP is slow</strong>. Please don't understand this an an offense. It's a fact that PHP - as implemented by Zend - is slow compared to other scripting languages. This typically is no problem when building websites, but you obviously can't do certain things: Implementing a ray tracer in PHP is definitely a bad idea - whereas in JavaScript you could do this.</p>\n\n<p>But apart from that, I think that PHP is pretty multi-purpose. You can use it for nearly anything - and I do ;)</p>\n    "},{"t":"How do you design the architecture of an Erlang/OTP-based distributed fault-tolerant multicore system?","l":"http://stackoverflow.com/questions/7307634/how-do-you-design-the-architecture-of-an-erlang-otp-based-distributed-fault-tole","q":"\n\n<p>I would like to build an Erlang/OTP-based system which solves an 'embarassingly parrallel' problem.</p>\n\n<p>I have already read/skimmed through:</p>\n\n<ul>\n<li>Learn You Some Erlang;</li>\n<li>Programming Erlang (Armstrong);</li>\n<li>Erlang Programming (Cesarini);</li>\n<li>Erlang/OTP in Action.</li>\n</ul>\n\n<p>I have got the gist of Processes, Messaging, Supervisors, gen_servers, Logging, etc.</p>\n\n<p>I do understand that certain architecture choices depend on the application in concern, but still I would like know some general principles of ERlang/OTP system design.</p>\n\n<p>Should I just start with a few gen_servers with a supervisor and incrementally build on that? </p>\n\n<p>How many supervisors should I have? How do I decide which parts of the system should be process-based? How should I avoid bottlenecks?</p>\n\n<p>Should I add logging later? </p>\n\n<p><strong>What is the general approach to Erlang/OTP distributed fault-tolerant multiprocessors systems architecture?</strong></p>\n    ","a":"\n<h2>Should I just start with a few gen_servers with a supervisor and incrementally build on that?</h2>\n\n<p>You're missing one key component in Erlang architectures here: applications! (That is, the concept of OTP applications, not software applications).</p>\n\n<p>Think of applications as components. A component in your system solves a particular problem, is responsible for a coherent set of resources or abstract something important or complex from the system.</p>\n\n<p>The first step when designing an Erlang system is to decide which applications are needed. Some can be pulled from the web as they are, these we can refer to as libraries. Others you'll need to write yourself (otherwise you wouldn't need this particular system). These applications we usually refer to as the business logic (often you need to write some libraries yourself as well, but it is useful to keep the distinction between the libraries and the core business applications that tie everything together).</p>\n\n<h2>How many supervisors should I have?</h2>\n\n<p>You should have one supervisor for each kind of process you want to monitor. </p>\n\n<p>A bunch of identical temporary workers? One supervisore to rule them all.</p>\n\n<p>Different process with different responsibilities and restart strategies? A supervisor for each different type of process, in a correct hierarchy (depending on when things should restart and what other process needs to go down with them?).</p>\n\n<p>Sometimes it is okay to put a bunch of different process types under the same supervisor. This is usually the case when you have a few singleton processes (e.g. one HTTP server supervisor, one ETS table owner process, one statistics collector) that will always run. In that case, it might be too much cruft to have one supervisor for each, so it is common to add the under one supervisor. Just be aware of the implications of using a particular restart strategy when doing this, so you don't take down your statistics process for example, in case your web server crashes (<code>one_for_one</code> is the most common strategy to use in cases like this).</p>\n\n<h2>How do I decide which parts of the system should be process-based?</h2>\n\n<p>Every concurrent activity in your system should be in it's own process. Having the wrong abstraction of concurrency is the most common mistake by Erlang system designers in the beginning.</p>\n\n<p>Some people are not used to deal with concurrency; their systems tend to have too little of it. One process, or a few gigantic ones, that runs everything in sequence. These systems are usually full of code smell and the code is very rigid and hard to refactor. It also makes them slower, because they may not use all the cores available to Erlang.</p>\n\n<p>Other people immediately grasp the concurrency concepts but fail to apply them optimally; their systems tend to overuse the process concept, making many process stay idle waiting for others that are doing work. These systems tend to be unnecessarily complex and hard to debug.</p>\n\n<p>In essence, in both variants you get the same problem, you don't use all the concurrency available to you and you don't get the maximum performance out of the system.</p>\n\n<p>If you stick to the <a href=\"http://www.codinghorror.com/blog/2007/03/curlys-law-do-one-thing.html\">single responsibility principle</a> and abide by the rule to have a process for every <em>truly</em> concurrent activity in your system, you should be okay.</p>\n\n<h2>How should I avoid bottlenecks?</h2>\n\n<p>Hard to say, depends very much on your system and what it's doing. Generally though, if you have a good division of responsibility between applications you should be able to scale the application that appears to be the bottleneck separately from the rest of the system.</p>\n\n<p>The golden rule here is to <em>measure, measure, measure</em>! Don't think you have something to improve until you've measured.</p>\n\n<p>Erlang is great in that it allows you to hide concurrency behind interfaces (known as implicit concurrency). For example, you use a functional module API, a normal <code>module:function(Arguments)</code> interface, that could in turn spawn thousands of processes without the caller having to know that. If you got your abstractions and your API right, you can always parallelize or optimize a library after you've started using it.</p>\n\n<p>That being said, here are some general guide lines:</p>\n\n<ul>\n<li>Try to send messages to the recipient directly, avoid channeling or routing messages through intermediary processes. Otherwise the system just spends time moving messages (data) around without really working.</li>\n<li>Don't overuse the OTP design patterns, such as gen_servers. In many cases, you only need to start a process, run some piece of code, and then exit. For this, a gen_server is overkill.</li>\n</ul>\n\n<p>And one bonus advice: don't reuse processes. Spawning a process in Erlang is so cheap and quick that it doesn't make sense to re-use a process once its lifetime is over. In some cases it might make sense to re-use state (e.g. complex parsing of a file) but that is better canonically stored somewhere else (in an ETS table, database etc.).</p>\n\n<h2>Should I add logging later?</h2>\n\n<p>There's some basic logging functionality in Erlang/OTP already, the <a href=\"http://erlang.org/doc/man/error_logger.html\">error logger</a>. Together with <a href=\"http://erlang.org/doc/man/sasl_app.html\">SASL</a> (System Architecture Support Libraries) you can get up and running with logging in no-time.</p>\n\n<p>When the time comes (and if you've abstracted the logging API from the beginning) you could exchange this for something that better fits your needs. The de-facto 3rd party logging library today is <a href=\"https://github.com/basho/lager\">Basho's Lager</a>.</p>\n\n<h2>What is the general approach to Erlang/OTP distributed fault-tolerant multiprocessors systems architecture?</h2>\n\n<p>To summarize what's been said above:</p>\n\n<ul>\n<li>Divide your system into applications</li>\n<li>Put your processes in the correct supervision hierarchy, depending on their needs and dependencies</li>\n<li>Have a process for every truly concurrent activity in your system</li>\n<li>Maintain a functional API towards the other components in the system. This lets you:\n<ul>\n<li>Refactor your code without changing the code that's using it</li>\n<li>Optimize code afterwards</li>\n<li>Distribute your system when needed (just make a call to another node behind the API! The caller won't notice!)</li>\n<li>Test the code more easily (less work setting up test harnesses, easier to understand how to use it)</li>\n</ul></li>\n<li>Start using the libraries available to you in OTP until you need something different (you'll know, when the time comes)</li>\n</ul>\n\n<p>Common pitfalls:</p>\n\n<ul>\n<li>Too many processes</li>\n<li>Too few processes</li>\n<li>Too much routing (forwarded messages, chained processes)</li>\n<li>Too few applications (I've never seen the opposite case, actually)</li>\n<li>Not enough abstraction (makes it hard to refactor and reason about. It also makes it hard to test!)</li>\n</ul>\n    "},{"t":"The way cores, processes, and threads work exactly?","l":"http://stackoverflow.com/questions/2986931/the-way-cores-processes-and-threads-work-exactly","q":"\n\n<p>I need a bit of advice for understanding how this whole procedure works exactly. If I am incorrect in any part described below, please correct me.</p>\n\n<p>In a single core CPU, it runs each process in the OS, jumping around from one process to another to utilize the best of itself. A process can also have many threads, in which the CPU core runs through these threads when it is running on the respective process.</p>\n\n<p>Now, on a multiple core CPU, </p>\n\n<ul>\n<li><p>Do the cores run in every process together, or can the cores run separately in different processes at one particular point of time? For instance, you have program A running two threads. Can a dual core CPU run both threads of this program? I think the answer should be yes if we are using something like <a href=\"http://en.wikipedia.org/wiki/OpenMP\">OpenMP</a>. But while the cores are running in this OpenMP-embedded process, can one of the cores simply switch to other process?</p></li>\n<li><p>For programs that are created for single core, when running at 100%, why is the CPU utilization of each core distributed? (ex. A dual core CPU of 80% and 20%. The utilization percentage of all cores always add up to 100% for this case.) Do the cores try to help each other by running each thread, of each process, in some ways?</p></li>\n</ul>\n\n<p>Frankly, I'm not sure how this works exactly. Any advice is appreciated.</p>\n    ","a":"\n<p><strong>Cores</strong> (or CPUs) are the physical elements of your computer that execute code. Usually, each core has all necessary elements to perform computations, register files, interrupt lines etc.</p>\n\n<p>Most operating systems represent applications as <strong>processes</strong>. This means that the application has its own address space (== view of memory), where the OS makes sure that this view and its content are isolated from other applications.</p>\n\n<p>A process consists of one or more <strong>threads</strong>, which carry out the real work of an application by executing machine code on a CPU. The operating system determines, which thread executes on which CPU (by using clever heuristics to improve load balance, energy consumption etc.). If your application consists only of a single thread, then your whole multi-CPU-system won't help you much as it will still only use one CPU for your application. (However, overall performance may still improve as the OS will run other applications on the other CPUs so they don't intermingle with the first one).</p>\n\n<p>Now to your specific questions:</p>\n\n<p>1) The OS usually allows you to at least give hints about on which core you want to execute certain threads. What OpenMP does is to generate code that spawns a certain amount of threads to distribute shared computational work from loops of your program in multiple threads. It can use the OS's hint mechanism (see: thread affinity) to do so.\nHowever, OpenMP applications will still run concurrently to others and thus the OS is free to interrupt one of the threads and schedule other (potentially unrelated) work on a CPU.\nIn reality, there are many different scheduling schemes you might want to apply depending on your situation, but this is highly specific and most of the time you should be able to trust your OS doing the right thing for you.</p>\n\n<p>2) Even if you are running a single-threaded application on a multi-core CPU, you notice other CPUs doing work as well. This comes a) from the OS doing its job in the meantime and b) from the fact that your application is never running alone -- each running system consists of a whole bunch of concurrently executing tasks. Check Windows' task manager (or <em>ps/top</em> on Linux) to check what is running.</p>\n    "},{"t":"GLSL multiple shaderprogram VS uniforms switches","l":"http://stackoverflow.com/questions/6539774/glsl-multiple-shaderprogram-vs-uniforms-switches","q":"\n\n<p>I'm working on a shader manager architecture and I have several questions for more advanced people.\nMy current choice oppose two designs which are:</p>\n\n<p><br></p><h2>1. Per material shader program</h2>\n=&gt; Create one shader program per material used in the program.<p></p>\n\n<h3>Potential cons:</h3>\n\n<ul>\n<li>Considering every object might have its own material, it involves a lot of glUseProgram calls.</li>\n<li>Implies the creation of a lot of shaderprogram objects.</li>\n<li>More complex architecture that #2.</li>\n</ul>\n\n<h3>Pros:</h3>\n\n<ul>\n<li>Shader code can be generated specifically for each \"options\" used in the material.</li>\n<li>If i'm not wrong, uniforms have to be set only one time (when the shaderprogram is created).</li>\n</ul>\n\n<p><br></p><h2>2. Global shader programs</h2>\n=&gt; Create one shader program per shader functionality (lightning, reflection, parallax mapping...) and use configuration variables to enable or discard options depending on the material to render.<p></p>\n\n<h3>Potential cons:</h3>\n\n<ul>\n<li>Uniforms have to be changed many times per frame.</li>\n</ul>\n\n<h3>Pros:</h3>\n\n<ul>\n<li>Lower shader programs count.</li>\n<li>Less SP swich (glUseProgram).</li>\n</ul>\n\n<p><br>You might notice that my current tendency is #1, but I wanted to know your opinion about it.</p>\n\n<ul>\n<li>Does initial uniforms setting offset the glUseProgram call overhead (I'm not especially speed freak) ?</li>\n<li>In the case #1, for any memory or performance consideration, should I call glLinkProgram only once when I create the SP, or I must unlink/link each time I call glUseProgram?</li>\n<li>Are there better solutions ?</li>\n</ul>\n\n<p>Thanks!</p>\n    ","a":"\n<p>It really depends on your hardware and the specific demands of your app.</p>\n\n<p>Another con of #2 is that your shader usually ends up not being as efficient because it has to do some conditional branching based on the uniforms you pass in.  So you're basically trading off between less time switching state versus decreased throughput in your shader.  It depends on which one is worse.</p>\n\n<p>You should definitely only call glLinkProgram once per shader.  Compiling a shader takes much longer than switching out already-compiled shaders.</p>\n\n<p>There aren't really any better solutions.  Pretty much everyone writing a rendering engine has to make the decision you're faced with.</p>\n    "},{"t":"Which workflow engine to choose? [closed]","l":"http://stackoverflow.com/questions/4940173/which-workflow-engine-to-choose","q":"\n\n<p>We are currently in the process of evaluating a BPM engine and I'd really appreciate the community input. I am doing my own due diligence but would also like to hear on the suggestion based on implementation stories.</p>\n\n<p>My main evaluation criteria are below</p>\n\n<ol>\n<li>open source and OEM friendly license</li>\n<li>production installations (success stories are a great help)</li>\n<li>commercial support available</li>\n<li>open standards support - BPMN</li>\n<li>dynamic creation/assembly of the workflow based on input</li>\n<li>embeddable</li>\n</ol>\n\n<p>Currently I am evaluating Activiti and JBPM. <a href=\"http://www.bonitasoft.com/\">Bonita</a> open BPM seems like a good candidate as well but never used it. Do you guys have any successful deployments on Bonita?</p>\n    ","a":"\n<p>I've just been doing an evaluation of Activiti vs jBPM.</p>\n\n<p>In fact there seems to be very little between the two solutions.</p>\n\n<ol>\n<li>Activiti is Apache V2, jBPM 5.0 is also Apache V2.</li>\n<li>We're currently using Activiti, but the project is still in dev, so I can't comment on its robustness in production.</li>\n<li>jBPM is beginning the productization process, so support for 5.x will be available in Q1 2012, see slide 32: <a href=\"http://www.slideshare.net/krisverlaenen/streamline-your-business-processes-and-enhance-productivity-by-using-jbpm\">jBPM demo</a>. jBPM 4 was not supported by Redhat.</li>\n<li>jBPM 4.x did not support BPMN 2.0, but 5.x does, Activiti does as well. jBPM 5.0 has just been released, which includes support for BPMN 2.0. So now both solutions support BPMN 2.0. </li>\n<li>I'm not quite sure what you mean by this, but you can do a lot through both APIs</li>\n<li>Again, not sure what you mean by this, do you mean embedded as part of an application server, in which case, yes for both solutions.</li>\n</ol>\n\n<p>One of our criteria for jBPM was the interaction with Guvnor, and when I downloaded and ran the demo install for jBPM (28/03/2011) and there still seemed to be some major bugs (<a href=\"https://issues.jboss.org/browse/GUVNOR-1274\">GUVNOR-1274</a>), so I personally would test a lot more before I chose to pursue this solution.</p>\n\n<p>In fact, we will be recommending one of the above two solutions, but we're not sure which yet, we'll look at it more closely later this year.</p>\n    "},{"t":"WPF MVVM Why use ContentControl + DataTemplate Views rather than straight XAML Window Views?","l":"http://stackoverflow.com/questions/19864891/wpf-mvvm-why-use-contentcontrol-datatemplate-views-rather-than-straight-xaml-w","q":"\n\n<p>I have a question about MVVM in WPF that is driving me batty.</p>\n\n<p><strong>Why do something like this:?</strong></p>\n\n<p>MainWindow.xaml:</p>\n\n<pre><code>&lt;Window x:Class=\"MVVMProject.MainWindow\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"&gt;\n    &lt;Grid&gt;\n        &lt;ContentControl Content=\"{Binding}\"/&gt;\n    &lt;/Grid&gt;\n&lt;/Window&gt;\n</code></pre>\n\n<p>Have your ExampleView.xaml set up as:</p>\n\n<pre><code>&lt;ResourceDictionary xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    xmlns:vms=\"clr-namespace:MVVMProject.ViewModels\"&gt;\n    &lt;DataTemplate DataType=\"{x:Type vms:ExampleVM}\" &gt;\n        &lt;Grid&gt;\n            &lt;ActualContent/&gt;\n        &lt;/Grid&gt;\n    &lt;/DataTemplate&gt;\n&lt;/ResourceDictionary&gt;\n</code></pre>\n\n<p>And create the window like this:</p>\n\n<pre><code>public partial class App : Application {\n\n    protected override void OnStartup(StartupEventArgs e) {\n\n        base.OnStartup(e);\n\n        MainWindow app = new MainWindow();\n        ExampleVM context = new ExampleVM();\n        app.DataContext = context;\n        app.Show();\n    }\n}\n</code></pre>\n\n<hr>\n\n<p><strong>When you can do it like this:?</strong></p>\n\n<p>App.xaml: (Set startup window/View)</p>\n\n<pre><code>&lt;Application x:Class=\"MVVMProject.App\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    StartupUri=\"ExampleView.xaml\"&gt;\n&lt;/Application&gt;\n</code></pre>\n\n<p>ExampleView.xaml: (a Window not a ResourceDictionary)</p>\n\n<pre><code>&lt;Window x:Class=\"MVVMProject.ExampleView\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    xmlns:vms=\"clr-namespace:MVVMProject.ViewModels\"&gt;\n    &gt;\n    &lt;Window.DataContext&gt;\n        &lt;vms:ExampleVM /&gt;\n    &lt;/Window.DataContext&gt;\n\n    &lt;Grid&gt;\n        &lt;ActualContent/&gt;\n    &lt;/Grid&gt;\n&lt;/Window&gt;\n</code></pre>\n\n<hr>\n\n<p>Essentially it's <strong>\"View as DataTemplate\" (VaD) vs. \"View as Window\" (VaW)</strong></p>\n\n<p>Here is my understanding of the comparison: (Note I use VS 2008 so I lack Blendability &amp;/or other stuff)</p>\n\n<ul>\n<li>VaD: Lets you switch Views without closing the window. (This is not desirable for my project)</li>\n<li>VaD: VM knows absolutely nothing about the View, whereas in VaW it (only) has to be able to instantiate it when opening another window</li>\n<li>VaW: I can actually see my xaml rendered in the Designer (I can't\nwith VaD, at least in my current setup)  </li>\n<li>VaW: Works intuitively with\nopening and closing windows; each window has (is) a corresponding View\n(and ViewModel)</li>\n<li>VaD: ViewModel can pass along initial window width, height, resizability etc. through properties (whereas in VaW they are directly set in the Window)</li>\n<li>VaW: Can set FocusManager.FocusedElement (not sure how in VaD)</li>\n<li>VaW: Less files, since my window types (e.g. Ribbon, Dialog) are incorporated into their Views</li>\n</ul>\n\n<hr>\n\n<p>So what's going on here?  Can't I just build my windows in XAML, access their data cleanly through properties of the VM, and be done with it? The code-behind is the same (virtually nil). I'm struggling to understand why I should shuffle all the View stuff into a ResourceDictionary.\n(   But I don't want to do it <em>wrong</em> ;-)   )</p>\n\n<hr>\n\n<p>Does it even matter? Is there something I've missed?\nThanks a lot for reading. :O</p>\n\n<hr>\n\n<p><em>Thanks to Rachel Lim and Nick Polyak for my blossoming understanding of MVVM</em></p>\n\n<p>Edit: Minor flow change</p>\n    ","a":"\n<p>People use <code>DataTemplates</code> that way when they want to dynamically switch Views depending on the ViewModel:</p>\n\n<pre><code>&lt;Window&gt;\n    &lt;Window.Resources&gt;\n       &lt;DataTemplate DataType=\"{x:Type local:VM1}\"&gt;\n          &lt;!-- View 1 Here --&gt;\n       &lt;/DataTemplate&gt;\n\n       &lt;DataTemplate DataType=\"{x:Type local:VM2}\"&gt;\n          &lt;!-- View 2 here --&gt;\n       &lt;/DataTemplate&gt;\n    &lt;Window.Resources&gt;\n\n    &lt;ContentPresenter Content=\"{Binding}\"/&gt;\n\n&lt;/Window&gt;\n</code></pre>\n\n<p>So, </p>\n\n<p>if <code>Window.DataContext</code> is an instance of <code>VM1</code>, then <code>View1</code> will be displayed, </p>\n\n<p>and if </p>\n\n<p><code>Window.DataContext</code> is an instance of <code>VM2</code>, then <code>View2</code> will be displayed.</p>\n\n<p>Granted, it makes no sense at all if only 1 View is expected, and never changed.</p>\n\n<p>I hope this is clear enough :P</p>\n    "},{"t":"Java EE Architecture - Are DAO's still recommended when using an ORM like JPA 2?","l":"http://stackoverflow.com/questions/3818589/java-ee-architecture-are-daos-still-recommended-when-using-an-orm-like-jpa-2","q":"\n\n<p>If I'm using an ORM like JPA2 - where I have my entities that are mapped to my database, should I still be using a DAO? It seems like a lot more overhead.</p>\n\n<p>For example, I would need to maintain three extra packages:</p>\n\n<ol>\n<li><p>One that specifies my domain objects (which pretty much map my Entity objects):</p>\n\n<pre><code>public class Employee {\n    private String firstName;\n    private String lastName;\n    ...\n    // Getters and setters\n}\n</code></pre></li>\n<li><p>One that contains interfaces that specify my DAO methods</p>\n\n<pre><code>public interface EmployeeDAO {\n    public void addEmployee(Employee employee);\n    public Employee getEmployeeById(long id);\n    ...\n}\n</code></pre></li>\n<li><p>One that contains session beans that implement my DAO's</p>\n\n<pre><code>public EmployeeJpaDAO implements EmployeeDAO {\n    interface method implementations here\n    ....\n    private method that transform my Employee entity into my Employee domain object\n}\n</code></pre></li>\n</ol>\n\n<p>Now that's a lot of extra baggage to add every time I need to perform a new CRUD operation.</p>\n\n<p>However the benefits I see from having a DAO is:</p>\n\n<ol>\n<li><p>You can have an in memory implementation of the DAO for unit testing your service layer. This means you don't need to access the database to test business logic, and you can be assured that your objects will always contain the same values for properties</p></li>\n<li><p>It separates business logic from database access logic</p></li>\n</ol>\n\n<p>The option that doesn't involve implementing a DAO is to just use entity objects and EntityManager in the service layer:</p>\n\n<pre><code>@Stateless\npublic class EmployeeEjb {\n    @PersistenceContext(unitName = \"employee\")\n    private EntityManager manager;\n\n    public Employee getEmployeeById(long id) {\n        return manager.createNamedQuery(Employee.GetEmployeeById).getResultList();\n    }\n    ...\n}\n</code></pre>\n\n<p>Is there no middle ground here? Has anyone come across an architecture or implemented an architecture that meets some of the benefits of a DAO layer (most importantly the unit testability of business logic) that I mentioned above, but doesn't involve all the overhead involved to implement a DAO layer?</p>\n\n<p>Thanks for any recommendations and/or suggestions! I'm really curious to see what some people have come up with in regards to this.</p>\n    ","a":"\n<blockquote>\n  <p>If I'm using an ORM like JPA2 - where I have my entities that are mapped to my database, should I still be using a DAO? It seems like a lot more overhead.</p>\n</blockquote>\n\n<p>It is. And clearly, Java EE doesn't encourage using the <a href=\"http://www.corej2eepatterns.com/Patterns2ndEd/DataAccessObject.htm\">DAO</a> pattern when using JPA (JPA already provides a standardized implementation of the <a href=\"http://www.corej2eepatterns.com/Patterns2ndEd/DomainStore.htm\">Domain Store</a> pattern and there isn't much value at shielding it behind a DAO). I find the DAO to be anti-DRY in such situation.</p>\n\n<p>So for <strong>simple</strong> cases (actually, most cases), I happily skip the DAO and I have no problem with that. For more <strong>complex</strong> cases (for example when using stored procedures, flat files), I'd use it. In other words, it depends, as summarized in <a href=\"http://www.infoq.com/news/2007/09/jpa-dao\">Has JPA Killed the DAO?</a>. See also the related questions below:</p>\n\n<h3>Related questions</h3>\n\n<ul>\n<li><a href=\"http://stackoverflow.com/questions/2100115/i-found-jpa-or-alike-dont-encourage-dao-pattern\">I found JPA, or alike, don't encourage DAO pattern</a></li>\n<li><a href=\"http://stackoverflow.com/questions/2970098/simple-but-good-pattern-for-ejb\">Simple but good pattern for EJB</a></li>\n<li><a href=\"http://stackoverflow.com/questions/3461411/what-is-a-good-strategy-for-seprating-layers-for-an-appication-that-can-be-used-o\">What is a good strategy for seprating layers for an appication that can be used online and offline?</a></li>\n<li><a href=\"http://stackoverflow.com/questions/1861201/using-jsf-jpa-and-dao-without-spring\">Using JSF, JPA and DAO. Without Spring?</a></li>\n<li><a href=\"http://stackoverflow.com/questions/3714355/whats-an-appropriate-dao-structure-with-jpa2-eclipselink\">What's an appropriate DAO structure with jpa2/eclipselink?</a></li>\n</ul>\n\n<blockquote>\n  <p>(...) One that contains session beans that implement my DAO's</p>\n</blockquote>\n\n<p>Noooo, you certainly don't want to implement a DAO as a Session Bean:</p>\n\n<ul>\n<li>You don't want to create as much (pooled) Session Bean as tables (big waste of resources)</li>\n<li>You don't want to chain Session Beans everywhere, don't reproduce errors from the past, this is a known bad practice that doesn't scale well.</li>\n</ul>\n\n<p>So if you really want to go the DAO way and want the EM to be injected, either implement your DAOs as Spring beans (in Java EE 5) or CDI managed bean (in Java EE 6). </p>\n\n<blockquote>\n  <p>You can have an in memory implementation of the DAO for unit testing your service layer.</p>\n</blockquote>\n\n<p>If you really want to do <strong>unit</strong> testing, mock the DAO/EntityManager, there is no difference. And if you want to do integration testing, you can configure JPA to use an in memory database. So at the end, I just don't buy this argument.</p>\n\n<blockquote>\n  <p>It separates business logic from database access logic</p>\n</blockquote>\n\n<p>Honestly, I don't see a <strong>big</strong> difference between relying on a DAO vs an entity manager, I don't see how a DAO separate things \"better\". Again, I don't buy this argument.</p>\n\n<p>And to my experience, changing the underlying persistence solution is a very exceptional event and I'm not going to introduce DAOs for something that is very likely not going to happen (<a href=\"http://en.wikipedia.org/wiki/You_ain%27t_gonna_need_it\">YAGNI</a>, <a href=\"http://en.wikipedia.org/wiki/KISS_principle\">KISS</a>).</p>\n\n<blockquote>\n  <p>Is there no middle ground here? Has anyone come across an architecture or implemented an architecture that meets some of the benefits of a DAO layer (most importantly the unit testability of business logic) that I mentioned above, but doesn't involve all the overhead involved to implement a DAO layer?</p>\n</blockquote>\n\n<p>I don't see much middle ground and, as strongly hinted, I don't use DAOs if I don't feel the need. And as I said, mock the <code>EntityManager</code> if you want to truly unit test the business logic. It works for me and I'm happy to write less code.</p>\n\n<h3>More resources</h3>\n\n<ul>\n<li><a href=\"http://www.adam-bien.com/roller/abien/entry/jpa_ejb3_killed_the_dao\">JPA/EJB3 killed the DAO</a> </li>\n<li><a href=\"http://www.adam-bien.com/roller/abien/entry/daos_aren_t_dead_but\">DAOs Aren't Dead - But They Either Collapsed Or Disappeared</a> </li>\n<li><a href=\"http://www.adam-bien.com/roller/abien/entry/you_should_dao_if\">...And Finally, You Should Introduce A DAO If:</a> </li>\n</ul>\n    "},{"t":"Interview Question: running time of two programs run seperately and then together","l":"http://stackoverflow.com/questions/5543578/interview-question-running-time-of-two-programs-run-seperately-and-then-togethe","q":"\n\n<p>I was recently asked this question in an interview, and while I did alright on the first two parts [I am assuming] I struggled a bit on the third.  Here's the question:</p>\n\n<p>You have two Linux programs, A and B.  When run separately, A and B each take one minute to complete on a system that has just been restarted.  [ie: fresh system: you reboot it, log in, get a shell prompt, run the program.]</p>\n\n<p>What can you tell me about the programs if:</p>\n\n<p>a) when run together, they take 2 minutes\nb) when run together, they take 1 minute\nc) when run together, they take 30 seconds</p>\n\n<p>I said for a) that if they take exactly double the time when run together, they share no mutual exclusion and are vying for all the same resources, probably don't share any sort of cache data or instructions [and thus don't help each other out from a cache perspective] and each program needs the full utilizaion of said resource to complete such that the OS cannot parallelize them.</p>\n\n<p>For b), I said that if they can run just as fast together, they probably share some spacial/temporal locality in the cash, and may lend themselves to being properly pipelined in such a way that while program A is waiting on something, program B can run in between those stages, and vice versa-- effectively running them both in 1 minute.</p>\n\n<p>For c), I was a bit stuck.  In retrospect, I probably should have said that perhaps program A and B were both doing a common task, where two of them running at once could complete said task faster than one running alone-- such as a garbage collector.  But the best that I could come up with was that perhaps they loaded out of the same sector on the hard disk, and that helped them both together run quickly.</p>\n\n<p>I am just looking for some input from some of the smarties here on things I probably missed.  The position was for a platforms/systems position that require a good understanding of hardware/software and operating systems, and namely interactions between them which is why [I'm assuming] the question was asked.</p>\n\n<p>I was also trying to think of examples that I could apply to each part to help show my knowledge of the questions real life applications, but on the spot I was coming up short.</p>\n\n<p>Thanks.</p>\n    ","a":"\n<h2>Together they take 2 minutes to complete</h2>\n\n<p>In this case, I think that each program is fully CPU-bound and can saturate 100% of the CPUs available on the machine. Therefore when the programs run together, each runs at half speed.</p>\n\n<p>It's also possible that this would be the observed behavior if both programs were able and willing to saturate some other resource apart from the CPU, for example some I/O device. However, since <em>in practice, usually</em> the performance of I/O devices does not decrease linearly with the load applied to them if they are oversaturated, I would consider that a less likely scenario and go with CPU-bound as a first guess.</p>\n\n<h2>Together they take 1 minute to complete</h2>\n\n<p>The two programs do not contest the same resources, or there are ample resources in the system to satisfy the demands of both. Therefore, they end up not interfering with each other.</p>\n\n<h2>Together they take half a minute to complete</h2>\n\n<p>The programs operate on the same input, and both can tell when all input is used up, so each ends up doing half the work it would do if launched alone at half the running time. Also, the system obviously has the capacity to supply double the amount of whatever resource these programs are constrained by.</p>\n\n<p>Since in this case the running time decreases linearly with the amount of processes (perfect scaling), it seems more likely that the resource constraining the programs is CPU for the same reasons explained in the \"2 minutes\" scenario. This also fits in well with the \"common input\" assumption, as the input would not be very likely to be coming from one source if there were e.g. different I/O devices supplying it.</p>\n\n<p>Therefore, the first guess in this case is that each program is CPU-bound and written such that it consumes at most half the CPU resources in the system.</p>\n    "},{"t":"Best practice: Extending or overriding an Android library project class","l":"http://stackoverflow.com/questions/9951610/best-practice-extending-or-overriding-an-android-library-project-class","q":"\n\n<p>We're using an <a href=\"http://developer.android.com/guide/developing/projects/index.html#LibraryProjects\">Android Library Project</a> to share core classes and resources across different builds (targets) of our Android application. The Android projects for each specific target <a href=\"http://developer.android.com/guide/developing/projects/projects-eclipse.html#ReferencingLibraryProject\">reference the Core library project</a> (behind the scenes, Eclipse creates and references a jar from the referenced library project).</p>\n\n<p>Overriding resources such as images and XML layouts is easy. Resource files placed in the target project, such as the app icon or an XML layout, automatically override the core library's resources with the same name when the app is built. However, sometimes a class needs to be overridden to enable target-specific behavior. For example, the Amazon target preferences screen cannot contain a link to the Google Play app page, requiring a change in the Amazon project's preferences.xml and preferences Activity class.</p>\n\n<p>The goal is to reduce the amount of duplicate code among target projects while removing as much target-specific code from the Core library as possible. We've come up with a couple of approaches to implement logic specific to different targets:</p>\n\n<ol>\n<li>Write the target-specific functions within Core library classes and use if/switch blocks to select behavior based on product SKU. This approach is not very modular and bloats the Core library codebase.</li>\n<li>Extend the particular Core class in a target project and override the base (Core) class functions as needed. Then keep a reference to the base-class object in the Core library and instantiate it with an extended class object (from <a href=\"http://stackoverflow.com/questions/6564133/android-library-project-how-to-overwrite-a-class\">Android library project - How to overwrite a class?</a>)</li>\n</ol>\n\n<p>Are there other strategies to override or extend an Android library project class? What are some of the best practices for sharing and extending common classes among Android app targets?</p>\n    ","a":"\n<blockquote>\n  <p>Library project is referenced as a raw project dependency (source-based mechanism), not as a compiled jar dependency (compiled-code based library mechanism).</p>\n</blockquote>\n\n<p>@yorkw this is not true for the latest versions of ADT Plugin for Eclipse\n<a href=\"http://developer.android.com/sdk/eclipse-adt.html\" rel=\"nofollow\">http://developer.android.com/sdk/eclipse-adt.html</a></p>\n\n<p><strong>From version 17 Change log</strong></p>\n\n<blockquote>\n  <p>New build features\n  Added feature to automatically setup JAR dependencies. Any .jar files in the /libs folder are added to the build configuration (similar to how the Ant build system works). Also, .jar files needed by library projects are also automatically added to projects that depend on those library projects. (more info)</p>\n</blockquote>\n\n<p>More info <a href=\"http://tools.android.com/recent/dealingwithdependenciesinandroidprojects\" rel=\"nofollow\">http://tools.android.com/recent/dealingwithdependenciesinandroidprojects</a></p>\n\n<p>Before that, update overwriting of the Activity from Library project was easy, just exclude the class.  Now the library is included as jar file, and there is no way to exclude class file from jar dependency.</p>\n\n<p>EDIT:</p>\n\n<p>My solution to overwrete/extend Activity from library jar:</p>\n\n<p>I created a simple util class:</p>\n\n<pre><code>public class ActivityUtil {\n\nprivate static Class getActivityClass(Class clazz) {\n\n    // Check for extended activity\n    String extClassName = clazz.getName() + \"Extended\";\n    try {\n        Class extClass = Class.forName(extClassName);\n        return extClass;\n    } catch (ClassNotFoundException e) {\n        e.printStackTrace();\n        // Extended class is not found return base\n        return clazz;\n    }\n}\n\npublic static Intent createIntent(Context context, Class clazz) {\n    Class activityClass = getActivityClass(clazz);\n    return new Intent(context, activityClass);\n}\n}\n</code></pre>\n\n<p>In order to overwrite a library's \"SampleActivity\" class it a the project which depends on that library, create a new class with the name SampleActivityExtended in the project in the same package and add the new activity to your AndroidManifest.xml.</p>\n\n<p>IMPORTANT:  all intents referencing overwritten activities should be created through the util class in the following manner:</p>\n\n<pre><code>Intent intent = ActivityUtil.createIntent(MainActivity.this, SampleActivity.class);\n...\nstartActivity(intent);\n</code></pre>\n    "},{"t":"What should you put into an Architecture Specification?","l":"http://stackoverflow.com/questions/4435792/what-should-you-put-into-an-architecture-specification","q":"\n\n<p>I'm currently revising a number of document templates for my company. One thing we've never had is a formal Architecture Specification, so I'm starting to put one together. </p>\n\n<p>What sort of things do you put into your architecture specs? Feel free to copy and paste a table of contents - that would be helpful. Are there any good templates already available on the web? </p>\n    ","a":"\n<p>I agree with Asaphs' sentiment; fortunately it's not impossible to produce useful / practical architectural documentation - just not common.</p>\n\n<p>For me the key thing is to understand who the document is for: when would they use it? Why would they use it?  Too many times it simply becomes a form-filling exercise for ticking boxes on some project plan.</p>\n\n<p>I'm assuming you mean a software architecture document or solution architecture document - and not an enterprise strategy or something.</p>\n\n<p>Remember too that there're two things a typical architecture document will do: </p>\n\n<ul>\n<li>Providing input into decisions to be made elsewhere: \"this is our current thinking - would someone please decide whether to spend the big $$ for a DR site or not, etc\".</li>\n<li>Recording decisions: particularly justifying your decisions.</li>\n</ul>\n\n<p>In terms of both structure and key information to capture I'd recommend looking at different views of the system: logical, physical, data, security, and so on.  A good starting point is the <a href=\"http://en.wikipedia.org/wiki/4%2B1\">4+1 model</a>.</p>\n\n<p>[Update:] One of the uses of such an <strong>artefact</strong> is Traceability - from requirements and design artefacts through to code artefacts; and while that might sound Waterfall orientated it actually applies (and works) for Agile based projects as well.</p>\n\n<p>[Update:] Artefact <strong>doesn't</strong> mean \"Word Document\".  The ToC example below is a supporting document / document based version of the system modelled in a UML modelling tool (SparxEA) which includes requirements as well.  Sometimes you \"have to\" use a document, but I try to be as sparing as possible.</p>\n\n<p>[Update:] The other good thing about a nice clearly laid out document is that it's easier for new blood to get some understanding of what they are inheriting - especially if previous staff are not available.</p>\n\n<p>The Software Engineering Institute at Carnegie Mellon has a bunch of information, and on the page below there's a link to a template: <a href=\"http://www.sei.cmu.edu/architecture/tools/viewsandbeyond/\">http://www.sei.cmu.edu/architecture/tools/viewsandbeyond/</a><br>\nBewared that it's very comprehensive - not for the faint of heart (or lacking in time).</p>\n\n<p>[Update:] Finally, here's an example Table of Contents from a recent project.  Despite the many sections the document's not overly long (only about 35 pages, and a good portion of that is diagrams).</p>\n\n<pre><code>Table of Contents\n1   Documentation Roadmap\n1.1 Document &amp; Version Information\n1.1.1   Document Contributors\n1.1.2   Referenced Documents\n1.1.3   Reviewers   \n1.1.4   Document Signoff    \n1.2 Glossary of Terms   \n1.3 Purpose and Scope of the SAD    \n1.4 Stakeholder Representation  \n2   Project Background  \n2.1 Problem Background  \n2.2 Solution Overview and Project Phases    \n2.3 Solution Context    \n2.3.1   Solution Usage  \n2.4 Architectural Goals \n2.5 Constraints \n2.6 Considerations  \n3   Register of Issues and Decisions    \n3.1 Issues Register \n3.2 Decisions Register  \n4   Overview of Key Views   \n5   Functional View \n6   Logical Layers View \n7   Physical View   \n7.1 Mapping of Logical and Physical Components  \n7.2 Mapping of Logical Layers and Bespoke Packages  \n7.3 Bespoke Physical Components \n7.4 Common  \n7.5 Business Logic  \n7.6 Data Provider Interfaces    \n7.7 MS SQL Data Provider    \n7.8 Data Repository \n7.9 External Data Services – Time Sheeting  \n7.10    External Data Services - DLR    \n7.11    UI - Flash  \n7.12    FlourineFX  \n7.13    UI - ASP.NET    \n7.14    Model   \n7.15    Login   \n7.16    Mapping To Physical Components  \n7.17    Solution Dependencies   \n8   Solution Views  \n8.1 Data View   23\n8.1.1   Conceptual Data Model   \n8.1.2   Physical Data Model \n8.2 Technology View \n8.2.1   Microsoft Windows Server    \n8.2.2   Microsoft Internet Information Server   \n8.2.3   Microsoft SQL Server    \n8.2.4   Microsoft .Net Framework    \n8.2.5   Microsoft ASP.NET   \n8.2.6   Microsoft ASP.NET Role Membership Provider  \n8.2.7   Dot Net Nuke (DNN)  \n8.2.8   AntiXSS Library \n8.2.9   Microsoft Enterprise Libraries  \n8.2.9.1 Application Logging Block   \n8.2.10  Log4Net \n8.2.11  Fluorine    \n8.2.12  Adobe Flash \n8.3 Security View   \n8.3.1   Data Encryption – Data at Rest  \n8.3.2   Data Encryption – Data in Flight    \n8.3.3   Authentication  \n8.3.4   Authorisation   \n8.3.5   Non-Repudiation \n8.3.6   Cross-Site Scripting (XSS) and SQL Injection    \n8.3.7   Other Security Concerns \n8.4 Infrastructure View \n8.5 Support View    \n8.6 Enterprise Standards Compliance \n9   Design Patterns and Principles  \n9.1 Dependency Inversion Principle  \n9.2 Dependency Injection Pattern    \n9.3 Factory Pattern \n9.4 Persistence Ignorance   \n9.5 Dependency Injection    \nAppendix – [legacy project name] Phase 1    \n9.6 Bespoke Physical Components \n</code></pre>\n    "},{"t":"Your thoughts on “Large Scale C++ Software Design”","l":"http://stackoverflow.com/questions/1860796/your-thoughts-on-large-scale-c-software-design","q":"\n\n<p>Reading the <a href=\"http://rads.stackoverflow.com/amzn/click/0201633620\">reviews at Amazon</a> and <a href=\"http://accu.informika.ru/accu/bookreviews/public/reviews/l/l000736.htm\">ACCU</a> suggests that John Lakos' book, <em>Large-Scale C++ Software Design</em> may be the Rosetta Stone for modularization.</p>\n\n<p>At the same time, the book seems to be really rare: not many have ever read it, and no pirate electronic copies are floating around.</p>\n\n<p>So, what do you think? </p>\n\n<p>[Since this is Number 3 at <a href=\"https://www.google.com/search?aq=1&amp;oq=large%20sc&amp;sugexp=chrome,mod=18&amp;sourceid=chrome&amp;ie=UTF-8&amp;q=large%20scale%20c%2b%2b%20software%20design\">Google search for the book title</a>, left my vote for reopening, it would be a pity to loose all the helpful discussion here (which I always thought was the place right for it).]</p>\n    ","a":"\n<p>I've read it, and consider it a very useful book on some practical issues with large C++ projects.  If you have already read a lot about C++, and know a bit about physical design and its implications, you may not find that much which is terribly \"new\" in this book.</p>\n\n<p>On the other hand, if your build takes 4 hours, and you don't know how to whittle it down, get a copy, read it, and take it all in.</p>\n\n<p>You'll start writing physically better code quite quickly.</p>\n\n<p>[Edit]\nIf you want to start somewhere, and can't immediately get a hold of the book, I found the <a href=\"http://gamesfromwithin.com/physical-structure-and-c-part-1-a-first-look\">Games From Within series on physical structure</a> useful even after reading Large Scale C++ design.</p>\n    "},{"t":"Best way to store Badge criteria?","l":"http://stackoverflow.com/questions/522943/best-way-to-store-badge-criteria","q":"\n\n<p>I've been thinking about how to implement the badge feature similar to SO's on a new website. What is the best way to store criteria for badges?</p>\n\n<p>Two ideas:</p>\n\n<ul>\n<li>All code</li>\n<li>'Second system' - create a meta architecture for defining badges and their criteria. Store some info in the database and have code query it to figure out the badges and their criteria.</li>\n</ul>\n\n<p>Are there better ways?</p>\n    ","a":"\n<p>Rules.</p>\n\n<p>You create events in the system, and use rules within an event stream processor.</p>\n\n<p>Specifically, say you have a badge \"made 10 posts\". You don't run \"select count(*) from posts where user = :user\" for every post. Rather, you have a simple rule that watches each post come by, and \"count them\", storing the rules state in the user profile.</p>\n\n<p>That way \"made 10 posts\" is as cheap as \"made 1,000,000\" posts.</p>\n\n<p>This also makes the system much more extensible.</p>\n    "},{"t":"How to implement a caching model without violating MVC pattern?","l":"http://stackoverflow.com/questions/4916701/how-to-implement-a-caching-model-without-violating-mvc-pattern","q":"\n\n<p>I have an ASP.NET MVC 3 (Razor) Web Application, with a particular page which is <strong>highly database intensive</strong>, and user experience is of the upmost priority.</p>\n\n<p>Thus, i am introducing caching on this particular page.</p>\n\n<p>I'm trying to figure out a way to implement this caching pattern whilst keeping my controller <strong>thin</strong>, like it currently is without caching:</p>\n\n<pre><code>public PartialViewResult GetLocationStuff(SearchPreferences searchPreferences)\n{\n   var results = _locationService.FindStuffByCriteria(searchPreferences);\n   return PartialView(\"SearchResults\", results);\n}\n</code></pre>\n\n<p>As you can see, the controller is very thin, as it should be. It doesn't care about how/where it is getting it's info from - that is the job of the service.</p>\n\n<p>A couple of notes on the flow of control:</p>\n\n<ol>\n<li>Controllers get DI'ed a particular <strong>Service</strong>, depending on it's area. In this example, this controller get's a <strong>LocationService</strong></li>\n<li><strong>Services</strong> call through to an <code>IQueryable&lt;T&gt;</code> <strong>Repository</strong> and materialize results into <code>T</code> or <code>ICollection&lt;T&gt;</code>.</li>\n</ol>\n\n<p>How i want to implement caching:</p>\n\n<ul>\n<li><strong>I can't use Output Caching</strong> - for a few reasons. First of all, this action method is invoked from the client-side (jQuery/AJAX), via <code>[HttpPost]</code>, which according to HTTP standards should not be cached as a request. Secondly, i don't want to cache purely based on the HTTP request arguments - the cache logic is a lot more complicated than that - there is actually two-level caching going on.</li>\n<li>As i hint to above, i need to use regular data-caching, e.g <code>Cache[\"somekey\"] = someObj;</code>.</li>\n<li>I don't want to implement a generic caching mechanism where <em>all</em> calls via the service go through the cache first - <strong>i only want caching on this particular action method</strong>.</li>\n</ul>\n\n<p>First thought's would tell me to create another service (which inherits <strong>LocationService</strong>), and provide the caching workflow there (check cache first, if not there call db, add to cache, return result).</p>\n\n<p>That has two problems:</p>\n\n<ol>\n<li>The services are basic <strong>Class Libraries</strong> - no references to anything extra. I would need to add a reference to <code>System.Web</code> here.</li>\n<li>I would have to access the HTTP Context outside of the web application, which is considered bad practice, not only for testability, but in general - right?</li>\n</ol>\n\n<p>I also thought about using the <code>Models</code> folder in the Web Application (which i currently use only for <strong>ViewModels</strong>), but having a cache service in a models folder just doesn't sound right.</p>\n\n<p>So - any ideas? Is there a MVC-specific thing (like Action Filter's, for example) i can use here? </p>\n\n<p>General advice/tips would be greatly appreciated.</p>\n    ","a":"\n<p>My answer is based on the assumption that your services implement an interface, for example the type of _locationService is actually ILocationService but is injected with a concrete LocationService.  Create a CachingLocationService that implements the ILocationService interface and change your container configuration to inject that caching version of the service to this controller. The CachingLocationService would itself have a dependecy on ILocationService which would be injected with the original LocationService class. It would use this to execute the real business logic and concern itself only with pulling and pushing from cache.</p>\n\n<p>You don't need to create CachingLocationService in the same assembly as the original LocationService. It could be in your web assembly. However, personally I'd put it in the original assembly and add the new reference.</p>\n\n<p>As for adding a dependency on HttpContext; you can remove this by taking a dependency on </p>\n\n<pre><code>Func&lt;HttpContextBase&gt; \n</code></pre>\n\n<p>and injecting this at runtime with something like </p>\n\n<pre><code>() =&gt; HttpContext.Current\n</code></pre>\n\n<p>Then in your tests you can mock HttpContextBase, but you may have trouble mocking the Cache object without using something like TypeMock.</p>\n\n<hr>\n\n<p>Edit: On further reading up on the .NET 4 System.Runtime.Caching namespace, your CachingLocationService should take a dependency on ObjectCache. This is the abstract base class for cache implementations. You could then inject that with System.Runtime.Caching.MemoryCache.Default, for instance.</p>\n    "},{"t":"Why put a DAO layer over a persistence layer (like JDO or Hibernate)","l":"http://stackoverflow.com/questions/1378413/why-put-a-dao-layer-over-a-persistence-layer-like-jdo-or-hibernate","q":"\n\n<p>Data Access Objects (DAOs) are a common design pattern, and recommended by Sun. But the earliest examples of Java DAOs interacted directly with relational databases -- they were, in essence, doing object-relational mapping (ORM). Nowadays, I see DAOs on top of mature ORM frameworks like JDO and Hibernate, and I wonder if that is really a good idea.</p>\n\n<p>I am developing a web service using JDO as the persistence layer, and am considering whether or not to introduce DAOs. I foresee a problem when dealing with a particular class which contains a map of other objects:</p>\n\n<pre><code>public class Book {\n    // Book description in various languages, indexed by ISO language codes\n    private Map&lt;String,BookDescription&gt; descriptions;\n}\n</code></pre>\n\n<p>JDO is clever enough to map this to a foreign key constraint between the \"BOOKS\" and \"BOOKDESCRIPTIONS\" tables. It transparently loads the BookDescription objects (using lazy loading, I believe), and persists them when the Book object is persisted.</p>\n\n<p>If I was to introduce a \"data access layer\" and write a class like BookDao, and encapsulate all the JDO code within this, then wouldn't this JDO's transparent loading of the child objects be circumventing the data access layer? For consistency, shouldn't all the BookDescription objects be loaded and persisted via some BookDescriptionDao object (or BookDao.loadDescription method)? Yet refactoring in that way would make manipulating the model needlessly complicated.</p>\n\n<p>So my question is, what's wrong with calling JDO (or Hibernate, or whatever ORM you fancy) directly in the business layer? Its syntax is already quite concise, and it is datastore-agnostic. What is the advantage, if any, of encapsulating it in Data Access Objects?</p>\n    ","a":"\n<p>It depends what your layer's goals are. You put an abstraction in to supply a different set of semantics over another set. Generally further layers are there to simplify somethings such as development of future maintennance. But they could have other uses.</p>\n\n<p>For example a DAO (or persistence handling) layer over an ORM code supply specialised recovery and error handling functionality that you didn't want polluting the business logic.</p>\n    "},{"t":"MVCS - Model View Controller Service","l":"http://stackoverflow.com/questions/5702391/mvcs-model-view-controller-service","q":"\n\n<p>I've been using MVC for a long time and heard about the \"<strong>Service</strong>\" layer (for example in Java web project) and I've been wondering if that is a <strong>real architectural pattern</strong> given I can't find a lot of information about it.</p>\n\n<p>The idea of MVCS is to have a <strong>Service layer between the controller and the model</strong>, to encapsulate all the business logic that could be in the controller. That way, the controllers are just there to forward and control the execution. And you can call a Service in many controllers (for example, a website and a webservice), without duplicating code.</p>\n    ","a":"\n<p>Service layer can be inerpreted a lot of ways, but it's usually where you have your core business processing logic, and sits below your MVC architecture, but above your data access architecture.</p>\n\n<p>For example you layer of a complete system may look like this:</p>\n\n<ol>\n<li>View Layer: Your MVC framework &amp; code of choice</li>\n<li>Service Layer: Your Controller will call this layer's objects to get or update Models, or other requests.</li>\n<li>Data Access Objects: These are abstractions that your service layer will call to get/update the data it needs. This layer will generally either call a Database or some other system (eg: LDAP server, web service, or NoSql-type DB)</li>\n</ol>\n\n<p>The service layer would then be responsible for:</p>\n\n<ul>\n<li>Retreiving and creating your 'Model' from various data sources (or data access objects).</li>\n<li>Updating values across various repositories/resources.</li>\n<li>Performing application specific logic and manipulations, etc.</li>\n</ul>\n\n<p>Your Model you use in your MVC may or may not come from your services. You may want to take the results your service gives you and manipulate them into a Model that's more specific to your medium (eg: a web page).</p>\n    "},{"t":"Unit of Work + Repository Pattern: The Fall of the Business Transaction Concept","l":"http://stackoverflow.com/questions/19548531/unit-of-work-repository-pattern-the-fall-of-the-business-transaction-concept","q":"\n\n<p>Combining <code>Unit of Work</code> and <code>Repository Pattern</code> is something used fairly widely nowadays. As Martin Fowler <a href=\"http://martinfowler.com/eaaCatalog/unitOfWork.html\">says</a> a purpose of using <code>UoW</code> is to form a <strong>Business Transaction</strong> while being ignorant of how repositories actually work (being persistent ignorant). I've reviewed many implementations; and ignoring specific details (concrete/abstract class, interface,...) they are more or less similar to what follows:</p>\n\n<pre><code>public class RepositoryBase&lt;T&gt;\n{\n    private UoW _uow;\n    public RepositoryBase(UoW uow) // injecting UoW instance via constructor\n    {\n       _uow = uow;\n    }\n    public void Add(T entity)\n    {\n       // Add logic here\n    }\n    // +other CRUD methods\n}\n\npublic class UoW\n{\n    // Holding one repository per domain entity\n\n    public RepositoryBase&lt;Order&gt; OrderRep { get; set; }\n    public RepositoryBase&lt;Customer&gt; CustomerRep { get; set; }\n    // +other repositories\n\n    public void Commit()\n    {\n       // Psedudo code: \n       For all the contained repositories do:\n           store repository changes.\n    }\n}\n</code></pre>\n\n<p><strong>Now my problem:</strong></p>\n\n<p><code>UoW</code> exposes public method <strong><code>Commit</code></strong> to store the changes. Also, because each repository has a shared instance of <code>UoW</code>, each <code>Repository</code> can access method <code>Commit</code> on UoW. Calling it by one repository makes all other repositories store their changes too; hence the result the whole concept of transaction collapses:</p>\n\n<pre><code>class Repository&lt;T&gt; : RepositoryBase&lt;T&gt;\n{\n    private UoW _uow;\n    public void SomeMethod()\n    {\n        // some processing or data manipulations here\n        _uow.Commit(); // makes other repositories also save their changes\n    }\n}\n</code></pre>\n\n<p>I think this must be not allowed. Considering the purpose of the <code>UoW</code> (business transaction), the method <code>Commit</code> should be exposed only to the one who started a <strong>Business Transaction</strong> for example Business Layer. What surprised me is that I couldn't find any article addressing this issue. In all of them <code>Commit</code> can be called by any repo being injected.</p>\n\n<p><strong>PS:</strong> I know I can tell my developers not to call <code>Commit</code> in a <code>Repository</code> but trusting Architecture is much much more reliable than trusting developers!</p>\n    ","a":"\n<p>I do agree with your concerns. I prefer to have an ambient unit of work, where the outermost function opening a unit of work is the one that decides whether to commit or abort. Functions called can open a unit of work scope which automatically enlists in the ambient UoW if there is one, or creates a new one if there is none.</p>\n\n<p>The implementation of the <code>UnitOfWorkScope</code> that I used is heavily inspired by how <code>TransactionScope</code> works. Using an ambient/scoped approach also removes the need for dependency injection.</p>\n\n<p>A method that performs a query looks like this:</p>\n\n<pre><code>public static Entities.Car GetCar(int id)\n{\n    using (var uow = new UnitOfWorkScope&lt;CarsContext&gt;(UnitOfWorkScopePurpose.Reading))\n    {\n        return uow.DbContext.Cars.Single(c =&gt; c.CarId == id);\n    }\n}\n</code></pre>\n\n<p>A method that writes looks like this:</p>\n\n<pre><code>using (var uow = new UnitOfWorkScope&lt;CarsContext&gt;(UnitOfWorkScopePurpose.Writing))\n{\n    Car c = SharedQueries.GetCar(carId);\n    c.Color = \"White\";\n    uow.SaveChanges();\n}\n</code></pre>\n\n<p>Note that the <code>uow.SaveChanges()</code> call will only do an actual save to the database if this is the root (otermost) scope. Otherwise it is interpreted as an \"okay vote\" that the root scope will be allowed to save the changes.</p>\n\n<p>The entire implementation of the <code>UnitOfWorkScope</code> is available at: <a href=\"http://coding.abel.nu/2012/10/make-the-dbcontext-ambient-with-unitofworkscope/\">http://coding.abel.nu/2012/10/make-the-dbcontext-ambient-with-unitofworkscope/</a></p>\n    "},{"t":"Is the LAMP stack appropriate for Enterprise use?","l":"http://stackoverflow.com/questions/349924/is-the-lamp-stack-appropriate-for-enterprise-use","q":"\n\n<p>Is the LAMP (Linux, Apache, MySQL, PHP / Ruby / Python) stack appropriate for Enterprise use? </p>\n\n<p>To be clear, by \"Enterprise\", I mean a large or very large company, where security, robustness, availability of skill sets, Total Cost of Ownership (TCO), scalability, and availability of tools are key considerations. Said another way, a company that looks for external adoption of frameworks / architecture - Something ubiquitous will be seen as more \"valid\" than something exotic / esoteric in this kind of environment.</p>\n\n<p>I've seen use cases where Oracle, IBM, and Sun have implemented systems on the LAMP stack for various Enterprises. I've also seen examples where websites like yellowpages.com (Ruby on rails) and Facebook (php) are built on it. However, none of these examples are exactly what I'm looking for. </p>\n\n<p>I'm really trying to find examples where it is an Enterprise standard at a very large bank (I.e., Citigroup), Telecom company (I.e., AT&amp;T), or manufacturer (I.e., Proctor and Gamble). Just to be clear, I'm not looking for an example where it's used in a limited sense (Like at JPMorgan Chase), but where it's a core platform for systems like CRM, manufacturing systems, or HR management, as well as for internal and external websites. </p>\n\n<p>The perception I've seen so far is that applications built on the LAMP stack perform slower and are less flexible. Some of the arguments I've heard are:</p>\n\n<ul>\n<li><p>Linux is seen as not as well supported as Unix, Solaris, or Windows Servers.</p></li>\n<li><p>Apache is harder to configure and maintain than web servers like BEA WebLogic or IIS.  </p></li>\n<li><p>MySQL is a \"not ready for prime time\" DB for hobbyists, and not a competitor for SQL Server or Oracle (Although PostgreSQL seems to have a reputation for being more robust). </p></li>\n<li><p>PHP / Ruby on rails are optimized for CRUD (Create, Read, Update and Delete operations). Although this is an advantage when building CRUD-intensive web aplications, both perform slower than Java/Java EE or C# (which are both common Enterprise standards). Furthermore, a lot of applications and systems (like manufacturing systems) have a lot of non-CRUD functionality that may be harder to build with PHP or Ruby, or even Python. </p></li>\n</ul>\n\n<p>Can anyone please provide arguments to support or refute the idea of the LAMP stack being appropriate for the Enterprise?</p>\n\n<p>Thanks!</p>\n\n<p>KA</p>\n\n<p>UPDATE: <a href=\"http://kaiseradvisor.blogspot.com/2009/07/sometimes-lamp-stack-is-appropriate-for.html\" rel=\"nofollow\">Some times the LAMP Stack is Appropriate for Enterprise Use: Externally-Facing Blogs</a></p>\n    ","a":"\n<p>\"but where it's a core platform for systems like CRM and HR, as well as for internal and external websites\"</p>\n\n<p>First, find a LAMP CRM or HR application.</p>\n\n<p>Then find a customer for the LAMP CRM or HR application.</p>\n\n<p>Sadly, there aren't a lot of examples of item 1.  Therefore, your case is proven.  It can't be used for enterprise applications because -- currently -- there aren't any of the applications you call \"enterprise\".</p>\n\n<p>Your other points, however, are very interesting.</p>\n\n<ol>\n<li><p><strong>Linux is seen as not as well supported as Unix, Solaris, or Windows Servers</strong>.  I think Red Hat would object strongly to this.  Give them a call.  I think they'll make a very persuasive sales pitch.  Read their <a href=\"http://customers.press.redhat.com/\">success stories</a>.</p></li>\n<li><p><strong>Apache is harder to configure and maintain than web servers like BEA WebLogic or IIS</strong>.  By whom?  Apache web site managers?  Or IIS web site managers?  This is entirely subjective.</p></li>\n<li><p><strong>MySQL is a \"not ready for prime time\" DB</strong>.  Take it up with Sun Microsystems.  I think they'd object strongly to this.  Give them a call.  I think they'll make a very persuasive sales pitch.  Read their <a href=\"http://www.sun.com/systems/solutions/mysql/perspectives.jsp\">success stories</a>.</p></li>\n<li><p><strong>PHP / Ruby on rails are optimized for CRUD, and both are slowly performing</strong>.  Could be true.  Java and Python might be faster.  PHP and Ruby aren't the last word in LAMP.</p></li>\n</ol>\n    "},{"t":"3D Game Development tips (especially game architecture) [closed]","l":"http://stackoverflow.com/questions/1201361/3d-game-development-tips-especially-game-architecture","q":"\n\n<p><strong>tl;dr version:</strong> What is the best advice (that you learned by experience and not from books) that you can give me, with regards to 3D game architecture? (as in, how to design and connect the components of a 3D game)</p>\n\n<p></p><hr><p></p>\n\n<p>When it comes to programming, there is only so much you can learn from books. It seems to me, many of the things learned are learned from other people, or by <strong>experience</strong>. Even learning something in a classroom has its advantages over books; the professor might slip in a little tidbit of knowledge that he learned from his experience, and it can make all the difference.</p>\n\n<h2>I'm looking for those tidbits here.</h2>\n\n<p>Books on game development only go so far. There's a big difference about a book that explains the logic and syntax of a programming language, and a book that tries to tell you how to make a game. The latter doesn't work so well (at least for me); but the former is the whole reason I'm studying computer science.</p>\n\n<p>I am going into my second year of college, and I'm 19 years old. <strong>I don't have experience</strong>, I have book knowledge. So I'm trying to piggyback off of you and your knowledge that you've gained from experience.</p>\n\n<h2>My current topic of interest is game architecture.</h2>\n\n<p>(or \"engine design\" if you prefer, though I'm not looking to create a everything-but-the-kitchen-sink game engine)</p>\n\n<p>I recently asked a question, <a href=\"http://stackoverflow.com/questions/1189236/data-structures-for-message-passing-within-a-program\">Data structures for message passing within a program?</a> and it resulted in a long, <a href=\"http://stackoverflow.com/questions/1189236/data-structures-for-message-passing-within-a-program/1191261#1191261\">excellent answer</a> from <a href=\"http://stackoverflow.com/users/103258/haffax\">haffax</a>. To him, he was just rattling off his experience and the knowledge he's gained from it; to me, it gave me many new things to think about that I had never read in a book before, and haven't experienced for myself. Go check out the answer, and up it if you like it.</p>\n\n<p>From it, I thought more about message passing within a program. I thought about how perhaps MVC is not a good fit for game architecture. His concepts of all game objects being equal and not a hierarchy, where instead you add \"Features\" to a game object, is something I've never heard before, and I really like it. And right at the beginning of the question he gave simple bits of advice:</p>\n\n<blockquote>\n  <p>Before starting to design any of the packages and classes, start with an analysis</p>\n</blockquote>\n\n<p>...</p>\n\n<blockquote>\n  <p>And for motivation, <strong>I speak from experience here</strong>, don't think of your task as writing a game engine, write a game!</p>\n</blockquote>\n\n<h2>I want more answers like that.</h2>\n\n<p>What are the most important game architecture concepts and tricks that you've taken from your experience as a game developer? When you sit down to write a game, how do you organize things? Do you separate your view and your model, or do you intertwine them and refactor later? What do you want to say about the effectiveness of MVC as a game architecture pattern? How do you keep track of so many things (graphics, audio, file loading, collision, AI, network) and make them all work together to create a finished game? How do you use design patterns and preserve the object oriented-ness of your game? How do you write automated tests for your game?</p>\n\n<p>I can come up with a million questions, but right now I just want to hear in general, whatever sticks out in your mind. What sort of experiences have you been through that changed your thinking? What is your philosophy when writing your games? How do you stay organized amidst the confusion and the massive-ness of the task of 3D game creation?</p>\n\n<h2>What game development tricks have you learned from experience?</h2>\n\n<p>Thank you for taking the time to read &amp; respond!!</p>\n    ","a":"\n<ol>\n<li><p>The rest of my list may be crap, but the most important thing is to <strong>just do it</strong>. You want experience making games, so make a game. Make your goal to complete a game, not just to work on a game.</p></li>\n<li><p><strong>Start simple</strong> and make progressively more complex games. Simpler games are easier to design, but can still be challenging. The lessons you'll learn will help you design more complex systems. Ain't no shame in making 2D games or clones of existing games.</p></li>\n<li><p><strong>Follow the <a href=\"http://www.butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod\">Solid principles of object oriented design</a></strong>. You sound like you want to unit test. Solid principles are key for designing testable objects.</p></li>\n<li><p><strong>Only use design patterns to solve problems.</strong> For instance, you may be tempted to use a singleton for an object with only one instance. Having only one instance of an object is not a problem. Lets say you want to unit test your game logic without your display logic doing anything, then MVC solves your problem.</p></li>\n<li><p><strong>Do what works for you.</strong> I track my progress with note cards arranged as a todo list on my wall. For a single person project, todo lists work very well.</p></li>\n<li><p>Become friends with art students.</p></li>\n<li><p><strong>Find or start a game making club at your school.</strong>  Work together to make simple games.</p></li>\n<li><p>Old wizened authors tell aspirant authors that they have to write one millions words before they can write one worth reading.  I think the adage also holds for game design. I'm not old nor wizened yet, but I say be prepared to design and complete ten games before you get praise from random strangers.</p></li>\n<li><p><strong>Use source control.</strong>  I'm a big fan of Mercurial using the TortoiseHG client.</p></li>\n</ol>\n    "},{"t":"How to Design and Architect a Java/Java EE web application?","l":"http://stackoverflow.com/questions/5739099/how-to-design-and-architect-a-java-java-ee-web-application","q":"\n\n<p>I am java developer with almost 5 years of experience on Struts, Spring and Hibernate. </p>\n\n<p>We have a new project coming up in few days. We have the complete requirements with us and we will be doing this project using Spring MVC, Spring  and the Hibernate.</p>\n\n<p>I have been asked to design and architect the entire web application. Designing and creating an Architect is something which I have not done till now in my career. And I don't know how do I go about this and where to start, what tools to use and so on. I don't know even the A,B,C's of design and architecture. </p>\n\n<p>You may be wondering why I was even I asked to do this at first place. The thing is I was given an opportunity to do this and at every stage I will be monitored and I will have my seniors reviewing the design. </p>\n\n<p>So any suggestion, ideas and steps to start and go ahead are welcome.</p>\n    ","a":"\n<p>I can add my 2 cents from my own experiences (although its more of a compilation of development best practises, you might find it useful to keep them in mind while designing your application):</p>\n\n<ul>\n<li>There is no one-size-fits-all design </li>\n<li>Try to keep application as light weight as possible. </li>\n<li>Use Maven/Gradle to manage dependencies \n<ul>\n<li>Don't rely excessively on IDE. Make sure your project builds without IDE (If you are using maven/gradle, It will :) Try to open you project with IDEA, Netbeans and Eclipse.</li>\n</ul></li>\n<li>For the technologies mentioned above, appfuse makes a good starting point. </li>\n<li>Design your database/entities first </li>\n<li>Use libraries sensibly and judiciously. Do NOT overuse them.</li>\n<li>Dont forget to write JUnit/TestNG (at least for service layer)</li>\n<li>Test application on all major browsers (not just your favorite one :) </li>\n<li>Determine how many total users and how many concurrent users your web app will have.<br>\n<ul>\n<li>Then decide whether you need caching or not.</li>\n<li>you will use app server clustering or not.</li>\n</ul></li>\n<li>Select the application server based on its capabilities and more importantly 'your needs'\n<ul>\n<li>Tomcat / Jetty are absolutely fine for most of the cases</li>\n</ul></li>\n<li>Avoid using any app-server specific api</li>\n<li>Use JPA interfaces/annotations even if using hibernate as JPA implementation</li>\n<li>Be extra cautious while mapping relationships in entities. Decide which properties and relationships will load lazily and which will load eagerly</li>\n<li>Keep application security in mind while designing the app. Spring security is excellent choice.</li>\n<li>Never abuse HttpSession. Dont store too much in it.</li>\n<li>Keep entities Serializable. Enforce developers to use toString(), hashCode() and equals()</li>\n<li>Dont Forget to use version controlling from Day 1</li>\n<li>Dont just assume that spring/hibernate/spring-mvc will be best choice for you. create small proof of concepts with atleast 3 to 4 options.</li>\n<li>Try to automate integration/build/deploy with CI tools like Jenkins</li>\n<li>Check and Tune SQL generated by Hibernate (time to time)</li>\n<li>Do not let business logic creep into view layer. Hate jsp scriptlets? Consider Velocity/Freemarker. JSP is not the only option. </li>\n<li>externalize the environment specific configuration by using Spring's PropertyPlaceholderConfigurator.</li>\n<li>If possible, try to integrate with existing User Authentication mechanism (Like LDAP/ OpenID) rather than writing your own. This will save you from reinventing the wheel and your users from remembering yet another set of username and password.</li>\n</ul>\n    "},{"t":"Advice for converting a large monolithic singlethreaded application to a multithreaded architecture?","l":"http://stackoverflow.com/questions/2204216/advice-for-converting-a-large-monolithic-singlethreaded-application-to-a-multith","q":"\n\n<p>My company's main product is a large monolithic C++ application, used for scientific data processing and visualisation.  Its codebase goes back maybe 12 or 13 years, and while we have put work into upgrading and maintaining it (use of STL and Boost - when I joined most containers were custom, for example - fully upgraded to Unicode and the 2010 VCL, etc) there's one remaining, very significant problem: it's fully singlethreaded.  Given it's a data processing and visualisation program, this is becoming more and more of a handicap.</p>\n\n<p>I'm both a <b>developer</b> and <b>the project manager</b> for the next release where we want to tackle this, and this is going to be a difficult job in both areas.  I'm seeking <b>concrete, practical, and architectural advice</b> on how to tackle the problem.</p>\n\n<p>The program's data flow might go something like this:</p>\n\n<ul>\n<li>a window needs to draw data</li>\n<li>In the paint method, it will call a GetData method, often hundreds of times for hundreds of bits of data in one paint operation</li>\n<li>This will go and calculate or read from file or whatever else is required (often quite a complex data flow - think of this as data flowing through a complex graph, each node of which performs operations)</li>\n</ul>\n\n<p>Ie, the paint message handler will block while processing is done, and if the data hasn't already been calculated and cached, this can be a long time.  Sometimes this is minutes.  Similar paths occur for other parts of the program that perform lengthy processing operations - the program is unresponsive for the entire time, sometimes hours.</p>\n\n<p>I'm seeking advice on how to approach changing this.  Practical ideas.  Perhaps things like:</p>\n\n<ul>\n<li>design patterns for asynchronously requesting data?</li>\n<li>storing large collections of objects such that threads can read and write safely?</li>\n<li>handling invalidation of data sets while something is trying to read it?</li>\n<li>are there patterns and techniques for this sort of problem?</li>\n<li>what should I be asking that I haven't thought of?</li>\n</ul>\n\n<p>I haven't done any multithreaded programming since my Uni days a few years ago, and I think the rest of my team is in a similar position.  What I knew was academic, not practical, and is nowhere near enough to have confidence approaching this.</p>\n\n<p>The ultimate objective is to have a fully responsive program, where all calculations and data generation is done in other threads and the UI is always responsive.  We might not get there in a single development cycle :)</p>\n\n<hr>\n\n<p><strong>Edit:</strong> I thought I should add a couple more details about the app:</p>\n\n<ul>\n<li>It's a 32-bit desktop application for Windows.  Each copy is licensed.  We plan to keep it a desktop, locally-running app</li>\n<li>We use <a href=\"http://www.embarcadero.com/products/cbuilder\">Embarcadero (formerly Borland) C++ Builder 2010</a> for development. This affects the parallel libraries we can use, since most seem (?) to be written for GCC or MSVC only.  Luckily they're actively developing it and its C++ standards support is much better than it used to be.  The compiler supports <a href=\"http://blogs.embarcadero.com/ddean/2009/11/11/34858\">these Boost components</a>.</li>\n<li>Its architecture is not as clean as it should be and components are often too tightly coupled.  This is another problem :)</li>\n</ul>\n\n<p><strong>Edit #2:</strong> Thanks for the replies so far!</p>\n\n<ul>\n<li>I'm surprised so many people have recommended a multi-process architecture (it's the top-voted answer at the moment), not multithreading.  My impression is that's a very Unix-ish program structure, and I don't know anything about how it's designed or works.  Are there good resources available about it, on Windows?  Is it really that common on Windows?</li>\n<li>In terms of concrete approaches to some of the multithreading suggestions, are there design patterns for asynchronous request and consuming of data, or threadaware or asynchronous MVP systems, or how to design a task-oriented system, or articles and books and post-release deconstructions illustrating things that work and things that don't work?  We can develop all this architecture ourselves, of course, but it's good to work from what others have done before and know what mistakes and pitfalls to avoid.</li>\n<li>One aspect that isn't touched on in any answers is project managing this.  My impression is estimating how long this will take and keeping good control of the project when doing something as uncertain as this may be hard.  That's one reason I'm after recipes or practical coding advice, I guess, to guide and restrict coding direction as much as possible.</li>\n</ul>\n\n<p>I haven't yet marked an answer for this question - this is not because of the quality of the answers, which is great (and thankyou) but simply that because of the scope of this I'm hoping for more answers or discussion.  Thankyou to those who have already replied!</p>\n    ","a":"\n<p>So, there's a hint in your description of the algorithm as to how to proceed:</p>\n\n<blockquote>\n  <p>often quite a complex data flow - think of this as data flowing through a complex graph, each node of which performs operations</p>\n</blockquote>\n\n<p>I'd look into making that data-flow graph be literally the structure that does the work.  The links in the graph can be thread-safe queues, the algorithms at each node can stay pretty much unchanged, except wrapped in a thread that picks up work items from a queue and deposits results on one.  You could go a step further and use sockets and processes rather than queues and threads; this will let you spread across multiple machines if there is a performance benefit in doing this.</p>\n\n<p>Then your paint and other GUI methods need split in two: one half to queue the work, and the other half to draw or use the results as they come out of the pipeline.</p>\n\n<p>This may not be practical if the app presumes that data is global.  But if it is well contained in classes, as your description suggests it may be, then this could be the simplest way to get it parallelised.</p>\n    "},{"t":"What is the difference between domain objects, POCOs and entities?","l":"http://stackoverflow.com/questions/6154311/what-is-the-difference-between-domain-objects-pocos-and-entities","q":"\n\n<p>I was under the impression they are all basically the same.  Are model objects also the same?</p>\n\n<p>Right now, in my architecture, I have:</p>\n\n<pre><code>class Person \n{\n\n    public string PersonId;        \n    public string Name;\n    public string Email;\n\n    public static bool IsValidName() { //logic here}\n    public static bool IsValidEmail() { //logic here }\n}\n\n\nclass PersonService\n{\n    private PersonRepository pRepository;\n\n    PersonService()\n    {\n        pRepository = new PersonRepository();\n    }\n\n    public bool IsExistingEmail(string email)\n    {\n        //calls repo method to see if email is in db\n    }\n\n\n    public Person GetPerson(email)\n    {\n        return pRepository.Get(email);\n    }\n\n\n    public void SavePerson(Person p)\n    {\n        if (Person.IsValidEmail(p.Email) &amp;&amp; !IsExistingEmail(p.Email)\n        {\n            pRepository.Save(p);\n        }\n    }\n\n}\n\n\nclass PersonRepository\n{\n    public void Save(Person p)\n    {\n        //save to db\n    }\n\n    public Person Get(string email)\n    {\n        //get from db\n    }\n\n    public bool IsExistingEmail(string email)\n    {\n        //see if email in db\n    }\n\n}\n</code></pre>\n\n<p>So which of the above classes are POCO, Domain Object, Model object, entity?</p>\n    ","a":"\n<p>These are <a href=\"http://domaindrivendesign.org/resources/ddd_terms\">terms</a> that are largely used in (Distributed) Domain Driven Design. They are not the same. The term <em>model Object</em> can be used as a synonym to the <em>domain object</em>.</p>\n\n<p><strong>Domain Objects.</strong> Objects from the business specific area that represent something meaningful to the domain expert. Domain objects are mostly represented by entities and value objects. Generaly speaking, most objects that live in domain layer contribute to the model and are domain objects.</p>\n\n<p><strong>Entity.</strong> An object fundamentally defined not by its attributes, but by a thread of continuity and identity. <em>(Meaning it <strong>must</strong> have <strong>Id</strong>)</em> </p>\n\n<p><strong>POCO.</strong> A simple object without complicated logic which doesn't require to be identifiable, usually it has just a few properties and is used with ORM or as a Data Transfer Object</p>\n\n<p>UPDATE<br>\nclass Person - Entity and POCO, instance of this class is Domain Object <br>\nclass PersonService - Service <br>\nclass PersonRepository - Repository</p>\n    "},{"t":"Where does Elixir/erlang fit into the microservices approach? [closed]","l":"http://stackoverflow.com/questions/30422184/where-does-elixir-erlang-fit-into-the-microservices-approach","q":"\n\n<p>Lately I've been doing some experiments with docker compose in order to deploy multiple collaborating microservices. I can see the many benefits that microservices provide, and now that there is a good toolset for managing them, I think that it's not extremely hard to jump into the microservices wagon.</p>\n\n<p>But, I have been experimenting with Elixir too, and I am quite fond of the benefits that provides by itself. Given that it encourages packing your code into multiple decoupled applications, and supports hot code upgrades, how would you mix docker with elixir (or erlang, for that matter)?</p>\n\n<p>For example, if I want to use docker because it provides dev-prod parity, how does elixir fit in that? Given that docker containers are immutable, I lose the ability to do hot-code upgrades, right? What about blue/green deployments or canary releases?</p>\n\n<p>I mean, I could just write microservices with Elixir and use them as if they were written in any other language, polyglotism is one of the benefits of microservices anyway, but then I'm not getting the full benefits of using the OTP platform, I guess that pure collaborative erlang applications are way more optimal that using intermediate queues to communicate between microservices written in different (or not) languages.</p>\n\n<p>Thanks in advance.</p>\n    ","a":"\n<p>This is a very open question but I will try to illustrate why Elixir/Erlang may be the best platform out there for developing distributed systems (regardless if you are working with microservices).</p>\n\n<p>First, let's start with some background. The Erlang VM and its standard library were designed upfront for building distributed systems and this really shows up. As far as I know, it is the only runtime and VM used widely in production designed upfront for this use case.</p>\n\n<h3>Applications</h3>\n\n<p>For example, you have already hinted at \"applications\". In Erlang/Elixir, code is packaged inside applications which:</p>\n\n<ol>\n<li><p>are started and stopped as unit. Starting and stopping your system is a matter of starting all applications in it</p></li>\n<li><p>provide a unified directory structure and configuration API (which is not XML!). If you have already worked with and configured an OTP application, you know how to work with any other one</p></li>\n<li><p>contains your application supervision tree, with all processes (by process I mean \"VM processes\" which are lightweight threads of computation) and their state</p></li>\n</ol>\n\n<p>The impact of this design is huge. It means that Elixir developers, when writing applications have a more explicit approach to:</p>\n\n<ol>\n<li><p>how their code is started and stopped</p></li>\n<li><p>what are the processes that make part of an application and therefore what is the application state</p></li>\n<li><p>how those process will react and be affected in case of crashes or when something goes wrong</p></li>\n</ol>\n\n<p>Not only that, the tooling around this abstraction is great. If you have Elixir installed, open up \"iex\" and type: <code>:observer.start()</code>. Besides showing information and graphs about your live system, you can kill random processes, see their memory usage, state and more. Here is an example of running this in a Phoenix application:</p>\n\n<p><img src=\"http://i.stack.imgur.com/7j9BR.png\" alt=\"Observer running with a Phoenix application\"></p>\n\n<p>The difference here is that Applications and Processes give you an <strong>abstraction to reason about your code in production</strong>. Many languages provides packages, objects and modules mostly for code organization with no reflection on the runtime system. If you have a class attribute or a singleton object: how can you reason about the entities that can manipulate it? If you have a memory leak or a bottleneck, how can you find the entity responsible for it?</p>\n\n<p>If you ask anyone running a distributed system, that's the kind of insight that they want, and with Erlang/Elixir you have that as the building block.</p>\n\n<h3>Communication</h3>\n\n<p>All of this is just the beginning really. When building a distributed system, you need to choose a communication protocol and the data serializer. A lot of people choose HTTP and JSON which, when you think about it, is a very verbose and expensive combination for performing what is really RPC calls.</p>\n\n<p>With Erlang/Elixir, you already have a communication protocol and a serialization mechanism out of the box. If you want to have two machines communicating with each other, you only need to give them names, ensure they have the same secret, and you are done. </p>\n\n<p>Jamie talked about this at Erlang Factory 2015 and how they were able to leverage this to build a game platform: <a href=\"https://www.youtube.com/watch?v=_i6n-eWiVn4\">https://www.youtube.com/watch?v=_i6n-eWiVn4</a></p>\n\n<p>If you want to use HTTP and JSON, that is fine too and libraries like Plug and frameworks like Phoenix will guarantee you are productive here too.</p>\n\n<h3>Microservices</h3>\n\n<p>So far I haven't talked about microservices. That's because, up to this point, they don't really matter. You are already designing your system and nodes around very tiny processes that are isolated. Call them nanoservices if you'd like to!</p>\n\n<p>Not only that, they are also packaged into applications, which group them as entities that can be started and stopped as unit. If you have applications A, B and C, and then you want to deploy them as [A, B] + [C] or [A] + [B] + [C], you will have very little trouble in doing so due to their inherent design. Or, even better, if you want to avoid adding the complexity of microservices deployments into your system upfront, you can just deploy them altogether in the same node.</p>\n\n<p>And, at the end of the day, if you are running all of this using the Erlang Distributed Protocol, you can run them in different nodes and they will be able to reach other as long as you refer to them by <code>{:node@network, :name}</code> instead of <code>:name</code>.</p>\n\n<p>I could go further but I hope I have convinced you at this point. :)</p>\n    "},{"t":"Insightful resources for game engine architecture?","l":"http://stackoverflow.com/questions/1413863/insightful-resources-for-game-engine-architecture","q":"\n\n<p>I am looking for resources that describe, in detail, the design decisions involved in game engine architecture. I am especially looking for analysis of the pros and cons of different design decisions at the lowest levels of the engine. The ideal resource, for example, might compare an inheritance-based object hierarchy to a flat, component-based object hierarchy. Or it might compare an in-engine editor with a separate editor tool.</p>\n\n<p>What I am <em>not</em> looking for is a tutorial on <em>how</em> to implement any particular decision -- I would rather have a resource that discusses <em>why</em> to implement a decision.</p>\n\n<p>Are there any blogs or books out there that offer this kind of insight into the game engine design process?</p>\n    ","a":"\n<p>David Eberly's books (<a href=\"http://rads.stackoverflow.com/amzn/click/0122290631\">Game Engine Design</a>) (<a href=\"http://rads.stackoverflow.com/amzn/click/012229064X\">Game Engine Architecture</a>) go into great detail in this area. They are packed with info and do not hold your hand, which I think is what you're looking for.</p>\n\n<p>For web references, check out <a href=\"http://gamedev.net\">gamedev.net</a>.</p>\n    "},{"t":"Difference between design pattern and Architecture?","l":"http://stackoverflow.com/questions/4243187/difference-between-design-pattern-and-architecture","q":"\n\n<p>When we read about Design pattern on internet we get 3 category Creational ,Structural and Behavioral but when we do architecture of a software then we think about MVP, MVC or MVVM.\nAnd in Creational pattern i found Singleton pattern but i have use singleton in my MPV so my question is: Is Design pattern a over all structure of a product ? \n* if yes then how singleton can be a design pattern because i can use it any where in my application basically it restrict only to create one instance at a time in memory but this concept does not define how software is design? \n* if no then where are MVP, MVC and MVVM in 3 type of pattern and what is the difference between Design and Architecture of software.</p>\n    ","a":"\n<p>It requires a detailed explanation but I will try to sketch the differences to best of my knowledge.</p>\n\n<p><strong>Pattern are</strong> distilled commonality that you find in programs. It allows us to deconstruct a large complex structure and build using simple parts. It provides a general solution for a class of problems. </p>\n\n<p>A large complex software goes through a series of deconstruction at different levels. At large level, architectural patterns are the tools. At smaller level, design patterns are the tools and at implementation level, programming paradigms are the tools.</p>\n\n<p>A pattern can occur at very different levels. See <a href=\"http://en.wikipedia.org/wiki/Fractal\">Fractals</a>. Quick sort, Merge sort are all algorithmic patterns for organizing a group of elements in a order.</p>\n\n<p>For a most simplistic view:</p>\n\n<pre><code> Programming paradigms   Specific to programming language\n ......................\n Design patterns         Solves reoccurring problems in software construction\n ......................\n Architectural patterns  Fundamental structural organization for software systems\n ......................\n</code></pre>\n\n<p><strong>Idioms</strong> are paradigm-specific and language-specific programming techniques that fill in low-level details.</p>\n\n<p><strong>Design patterns</strong> are usually associated with code level commonalities. It provides various schemes for refining and building smaller subsystems. It is usually influenced by programming language. Some patterns pale into insignificance due to <a href=\"http://us.pycon.org/2009/conference/schedule/event/51/\">language paradigms</a>.\nDesign patterns are medium-scale tactics that flesh out some of the structure and behavior of entities and their relationships.</p>\n\n<p>While <strong>architectural patterns</strong> are seen as commonality at higher level than design patterns. \nArchitectural patterns are high-level strategies that concerns large-scale components, the global properties and mechanisms of a system.</p>\n\n<p>How are patterns obtained?\nThrough :</p>\n\n<ol>\n<li>re-use, </li>\n<li>classification </li>\n<li>and finally abstraction to distill the commonality. </li>\n</ol>\n\n<p>If you have followed the thoughts laid above. You will see that Singleton is a \"design pattern\" while MVC is one of the \"architectural\" pattern to deal with separation of concerns.</p>\n\n<p>Try reading on:</p>\n\n<ol>\n<li><a href=\"http://en.wikipedia.org/wiki/Architectural_pattern_%28computer_science%29\">http://en.wikipedia.org/wiki/Architectural_pattern_(computer_science)</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Design_pattern\">http://en.wikipedia.org/wiki/Design_pattern</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/Anti-pattern\">http://en.wikipedia.org/wiki/Anti-pattern</a></li>\n</ol>\n    "},{"t":"How can Google Chrome isolate tabs into seperate processes while looking like a single application?","l":"http://stackoverflow.com/questions/2019500/how-can-google-chrome-isolate-tabs-into-seperate-processes-while-looking-like-a","q":"\n\n<p>We have been told that Google Chrome runs each tab in a separate process. Therefore a crash in one tab would not cause problems in the other tabs.</p>\n\n<p>AFAIK, multi-processes are mostly used in programs without a GUI.  I have never read any technique that could embed multiple GUI processes into a single one.</p>\n\n<p>How does Chrome do that?</p>\n\n<p>I am asking this question because I am designing CCTV software which will use video decoding SDKs from multiple camera manufactures, some of which are far from stable. So I prefer to run these SDKs in different processes, which I thought is similar to Chrome.</p>\n    ","a":"\n<p>Basically, they use another process that glues them all together into the GUI.</p>\n\n<p>Google Chrome creates three different types of processes: browser, renderers, and plug-ins.</p>\n\n<p><strong>Browser:</strong>  There's only one browser process, which manages the tabs, windows, and \"chrome\" of the browser.  This process also handles all interactions with the disk, network, user input, and display, but it makes no attempt to parse or render any content from the web.</p>\n\n<p><strong>Renderers:</strong>  The browser process creates many renderer processes, each responsible for rendering web pages.  The renderer processes contain all the complex logic for handling HTML, JavaScript, CSS, images, and so on.  Chrome achieves this using the open source WebKit rendering engine, which is also used by Apple's Safari web browser.  Each renderer process is run in a sandbox, which means it has almost no direct access to the disk, network, or display.  All interactions with web apps, including user input events and screen painting, must go through the browser process.  This lets the browser process monitor the renderers for suspicious activity, killing them if it suspects an exploit has occurred.</p>\n\n<p><strong>Plug-ins:</strong>  The browser process also creates one process for each type of plug-in that is in use, such as Flash, Quicktime, or Adobe Reader.  These processes just contain the plug-ins themselves, along with some glue code to let them interact with the browser and renderers.</p>\n\n<p>Source: <a href=\"http://blog.chromium.org/2008/09/multi-process-architecture.html\">Chromium Blog: Multi-process Architecture</a></p>\n    "},{"t":"How to best create a RESTful API in Node.js","l":"http://stackoverflow.com/questions/14990544/how-to-best-create-a-restful-api-in-node-js","q":"\n\n<p>I'm a beginner in Node (and generally all back-end web development), and I have started to write a RESTful API in Node. There are a few things I'm trying to get my head around.</p>\n\n<p>My application uses Express and Mongoose, and I am using the <code>express-resource</code> module to easily create my CRUD routes for the API resources. But there are a couple of things I am unhappy about, and think I could do better.</p>\n\n<p>The first is Mongoose. If I want to write tests for my API, I have no way of stubbing Mongoose to force it to in memory data. All of the tutorials out there seem to point to Mongoose, however, and I'm really not sure what I should be using.</p>\n\n<p>Secondly, my resource seems to have a lot of boilerplate code. Is this really the best way to create a RESTful API in Node.js? Are there other modules that will help me to create my CRUD routes? I believe there are ways you can create CRUD routes right from your schema, without anymore code, but I'm really not sure how.</p>\n\n<p>I have seen projects out there such as Tower.js and CompoundJS (formally RailwayJS) that seem to be these comprehensive solutions that solve much more than my issues here. Perhaps I should be using them, but I really only want the Node.js application to be an API and nothing more. I am dealing with the front-end independently of the API.</p>\n\n<p>To provide some context, here is my current situation. Currently, I have a model defined in Mongoose:</p>\n\n<pre><code>var mongoose = require('mongoose')\n  , Schema = mongoose.Schema\n  , Link\n\nvar LinkSchema = new Schema({\n  uri: String,\n  meta: {\n    title: String,\n    desc: String\n  },\n  shares: [{\n    uid: Schema.Types.ObjectId,\n    date: Date,\n    message: String\n  }]\n})\n\nLink = module.exports = mongoose.model('Link')\n</code></pre>\n\n<p>Next, I define the controllers for the CRUD routes:</p>\n\n<pre><code>var mongoose = require('mongoose')\n  , _ = require('underscore')\n  , Link = mongoose.model('Link')\n\nexports.load = function (req, id, fn) {\n  Link.findById(req.params.link, function (err, link) {\n    if (err) {\n      return res.send(err)\n    }\n\n    fn(null, link)\n  })\n}\n\nexports.index = function (req, res) {\n  var filterByUser = req.query.user ? { 'shares.uid': req.query.user } : {}\n\n  Link.find(filterByUser, function (err, links) {\n    if (err) {\n      return res.send(err)\n    }\n\n    res.send(links)\n  })\n}\n\nexports.create = function (req, res) {\n  var link = new Link(req.body)\n\n  link.save(function (err) {\n    if (err) {\n      // TODO: send 404\n      return res.send(err)\n    }\n\n    res.send(link)\n  })\n}\n\nexports.show = function (req, res) {\n  res.send(req.link)\n}\n\nexports.update = function (req, res) {\n  req.link = _(req.link).extend(req.body)\n\n  req.link.save(function (err, link) {\n    if (err) {\n      return res.send(err)\n    }\n\n    res.send(link)\n  })\n}\n\nexports.patch = exports.update\n\nexports.destroy = function (req, res) {\n  req.link.remove(function (err) {\n    if (err) {\n      return res.send(err)\n    }\n\n    res.send()\n  })\n}\n</code></pre>\n\n<p>Finally, I use the <code>express-resource</code> module to map these controllers to the necessary CRUD routes on top of the Express app.</p>\n\n<pre><code>app.resource('api/links', require('../resources/links'))\n</code></pre>\n    ","a":"\n<p>You should look into <a href=\"http://mcavage.github.com/node-restify/\">restify</a></p>\n\n<p>If you want to use express, you can also check out this project that I made -- called <a href=\"https://github.com/baugarten/node-restful\">node-restful</a>.</p>\n\n<p>This library seems to be much more mature and have more features though: <a href=\"https://github.com/jspears/mers\">https://github.com/jspears/mers</a></p>\n    "},{"t":"Why should a web architecture be loosely coupled?","l":"http://stackoverflow.com/questions/2868627/why-should-a-web-architecture-be-loosely-coupled","q":"\n\n<p>When I look at ASP.NET MVC projects I everytime see loose coupled architecture.</p>\n\n<p>For what do I need a loose coupling in a web architecture (if I do not make unit tests)?</p>\n\n<p>What are <strong>advantages</strong> and <strong>disadvantages</strong> of this?</p>\n\n<p>What is the <strong>main reason</strong> to decouple layers/classes?</p>\n\n<p>What if I do not want to change my DAL for example? I mean when shall I change my whole DAL?! So I could couple my DAL to the UI. What is bad with this?</p>\n    ","a":"\n<p>It will save you a lot of time for any project that isn't trivially small, where I define trivially small as less than a couple thousand lines of code (depending on the language).</p>\n\n<p>The reason is that once you get past super small projects, each change or update gets harder the more tightly coupled it is.  Being loosely coupled enables you to keep moving forward, adding features, fixing bugs, etc.  </p>\n\n<p>At a certain point I think any program becomes a nightmare to maintain, update and add on to.  The more loosely coupled the design is, the further that point is delayed.  If it's tightly coupled, maybe after about 10,000 lines of code it becomes unmaintainable, adding some features become impossible without essentially rewriting from scratch.</p>\n\n<p>Being loosely coupled allows it to grow to 1,000,000 - 10,000,000 lines of code while still being able to make changes and add new features within a reasonable amount of time.</p>\n\n<p>These numbers aren't meant to be taken literally as they're just made up, but to give a sense of where it becomes helpful.</p>\n\n<p>If you never need to update the program and it's fairly simple then sure, it's fine to be tightly coupled.  It's even okay to start that way but know when it's time to separate stuff out, but you still need experience writing loosely coupled code to know at what point it becomes beneficial.</p>\n\n<p><a href=\"http://code.google.com/p/fizzbuzz/source/browse/#svn/trunk/trunk\">Enterprise Fizzbuzz</a> is a intentionally humorous example of how it's possible to go overboard with overengineering, and not every project is going to need to same level of decoupling.</p>\n\n<p>MVC is generally considered a good starting point because most projects will become big enough for it to be helpful.  When the project gets bigger, that level of decoupling isn't enough and the M part needs to be split into several layers itself, and so forth.  There isn't a one-size fit all, but MVC is a good amount of decoupling for most projects.</p>\n    "},{"t":"When should a web service not be used?","l":"http://stackoverflow.com/questions/204653/when-should-a-web-service-not-be-used","q":"\n\n<p>Using a web service is often an excellent architectural approach. And, with the advent of WCF in .Net, it's getting even better.</p>\n\n<p>But, in my experience, some people seem to think that web services should always be used in the data access layer for calls to the database. I don't think that web services are the universal solution.</p>\n\n<p>I am thinking of smaller intranet applications with a few dozen users. The web app and its web service are deployed to one web server, not a web farm. There isn't going to be another web app in the future that can use this particular web service. It seems to me that the cost of calling the web service unnecessarily increases the burden on the web server. There is a performance hit to inter-process calls. Maintaining and debugging the code for the web app and the web service is more complicated. So is deployment. I just don't see the advantages of using a web service here.</p>\n\n<p>One could test this by creating two versions of the web app, with and without the web service, and do stress testing, but I haven't done it.</p>\n\n<p>Do you have an opinion on using web services for small-scale web app's? Any other occasions when web services are not a good architectural choice?</p>\n    ","a":"\n<p>Web Services are an absolutely horrible choice for data access.  It's a ton of overhead and complexity for almost zero benefit.</p>\n\n<p>If your app is going to run on one machine, why deny it the ability to do in-process data access calls?  I'm not talking about directly accessing the database from your UI code, I'm talking about abstracting your repositories away but still including their assemblies in your running web site.</p>\n\n<p>There are cases where I'd recommend web services (and I'm assuming you mean SOAP) but that's mostly for interoperability.</p>\n\n<p>The granularity of the services is also in question here.  A service in the SOA sense will encapsulate an operation or a business process.  Data access methods are only part of that process.</p>\n\n<p>In other words:</p>\n\n<pre><code>  - someService.SaveOrder(order);  // &lt;-- bad\n    // some other code for shipping, charging, emailing, etc\n\n  - someService.FulfillOrder(order);  //&lt;-- better\n    //the service encapsulates the entire process\n</code></pre>\n\n<p>Web services for the sake of web services is irresponsible programming.</p>\n    "},{"t":"What's the difference between application layer and business logic layer?","l":"http://stackoverflow.com/questions/2630758/whats-the-difference-between-application-layer-and-business-logic-layer","q":"\n\n<p>What's the difference between application layer and business logic layer? I kind of understand that business layer provides business specific services and application layer couples business services and provides services to the end user (Web Service, UI, etc). Am I right?</p>\n    ","a":"\n<p>That sounds about correct.</p>\n\n<p>The <strong>business layer</strong> implements the <strong>Domain Model</strong> in a <strong>boundary-technology-neutral</strong> way. In other words, it doesn't depend on any particular UI or service interface-related technology, such as web libraries or windowing APIs. You should be able to consume the business layer from any type of application - web, rich client, web service, etc.</p>\n\n<p>The <strong>application layer</strong> bridges the gap between the business layer and the boundary technology.</p>\n    "},{"t":"Differences between ARM architectures from a C programmer's perspective?","l":"http://stackoverflow.com/questions/4381102/differences-between-arm-architectures-from-a-c-programmers-perspective","q":"\n\n<p>I'm fairly new to programming for ARM. I've noticed there are several architectures like ARMv4, ARMv5, ARMv6, etc. What is the difference between these? Do they have different instruction sets or behaviors? </p>\n\n<p>Most importantly, if I compile some C code for ARMv6, will it run on ARMv5? What about ARMv5 code running on ARMv6? Or would I only have to worry about the difference if I were writing kernel assembly code?</p>\n    ","a":"\n<p>The ARM world is a bit messy.</p>\n\n<p>For the C programmers, things are simple: all ARM architectures offer a regular, 32-bit with flat addressing programming model. As long as you stay with C source code, the only difference you may see is about endianness and performance. Most ARM processors (even old models) can be both big-endian and little-endian; the choice is then made by the logic board and the operating system. Good C code is <em>endian neutral</em>: it compiles and works correctly, regardless of the platform endianness (endian neutrality is good for reliability and maintainability, but also for performance: non-neutral code is code which accesses the same data through pointers of distinct sizes, and this wreaks havoc with the strict aliasing rules that the compiler uses to optimize code).</p>\n\n<p>The situation is quite different if you consider <strong>binary</strong> compatibility (i.e. reusing code which has been compiled once):</p>\n\n<hr>\n\n<ul>\n<li>There are several instruction sets:\n<ol>\n<li>the original ARM instruction set with a 26-bit program counter (very old, very unlikely to be encountered nowadays)</li>\n<li>the ARM instruction set with a 32-bit program counter (often called \"ARM code\")</li>\n<li>the Thumb instruction set (16-bit simplified opcodes)</li>\n<li>the Thumb-2 instruction set (Thumb with extensions)</li>\n</ol></li>\n</ul>\n\n<p>A given processor may implement several instruction sets. The newest processor which knows only ARM code is the StrongARM, an ARMv4 representative which is already quite old (15 years). The ARM7TDMI (ARMv4T architecture) knows both ARM and Thumb, as do almost all subsequent ARM systems except the Cortex-M. ARM and Thumb code can be mixed together within the same application, as long as the proper glue is inserted where conventions change; this is called <em>thumb interworking</em> and can be handled automatically by the C compiler.</p>\n\n<p>The Cortex-M0 knows only Thumb instructions. It knows a few extensions, because in \"normal\" ARM processors, the operating system must use ARM code (for handling interrupts); thus, the Cortex-M0 knows a few Thumb-for-OS things. This does not matter for application code.</p>\n\n<p>The other Cortex-M know only Thumb-2. Thumb-2 is <em>mostly</em> backward compatible with Thumb, at least at assembly level.</p>\n\n<hr>\n\n<ul>\n<li>Some architectures add extra instructions.</li>\n</ul>\n\n<p>Thus, if some code is compiled with a compiler switch telling that this is for an ARMv6, then the compiler may use one of the few instructions with the ARMv6 has but not the ARMv5. This is a common situation, encountered on almost all platforms: e.g., if you compile C code on a PC, with GCC, using the <code>-march=core2</code> flag, then the resulting binary may fail to run on an older Pentium processor.</p>\n\n<hr>\n\n<ul>\n<li>There are several call conventions.</li>\n</ul>\n\n<p>The call convention is the set of rules which specify how functions exchange parameters and return values. The processor knows only of its registers, and has no notion of a stack. The call convention tells in which registers parameters go, and how they are encoded (e.g. if there is a <code>char</code> parameter, it goes in the low 8 bits of a register, but is the caller supposed to clear/sign-extend the upper 24 bits, or not ?). It describes the stack structure and alignment. It normalizes alignment conditions and padding for structure fields.</p>\n\n<p>There are two main conventions for ARM, called ATPCS (old) and AAPCS (new). They are quite different on the subject of floating point values. For integer parameters, they are mostly identical (but AAPCS requires a stricter stack alignment). Of course, conventions vary depending on the instruction set, and the presence of Thumb interworking.</p>\n\n<p>In some cases, it is possible to have some binary code which conforms to both ATPCS and AAPCS, but that is not reliable and there is no warning on mismatch. So the bottom-line is: you cannot have true binary compatibility between systems which use distinct call conventions.</p>\n\n<hr>\n\n<ul>\n<li>There are optional coprocessors.</li>\n</ul>\n\n<p>The ARM architecture can be extended with optional elements, which add their own instructions to the core instruction set. The FPU is such an optional coprocessor (and it is very rarely encountered in practice). Another coprocessor is NEON, a SIMD instruction set found on some of the newer ARM processors.</p>\n\n<p>Code which uses a coprocessor will not run on a processor which does not feature that coprocessor, unless the operating system traps the corresponding opcodes and emulates the coprocessor in software (this is more or less what happens with floating-point arguments when using the ATPCS call convention, and it is <em>slow</em>).</p>\n\n<hr>\n\n<p>To sum up, if you have C code, then recompile it. Do not try to reuse code compiled for another architecture or system.</p>\n    "},{"t":"What is a “feature flag”?","l":"http://stackoverflow.com/questions/7707383/what-is-a-feature-flag","q":"\n\n<p>Highscalability mention feature flags here:</p>\n\n<p><a href=\"http://www.iheavy.com/2011/08/26/5-things-are-toxic-to-scalability/\">http://www.iheavy.com/2011/08/26/5-things-are-toxic-to-scalability/</a> </p>\n\n<p>What exactly are feature flags?</p>\n\n<p>Thanks</p>\n    ","a":"\n<p>The ability to turn features (sub-sections) of your application on/off at a moments notice.</p>\n\n<p>I guess the example there was that it's handy to have the control to reduce the feature-set somewhat if you need to, say, reduce db queries if the load is too high.</p>\n    "},{"t":"How to design scalable applications? [closed]","l":"http://stackoverflow.com/questions/907260/how-to-design-scalable-applications","q":"\n\n<p>How do you design/architect a scalable application? Any suggestion of books or websites that could help to understand how to scale out applications?</p>\n\n<p>Thanks</p>\n    ","a":"\n<p>Over the past year I've had to come up to speed on this question for a project my company's working on, and I've found these resources extremely helpful: Todd Hoff's <a href=\"http://www.highscalability.com\">highscalability.com</a>; <a href=\"http://rads.stackoverflow.com/amzn/click/067232699X\">Scalable Internet Architectures</a>, by Theo Schlossnagle; and <a href=\"http://rads.stackoverflow.com/amzn/click/0596102356\">Building Scalable Web Sites</a>, by Cal Henderson.  Highscalability.com in particular will point you to many good presenations, tutorials, books, and papers, and is a great place to start.  All of the advice is practical, and based on experience at sites like Flickr, Twitter, and Google.</p>\n\n<p>BTW, scalability is not performance.  A perfectly scalable system is one that has a fixed marginal cost to add additional users or capacity.  </p>\n    "},{"t":"Does KnockoutJS provide suitable architecture for building large web apps?","l":"http://stackoverflow.com/questions/7963948/does-knockoutjs-provide-suitable-architecture-for-building-large-web-apps","q":"\n\n<h2>Quick question:</h2>\n\n<p><em>Will KnockoutJS provide a solid ground for developing a <strong>large</strong> web app? I am afraid of having one huge viewModel that will become unmaintainable.</em></p>\n\n<h2>Background info</h2>\n\n<p>I'll be building a web app that will be heavily client-side based. The backend will just be a RESTful endpoint. The entire interface of the web app will be built in pure HTML/CSS/JS - no server side scripting involved. </p>\n\n<p>The web app itself will consist of several smaller apps with one general login (kind of like Google's web apps where you have Gmail, Docs, Calendar, Reader, etc.). </p>\n\n<p>Each of those web apps will have some common functionality (such as a sidebar tree view, a top bar menu view, a notifications system), and some app-unique features. Usually I break my apps down to encapsulate functionality, something like:</p>\n\n<pre><code>var myNamespace = {\n    common: {\n        settings: {},\n        user: {},\n        notifications: {}\n    },\n    app1: {},\n    app2: {},\n    app3: {}\n};\n</code></pre>\n\n<p>Now, I really enjoy working with KnockoutJS and figured that it will be helpful when building some elements of my project (such as the notification system, or an advanced grid view with auto-refresh as the app will support collaboration). But I just can't figure out where to put my viewModel into this structure. </p>\n\n<p>I can only find trivial examples of how to build apps with KnockoutJS. <em>Can you actually build something more advanced than a Twitter reader with it?</em> Are there any good examples of how to break down a lot of functionality in the viewModel, or perhaps into many viewModels?</p>\n\n<h1>Proposed solution</h1>\n\n<p>While the more theoretical question (the Quick question) is still kind of unanswered here, I think I've found a solution that works in practice. @Simon 's answer gave me some food for thought, and here's what I've got so far:</p>\n\n<pre><code>// First: a collection of Observables that I want to share\nld.collectionOfObservables = {\n    notifications: ko.observableArray([]),\n};\n\n// Now let's define a viewModel. I put all my stuff inside the\n// 'ld' namespace to avoid cluttering the global object. \nld.viewModel1 = function (args) {\n    // Look inside args and bind all given parameters \n    // Normally you will want args to be an object of Observables. \n    for (var key in args) {\n        if (args.hasOwnProperty(key)) {\n            this[key] = args[key];\n        }\n    };\n    // So, by now we already have some observables in\n    // 'this', if there were any supplied in 'args'.\n    // Additionally, we define some model-unique properties/observables\n    this.folders = [ 'Inbox', 'Archive', 'Sent', 'Spam' ];\n    this.selectedFolder = ko.observable('Inbox');\n};\n// *** Let's pretend I create similar class and call it ld.viewModel2 ***\nld.viewModel2 = function (args) { .... }\n\n// OK, now go on and instantiate our viewModels!\n// This is the fun part: we can provide 0-many observables here, by providing them in an object\n// This way we can share observables among viewModels by simply suppling the same observables to different viewModels\nvar vm1 = new ld.viewModel1({ \n    notifications: ld.collectionOfObservables.notifications,  // we take an Observable that was defined in the collection\n});\nvar vm2 = new ld.viewModel2({ \n    notifications: ld.collectionOfObservables.notifications,  // shared with vm1\n});\n\n// Of course, we could just send the entire ld.collectionOfObservables as an array \n// but I wanted to show that you can be more flexible and chose what to share.\n// Not easy to illustrate with *one* shared Observable - notifications - \n// but I hope you get the point. :)\n\n// Finally, initiate the new viewModels in a specified scope\nko.applyBindings(vm1, document.getElementById('leftPane')); \nko.applyBindings(vm2, document.getElementById('bottomPane'));\n</code></pre>\n\n<p>Now, if JS had real inheritance it'd be even better cause right now I feel that all my viewModels start with this:</p>\n\n<pre><code>for (var key in args) {\n    if (args.hasOwnProperty(key)) {\n        this[key] = args[key];\n    }\n};\n</code></pre>\n\n<p>But that's just a minor inconvenience. Let me know what you think!</p>\n\n<p><strong>Edit 1:</strong>\nCould the solution be as simple as using the <code>with:</code> binding? See \"<a href=\"http://blog.stevensanderson.com/2011/08/31/knockout-1-3-0-beta-available/\">1. Control flow bindings</a>\" for an example.</p>\n\n<p><strong>Edit 2:</strong>\nI think my last edit was too quick. <code>with:</code> binding may help with the structure of your code, but AFAIK it doesn't help you share observables between those different parts. So the proposed solution above is still the way to go.</p>\n    ","a":"\n<p>You can use partial views and share observables between them.</p>\n\n<pre><code>    var some_observable = ko.observable()\n\n    var Model1 = function(something) {\n        this.something_1 = something;\n    };\n    var Model2 = function(something) {\n        this.something_2 = something;\n    };\n\n    var view_1 = Model1(some_observable);\n    var view_2 = Model2(some_observable);\n\n    ko.applyBindings(view_1, document.getElementById('some-id'));\n    ko.applyBindings(view_2, document.getElementById('some-other-id'));\n\n    &lt;div id='some-id'&gt;\n        &lt;input data-bind='value: something_1' /&gt;\n    &lt;/div&gt;\n    &lt;div id='some-other-id'&gt;\n        &lt;input data-bind='value: something_2' /&gt;\n    &lt;/div&gt;\n</code></pre>\n\n<p>I've been using this aproach to maintain a list photos in a gallery application, where one view renders thumbnails and another view takes care of uploads.</p>\n    "},{"t":"How to structure Javascript programs in complex web applications?","l":"http://stackoverflow.com/questions/2407872/how-to-structure-javascript-programs-in-complex-web-applications","q":"\n\n<p>I have a problem, which is not easily described. I'm writing a web application that makes strong usage of jQuery and AJAX calls. Now I don't have a lot of experience in Javascript archicture, but I realize that my program has not a good structure. I think I have too many identifiers referring to the same (at least more or less) thing.</p>\n\n<p>Let's have an look at an arbitrary exemplary UI widget that  makes up a tiny part of the application: The widget may be a part of a window and the window may be a part of a window manager:</p>\n\n<ol>\n<li>The eventhandlers use DOM elements as parameters. The DOM element represents a widget in the browser.</li>\n<li>A lot of times I use jQuery objects (Basically wrappers around DOM elements) to do something with the widget. Sometimes they are used transiently, sometimes they are stored in a variable for later purposes.</li>\n<li>The AJAX function calls use string identifiers for these widgets. They are processed server side.</li>\n<li>Beside that I have a widget class whose instances represent a widget. It is instantiated through the new operator.</li>\n</ol>\n\n<p>Now I have somehow four different object identifiers for the same thing, which needs to be kept in sync until the page is loaded anew. This seems not to be a good thing.</p>\n\n<h3>Any advice?</h3>\n\n<p><br>\n<br>\n<b>EDIT:</b><br>\n<em>@Will Morgan</em>: It's a form designer that allows to create web forms within the browser. The backend is Zope, a python web application server. It's difficult to get more explicit as this is a general problem I observe all the time when doing Javasscript-development with the trio jQuery, DOM tree and my own prototyped class instances.</p>\n\n<p><b>EDIT2:</b><br>\nI think it would helpful to  make an example, albeit an artificial one. Below you see a logger widget that can be used to add a block element to a web page in which logged items are displayed.</p>\n\n<pre><code>makeLogger = function(){\n     var rootEl = document.createElement('div');\n     rootEl.innerHTML = 'Logged items:';\n     rootEl.setAttribute('class', 'logger');\n\n     var append = function(msg){\n           // append msg as a child of root element.\n           var msgEl = document.createElement('div');\n           msgEl.innerHTML = msg;\n           rootEl.appendChild(msgEl);\n     };\n\n     return {\n          getRootEl: function() {return rootEl;},\n          log      : function(msg) {append(msg);}\n     };\n};\n\n// Usage \nvar logger = makeLogger();\nvar foo = document.getElementById('foo');\nfoo.appendChild(logger.getRootEl());\nlogger.log('What\\'s up?');\n</code></pre>\n\n<p>At this point I have a wrapper around the HTMLDivElement (the hosted object). With having the logger instance (the native object) at hand I can easily work with it through the function <em>logger.getRootEl()</em>.<br>\nWhere I get stuck is when I only have the DOM element at hand and need to do something with the public API returned by function <em>makeLogger</em> (e.g. in event handlers). And this is where the mess starts. I need to hold all the native objects in a repository or something so that I can retrieve again. It would be so much nicer to have a connection (e.g. a object property) from the hosted object back to my native object.\nI know it can be done, but it has some drawbacks:</p>\n\n<ul>\n<li>These kind of (circular) references are potentially memory leaking up to IE7</li>\n<li>When to pass the <i>hosted object</i> and when to pass the <i>native object</i> (in functions)?</li>\n</ul>\n\n<p>For now, I do the back referencing with jQuery's data() method. But all in all I don't like the way I have to keep track of the relation between the hosted object and its native counterpart.  </p>\n\n<h3>How do you handle this scenario?</h3>\n\n<p><br>\n<br>\n<b>EDIT3:</b><br>\nAfter some insight I've gained from Anurag's example..<br>\n<em>@Anurag:</em> If I've understood your example right, the critical point is to set up the correct (what's correct depends on your needs, though) <b><i>execution context</i></b> for the event handlers. And this is in your case the presentation object instance, which is done with Mootool's bind() function. So you ensure that you're <em>ALWAYS</em> dealing with the wrapper object (I've called it the native object) instead of the DOM object, right?\n<br>\n<br>\n<b><i>A note for the reader:</i></b> You're not forced to use Mootools to achieve this. In jQuery, you would setup your event handlers with the <em>$.proxy()</em> function, or if you're using plain old Javascript, you would utilize the <em>apply</em> property that every function exposes. \n</p>\n    ","a":"\n<p>For the four objects that need to be synchronized, you could have a single object and pass the reference around in a constructor, or as function arguments.</p>\n\n<p>The way I fix this problem is to never lose a reference to the wrapper object. Whenever a DOM object is needed (for example inserting into the page), this wrapper object provides it. But sticking that widget onto the screen, the wrapper object sets up all event handling and AJAX handling code specific to the widget, so the reference the the wrapper is maintained at all times in these event handlers and AJAX callbacks.</p>\n\n<p>I've created a <a href=\"http://jsfiddle.net/YHcTv/5/\" rel=\"nofollow\">simple example</a> on jsfiddle using MooTools that might make sense to you.</p>\n    "},{"t":"Windows Mobile Development - Where to begin? [closed]","l":"http://stackoverflow.com/questions/377604/windows-mobile-development-where-to-begin","q":"\n\n<p>Okay, I will shortly be starting down the path of windows mobile development. I know nothing about the subject really and I am looking for people with experience to let me know of any gottchas you may know of. </p>\n\n<p>Right now I dont even have a breif of what is requied but the assumption is that the application will be very little more than a bunch of CRUD forms for updating data. The only other requirment knowladge I have is that the application will need to support offline storage when there is no signal avaliable. This in turn will obviously require some kind of syncronization when signal returns. </p>\n\n<p>My initial thoughts are that the application will primarily be a front end to interact with a web service layer. Im assuming that WCF will be an appropriate technology for building these services? I also thought that SQL Server CE would be a good route to go down with regards to the offline storage issues. </p>\n\n<p>Any knowlage that you feel is useful within this domain would be appreciated. Advice, links, books anything appreciated.  </p>\n\n<p>EDIT: It has been noted that there are two ways to go with off-line synchronization. To either use some form of message queuing or to use SQL synchronization tools. Could anyone offer a good comparison and introduction to these?</p>\n\n<p>EDIT 2: After a little more digging I get the impression that there are basically 3 different approaches I can use here:</p>\n\n<ol>\n<li>Emmbeded Database to query against then syncronization online, when able</li>\n<li>MSMQ along with .NET remoting </li>\n<li>WCF with ExchangeWebServiceMailTransport bindings using Exchange Server.</li>\n</ol>\n\n<p>Now, there has been a nice few points raised on the first issue, and I think I understand at some level the issues I would face. But I'd like to get a little more information regarding MSMQ implementations and using WCFs new bindings. </p>\n    ","a":"\n<p>Here a few words from my experience so far (about 9 months) of .net Windows Mobile development.</p>\n\n<ol>\n<li><p>Well you are occasionally connected.  (Or more likely occasionally disconnected).  You have to choose whether you are going to use messaging with queues (i.e. WCF/SOAP/XML or something like it) or database synchronisation.  I choose the SQL synchronisation route so I can't really comment on messaging.  The SQL synchronisation route is not hassle free!</p></li>\n<li><p>If you go down the sync route with SQL compact like me you basically have two choices.  SQL Server merge replication or the newer ADO.NET Synchronisation services.  If you choose the former you need to be really careful with your DB design to ensure it can be easily partitioned between mobile subscribers and the publisher.  You really need to think about conflicts, and splitting tables that wouldn't normally be split in a normalised DB design is one way of doing that.  You have to consider situations where a device goes offline for some time and the publisher DB (i.e. main DB) and/or a subscriber alters the same data.  What happens when the device comes back online?  It might mean resolving conflicts even if you have partitioned things well.  This is where I got burnt.  But SQL Merge Replication can work well and reduces the amount of code you have to write.</p></li>\n<li><p>Roll your own DAL.  Don't attempt to use datareaders etc. directly from UI code and don't use typed datasets either.  There may be third party DALs that work with Windows Mobile (i.e. I know LLBLGEN does, might be worth a look) but Linq-to-SQL is not supported and anyway you need something lightweight.  The chances are the DAL won't be too big so roll it yourself.</p></li>\n<li><p>If you are using .net you'll probably end up wanting some unimplemented platform features.  I recommend using this inexpensive framework to give you what your missing (especially as related to connectivity and power management) - <a href=\"http://www.opennetcf.com/Products/SmartDeviceFramework/tabid/65/Default.aspx\">http://www.opennetcf.com/Products/SmartDeviceFramework/tabid/65/Default.aspx</a></p></li>\n<li><p>Windows Mobile devices partially switch off to save power when not in use.  If you are doing a polling type design you'll need to wake them up every x mins.  A normal .net timer class won't do this.  You'll need to use a platform feature which can be used from OpenNetCF (above). The timer class is called LargeIntervalTimer and is in the OpenNetCF.WindowsCE assembly/namespace (I think).</p></li>\n</ol>\n\n<p>Good Luck!</p>\n    "},{"t":"What's your recommendation for architecting GWT applications? MVC, MVP or custom messaging solution?","l":"http://stackoverflow.com/questions/1234389/whats-your-recommendation-for-architecting-gwt-applications-mvc-mvp-or-custom","q":"\n\n<p>I just started a new GWT project for a client and I'm interested in hearing people's experience with various GWT MVC architectures. On a recent project, I used both <a href=\"http://raibledesigns.com/rd/entry/gxt%5Fs%5Fmvc%5Fframework\">GXT MVC</a>, as well as a custom messaging solution (based on <a href=\"http://doc.appcelerator.org/mq:start\">Appcelerator's MQ</a>). GXT MVC worked OK, but it seemed like overkill for GWT and was hard to make work with browser history. I've heard of <a href=\"http://puremvc.org/\">PureMVC</a> and <a href=\"http://gwtiger.org/\">GWTiger</a>, but never used them. Our custom MQ solution worked pretty well, but made it difficult to test components with JUnit.</p>\n\n<p>In addition, I've heard that Google Wave (a GWT application) is written using a Model-View-Presenter pattern. A <a href=\"http://code.google.com/p/gwt-mvp-sample/\">sample MVP application</a> was recently published, but looking at the code, it doesn't seem that intuitive.</p>\n\n<p>If you were building a new GWT application, which architecture would you use? What are the pros and cons of your choice?</p>\n\n<p>Thanks,</p>\n\n<p>Matt</p>\n    ","a":"\n<p>It's worth noting that google has finally written out a tutorial for designing using the mvp architecture. It clarifies a lot of the elements from the google i/o talk listed above. Take a looK: <a href=\"https://developers.google.com/web-toolkit/articles/mvp-architecture\">https://developers.google.com/web-toolkit/articles/mvp-architecture</a></p>\n    "},{"t":"What is XML good for and when should i be using it?","l":"http://stackoverflow.com/questions/2871981/what-is-xml-good-for-and-when-should-i-be-using-it","q":"\n\n<p>I'm curious, I've been developing pretty powerful websites/web apps, and I've never learned XML, even odder I've never really felt the need to. It's not like curl or Prepared Statements where, before knowing what they did and how they worked, I had a feeling 'there's got to be an easier way to do this!' or 'there's got to be something designed for this!'.</p>\n\n<p>Currently I work with MySQL and JSON and I don't have this feeling of 'I need to learn that' (XML), this must be wrong!</p>\n\n<p>I'm really interested to hear some compelling arguments for XML, and learn about things which it can do beter than JSON or MySQL (or some other aspect of web dev) and when i should be using it!</p>\n    ","a":"\n<p>JSON is very lightweight which makes it better suited for passing data around to the front end.</p>\n\n<p>XML has descriptive tags that (I personally find) make it easier to read in a raw format.\nIf I wanted to have any sort of settings file that is loaded in from my program, i would have it in an XML file format.</p>\n\n<p>That's my idea of it anyway, but i'm sure there are much more in-depth reasons for choosing one over the other. Of which i am not experienced enough to list :)</p>\n\n<p>However i did find a couple of sites that make some good points.</p>\n\n<p><a href=\"http://ajaxian.com/archives/json-vs-xml-the-debate\">http://ajaxian.com/archives/json-vs-xml-the-debate</a> (Some good points in the comments)</p>\n\n<p><a href=\"http://webignition.net/articles/xml-vs-yaml-vs-json-a-study-to-find-answers/\">http://webignition.net/articles/xml-vs-yaml-vs-json-a-study-to-find-answers/</a></p>\n    "},{"t":"ASP.NET MVC vs WebForms: speed and architecture comparison [closed]","l":"http://stackoverflow.com/questions/1035642/asp-net-mvc-vs-webforms-speed-and-architecture-comparison","q":"\n\n<p>I had an argument with one of my friends who is an architect at a pretty large internet company. Basically he was saying that ASP.NET MVC is not for large-scale enterprise applications, that it is not as flexible as WebForms, and that an MVC app will be slower than a web forms app. </p>\n\n<p>From my own experience working with MVC, I can say that it is more flexible and it is lighter weight because there is no page life cycle, viewstate, etc..  It should thus load faster at the very least. As far as I know, MVC is designed for medium to large scale traffic. </p>\n\n<p>What do you guys think? Has anyone compared speed and performance? And is ASP.NET MVC better for large scale apps than ASP.NET WebForms? </p>\n\n<p>In short, between these two choices, which would you choose to use for a large scale enterprise application?</p>\n    ","a":"\n<ul>\n<li>Development Speed: WebForms</li>\n<li>Performance Speed: MVC</li>\n<li>Ease of Use: WebForms (Typically)</li>\n<li>Unit Testing: MVC (Typically)</li>\n</ul>\n    "},{"t":"Recommended practice to deploy MongoDB on EC2 for production? [closed]","l":"http://stackoverflow.com/questions/7237606/recommended-practice-to-deploy-mongodb-on-ec2-for-production","q":"\n\n<p>I would like to deploy mongoDB on EC2 for my production. However, I could not find enough information online to help answer my architectural questions.</p>\n\n<ol>\n<li>In general, what should be the initial cluster w/N shards?</li>\n<li>What should be the deployment plan for adding additional shards?</li>\n<li>What should be the failover strategy (what happens when one or more nodes fail)?</li>\n<li>What should be the disaster recovery strategy? I am thinking about setting up some nodes in US East and other nodes in US West like <a href=\"http://www.examville.com/examville/MongoDB%20on%20Amazon%20Web%20Services-ID7253\">this powerpoint file</a> says.</li>\n</ol>\n\n<p>Answers are very appreciated.</p>\n    ","a":"\n<ol>\n<li>Start with sharding enabled but limit the amount of shards to what\nyou actually need. Starting with sharding enabled means having\nmongos daemons in place, select your shard keys for the relevant\ncollections and make your queries targeted as opposed to global\nwhenever possible. From that point on add shards as load increases.\nPossible exception is when you expect a lot of traffic influx at\nlaunch in which case you want to both add more shards and pre-split\nand pre-move your chunks to the appropriate shards since chunk balancing is a slow process.</li>\n<li>No such plan is necessary. Shards can be added and removed on fly.\nNote that removing shards involved retiring them. From that point it\nwill take a (significant) amount of time before all chunks are moved\nto other shards so that the instance can be removed.</li>\n<li>Replica sets allow for this. If your durability requirements aren't\nsuper critical you can achieve some cost efficiency by hosting\nmultiple arbiters on a single instance rather than doing full 3\nmember repsets. Also note that repsets will improve read performance\nfor eventual consistency compatible queries using the \"slaveOk\"\nflag. Also, you can consider achieving similar levels of durability\nwith less overhead by using disk level failover (e.g. RAID10).\nObviously this doesn't catch full instance failures.</li>\n<li>Geographical datacenter splits are always a good idea but do note\nthat replication performance will suffer significantly. Strategies\nfor this are no different than any other database.</li>\n</ol>\n\n<p>Further notes :</p>\n\n<ul>\n<li>EC2 network layer is limited to 100k packets per second. For small, high throughput queries this will become a bottleneck quickly.</li>\n<li>RAID your EBS volumes. Running on a single EBS volume will cause EXTREMELY irratic performance. This becomes more stable as more volumes are part of the RAID setup. Must have!</li>\n<li>Use high memory instances. We've seen significant performance\nimprovements here since there's only so much you can do about right\nbalancing your indexes and keeping only relevant data in memory. Keep\nan eye on your faults/sec in mongostat. These are pagefaults and thus\nthe amount of times mongo has to hit disk to swap out a page.</li>\n</ul>\n    "},{"t":"How would you design an AppEngine datastore for a social site like Twitter?","l":"http://stackoverflow.com/questions/1630087/how-would-you-design-an-appengine-datastore-for-a-social-site-like-twitter","q":"\n\n<p>I'm wondering what would be the best way to design a social application where members make activities and follow other member's activities using Google AppEngine.</p>\n\n<p>To be more specific lets assume we have these entities:</p>\n\n<ul>\n<li><strong>Users</strong> who have friends</li>\n<li><strong>Activities</strong> which represent actions made by users (lets say each has a string message and a ReferenceProperty to its owner user, or it can use parent association via appengine's key)</li>\n</ul>\n\n<p>The hard part is following your friend's activities, which means aggregating the latest activities from all your friends.\nNormally, that would be a join between the Activities table and your friends list but thats not a viable design on appengine as there are no join simulating it will require firing up N queries (where N is number of friends) and then merging in memory - very expensive and will probably exceed request deadline...)</p>\n\n<p>I'm currently thinking of implementing this using inbox queues where creation of a new Activity will fire a background process that will put the new activity's key in the \"inbox\" of every following user:</p>\n\n<ul>\n<li>Getting \"All the users who follow X\" is a possible appengine query</li>\n<li>Not a very expensive batch input into a new \"Inbox\" entity that basically stores (User, Activity Key) tuples.</li>\n</ul>\n\n<p>I'll be happy to heard thought on this design or alternative suggestions etc.</p>\n    ","a":"\n<p>Take a look at <a href=\"http://code.google.com/events/io/2009/sessions/BuildingScalableComplexApps.html\">Building Scalable, Complex Apps on App Engine</a> (<a href=\"http://www.scribd.com/doc/16952419/Building-scalable-complex-apps-on-App-Engine\">pdf</a>), a fascinating talk given at Google I/O by Brett Slatkin. He addresses the problem of building a scalable messaging service like Twitter.</p>\n\n<p>Here's his <strong>solution</strong> using a list property:</p>\n\n<pre><code>class Message(db.Model):\n    sender = db.StringProperty()\n    body = db.TextProperty()\n\nclass MessageIndex(db.Model):\n    #parent = a message\n    receivers = db.StringListProperty()\n\nindexes = MessageIndex.all(keys_only = True).filter('receivers = ', user_id)\nkeys = [k.parent() for k in indexes)\nmessages = db.get(keys)\n</code></pre>\n\n<p>This key only query finds the message indices with a receiver equal to the one you specified without deserializing and serializing the list of receivers. Then you use these indices to only grab the messages that you want.</p>\n\n<p>Here's <strong>the wrong way</strong> to do it:</p>\n\n<pre><code>class Message(db.Model):\n    sender = db.StringProperty()\n    receivers = db.StringListProperty()\n    body = db.TextProperty()\n\nmessages = Message.all().filter('receivers =', user_id)\n</code></pre>\n\n<p>This is inefficient because queries have to unpackage all of the results returned by your query. So if you returned 100 messages with 1,000 users in each receivers list you'd have to deserialize 100,000 (100 x 1000) list property values. Way too expensive in datastore latency and cpu.</p>\n\n<p>I was pretty confused by all of this at first, so I wrote up a <a href=\"http://www.gomuse.com/google-app-engine-using-the-list-property-dbl\">short tutorial about using the list property</a>. Enjoy :)</p>\n    "},{"t":"Alternatives to many-to-many relationships with CQRS","l":"http://stackoverflow.com/questions/3932791/alternatives-to-many-to-many-relationships-with-cqrs","q":"\n\n<p>How do we model classic many-to-many relationships with CQRS/DDD?</p>\n\n<p>I know that both DDD and CQRS implementations and solutions tend to be domain-specific, so it may be difficult to come up with a general answer to this question.</p>\n\n<p>However, let's assume we have the familiar relationship between <em>Book</em> and <em>Author</em>. This is a classic many-to-many relationship.</p>\n\n<p>To me, it seems most natural that <em>Book</em> and <em>Author</em> are two different <strong>Entities</strong> that each belong in their own <strong>Aggregate Root</strong>. Thus, explicitly modeling the many-to-many relationship between them is not the way to go.</p>\n\n<p>How do we model an AddBookCommand? We want to be able to add a book to our library, and also somehow state that a particular <em>Author</em> wrote this <em>Book</em>. How do we model (and persist) such a relationship?</p>\n\n<p>Neither <em>Book</em> nor <em>Author</em> seem like good candidates for <strong>Value Objects</strong>...</p>\n    ","a":"\n<p>Supposing that both are aggregates, copy whatever author data you need into the Book aggregate upon adding the new book so that any subsequent commands have enough author data to work with. Now if the Author aggregate needs information about the books written by the author, then it could \"subscribe\" to the NewBookAdded event (technically you could send a RegisterAsAuthorOfBook command to the Author aggregate as a result of the NewBookAdded event). I presume one could model this the other way around as well, but I'm not that intimate with the Book Author domain.</p>\n\n<p>Bottom line is that you don't really store many-to-many because they don't scale. You have to start thinking of them (aggregates) as sending messages to each other. The bigger question is what needs to be consistent and at what point in time does it need to be consistent. Do we care that the Author does not instantaneously reflect the fact a new Book has been added, of which she/he's the author? Are there any invariants that Author wants to enforce with regard to the books he/she has written (and vice versa)?</p>\n\n<p>Another thing is to stop being data oriented and more behavior oriented. What's the behavior of the Book and Author aggregate? This will tell what data is required at which point and how it should be modelled.</p>\n\n<p><a href=\"http://pastie.org/1220582\">http://pastie.org/1220582</a> for a first stab at the Book aggregate.</p>\n    "},{"t":"Achievements / Badges system","l":"http://stackoverflow.com/questions/1744747/achievements-badges-system","q":"\n\n<p>I have been browsing this site for the answer but I'm still a little unsure how to plan a similar system in its database structure and implementation.</p>\n\n<p>In PHP and MySQL it would be clear that some achievements are earned immediately (when a specialized action is taken, in SO case: Filled out all profile fields), although I know SO updates and assigns badges after a certain amount of time. With so many users &amp; badges wouldn't this create performance problems (in terms of scale: high number of both users &amp; badges).</p>\n\n<p>So the database structure I assume would something as simple as:</p>\n\n<pre><code>Badges     |    Badges_User      |    User\n----------------------------------------------\nbd_id      |    bd_id            |  user_id\nbd_name    |    user_id          |  etc\nbd_desc    |    assigned(bool)   |  \n           |    assigned_at      |\n</code></pre>\n\n<p>But as some people have said it would be better to have an incremental style approach so a user who has 1,000,000 forum posts wont slow any function down.</p>\n\n<p>Would it then be another table for badges that could be incremental or just a 'progress' field in the badges_user table above?</p>\n\n<p>Thanks for reading and please focus on the scalability of the desired system (like SO thousands of users and 20 to 40 badges).</p>\n\n<p>EDIT: to some iron out some confusion I had assigned_at as a Date/Time, the criteria for awarding the badge would be best placed inside prepared queries/functions for each badge wouldn't it? (better flexibility)</p>\n    ","a":"\n<p>I think the structure you've suggested (without the \"assigned\" field as per the comments) would work, with the addition of an additional table, say \"Submissions_User\", containing a reference to user_id &amp; an incrementing field for counting submissions. Then all you'd need is an \"event listener\" as per <a href=\"http://stackoverflow.com/questions/522943/best-way-to-store-badge-criteria\">this post</a> and methinks you'd be set.</p>\n\n<p>EDIT: For the achievement badges, run the event listener upon each submission (only for the user making the submission of course), and award any relevant badge on the spot. For the time-based badges, I would run a CRON job each night. Loop through the complete user list once and award badges as applicable.</p>\n    "},{"t":"Domain Validation in a CQRS architecture","l":"http://stackoverflow.com/questions/10879421/domain-validation-in-a-cqrs-architecture","q":"\n\n<p><em>Danger ... Danger Dr. Smith... Philosophical post ahead</em></p>\n\n<p>The purpose of this post is to determine if placing the validation logic outside of my domain entities (aggregate root actually) is actually granting me more flexibility or it's <em>kamikaze code</em></p>\n\n<p>Basically I want to know if there is a better way to validate my domain entities. This is how I am planning to do it but I would like your opinion</p>\n\n<p>The first approach I considered was:</p>\n\n<pre><code>class Customer : EntityBase&lt;Customer&gt;\n{\n   public void ChangeEmail(string email)\n   {\n      if(string.IsNullOrWhitespace(email))   throw new DomainException(“...”);\n      if(!email.IsEmail())  throw new DomainException();\n      if(email.Contains(“@mailinator.com”))  throw new DomainException();\n   }\n}\n</code></pre>\n\n<p>I actually do not like this validation because even when I am encapsulating the validation logic in the correct entity, this is violating the Open/Close principle (Open for extension but Close for modification) and I have found that violating this principle, code maintenance becomes a real pain when the application grows up in complexity. Why? Because domain rules change more often than we would like to admit, and if the rules are <strong>hidden and embedded</strong> in an entity like this, they are hard to test, hard to read, hard to maintain but the real reason why I do not like this approach is: if the validation rules change, I have to come and edit my domain entity. This has been a really simple example but in RL the validation could be more complex</p>\n\n<p>So following the philosophy of Udi Dahan, <strong>making roles explicit</strong>, and the recommendation from Eric Evans in the blue book, the next try was to implement the specification pattern, something like this</p>\n\n<pre><code>class EmailDomainIsAllowedSpecification : IDomainSpecification&lt;Customer&gt;\n{\n   private INotAllowedEmailDomainsResolver invalidEmailDomainsResolver;\n   public bool IsSatisfiedBy(Customer customer)\n   {\n      return !this.invalidEmailDomainsResolver.GetInvalidEmailDomains().Contains(customer.Email);\n   }\n}\n</code></pre>\n\n<p>But then I realize that in order to follow this approach I had to mutate my entities first in order to pass the <em>value being valdiated</em>, in this case the email, but mutating them would cause  my domain events being fired which I wouldn’t like to happen until the new email is valid</p>\n\n<p><strong>So after considering these approaches, I came out with this one, since I am going to implement a CQRS architecture:</strong></p>\n\n<pre><code>class EmailDomainIsAllowedValidator : IDomainInvariantValidator&lt;Customer, ChangeEmailCommand&gt;\n{\n   public void IsValid(Customer entity, ChangeEmailCommand command)\n   {\n      if(!command.Email.HasValidDomain())  throw new DomainException(“...”);\n   }\n}\n</code></pre>\n\n<p>Well that’s the main idea, the entity is passed to the validator in case we need some value from the entity to perform the validation, the command contains the data coming from the user and since the validators are considered <strong>injectable</strong> objects they could have external dependencies injected if the validation requires it.</p>\n\n<p><strong>Now the dilemma</strong>, I am happy with a design like this because my validation is encapsulated in individual objects which brings many advantages: easy unit test, easy to maintain, domain invariants are explicitly expressed using the Ubiquitous Language, easy to extend, validation logic is centralized and validators can be used together to enforce complex domain rules. And even when I know  I am placing the validation of my entities outside of them (You could argue a code smell - Anemic Domain) but I think the trade-off is acceptable</p>\n\n<p>But there is one thing that I have not figured out how to implement it in a clean way. <em>How should I use this components...</em></p>\n\n<p>Since they will be injected, they won’t fit naturally inside my domain entities, so basically I see two options:</p>\n\n<ol>\n<li><p>Pass the validators to each method of my entity</p></li>\n<li><p>Validate my objects externally (from the command handler)</p></li>\n</ol>\n\n<p>I am not happy with the option 1 so I would explain how I would do it with the option 2</p>\n\n<pre><code>class ChangeEmailCommandHandler : ICommandHandler&lt;ChangeEmailCommand&gt;\n{\n   // here I would get the validators required for this command injected\n   private IEnumerable&lt;IDomainInvariantValidator&gt; validators;\n   public void Execute(ChangeEmailCommand command)\n   {\n      using (var t = this.unitOfWork.BeginTransaction())\n      {\n         var customer = this.unitOfWork.Get&lt;Customer&gt;(command.CustomerId);\n         // here I would validate them, something like this\n         this.validators.ForEach(x =. x.IsValid(customer, command));\n         // here I know the command is valid\n         // the call to ChangeEmail will fire domain events as needed\n         customer.ChangeEmail(command.Email);\n         t.Commit();\n      }\n   }\n}\n</code></pre>\n\n<p>Well this is it. Can you give me your thoughts about this or share your experiences with Domain entities validation</p>\n\n<p><strong>EDIT</strong></p>\n\n<p>I think it is not clear from my question, but the real problem is: Hiding the domain rules has serious implications in the future maintainability of the application, and also domain rules change often during the life-cycle of the app. Hence implementing them with this in mind would let us extend them easily. Now imagine in the future a rules engine is implemented, if the rules are encapsulated outside of the domain entities, this change would be easier to implement</p>\n\n<p>I am aware that placing the validation outside of my entities breaks the encapsulation as @jgauffin mentioned in his answer, but I think that the benefits of placing the validation in individual objects is much more substantial than just keeping the encapsulation of an entity. Now I think the encapsulation makes more sense in a traditional n-tier architecture because the entities were used in several places of the domain layer, but in a CQRS architecture, when a command arrives, there will be  a command handler accessing an aggregate root and performing operations against the aggregate root only creating a perfect window to place the validation.</p>\n\n<p>I'd like to make a small comparison between the advantages to place validation inside an entity vs placing it in individual objects</p>\n\n<ul>\n<li><p>Validation in Individual objects</p>\n\n<ul>\n<li>Pro. Easy to write</li>\n<li>Pro. Easy to test</li>\n<li>Pro. It's explicitly expressed</li>\n<li>Pro. It becomes part of the Domain design, expressed with the current Ubiquitous Language</li>\n<li>Pro. Since it's now part of the design, it can be modeled using UML diagrams</li>\n<li>Pro. Extremely easy to maintain</li>\n<li>Pro. Makes my entities and the validation logic loosely coupled</li>\n<li>Pro. Easy to extend</li>\n<li>Pro. Following the SRP</li>\n<li>Pro. Following the Open/Close principle</li>\n<li>Pro. Not breaking the law of Demeter (mmm)?</li>\n<li>Pro. I'is centralized</li>\n<li>Pro. It could be reusable</li>\n<li>Pro. If required, external dependencies can be easily injected</li>\n<li>Pro. If using a plug-in model, new validators can be added just by dropping the new assemblies without the need to re-compile the whole application</li>\n<li>Pro. Implementing a rules engine would be easier</li>\n<li>Con. Breaking encapsulation</li>\n<li>Con. If encapsulation is mandatory, we would have to pass the individual validators to the entity  (aggregate) method</li>\n</ul></li>\n<li><p>Validation encapsulated inside the entity</p>\n\n<ul>\n<li>Pro. Encapsulated?</li>\n<li>Pro. Reusable?</li>\n</ul></li>\n</ul>\n\n<p>I would love to read your thoughts about this</p>\n    ","a":"\n<p>I agree with a number of the concepts presented in other responses, but I put them together in my code.</p>\n\n<p>First, I agree that using Value Objects for values that include behavior is a great way to encapsulate common business rules and an e-mail address is a perfect candidate. However, I tend to limit this to rules that are constant and will not change frequently. I'm sure you are looking for a more general approach and e-mail is just an example, so I won't focus on that one use-case.</p>\n\n<p>The key to my approach is recognizing that validation serves different purposes at different locations in an application.  Put simply, validate only what is required to ensure that the current operation can execute without unexpected/unintended results.  That leads to the question what validation should occur where?</p>\n\n<p>In your example, I would ask myself if the domain entity really cares that the e-mail address conforms to some pattern and other rules or do we simply care that 'email' cannot be null or blank when ChangeEmail is called?  If the latter, than a simple check to ensure a value is present is all that is needed in the ChangeEmail method.</p>\n\n<p>In CQRS, all changes that modify the state of the application occur as commands with the implementation in command handlers (as you've shown). I will typically place any 'hooks' into business rules, etc. that validate that the operation MAY be performed in the command handler. I actually follow your approach of injecting validators into the command handler which allows me to extend/replace the rule set without making changes to the handler. These 'dynamic' rules allow me to define the business rules, such as what constitutes a valid e-mail address, before I change the state of the entity - further ensuring it does not go into an invalid state. But 'invalidity' in this case is defined by the business logic and, as you pointed out, is highly volitile.</p>\n\n<p>Having come up through the CSLA ranks, I found this change difficult to adopt because it does seem to break encapsulation. But, I agrue that encapsulation is not broken if you take a step back and ask what role validation truly serves in the model.</p>\n\n<p>I've found these nuances to be very important in keeping my head clear on this subject.  There is validation to prevent bad data (eg missing arguments, null values, empty strings, etc) that belongs in the method itself and there is validation to ensure the business rules are enforced.  In the case of the former, if the Customer must have an e-mail address, then the only rule I need to be concerned about to prevent my domain object from becoming invalid is to ensure that an e-mail address has been provided to the ChangeEmail method.  The other rules are higher level concerns regarding the validity of the value itself and really have no affect on the validity of the domain entity itself.</p>\n\n<p>This has been the source of a lot of 'discussions' with fellow developers but when most take a broader view and investigate the role validation really serves, they tend to see the light.</p>\n\n<p>Finally, there is also a place for UI validation (and by UI I mean whatever serves as the interface to the application be it a screen, service endpoint or whatever). I find it perfectly reasonably to duplicate some of the logic in the UI to provide better interactivity for the user.  But it is because this validation serves that single purpose why I allow such duplication.  However, using injected validator/specification objects promotes reuse in this way without the negative implications of having these rules defined in multiple locations.</p>\n\n<p>Not sure if that helps or not...</p>\n    "},{"t":"Concrete symptoms of over-engineering","l":"http://stackoverflow.com/questions/1941770/concrete-symptoms-of-over-engineering","q":"\n\n<p>I have recently found myself in the position of explaining an (In-House) application I have written to two candidates my company likes to hire in order to assist in maintenance and adding minor features.</p>\n\n<p>It is the first \"production\" application I have written, it has 45k LOCs and I spent almost two years of \"solo\" development on it. I am fairly young (18) and wrote the application from scratch while being contracted as stand-in for a former developer who left the company. Unexperienced in designing applications of this size, I tried to use common architecture- and design-patterns. </p>\n\n<p>Today I know I have done some serious over-engineering, e.g. using a disconnected change tracking architecture instead of the Unit Of Work pattern, which the chosen ORM has  already implemented. I will probably never have to go \"real\" three tiers.</p>\n\n<p>Both candidates have 10 years+ background in In-House Application Development with the relevant platform. Being half their age and having little experience I do respect their opinion. When I was explaining the application architecture to them, comments were along the lines of:</p>\n\n<ul>\n<li>Jeez, no one would pay me to do stuff like that, I have to get things done</li>\n<li>Stick with what the framework does, don't use fancy libraries/technologies</li>\n<li>Don't wrap framework code. On a team, everyone will write his own wrapper code anyway.</li>\n<li>You're using .NET 3.5? Well, we are using 2.0.</li>\n<li>What does that LINQ stuff buy me? All this query composition and projection seems too complicated.</li>\n</ul>\n\n<p>Now I am asking myself:<br>\nAm I an <a href=\"http://www.joelonsoftware.com/articles/fog0000000018.html\">architecture astronaut</a>? How do I know I am going too far with architecture? What are common symptoms of over-engineering?</p>\n    ","a":"\n<blockquote>\n  <p>What are common symptoms of\n  over-engineering?</p>\n</blockquote>\n\n<p>Code that solves problems you don't have.</p>\n    "},{"t":"Does Test Driven Development take the focus from Design?","l":"http://stackoverflow.com/questions/80243/does-test-driven-development-take-the-focus-from-design","q":"\n\n<p>I have mixed feelings about TDD. While I believe in testing I have a issues with the idea of the test driving my development effort.</p>\n\n<p>When you code to satisfy some tests written for an interface for requirements you have right now, you might shift your focus from building maintainable code, from clean design and from sound architecture.</p>\n\n<p>I have a problem with driven not with testing. Any thoughts?</p>\n    ","a":"\n<p>No.</p>\n\n<p>If done right, Test Driven Development IS your design tool.</p>\n\n<p>I hope you forgive me for linking to <a href=\"http://dotnet.kapenilattex.com/?p=36\">my own blog entry, wherein I discuss the pitfalls of Test Driven Development that went wrong</a> simply because developers treated their tests as, merely, tests.</p>\n\n<p>In a previous project, devs used a highly damaging singleton pattern that enforced dependencies throughout the project, which just broke the whole thing when requirements were changed:</p>\n\n<blockquote>\n  <p>TDD was treated as a task, when it\n  should have been treated as an an\n  approach. [...]</p>\n  \n  <p>There was a failure to recognize\n  that TDD is not about tests, it’s\n  about design. The rampant case of\n  singleton abuse in the unit tests made\n  this obvious: instead of the test\n  writers thinking “WTF are these\n  singleton = value; statements doing in\n  my tests?”, the test writers just\n  propagated the singleton into the\n  tests. 330 times.</p>\n  \n  <p>The unfortunate consequence is that\n  the build server-enforced testing was\n  made to pass, whatever it took. </p>\n</blockquote>\n\n<p>Test Driven Development, done right, should make developers highly aware of design pitfalls like tight coupling, violations of DRY (don't repeat yourself), violations of SRP (Single Responsibility Principle), etc.</p>\n\n<p>If you write passing code for your tests for the sake of passing your tests, you have already failed: you should treat <em>hard to write</em> tests as signposts that make you ask: why is this done this way? Why can't I test this code without depending on some other code? Why can't I reuse this code? Why is this code breaking when used by itself? </p>\n\n<p>Besides if your design is <em>truly</em> clean, and your code <em>truly</em> maintainable why is it not trivial to write a test for it?</p>\n    "},{"t":"Software development process for small teams","l":"http://stackoverflow.com/questions/166212/software-development-process-for-small-teams","q":"\n\n<p>I might be an exception here but I have never worked on a team with more than three developers and / or five people. Still we could manage to get the job done (somehow).</p>\n\n<p>Is there a software development process which fits this \"extreme\" scenario? And, if you work as a standalone programmer is there something you can adapt to your daily life to make it more predicatable, coherent, documented and still get the job done?</p>\n    ","a":"\n<p>The <a href=\"http://en.wikipedia.org/wiki/Agile_software_development\">agile methodologies</a> are a good starting point because, imho, they are better suited for small groups. </p>\n\n<p>As for keeping your personal working pace I'd recommend a method based on TODO lists and some tool like <a href=\"http://www.task2gather.com/\">Task2Gather</a>. You might want to look at <a href=\"http://en.wikipedia.org/wiki/Getting_Things_Done\">GTD</a>, too.</p>\n\n<p>Things I would never give up even for a team of me: </p>\n\n<ul>\n<li>source version control</li>\n<li>backups</li>\n<li>TODO</li>\n<li>unit testing/<a href=\"http://babilsenior.blogspot.com/2008/10/test-driven-development1-eng.html\">TDD</a></li>\n<li>code documentation</li>\n<li>refactoring/code reviews</li>\n</ul>\n    "},{"t":"Haproxy in front of varnish or the other way round?","l":"http://stackoverflow.com/questions/15448196/haproxy-in-front-of-varnish-or-the-other-way-round","q":"\n\n<p>I can imagine two setups:</p>\n\n<p><strong>Load-balance then cache</strong></p>\n\n<pre><code>                          +-- Cache server #1 (varnish) -- App server #1\n                         /\nLoad Balancer (haproxy)-+---- Cache server #2 (varnish) -- App server #2\n                         \\\n                          +-- Cache server #3 (varnish) -- App server #3\n</code></pre>\n\n<p><strong>Cache then load-balance</strong></p>\n\n<pre><code>                                                       +-- App server #1\n                                                      /\nCache Server (varnish) --- Load Balancer (haproxy) --+---- App server #2\n                                                      \\\n                                                       +-- App server #3\n</code></pre>\n\n<p>The problem with the first setup is that there are multiple caches, which wastes a lot of memory and makes invalidating cache more complicated.</p>\n\n<p>The problem with the second setup is that there might be a performance hit and two single points of failure (varnish and haproxy) instead of just one (haproxy)?</p>\n\n<p>I'm tempted to go with the second setup because both haproxy and varnish are supposed to be fast and stable: what's your opinion?</p>\n    ","a":"\n<p>I built a similar setup a few years back for a busy web application (only I did it with Squid instead of Varnish), and it worked out well.</p>\n\n<p>I would recommend using your first setup (HAProxy -&gt; Varnish) with two modifications: </p>\n\n<ol>\n<li>Add a secondary HAProxy server using <code>keepalived</code> and a shared virtual IP</li>\n<li>Use the <code>balance uri</code> load balancing algorithm to optimize cache hits</li>\n</ol>\n\n<p>Pros:</p>\n\n<ul>\n<li>Peace of mind with HAProxy (x2) and Varnish (x3) redundancy</li>\n<li>Better hit rate efficiency on Varnish with HAProxy URI load balancing option</li>\n<li>Better performance from the cache servers as they don't need to keep as much in memory</li>\n<li>Invalidating cache is easier since the same URI will go to the same server every time</li>\n</ul>\n\n<p>Cons:</p>\n\n<ul>\n<li>URI balancing works well, but if a cache server goes down, your backend servers will get hit as the other cache server(s) that pick up the slack from the updated URI balancing hash will need to re-retrieve the cached data. Maybe not a big con, but I did have to keep that in mind for my system.</li>\n</ul>\n    "},{"t":"How should I structure a Java application, in other words: where do I put my classes?","l":"http://stackoverflow.com/questions/7596/how-should-i-structure-a-java-application-in-other-words-where-do-i-put-my-cla","q":"\n\n<p>First of all, I know how to build a Java application. But I have always been puzzled about where to put my classes. There are proponents for organizing the packages in a strictly domain oriented fashion, others separate by tier.</p>\n\n<p>I myself have always had problems with a) with naming, b) with placing</p>\n\n<ol>\n<li>Where do you put your domain specific constants (and what is the best name for such a class)?</li>\n<li>Where do you put classes for stuff which is both infrastructural and domain specific (for instance I have a FileStorageStrategy class, which stores the files either in the database, or alternatively in database)?</li>\n<li>Where to put Exceptions?</li>\n<li>Are there any standards to which I can refer?</li>\n</ol>\n    ","a":"\n<p>I've really come to like Maven's <a href=\"http://maven.apache.org/guides/introduction/introduction-to-the-standard-directory-layout.html\">Standard Directory Layout</a>.</p>\n\n<p>One of the key ideas for me is to have two source roots - one for production code and one for test code like so:</p>\n\n<pre><code>MyProject/src/main/java/com/acme/Widget.java\nMyProject/src/test/java/com/acme/WidgetTest.ava\n</code></pre>\n\n<p>(here, both src/main/java and src/test/java are source roots).</p>\n\n<p>Advantages:</p>\n\n<ul>\n<li>Your tests have package (or \"default\") level access to your classes under test.</li>\n<li>You can easily package only your production sources into a JAR by dropping src/test/java as a source root.</li>\n</ul>\n\n<p>One rule of thumb about class placement and packages:</p>\n\n<p>Generally speaking, well structured projects will be free of <a href=\"http://en.wikipedia.org/wiki/Circular_dependency\">circular dependencies</a>. Learn when they are bad (and when they are <a href=\"http://beust.com/weblog/archives/000208.html\">not</a>), and consider a tool like <a href=\"http://www.google.ca/search?q=JDepend&amp;ie=utf-8&amp;oe=utf-8&amp;aq=t&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a\">JDepend</a> or <a href=\"http://www.hello2morrow.com/en/sonarj/sonarj.php\">SonarJ</a> that will help you eliminate them.</p>\n    "},{"t":"Android application architecture - MVVM or MVC?","l":"http://stackoverflow.com/questions/8510683/android-application-architecture-mvvm-or-mvc","q":"\n\n<p>I got an android project I'm beginning to work on, and I want its structure to be as robust as possible.</p>\n\n<p>I'm coming from a WPF MVVM background and I've been reading a little about android applications architecture, but I just couldn't find a straight clear answer about which architecture I should use.</p>\n\n<p>Some people suggested using MVVM - <a href=\"http://vladnevzorov.com/2011/04/30/android-application-architecture-part-ii-architectural-styles-and-patterns/\">http://vladnevzorov.com/2011/04/30/android-application-architecture-part-ii-architectural-styles-and-patterns/</a></p>\n\n<p>and others suggested using MVC, but didn't specify how exactly it should be implemented.</p>\n\n<p>As I said I'm coming from a WPF-MVVM background, and therefore I know it heavily relies on bindings which as far as I understand, are not supported by default in Android.</p>\n\n<p>It seems like there is a 3rd party solution - <a href=\"http://code.google.com/p/android-binding/\">http://code.google.com/p/android-binding/</a>\nBut I don't know if I'd like to rely on that. What if its development would stop and it will not be supported by future APIs and etc..</p>\n\n<p>Basically what I'm looking for is a thorough tutorial that will teach me the best practices for building the application's structure. Folders and classes structure and etc. I just couldn't find any thorough tutorial, and I would have expected that Google would supply such a tutorial for its developers. I just don't think that this kind of documentation handles the technical aspect good enough - <a href=\"http://developer.android.com/guide/topics/fundamentals.html\">http://developer.android.com/guide/topics/fundamentals.html</a></p>\n\n<p>I hope I've been clear enough and that I'm not asking for too much, I just want to be sure about my application's structure, before my code will turn into a spaghetti monster.</p>\n\n<p>Thanks! </p>\n    ","a":"\n<p>First of all, Android doesn't force you to use any architecture. Not only that but it also makes it somewhat difficult to try to follow to any. This will require you to be a smart developer in order to avoid creating a spaghetti codebase :)</p>\n\n<p>You can try to fit in any pattern you know and you like. I find that the best approach will in some way get into your guts as you develop more and more applications (sorry about that but as always, you'll have to make lots of mistakes until you start doing it right).</p>\n\n<p>About the patterns you know, let me do something wrong: I'll mix three different patterns so you get the feeling of what does what in android. I believe the Presenter/ModelView should be somewhere in the Fragment or Activity. Adapters might sometimes do this job as they take care of inputs in lists. Probably Activities should work like Controllers too. Models should be regular java files whereas the View should lay in layout resources and some custom components you might have to implement.</p>\n\n<hr>\n\n<p>I can give you some tips. <strong>This is a community wiki answer</strong> so hopefully other people might include other suggestions.</p>\n\n<h2>File Organization</h2>\n\n<p>I think there are mainly two sensible possibilities:</p>\n\n<ul>\n<li>organize everything by <em>type</em> - create a folder for all activities, another folder for all adapters, another folder for all fragments, etc</li>\n<li>organize everything by <em>domain</em> (maybe not the best word). This would mean everything related to \"ViewPost\" would be inside the same folder - the activity, the fragment, the adapters, etc. Everything related to \"ViewPost\" would be in another folder. Same for \"EditPost\", etc. I guess activities would mandate the folders you'd create and then there would be a few more generic ones for base classes for example.</li>\n</ul>\n\n<p>Personally, I have only been involved in projects using the first approach but I really would like to try the later as I believe it could make things more organized. I see no advantage in having a folder with 30 unrelated files but that's what I get with the first approach.</p>\n\n<h2>Naming</h2>\n\n<ul>\n<li>When creating layouts and styles, always name (or identify them) using a prefix for the activity (/fragment) where they are used.</li>\n</ul>\n\n<p>So, all strings, styles, ids used in the context of \"ViewPost\" should start be \"@id/view_post_heading\" (for a textview for example), \"@style/view_post_heading_style\", \"@string/view_post_greeting\".</p>\n\n<p>This will optimize autocomplete, organization, avoid name colision, etc.</p>\n\n<h2>Base Classes</h2>\n\n<p>I think you'll want to use base classes for pretty much everything you do: Adapters, Activities, Fragments, Services, etc. These might be useful at least for debugging purposes so you know which events are happening in all your activity.</p>\n\n<h2>General</h2>\n\n<ul>\n<li>I never use anonymous classes - these are ugly and will drive your attention away when you are trying to read the code</li>\n<li>Sometimes I prefer to use inner classes (compared to create a dedicated class) - if a class is not going to be used anywhere else (and it's small) I think this is very handy.</li>\n<li>Think about your logging system from the beginning - you can use android's logging system but make a good use of it!</li>\n</ul>\n    "},{"t":"Practical example of architecture using EBC?","l":"http://stackoverflow.com/questions/8743937/practical-example-of-architecture-using-ebc","q":"\n\n<p>I was intrigued by Robert Martin's talk about <a href=\"http://confreaks.net/videos/759-rubymidwest2011-keynote-architecture-the-lost-years\">\"Architecture: The Lost Years\"</a>.  In it he discusses the Entity, Boundary, Control design pattern on which MVC is based.  I love the idea of deferring architectural decisions.  He described deferring the decision about how to implement the DB layer in his own wiki app FitNesse.  I have organically deferred decisions like this in my own coding, though there wasn't a preconceived modular design that brought this about.</p>\n\n<p>I want to better understand this EBC architecture (which seems closely related to DCI) from a practical standpoint so that I can begin using in a small project.  I want to capitalize on \"deferring decisions\" and the ability to swap out aspects of the design like the UI.</p>\n\n<p>Rails, for example, uses a form of EBC (MVC) but it's so heavily baked in that one could not easily substitute an alternate UI thus converting a Rails app to a console app or a desktop app.  The intriguing thing about design for me is this ability to transform applications by swapping one thing out and plugging another in.  That is, I wonder at the idea of designing an architecture so that one can, in a manner of speaking, swap out the UI or the persistence layer.  I feel that if the architecture is well designed, the coupling will be low, and such a feat will be within grasp.  </p>\n\n<p>I've ordered <a href=\"http://rads.stackoverflow.com/amzn/click/0201544350\">the book</a> by Ivar Jacobson that Bob mentioned in his talk.  I've search online quite a bit but all of the examples I've found show simple diagrams.  I speak code.  I would benefit more from looking over a few simple classes that demonstrate the concept and show how one might swap out one layer (UI, DB) for some other implementation through the use of boundary classes.  </p>\n\n<p>If someone can't point me to a good resource illustrating this, would this be hard to whip up?  Maybe we could use the standby example used in lots of software books: a video rental store (almost a relic these days).  Please demonstrate how the UI or DB layer could be swapped.  One thing that's confusing me is views.  I can't tell from the diagrams I've seen if the views are the boundary classes themselves or if they just communicate with them.  Also, Bob mentioned that the original intent of EBC was that we'd have lots of micro-views not a single macro-view (as we do in typical MVC); I'm curious what this might look like.  (I prefer Ruby or JavaScript but, as beggars can't be choosers, any example would be fine.)</p>\n\n<p>Thank you.</p>\n    ","a":"\n<p>As far as I understand the video by Uncle Bob using \"EBI\" (<strong>Entity</strong>, <strong>Boundary</strong>, and <strong>Interactor</strong>) you should completely decouple your business behavior/state from frameworks/OS and services. </p>\n\n<p>So in case of an Rails app your business behavior/state is completly free of dependencies to the <em>Rails</em> framework and hence can be tested like with rspec without firing Rails!</p>\n\n<p>So on the business side you have <strong>Boundary</strong> classes wich interact with the Rails side using request and response models (very simple dataholders, not to be exchanged with the usual models from <em>Rails</em>). Only the <strong>Boundary</strong> classes interact with the <strong>Interactor</strong> classes which implement the (business) use cases / scenarios. And only the <strong>Interactor</strong> classes interact with the <strong>Entity</strong> classes which encapsulate the business state.</p>\n\n<p>On the <em>Rails</em> side you find <strong>Controller</strong> classes interacting with <strong>Boundary</strong> classes (using Request models) and backwards a <strong>Boundary</strong> class interacts with a <strong>Presenter</strong> (using a Response model). Only <strong>Presenters/Controllers</strong> interact with Views (with the help of models (again simple data-holders). Note that in the realm of <em>Rails</em> <strong>Presenters</strong> are most likely <strong>Controllers</strong>.</p>\n\n<p>Where does this leave AR? Well AR just provides the persistant service. On the same level as the <strong>Presenter/Controller</strong> level you will find <strong>Service</strong> classes which provide their services to the <strong>Boundary</strong> classes. So they provide all the necessary services which are frameworks/OS/technology dependent like persistance, security, timing, notifaction, etc..</p>\n\n<p>With this architecture you are really able to reuse your business logic and completely replace the UI or database technology. For example, porting to mobile (iOS, Android, Windows) should be pretty straight forward.</p>\n\n<p>With <em>Rails</em>, your <strong>app folder</strong> could look like:</p>\n\n<pre><code>app/\n    controllers/    Only these interact with Boundary classes\n    models/         simple data-holders, no AR here! (see services)\n    views/  \n    services/       AR-stuff\n    boundaries/     To be tested without Rails\n         models/    Request &amp; Response\n    interactors/    use cases / scenarios, to be tested without Rails\n         entities/  \"the real business model without technical dependencies\"\n</code></pre>\n\n<p>With this architecture, you need to code a bit more but don't forget the benefits of a good architecture:</p>\n\n<ol>\n<li>A good architecture allows major changes to be deferred</li>\n<li>A good architecture maximizes (major) changes not made</li>\n</ol>\n\n<p>Last note: compared to the MVC pattern, its more like the M is replaced by EBI, the C can be splitted in CP/resenter), and an S(ervice) is added. So this could be called: VCPS/EBI but that sounds ugly to me ;-) BEPVICS maybe?</p>\n\n<p><strong>@Seralize</strong>, thanks for your feedback. </p>\n\n<p>Let me try to answer your questions, so far I understand them: the stuff in services are coupled to Rails. They provide the implementation for the logic in EBI side. In the usecase of security, you have to be clear what (quantified) requirements you have, so you know what logic you can implement on EBI side, for instance (business) rules about when a user(role) has access to what content(and needs to be authenticated). </p>\n\n<p>This means to implement authentication will be implemented using Rails, this service will be used by EBI. This security related logic in EBI is then pretty easy to reuse in your Java GUI example. There you have only to reimplement the authentication service. </p>\n\n<p><strong>To be clear in the security example:</strong> </p>\n\n<p>The EBI side has the logic: what stuff needs what kind of security and when and how. The Rails knows nothing about this, it request what to do from the EBI side and or the EBI side request the Rails side to act.</p>\n\n<p>The Rails side only implements the way how to do security like asking the user to authenticate (when needed) and passing the result of this to EBI so the logic can decide what should be done next.</p>\n\n<blockquote>\n  <p>EBI demands both sides to be decoupled &amp; independent. It were as you\n  are developing the EBI as a library with a defined API.</p>\n</blockquote>\n    "},{"t":"Architectural Thinking in Functional Languages","l":"http://stackoverflow.com/questions/2003487/architectural-thinking-in-functional-languages","q":"\n\n<p>My Related Questions box overfloweth with functional programming questions. Having reviewed the most relevant, I'm still curious to hear opinions on the following:</p>\n\n<p><em>How do you think about structuring an application in a functional language?</em></p>\n\n<p>I'm not talking about a language-specific grammar. I'm interested in conceptual organizational paradigms (e.g object orientation). </p>\n\n<p>Like many, my first exposure to encapsulation and code reuse came from the OO background. As I've been researching different languages, functional programming really caught my eye. I'm beginning to grasp the benefits of immutability, higher-order functions, et cetera. But I still lose my sense of how to structure a functional application without falling back on OO concepts. Actually, many of the functional examples I've seen have more in common with spaghetti code, although I'm sure that's due to the simplicity of the examples rather than any inherent flaw in the functional approach.</p>\n\n<p>This question is kin to \"when should I use functional programming,\" but I've already satisfied myself that the functional approach, despite pros and cons in certain domains, is usable for just about anything that you want. I just have trouble picturing the big-picture organization of a complex app.</p>\n    ","a":"\n<p>In the late 1970s, Barbara Liskov and others developed a boatload of large-scale \"object-oriented design\" techniques which are still widely used today and which apply unchanged to functional programming.  They are easiest to apply with a language that has explicit interfaces and implementations, which means Standard ML (where interfaces are called \"signatures\" and implementations are called \"structures\" or \"functors\") or Objective Caml (where interfaces are called \"module types\" and implementations are called \"modules\").  If you prefer Scheme then the \"unit\" language developed by Matthew Flatt and Matthias Felleisen is built into PLT Scheme and is a very good way of expressing large-scale functions.</p>\n\n<p>In brief:</p>\n\n<ul>\n<li><p>Organize your applications around abstract types (classes in OO, \"abstract types\" in FP) and the operations on those types.</p></li>\n<li><p>Use encapsulation mechanisms (classes in OO, modules in FP) to hide the representations of your abstract types.</p></li>\n<li><p>Structure your application so that each implementation depends on other implementations indirectly, through their interfaces.  This way you limit the amount of code you have to understand to build or modify any one piece of your application.</p></li>\n<li><p>Go to town!</p></li>\n</ul>\n\n<p>The main difference is that when you're writing functional programs, you don't use inheritance to reuse implementations.  Instead you use higher-order functions, or you use <a href=\"http://www.cs.tufts.edu/~nr/pubs/maniaws-abstract.html\">modules which take other modules as parameters</a>.</p>\n\n<p><strong>Summary:</strong> at the architectural level, there's not a lot of difference, but when using functional languages you may need to hunt a little harder to find the encapsulation mechanisms that you need.</p>\n    "},{"t":"Python, PyTables, Java - tying all together","l":"http://stackoverflow.com/questions/1953731/python-pytables-java-tying-all-together","q":"\n\n<h1>Question in nutshell</h1>\n\n<p>What is the best way to get Python and Java to play nice with each other?</p>\n\n<h1>More detailed explanation</h1>\n\n<p>I have a somewhat complicated situation.  I'll try my best to explain both in pictures and words.  Here's the current system architecture:</p>\n\n<p><img src=\"http://i50.tinypic.com/2s6lutk.png\" alt=\"Current system architecture\"></p>\n\n<p>We have an agent-based modeling simulation written in Java.  It has options of either writing locally to CSV files, or remotely via a connection to a Java server to an <a href=\"http://www.hdfgroup.org/HDF5/\">HDF5</a> file.  Each simulation run spits out over a gigabyte of data, and we run the simulation dozens of times.  We need to be able to aggregate over multiple runs of the same scenario (with different random seeds) in order to see some trends (e.g. min, max, median, mean).  As you can imagine, trying to move around all these CSV files is a nightmare; there are multiple files produced per run, and like I said some of them are enormous.  That's the reason we've been trying to move towards an HDF5 solution, where all the data for a study is stored in one place, rather than scattered across dozens of plain text files.  Furthermore, since it is a binary file format, it should be able to get significant space savings as compared to uncompressed CSVS.</p>\n\n<p>As the diagram shows, the current post-processing we do of the raw output data from simulation also takes place in Java, and reads in the CSV files produced by local output.  This post-processing module uses JFreeChart to create some charts and graphs related to the simulation.</p>\n\n<h2> The Problem </h2>\n\n<p>As I alluded to earlier, the CSVs are really untenable and are not scaling well as we generate more and more data from simulation.  Furthermore, the post-processing code is doing more than it should have to do, essentially performing the work of a very, very poor man's relational database (making joins across 'tables' (csv files) based on foreign keys (the unique agent IDs).  It is also difficult in this system to visualize the data in other ways (e.g. Prefuse, Processing, JMonkeyEngine getting some subset of the raw data to play with in MatLab or SPSS).</p>\n\n<h2> Solution? </h2>\n\n<p>My group decided we really need a way of filtering and querying the data we have, as well as performing cross table joins.  Given this is a write-once, read-many situation, we really don't need the overhead of a real relational database; instead we just need some way to put a nicer front end on the HDF5 files.  I found a few papers about this, such as one describing how to use <a href=\"http://www.springerlink.com/content/8fudjp9enmkcgyr8/\">XQuery as the query language on HDF5 files</a>, but the paper describes having to write a compiler to convert from XQuery/XPath into the native HDF5 calls, way beyond our needs.\nEnter <a href=\"http://www.pytables.org/moin\">PyTables</a>.  It seems to do exactly what we need (provides two different ways of querying data, either through Python list comprehension or through <a href=\"http://www.pytables.org/docs/manual/ch05.html#inkernelSearch\">in-kernel (C level) searches</a>.</p>\n\n<p>The proposed architecture I envision is this:\n<img src=\"http://i46.tinypic.com/9aseg3.png\" alt=\"Envisioned architecture\"></p>\n\n<p>What I'm not really sure how to do is to link together the python code that will be written for querying, with the Java code that serves up the HDF5 files, and the Java code that does the post processing of the data.  Obviously I will want to rewrite much of the post-processing code that is implicitly doing queries and instead let the excellent PyTables do this much more elegantly.</p>\n\n<h2> Java/Python options</h2>\n\n<p>A simple google search turns up a few options for <a href=\"http://wiki.cacr.caltech.edu/danse/index.php/Communication%5Fbetween%5FJava%5Fand%5FPython\">communicating between Java and Python</a>, but I am so new to the topic that I'm looking for some actual expertise and criticism of the proposed architecture.  It seems like the Python process should be running on same machine as the Datahose so that the large .h5 files do not have to be transferred over the network, but rather the much smaller, filtered views of it would be transmitted to the clients.  <a href=\"http://pyro.sourceforge.net/projects.html\">Pyro</a> seems to be an interesting choice - does anyone have experience with that?</p>\n    ","a":"\n<p>This is an epic question, and there are lots of considerations.  Since you didn't mention any specific performance or architectural constraints, I'll try and offer the best well-rounded suggestions.</p>\n\n<p>The initial plan of using PyTables as an intermediary layer between your other elements and the datafiles seems solid.  However, one design constraint that wasn't mentioned is one of the most critical of all data processing:  Which of these data processing tasks can be done in batch processing style and which data processing tasks are more of a live stream.</p>\n\n<p>This differentiation between \"we know exactly our input and output and can just do the processing\" (batch) and \"we know our input and what needs to be available for something else to ask\" (live) makes all the difference to an architectural question.  Looking at your diagram, there are several relationships that imply the different processing styles.</p>\n\n<p>Additionally, on your diagram you have components of different types all using the same symbols.  It makes it a little bit difficult to analyze the expected performance and efficiency.</p>\n\n<p>Another contraint that's significant is your IT infrastructure.  Do you have high speed network available storage?  If you do, intermediary files become a brilliant, simple, and fast way of sharing data between the elements of your infrastructure for all batch processing needs.  You mentioned running your PyTables-using-application on the same server that's running the Java simulation.  However, that means that server will experience load for both writing and reading the data.  (That is to say, the simulation environment could be affected by the needs of unrelated software when they query the data.)</p>\n\n<p>To answer your questions directly:</p>\n\n<ul>\n<li>PyTables looks like a nice match.</li>\n<li>There are many ways for Python and Java to communicate, but consider a language agnostic communication method so these components can be changed later if necessarily.  This is just as simple as finding libraries that support both Java and Python and trying them.  The API you choose to implement with whatever library should be the same anyway. (XML-RPC would be fine for prototyping, as it's in the standard library, Google's Protocol Buffers or Facebook's Thrift make good production choices.  But don't underestimate how great and simple just \"writing things to intermediary files\" can be if data is predictable and batchable.</li>\n</ul>\n\n<p>To help with the design process more and flesh out your needs:</p>\n\n<p>It's easy to look at a small piece of the puzzle, make some reasonable assumptions, and jump into solution evaluation.  But it's even better to look at the problem holistically with a clear understanding of your constraints.  May I suggest this process:</p>\n\n<ul>\n<li>Create two diagrams of your current architecture, physical and logical.\n<ul>\n<li>On the physical diagram, create boxes for each physical server and diagram the physical connections between each.\n<ul>\n<li>Be certain to label the resources available to each server and the type and resources available to each connection.</li>\n<li>Include physical hardware that isn't involved in your current setup if it might be useful.  (If you have a SAN available, but aren't using it, include it in case the solution might want to.)</li>\n</ul></li>\n<li>On the logical diagram, create boxes for every <em>application</em> that is running in your current architecture.\n<ul>\n<li>Include relevant libraries as boxes <em>inside</em> the application boxes.  (This is important, because your future solution diagram currently has PyTables as a box, but it's just a library and can't do anything on it's own.)</li>\n<li>Draw on disk resources (like the HDF5 and CSV files) as cylinders.</li>\n<li>Connect the applications with arrows to other applications and resources as necessary.  Always draw the arrow <em>from</em> the \"actor\" <em>to</em> the \"target\".  So if an app writes and HDF5 file, they arrow goes from the app to the file.  If an app reads a CSV file, the arrow goes from the app to the file.</li>\n<li>Every arrow must be labeled with the communication mechanism.  Unlabeled arrows show a relationship, but they don't show <em>what</em> relationship and so they won't help you make decisions or communicate constraints.</li>\n</ul></li>\n</ul></li>\n</ul>\n\n<p>Once you've got these diagrams done, make a few copies of them, and then right on top of them start to do data-flow doodles.  With a copy of the diagram for each \"end point\" application that needs your original data, start at the simulation and end at the end point with a pretty much solid flowing arrow.  Any time your data arrow flows across a communication/protocol arrow, make notes of how the data changes (if any).</p>\n\n<p>At this point, if you and your team all agree on what's on paper, then you've explained your current architecture in a manner that should be easily communicable to anyone.  (Not just helpers here on stackoverflow, but also to bosses and project managers and other purse holders.)</p>\n\n<p>To start planning your solution, look at your dataflow diagrams and work your way backwards from endpoint to startpoint and create a nested list that contains every app and intermediary format on the way back to the start.  Then, list requirements for every application.  Be sure to feature:</p>\n\n<ul>\n<li>What data formats or methods can this application use to communicate.</li>\n<li>What data does it actually want. (Is this always the same or does it change on a whim depending on other requirements?)</li>\n<li>How often does it need it.</li>\n<li>Approximately how much resources does the application need.</li>\n<li>What does the application do now that it doesn't do that well.</li>\n<li>What can this application do now that would help, but it isn't doing.</li>\n</ul>\n\n<p>If you do a good job with this list, you can see how this will help define what protocols and solutions you choose.  You look at the situations where the data crosses a communication line, and you compare the requirements list for <em>both sides</em> of the communication.</p>\n\n<p>You've already described one particular situation where you have quite a bit of java post-processing code that is doing \"joins\" on tables of data in CSV files, thats a \"do now but doesn't do that well\".  So you look at the other side of that communication to see if the other side can do that thing well.  At this point, the other side is the CSV file and before that, the simulation, so no, there's nothing that can do that better in the current architecture.</p>\n\n<p>So you've proposed a new Python application that uses the PyTables library to make that process better.  Sounds good so far!  But in your next diagram, you added a bunch of other things that talk to \"PyTables\".  Now we've extended past the understanding of the group here at StackOverflow, because we don't know the requirements of those other applications.  But if you make the requirements list like mentioned above, you'll know exactly what to consider.  Maybe your Python application using PyTables to provide querying on the HDF5 files can support all of these applications.  Maybe it will only support one or two of them.  Maybe it will provide live querying to the post-processor, but periodically write intermediary files for the other applications.  We can't tell, but with planning, you can.</p>\n\n<p>Some final guidelines:</p>\n\n<ul>\n<li><strong>Keep things simple!</strong> The enemy here is complexity.  The more complex your solution, the more difficult the solution to implement and the more likely it is to fail.  Use the least number operations, use the least complex operations.  Sometimes just one application to handle the queries for all the other parts of your architecture is the simplest.  Sometimes an application to handle \"live\" queries and a separate application to handle \"batch requests\" is better.</li>\n<li><strong>Keep things simple!</strong>  It's a big deal!  Don't write anything that can already be done for you.  (This is why intermediary files can be so great, the OS handles all the difficult parts.)  Also, you mention that a relational database is too much overhead, but consider that a relational database also comes with a very expressive and well-known query language, the network communication protocol that goes with it, <em>and</em> you don't have to develop anything to use it!  Whatever solution you come up with has to be <em>better</em> than using the off-the-shelf solution that's going to work, for certain, very well, or it's not the best solution.</li>\n<li><strong>Refer to your physical layer documentation frequently</strong> so you understand the resource use of your considerations.  A slow network link or putting too much on one server can both rule out otherwise good solutions.</li>\n<li><strong>Save those docs.</strong> Whatever you decide, the documentation you generated in the process is valuable.  Wiki-them or file them away so you can whip them out again when the topic come s up.</li>\n</ul>\n\n<p>And the answer to the direct question, \"How to get Python and Java to play nice together?\" is simply \"use a language agnostic communication method.\"  The truth of the matter is that Python and Java are both not important to your describe problem-set.  What's important is the data that's flowing through it.  Anything that can easily and effectively share data is going to be just fine.</p>\n    "},{"t":"Building an archive for XCode 4.6 release with phonegap v 2.9 fails","l":"http://stackoverflow.com/questions/17351446/building-an-archive-for-xcode-4-6-release-with-phonegap-v-2-9-fails","q":"\n\n<p>This appears to be a recurring phenomena.</p>\n\n<p>I saw a number of prior questions, where the solution was to delete armv6,\nand then the archive would work.  Of course, armv6 is gone.</p>\n\n<p>So, now, building with both current, <strong>Xcode 4.6.3 phonegap 2.9.</strong>\nAnd yes, the app works fine on iphones, ipads, and in the simulator.</p>\n\n<p>I get this message at the end of the create archive step:</p>\n\n<pre><code>    /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin/clang -arch armv7s -isysroot /Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS6.1.sdk -L/Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/BuildProductsPath/Release-iphoneos -F/Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/BuildProductsPath/Release-iphoneos -filelist /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/IntermediateBuildFilesPath/peeq.build/Release-iphoneos/peeq.build/Objects-normal/armv7s/peeq.LinkFileList -dead_strip -weak_framework CoreFoundation -weak_framework UIKit -weak_framework AVFoundation -weak_framework CoreMedia -weak-lSystem -force_load /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/InstallationBuildProductsLocation/Applications/libCordova.a -ObjC -fobjc-link-runtime -miphoneos-version-min=5.0 -framework CoreLocation -framework ImageIO -framework OpenAL -framework AssetsLibrary /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/BuildProductsPath/Release-iphoneos/libCordova.a -framework Foundation -weak_framework UIKit -framework CoreGraphics -framework AddressBook -framework AddressBookUI -framework AudioToolbox -weak_framework AVFoundation -framework CFNetwork -framework MediaPlayer -framework QuartzCore -framework SystemConfiguration -framework MobileCoreServices -weak_framework CoreMedia -framework CoreLocation -o /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/IntermediateBuildFilesPath/peeq.build/Release-iphoneos/peeq.build/Objects-normal/armv7s/peeq\n\nld: file not found: /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/InstallationBuildProductsLocation/Applications/libCordova.a\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n</code></pre>\n\n<p>And went over and looked around the file system there:</p>\n\n<pre><code>cd /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build\n./Intermediates/ArchiveIntermediates/peeq/BuildProductsPath/Release-iphoneos/libCordova.a\n./Intermediates/ArchiveIntermediates/peeq/IntermediateBuildFilesPath/CordovaLib.build/Release-iphoneos/CordovaLib.build/Objects-normal/armv7/libCordova.a\n./Intermediates/ArchiveIntermediates/peeq/IntermediateBuildFilesPath/CordovaLib.build/Release-iphoneos/CordovaLib.build/Objects-normal/armv7s/libCordova.a\n./Intermediates/ArchiveIntermediates/peeq/IntermediateBuildFilesPath/UninstalledProducts/libCordova.a\n</code></pre>\n\n<p>And its been built, just not put where the linker wanted to find it.</p>\n\n<p>So, no doubt some build setting either tells the linker to look there, or\ntells the build to put it where the linker wants to find it.</p>\n\n<p>Unless its something else.  </p>\n\n<p>My question is how to get the app archive to build\ncorrectly, so it can go off to the store.</p>\n\n<p>Thanks,\njohn</p>\n\n<hr>\n\n<p>A fine person who works at Apple told me where to look, at which point, this was solved.</p>\n\n<p>Deep within the Build Settings, there is a field to be set, called Other Linker Flags</p>\n\n<p>It starts out showing no value, but if you click on it, it pops up with Debug and Release.</p>\n\n<p>In the very long string that is Release, one finds a -force_load libCordova.a<br>\nand deletes that part of the string.</p>\n\n<p>From:</p>\n\n<pre><code>-weak_framework CoreFoundation -weak_framework UIKit -weak_framework AVFoundation -weak_framework CoreMedia -weak-lSystem -force_load ${TARGET_BUILD_DIR}/libCordova.a -ObjC\n</code></pre>\n\n<p>To:</p>\n\n<pre><code>-weak_framework CoreFoundation -weak_framework UIKit -weak_framework AVFoundation -weak_framework CoreMedia -weak-lSystem  -ObjC\n</code></pre>\n\n<p>Its probably a bug in some fashion that phonegap defaults this in place, I shall\nalso contact them and see if it can default repair it.</p>\n\n<p>His note that pointed me at it:</p>\n\n<p>I notice that your link command contains both this:</p>\n\n<pre><code>-force_load /Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/InstallationBuildProductsLocation/Applications/libCordova.a\n</code></pre>\n\n<p>and this:</p>\n\n<pre><code>/Users/peeq/Library/Developer/Xcode/DerivedData/peeq-gylybvwifdxjmtajtbvdsdpjcvkl/Build/Intermediates/ArchiveIntermediates/peeq/BuildProductsPath/Release-iphoneos/libCordova.a\n</code></pre>\n\n<p>The path being passed to -force_load is the bogus path that the linker is complaining about. I think that you need to remove the “-force_load” linker flag. Do you have such a flag set in the “Other Linker Flags” setting?</p>\n    ","a":"\n<p>Found a fix.</p>\n\n<ol>\n<li>In your Target's Build Settings, find <code>Other Linker Flags</code></li>\n<li>Change <code>$(TARGET_BUILD_DIR)/libCordova.a</code></li>\n<li>To <code>$(BUILT_PRODUCTS_DIR)/libCordova.a</code></li>\n</ol>\n    "},{"t":"Avoiding Circular Dependencies of header files [duplicate]","l":"http://stackoverflow.com/questions/4816698/avoiding-circular-dependencies-of-header-files","q":"\n\n<div class=\"question-status question-originals-of-duplicate\">\n    <p>This question already has an answer here:</p>\n    <ul>\n        <li>\n            <a href=\"/questions/625799/resolve-circular-dependencies-in-c\" dir=\"ltr\">Resolve circular dependencies in c++</a>\n                <span class=\"question-originals-answer-count\">\n                    7 answers\n                </span>\n        </li>\n    </ul>\n</div>\n<p>Do you have any good advice on how to avoid <strong>circular dependencies of header files</strong>, please?</p>\n\n<p>Of course, from the beginning, I try to design the project as transparent as possible. However, as more and more features and classes are added, and the project gets less transparent, circular dependencies start happening.</p>\n\n<p><strong>Are there any general, verified, and working rules?</strong> Thanks.</p>\n    ","a":"\n<p>If you have circular dependency then you doing something wrong.</p>\n\n<p>As for example:</p>\n\n<pre><code>foo.h\n-----\nclass foo {\npublic:\n   bar b;\n};\n\nbar.h\n-----\nclass bar {\npublic:\n   foo f;\n};\n</code></pre>\n\n<p>Is illegal you probably want:</p>\n\n<pre><code>foo.h\n-----\nclass bar; // forward declaration\nclass foo {\n   ...\n   bar *b;\n   ...\n};\n\nbar.h\n-----\nclass foo; // forward declaration\nclass bar {\n   ...\n   foo *f;\n   ...\n};\n</code></pre>\n\n<p>And this is ok.</p>\n\n<p>General rules:</p>\n\n<ol>\n<li>Make sure each header can be included on its own.</li>\n<li>If you can use forward declarations use them! </li>\n</ol>\n    "},{"t":"Ember.JS - How to use multiple models, controllers and views in same page?","l":"http://stackoverflow.com/questions/15081058/ember-js-how-to-use-multiple-models-controllers-and-views-in-same-page","q":"\n\n<p>I mostly understand the basics of Ember.JS. Most examples out there really just deal with a single controller and a model to show something on a page. I am really after building a full web app with Ember so can anyone tell me how do I organize and connect multiple controllers, models and views into a single page?</p>\n\n<p>For example, if I navigate to /app/posts, I want to show a navigation-bar with bunch of things including some logged in information, a sidebar to search with a controller attached to it, a bunch of posts listed in the middle and maybe a twitter feed populated on the sidebar with a TwitterFeedController.</p>\n\n<p>How do I connect a bunch of these together. What is the basic way to achieve \"Sections\" with their own controllers and models and views in Ember.JS?</p>\n\n<p>I understand there's named \"outlets\". Current documentation doesn't seem to mention it past having a main {{ outllet }} in application template. I can't find the definition on their public API docs too (might be blind...).</p>\n\n<p>Thanks in advance!</p>\n    ","a":"\n<p>Hope this answers <a href=\"http://jsfiddle.net/schawaska/dWcUp/\">Example1</a> and this one too <a href=\"http://jsfiddle.net/rlivsey/QWR6V/\">Example2</a></p>\n\n<pre><code>&lt;script type=\"text/x-handlebars\" data-template-name=\"application\"&gt;\n    {{partial 'navbar'}}\n    {{outlet}}   \n    {{partial 'footer'}}\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"_navbar\"&gt;\n    &lt;div class=\"navbar navbar-inverse\"&gt;\n        &lt;div class=\"navbar-inner\"&gt;\n            {{#linkTo \"app\" class=\"brand\"}}{{unbound App.app_title}}{{/linkTo}}\n            &lt;ul class=\"nav\"&gt;\n                &lt;li class=\"divider-vertical\"&gt;\n                    {{#linkTo \"app\"}}Home{{/linkTo}}\n                &lt;/li&gt;\n                &lt;li class=\"divider-vertical\"&gt;\n                    {{#linkTo \"products\"}}Products{{/linkTo}}\n                &lt;/li&gt;\n            &lt;/ul&gt;\n        &lt;/div&gt;\n    &lt;/div&gt;\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"_footer\"&gt;\n    &lt;div class=\"row\"&gt;\n        &lt;div class=\"span12\"&gt;\n            &amp;copy; 2013:1.0-pre4 - {{unbound App.contact}} \n        &lt;/div&gt;\n    &lt;/div&gt;    \n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"app\"&gt;\n    &lt;h2&gt;Home&lt;/h2&gt;\n    &lt;p&gt;Bacon ipsum dolor sit amet tenderloin short ribs short loin meatball sausage chicken pastrami. Hamburger sausage tri-tip, bacon spare ribs bresaola short ribs chuck frankfurter shoulder. Fatback pork belly turducken, ham drumstick salami hamburger pork sausage. Jowl corned beef andouille shank boudin. Shankle salami corned beef, pastrami leberkas turducken venison shoulder fatback jowl ball tip ground round biltong andouille boudin.&lt;/p&gt;\n    &lt;p&gt;Biltong boudin turkey rump shankle ball tip, strip steak drumstick spare ribs. Cow short ribs leberkas swine sirloin shank drumstick rump hamburger frankfurter ham hock. Bresaola turkey bacon prosciutto salami jowl pancetta meatloaf ground round ball tip filet mignon kielbasa tongue chuck strip steak. T-bone leberkas beef ribs kielbasa shankle pork chop spare ribs chuck strip steak shoulder frankfurter turducken. Pork loin ham cow chicken boudin venison. Filet mignon cow jowl pig ball tip, meatball boudin leberkas ham short loin drumstick tenderloin venison chicken. Chuck beef filet mignon capicola shankle, fatback flank ham hock corned beef meatloaf short ribs bacon.&lt;/p&gt;\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"categories\"&gt;\n    &lt;h2&gt;Categories&lt;/h2&gt;\n    &lt;p&gt;Listing available products and services&lt;/p&gt;\n    &lt;ul class=\"thumbnails\"&gt;\n    {{#each category in controller}}\n        &lt;li class=\"span3\"&gt;\n            &lt;div class=\"thumbnail\"&gt;\n                &lt;h4&gt;{{category.name}}&lt;/h4&gt;\n                &lt;img {{bindAttr src=\"category.imageUrl\" alt=\"category.name\"}} /&gt;\n                {{#linkTo \"products.category\" category class=\"btn\"}}\n                    Details\n                {{/linkTo}}\n            &lt;/div&gt;\n        &lt;/li&gt;\n    {{else}}\n        &lt;li&gt;Loading...&lt;/li&gt;\n    {{/each}}\n    &lt;/ul&gt;\n    &lt;hr /&gt;\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"products\"&gt;\n    {{render categories}}\n    {{outlet}}\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"products/index\"&gt;\n    &lt;h2&gt;Products&lt;/h2&gt;\n    &lt;ul class=\"thumbnails\"&gt;\n    {{#each product in controller}}\n        &lt;li class=\"span3\"&gt;\n            &lt;div class=\"thumbnail\"&gt;\n                &lt;h4&gt;{{product.name}}&lt;/h4&gt;\n                &lt;img {{bindAttr src=\"product.imageUrl\" alt=\"product.name\"}} /&gt;\n                {{#linkTo \"products.product\" product class=\"btn\"}}\n                    Details\n                {{/linkTo}}\n            &lt;/div&gt;\n        &lt;/li&gt;\n    {{else}}\n        &lt;li&gt;Loading...&lt;/li&gt;\n    {{/each}}\n    &lt;/ul&gt;\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"products/product\"&gt;\n    &lt;h4&gt;&lt;em style=\"color: gray\"&gt;Products&lt;/em&gt;/&lt;em style=\"color: gray\"&gt;Category: {{category.name}}&lt;/em&gt;/{{name}}&lt;/h4&gt;&lt;br /&gt;\n    &lt;img {{bindAttr src=\"imageUrl\" alt=\"name\"}}/&gt;\n    $ {{price}} hahahahaha\n&lt;/script&gt;\n\n&lt;script type=\"text/x-handlebars\" data-template-name=\"products/category\"&gt;\n    &lt;h2&gt;{{name}}&lt;/h2&gt;\n&lt;/script&gt;\n\n&lt;script type=\"text/javascript\" src=\"http://code.jquery.com/jquery-1.8.2.min.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"https://raw.github.com/wycats/handlebars.js/1.0.rc.2/dist/handlebars.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"https://raw.github.com/emberjs/ember.js/release-builds/ember-1.0.0-pre.4.js\"&gt;&lt;/script&gt;\n&lt;script type=\"text/javascript\" src=\"https://raw.github.com/MilkyWayJoe/ember.js/master/ember.min.js\"&gt;&lt;/script&gt;\n\n\nvar BaseApp = Em.Application.extend({\n    app_title: 'Auto Web Shop',\n    contact: function() {\n        if(this.get('link') !== '') {\n            var html = '&lt;a href=\"%@\" target=\"_blank\"&gt;%@&lt;/a&gt;'\n                       .fmt(this.get('link'), this.get('author'));\n            return new Handlebars.SafeString(html);\n        } else {\n            return this.get('author');\n        }\n    }.property('author', 'link') \n});\n\n// Extensions - End\n\nwindow.App = BaseApp.create({\n    author: 'Your Name Here',\n    link: 'https://twitter.com/torontoemberjs'\n});\n\n// Controllers - Begin\n\nApp.ShopController = Em.ArrayController.extend();\nApp.ProductsController = Em.ArrayController.extend();\nApp.ProductsIndexController = Em.ArrayController.extend();\nApp.CategoriesController = Em.ArrayController.extend();\n\n// Controllers - End\n\n// Routes - Begin\n\nApp.Router.map(function() {\n    this.resource('app');\n    this.resource('products', function() {\n        this.route('product', {path: 'product/:product_id'});\n        this.route('category', {path: 'category/:category_id'})\n    });\n});\n\nApp.ApplicationRoute = Em.Route.extend({\n  setupController: function() {\n      this.controllerFor('categories').set('model', App.Category.find());\n  }\n});\n\nApp.ProductsIndexRoute = Em.Route.extend({\n    model: function() {\n        return App.Product.find();\n    }\n});\n\nApp.IndexRoute = Em.Route.extend({\n    redirect: function() {\n        this.transitionTo('app');   \n    }\n});\n\n// Routes - End\n\n// Models - Begin\n\n// Defining a Data Store for the application from DS namespace\nApp.Store = DS.Store.extend({\n    // Until Ember reaches 1.0, Ember-Data will use a revisions to \n    // alert developers about breaking changes to the API. At the time I'm \n    // writing this, Ember-Data is on revision 11. To find out more, go to:\n    // https://github.com/emberjs/data/blob/master/BREAKING_CHANGES.md\n    revision: 11,\n    // Define your adapter. The Adapter is responsible to 'translate' the data from\n    // your backend API into what Ember-Data needs in order for it to work. Ember-Data\n    // comes with a REST Adapter and a Fixture Adapter, the later is very useful for \n    // debugging and for mocking up an application. This example uses the Fixture Adapter\n    adapter: 'DS.FixtureAdapter'\n});\n\nApp.Category = DS.Model.extend({\n    name: DS.attr('string'),    \n    imageUrl: DS.attr('string'),\n    products: DS.hasMany('App.Product')\n});\n\nApp.Product = DS.Model.extend({\n    name: DS.attr('string'),\n    imageUrl: DS.attr('string'),\n    price: DS.attr('number'),\n    category: DS.belongsTo('App.Category')\n});\n\n// Loading sample data\n// Note that all fixtures have an `id` property. That's because Ember-Data needs your \n// models to have an Id, but you don't define it on your model classes.\nApp.Category.FIXTURES = [\n    {\n        id: 1, \n        name: 'Air Conditioners', \n        imageUrl: 'http://img9.imageshack.us/img9/1207/howtoreplaceyourcarairc.jpg', \n        products: []\n    },\n    {    \n        id: 2,\n        name: 'Tires', \n        imageUrl: 'http://img526.imageshack.us/img526/5290/r8wheel1ljpg0f089f10250.jpg', \n        products: []\n    },\n    {\n        id: 3, \n        name: 'Brakes', \n        imageUrl: 'http://img651.imageshack.us/img651/5600/brakes.gif', \n        products: []\n    },\n    {\n        id: 4,\n        name: 'Exhausts', \n        imageUrl: 'http://img217.imageshack.us/img217/7366/carbon20fibre20exhaust2.jpg', \n        products: []\n    },\n    {\n        id: 5, \n        name: 'Batteries', \n        imageUrl: 'http://img842.imageshack.us/img842/268/t2ec16nhjhqe9nzej50bqu7.jpg', \n        products: []\n    },\n    {\n        id: 6,\n        name: 'Wipers', \n        imageUrl: 'http://img145.imageshack.us/img145/3750/1208764x64.jpg', \n        products: []\n    },\n    {\n        id: 7, \n        name: 'GPS', \n        imageUrl: 'http://img687.imageshack.us/img687/8899/kgrhqroifcpor3cm0bq1ufc.jpg',\n        products: [701,702,703]\n    }, \n    {\n        id: 8,\n        name: 'Windshields',\n        imageUrl: 'http://img405.imageshack.us/img405/6826/windshield3thumb.jpg',\n        products: []\n    }\n];\n\nApp.Product.FIXTURES = [\n    {\n        id: 201,\n        name: 'Pirelli P4 Four Seasons',\n        category: 2,\n        price: 9999,\n        imageUrl: 'http://img4.imageshack.us/img4/4372/pirellip4fourseasonslg.jpg'\n    },\n    {\n        id: 701, \n        name: 'Tomtom Start 4.3\" GPS (45TM)', \n        category: 7, \n        price: 12999, \n        imageUrl: 'http://img856.imageshack.us/img856/7471/seeq2501.jpg'\n    },\n    {\n        id: 702, \n        name: 'Garmin nüvi 4.3\" GPS (40)', \n        category: 7,\n        price: 11999, \n        imageUrl: 'http://img27.imageshack.us/img27/5116/88121963.jpg'\n    },\n    {\n        id: 703, \n        name: 'Magellan RoadMate 2230T 4.3\" GPS ', \n        category: 7, \n        price: 14399, \n        imageUrl: 'http://img820.imageshack.us/img820/7981/36361380.png'\n    }\n];\n\n// Models - End\n\n\n\n// Views - Begin\n\n// Views - End\n</code></pre>\n    "},{"t":"What are the best use cases for using Scala for new development?","l":"http://stackoverflow.com/questions/4622247/what-are-the-best-use-cases-for-using-scala-for-new-development","q":"\n\n<p>Why should I choose Scala over another language for a new project?  In what areas does it excel in?</p>\n\n<p><strong>Note</strong></p>\n\n<p>There were a few nice answers given, sadly I could only mark one as the accepted answer.  However, overall it looks like Scala's appeal comes from two primary things:</p>\n\n<ol>\n<li>Excellent support for concurrency</li>\n<li>Attracting top engineering talent</li>\n</ol>\n    ","a":"\n<p>First read this: <a href=\"http://www.gotw.ca/publications/concurrency-ddj.htm\">The free lunch is Over</a></p>\n\n<p>Concurrency is becoming ever-more important.  Already we have 1000 core processors being demonstrated, and what computer nowadays doesn't already come with a GPU capable of highly-parallel operations?</p>\n\n<p>In order to take advantage of future machines, your software has to be able to make use of all this concurrency, and Java's current threading primitives just aren't going to help here.  Let's face it, concurrent programming under current mainstream paradigms is crazy-hard.</p>\n\n<p>Scala is a functional language.  As such it fully embraces concepts such as immutability, for-comprehensions, closures, etc.  It also has 4 native actor libraries available (at last count).  All of this is perfectly suited to the next generation of concurrent programming.  You can't bury your head in the sand and pretend that none of this exists - <em>that would be like writing a program in 1995 that only stores 2-digit years</em> - imperative loops simply aren't going to cut it any more!</p>\n\n<p>Scala 2.9, due to be released early 2011, will support parallel operations such as:</p>\n\n<pre><code>List(1,2,3,4).par map { 2 * _ }  //one thread for each input value in the list!\n</code></pre>\n\n<p>On top of all that, Scala can do everything that Java does, typically with a much clean syntax.  It's also far more object-oriented than Java (with its primitives and static methods), a fact which is often overlooked in the false belief that object orientation and functional programming are mutually exclusive.</p>\n\n<p>In what area does Scala excel?  I guess that area would have to be \"the future\"...</p>\n    "},{"t":"CMake Multiarchitecture Compilation","l":"http://stackoverflow.com/questions/5334095/cmake-multiarchitecture-compilation","q":"\n\n<p>I'm trying to learn CMake, but the lack of decent tutorials is making it difficult (although it's possible I'm not looking hard enough). I want to know how I could write a CMake setup which allows compilation for both x86 and x64 architectures using any compiler and OS, but I cannot seem to find information on it in any tutorials.</p>\n    ","a":"\n<p>It would be great if CMake had an 32/64bit option out of the box. It does not, so you will need to apply one of different compiler or generator dependend methods. E.g.:</p>\n\n<ul>\n<li><p>GCC (on Linux) and some other compilers, e.g. Sun Studio. Set <code>CFLAGS</code> and <code>CXXFLAGS</code> to include <code>-m32</code> (32-bit build) or <code>-m64</code> (64-bit build).</p></li>\n<li><p>Windows, Visual Studio generator. Use 64 bit generator, e.g. </p>\n\n<p><code>cmake -G \"Visual Studio 10 Win64\" path\\to\\source\\dir</code> </p>\n\n<p>to compile 64-bit (x64). Omit \"Win64\" in generator name, to build for 32 bit</p></li>\n<li><p>Mac OS X. Use <code>CMAKE_OSX_ARCHITECTURES</code> CMake variable. </p>\n\n<p><code>cmake -DCMAKE_OSX_ARCHITECTURES=i386 /path/to/source/dir</code>\nwill compile 32 bit build</p>\n\n<p><code>cmake -DCMAKE_OSX_ARCHITECTURES=x86_64 /path/to/source/dir</code>\nwill compile 64 bit.</p>\n\n<p><code>cmake \"-DCMAKE_OSX_ARCHITECTURES=x86_64;i386\" /path/to/source/dir</code> will create 96-bit universal binaries :)</p></li>\n</ul>\n\n<p>The above is slightly reworded.</p>\n\n<p><a href=\"http://dev.mysql.com/doc/internals/en/compiling-for-different-hardware-achitectures.html\" rel=\"nofollow\">http://dev.mysql.com/doc/internals/en/compiling-for-different-hardware-achitectures.html</a></p>\n    "},{"t":"From AngularJS to Flux - The React Way","l":"http://stackoverflow.com/questions/27264487/from-angularjs-to-flux-the-react-way","q":"\n\n<p>As a developer with good hands-on AngularJS experience, how do I adjust my mental model of writing web apps in Flux using React?</p>\n\n<p>I'm not looking for a Flux+React vs Angular answer (already plenty of that online), but I <em>would</em> like to know what are the <em>biggest</em> differences in the two \"mindsets\": beforehand, I was introduced into <em>The Angular Way</em>; comparatively, what is <em>The React Way</em> ?</p>\n\n<p>As I leave the Angular universe and transition to Flux, what are the <strong>key things</strong> I need to <strong>start paying attention to</strong>?</p>\n\n<p>Differences first, and now similarities: AngularJS is very opinionated and had some very big no-no's, like - don't put UI/DOM code in controllers. What are the big no-no's and opinions of React?</p>\n\n<p>Last but not least, Facebook refers to Flux as an <em>alternative to MVC</em>, but as I am looking at it - React is the view engine, stores are model containers focused on a single domain, and the dispatcher and actions form a controller. So isn't this actually MVC with a different name?</p>\n    ","a":"\n<p>I'll let others do the compare/contrast with Angular, but here are some answers to two of your questions.</p>\n\n<blockquote>\n  <p>So isn't this actually MVC with a different name?</p>\n</blockquote>\n\n<p>The presence in Flux of a separation of concerns between the data/logic layer and the view layer does not make it MVC.  Many other patterns have a similar split, most notably CQRS, arguably Flux's closest cousin.  There is no controller in Flux, in the MVC sense.  The Actions and Dispatcher do not amount to a controller.  The Controller-views are close, but are actually quite limited in their controller-like aspect.  A key difference is that MVC controllers contain application logic and act <em>upon</em> models.  Flux stores, by contrast, contain all the application logic and have no setters.</p>\n\n<blockquote>\n  <p>As I leave the Angular universe and transition to Flux, what are the key things I need to start paying attention to?</p>\n</blockquote>\n\n<p>Key values of Flux:</p>\n\n<ul>\n<li>Simplicity over complexity.</li>\n<li>The mental model of the programmer is at least as important as the code itself.</li>\n<li>Parts of the application should be highly decoupled and \"know\" as little about the other parts as possible.</li>\n<li>Inversion of control: all control should reside in the stores, where state is managed.  Stores are not acted upon, but rather informed by actions.</li>\n<li>Applications should stay resilient and flexible as they grow, allowing for new, unexpected features to be developed more quickly and easily.</li>\n</ul>\n\n<p>Key concepts in Flux:</p>\n\n<ul>\n<li>Unidirectional data flow: Action → Dispatcher → Stores → Views\n<ul>\n<li><em>Every</em> change in state and <em>all</em> new data begins with a dispatched Action.</li>\n<li>This four-step data flow is the core mental model for the Flux programmer.</li>\n</ul></li>\n<li>A dispatch causes an application-wide transformation of application state.\n<ul>\n<li>This is a moment in time, creating a snapshot of change.  This is easy to reason about.</li>\n<li>We cannot dispatch while dispatching and preserve this simplicity.  Thus, any corollary change must be driven by the original action.</li>\n</ul></li>\n<li>Flux stores are domain models, not ORM models.  They contain all logic and manage all state for a particular logical domain within the application.  They may contain collections, singular values or a combination of both.</li>\n<li>Flux assumes that <em>derived data</em> -- where one store depends on changes in another store -- is an eventuality in complex applications where models or stores manage normalized data.  To deal with this, a Flux Dispatcher should expose a mechanism to declaratively manage this dependency <em>within the store</em>.  In Facebook's Dispatcher, this is done with the <code>waitFor()</code> method.  This allows one store to wait for another store's response to an action before moving forward with its own response.</li>\n</ul>\n\n<p>Primary parts of a Flux application:</p>\n\n<ul>\n<li><strong>Actions</strong>: an object literal containing new data and a specific type,\nallowing Stores to discern whether it is relevant to their domain.</li>\n<li><strong>Dispatcher</strong>: a registry of callbacks that, by way of the callbacks,\ndistributes a payload (an Action) to the registrants (the Stores).  It has no intelligence of its own.  All intelligence is in the Stores.</li>\n<li><strong>Stores</strong>: a domain model which registers itself with the Dispatcher and emits a 'change' event whenever a change in its state occurs.</li>\n<li><strong>Controller-views</strong>: view components near the root of the component tree. They listen for 'change' events in stores and respond to this event by retrieving new data through the store's exposed getter methods and passing it to their children.  The only difference between Controller-views and Views is this listening functionality. </li>\n<li><strong>Views</strong>: stateless children of the controller-view components, receiving and passing along data, much like pure functions.  Views and Controller-views are most often implemented with React, as it provides the ability to re-render at will with very little performance loss.</li>\n<li><strong>Utils</strong>: libraries of pure functions that can be easily shared across different modules.</li>\n</ul>\n\n<p>Overview, in depth: <a href=\"http://facebook.github.io/flux/docs/overview.html\">http://facebook.github.io/flux/docs/overview.html</a></p>\n\n<p>Tutorial: <a href=\"http://facebook.github.io/flux/docs/todo-list.html\">http://facebook.github.io/flux/docs/todo-list.html</a></p>\n\n<p>Examples: <a href=\"https://github.com/facebook/flux/tree/master/examples\">https://github.com/facebook/flux/tree/master/examples</a></p>\n\n<p>Actions and the Dispatcher: <a href=\"http://facebook.github.io/react/blog/2014/07/30/flux-actions-and-the-dispatcher.html\">http://facebook.github.io/react/blog/2014/07/30/flux-actions-and-the-dispatcher.html</a></p>\n\n<p>Testing: <a href=\"http://facebook.github.io/react/blog/2014/09/24/testing-flux-applications.html\">http://facebook.github.io/react/blog/2014/09/24/testing-flux-applications.html</a></p>\n\n<p>More out in the wild: <a href=\"http://facebook.github.io/react/blog/2014/10/17/community-roundup-23.html\">http://facebook.github.io/react/blog/2014/10/17/community-roundup-23.html</a></p>\n    "},{"t":"How to choose which type of NoSQL to use [closed]","l":"http://stackoverflow.com/questions/5689091/how-to-choose-which-type-of-nosql-to-use","q":"\n\n<p>There is a great list of various NoSQL database platforms at <a href=\"http://nosql-database.org\">http://nosql-database.org</a>.  It categorizes each as a \"wide column store\", \"document store\", \"key-value store\", or \"graph store\".  What I'm not finding is guidance on how to choose which of those 3 categories is most appropriate for a given problem.  </p>\n\n<p>What are the pros/cons or strengths/weaknesses of each type?<br>\nWhich classes of problems is each type best suited for?</p>\n\n<p>To be clear, I'm asking about distinctions between these 3 types of NoSQL systems and <em>not</em> specific implementations of them.</p>\n    ","a":"\n<p>There is a good <a href=\"http://www.thoughtworks.com/articles/nosql-comparison\">article</a> (though it doesn't go in depth) on this exact issue on the thoughtworks site.</p>\n\n<p>And <a href=\"http://blog.nahurst.com/visual-guide-to-nosql-systems\">this visual guide</a> is excellent as well</p>\n    "},{"t":"What is the relationship between DDD and the “Onion Architecture”?","l":"http://stackoverflow.com/questions/3399576/what-is-the-relationship-between-ddd-and-the-onion-architecture","q":"\n\n<p>What is the relationship between <a href=\"http://en.wikipedia.org/wiki/Domain-driven_design\">Domain-driven design</a> (DDD) and \"<a href=\"http://jeffreypalermo.com/blog/the-onion-architecture-part-1/\">The Onion Architecture</a>\" of Jeffrey Palermo?</p>\n    ","a":"\n<p>In my oppinion - they compliment each other - but from very different perspectives.</p>\n\n<p>Onion Architecture is all about making the Domain/BusinessLogic independant on 'inferior' things like data-acccess, UI, services etc. The Onion Architecture doesn't really care how you made the domain you have - it's adamant about protecting it from outside dependencies.</p>\n\n<p>Domain Driven Design is all about how you model your Domain and what you call your objects. Meaning that each Domain class should have a direct relation to what it represents in the business domain it is adressing (ie. the physical/real world). So a Customer object should be named a Customer in code - it should have the same rules as a Customer does in the real world (or as close as it is possible). </p>\n    "},{"t":"Are there any open source projects using DDD (Domain Driven Design)? [closed]","l":"http://stackoverflow.com/questions/152120/are-there-any-open-source-projects-using-ddd-domain-driven-design","q":"\n\n<p>I'm trying to understand the concepts behind DDD, but I find it hard to understand just by reading books as they tend to discuss the topic in a rather abstract way. I would like to see some good implementations of DDD in code, preferably in C#.</p>\n\n<p>Are there any good examples of projects practicing DDD in the open source world?</p>\n    ","a":"\n<p>Eric Evans and a Swedish consulting company have released a sample application based on the shipping example that Eric uses throughout the book.  It's in Java, but the concepts are well documented on the project page.</p>\n\n<p><a href=\"http://dddsample.sourceforge.net/\">http://dddsample.sourceforge.net/</a></p>\n\n<p>However, be warned that DDD is more about the journey than the destination.  Understand that the sample code you are looking took many forms before it became what you see now.  You did not see the awkward models that were used initially and you're missing the steps take to refactor the model based on insight gained along the way.  While the building blocks are important in DDD, Eric belives they are over-emphasized, so take all samples with a grain of salt.</p>\n    "},{"t":"designing a badge system, where to fire business logic? In code or stored procedures? or both?","l":"http://stackoverflow.com/questions/314412/designing-a-badge-system-where-to-fire-business-logic-in-code-or-stored-proced","q":"\n\n<p>If you were to build a badge system similiar to how SO does it, would you put the logic/business layer in the database directly (via stored procedure, scheduled sql jobs) or put it in the server side?</p>\n\n<p>From what I can think of, you have to:</p>\n\n<ol>\n<li>list badges that pertain to the current user action</li>\n<li>check if the user has a badge already or not</li>\n<li>insert badge for user </li>\n</ol>\n\n<p><b>Potential options</b></p>\n\n<ol>\n<li>business logic in the web application that calls stored procedures etc.</li>\n<li>stored procedures ONLY</li>\n<li>sql server job that runs every x minutes</li>\n<li>windows service that runs every x minutes</li>\n</ol>\n\n<p>Would a combination of these be required? I think it would since some badges are based on milestones for a given question, maybe a batch job is better?</p>\n\n<p><b>Update</b></p>\n\n<p>A system where you can modify the badge system, then re-run the entire badge linking for everyone would be even better.  i.e. say you change the logic for some badges, now you have to re-apply it to all the questions/answers/votes/etc.</p>\n\n<p><b>interesting problem to solve!!</b></p>\n    ","a":"\n<p>I would recommend putting all business logic in the business layer.  I recommend this for a few reasons:</p>\n\n<ul>\n<li>Keep the business logic in one\nlanguage / place</li>\n<li>Scalability -\nYou can partition data, implement\ndifferent caching mechanisms, etc.</li>\n<li>Seperation of concerns - let your DB do what it does best...store data, let your programming language make decisions on that data.</li>\n</ul>\n    "},{"t":"Business Logic Layer and Data Access layer: circular dependency","l":"http://stackoverflow.com/questions/458098/business-logic-layer-and-data-access-layer-circular-dependency","q":"\n\n<p>I’m having a little Architecture problem. In my project I have a Business Logic Layer (BLL) that contains all my business rules, models and OO API for the interface. Each object has static methods like getById that return an instance of said object. Each object also has methods like save and, delete. This is very straightforward OO code.</p>\n\n<p>Now I have a DataAccess layer (DAL), contained in a separate namespace, for each BLL object I have a DataClass or “Repository” which executes the getById and save commands. So in a way, the BLL save and getById methods are a thin layer around the DataClass methods.</p>\n\n<pre><code>public static NewsItem GetByID(int id)\n{\n       return DataFactory.GetNewsItemRepository().GetNewsItemById(id);\n}\n</code></pre>\n\n<p>In order for the DataClasses to return BLL objects, they need to know the BLL. so now we have:</p>\n\n<p>GUI ---&gt; BLL &lt;----&gt;DAL</p>\n\n<p>The DataFactory only returns objects that implement an Interface, so I can hide implementation details like “OracleNewsItemRepository”.</p>\n\n<p>But now for the thing that has been bugging me ever since I started Object Oriented programming. In my current solution, both BLL and the DAL need to know each other. This is a Circular Dependency, and it is best practice to avoid circular dependencies. Also I only want to expose the interfaces (and my DataFactory) and not my classes. This can be done by placing the DAL layer in a separate Assembly. Which would make sense. However, Visual Studio does not allow two Assemblies to refer eachother. Another question about this: <a href=\"http://stackoverflow.com/questions/457044/c-internal-access-modifiers\">http://stackoverflow.com/questions/457044/c-internal-access-modifiers</a></p>\n\n<p>Somehow I think I got my whole data access pattern wrong. It feels like I am convoluting the ActiveRecord pattern with other stuff like DataMappers. I have spent a lot of time on Martin Fowler’s site, but those patterns are described very generic and are illustrated by a very abstract UML diagram.</p>\n\n<p>They don’t solve my problem. Maybe I’m a bit anal, and there is no such thing as a “perfect data access pattern”. And what I do now doesn’t seem terribly wrong. But how I do things now, seems off…</p>\n\n<p>Any ideas?</p>\n    ","a":"\n<p>I think your data access pattern is fine.  What you are not doing is coupling your BLL to the OracleDAL.  You are coupling to the DAL interfaces.  A certain bit of coupling is absolutely required or you could never get anything done.</p>\n\n<p>I assume that your DataFactory and the INewsItemRepository classes exist outside your DAL Layer.  The following is an example of how my solutions are organized.  I don't use ActiveRecord, so this may not suit you perfectly.</p>\n\n<pre>Core (Project)\n  Domain\n    Business Entities\n  Data\n    Repository Interfaces\n    **Your DataFactory**\n\nOracleData (Project)\n  Data\n    Oracle Repository Implementations\n\nSqlData (Project)\n  Data\n    Sql Repository Implementations\n\nUI (Project)\n</pre>\n\n<p>Hope this helps.</p>\n    "},{"t":"Transactions best practices","l":"http://stackoverflow.com/questions/39583/transactions-best-practices","q":"\n\n<p>How much do you rely on database transactions?  </p>\n\n<p>Do you prefer small or large transaction scopes ?  </p>\n\n<p>Do you prefer client side transaction handling (e.g. TransactionScope in .NET) over server \nside transactions or vice-versa?    </p>\n\n<p>What about nested transactions?  </p>\n\n<p>Do you have some tips&amp;tricks related to transactions ?</p>\n\n<p>Any gotchas you encountered working with transaction ?</p>\n\n<p>All sort of answers are welcome.</p>\n    ","a":"\n<p>I always wrap a transaction in a using statement.</p>\n\n<pre><code>using(IDbTransaction transaction )\n{\n// logic goes here.\n   transaction.Commit();\n}\n</code></pre>\n\n<p>Once the transaction moves out of scope, it is disposed. If the transaction is still active, it is rolled back. This behaviour fail-safes you from accidentally locking out the database. Even if an unhandled exception is thrown, the transaction will still rollback. </p>\n\n<p>In my code I actually omit explicit rollbacks and rely on the using statement to do the work for me. I only explicitly perform commits.  </p>\n\n<p>I've found this pattern has drastically reduced record locking issues.</p>\n    "},{"t":"How to break apart layers in a strict-layered architecture and promote modularity without causing unnecessary redundancy?","l":"http://stackoverflow.com/questions/9182034/how-to-break-apart-layers-in-a-strict-layered-architecture-and-promote-modularit","q":"\n\n<p>I've received the go-ahead to start building the foundation for a new architecture for our code base at my company. The impetus for this initiative is the fact that:</p>\n\n<ul>\n<li>Our code base is over ten years old and is finally breaking at the seams as we try to scale.</li>\n<li>The top \"layers\", if you want to call them such, are a mess of classic ASP and .NET.</li>\n<li>Our database is filled with a bunch of unholy stored procs which contain thousands of lines of business logic and validation.</li>\n<li>Prior developers created \"clever\" solutions that are non-extensible, non-reusable, and exhibit very obvious anti-patterns; these need to be deprecated in short order.</li>\n</ul>\n\n<p>I've been referencing the <a href=\"http://msdn.microsoft.com/en-us/library/ff650706.aspx\">MS Patterns and Practices Architecture Guide</a> quite heavily as I work toward an initial design, but I still have some lingering questions before I commit to anything. Before I get into the questions, here is what I have so far for the architecture:</p>\n\n<p>(High-level)</p>\n\n<p><img src=\"http://i.stack.imgur.com/KWZbT.png\" alt=\"High-level\"></p>\n\n<p>(Business and Data layers in depth)</p>\n\n<p><img src=\"http://i.stack.imgur.com/VM5M4.png\" alt=\"Business and Data layers in depth\"></p>\n\n<p>The diagrams basically show how I intend to break apart each layer into multiple assemblies. So in this candidate architecture, we'd have <em>eleven</em> assemblies, not including the top-most layers.</p>\n\n<p>Here's the breakdown, with a description of each assembly:</p>\n\n<ul>\n<li><code>Company.Project.Common.OperationalManagement</code> : Contains components which implement exception handling policies, logging, performance counters, configuration, and tracing.</li>\n<li><code>Company.Project.Common.Security</code> : Contains components which perform authentication, authorization, and validation.</li>\n<li><code>Company.Project.Common.Communication</code> : Contains components which may be used to communicate with other services and applications (basically a bunch of reusable WCF clients).</li>\n<li><code>Company.Project.Business.Interfaces</code> : Contains the interfaces and abstract classes which are used to interact with the business layer from high-level layers.</li>\n<li><code>Company.Project.Business.Workflows</code> : Contains components and logic related to the creation and maintenance of business workflows.</li>\n<li><code>Company.Project.Business.Components</code> : Contains components which encapsulate business rules and validation.</li>\n<li><code>Company.Project.Business.Entities</code> : Contains data objects that are representative of business entities at a high-level. Some of these may be unique, some may be composites formed from more granular data entities from the data layer.</li>\n<li><code>Company.Project.Data.Interfaces</code> : Contains the interfaces and abstract classes which are used to interact with the data access layer in a repository style.</li>\n<li><code>Company.Project.Data.ServiceGateways</code> : Contains service clients and components which are used to call out to and fetch data from external systems.</li>\n<li><code>Company.Project.Data.Components</code> : Contains components which are used to communicate with a database.</li>\n<li><code>Company.Project.Data.Entities</code> : Contains much more granular entities which represent business data at a low level, suitable for persisting to a database or other data source in a transactional manner.</li>\n</ul>\n\n<p>My intent is that this should be a strict-layered design (a layer may only communicate with the layer directly below it) and the modular break-down of the layers should promote high cohesion and loose coupling. But I still have some concerns. Here are my questions, which I feel are objective enough that they are suitable here on SO...</p>\n\n<ol>\n<li>Are my naming conventions for each module and its respective assembly following standard conventions, or is there a different way I should be going about this?</li>\n<li>Is it beneficial to break apart the business and data layers into multiple assemblies?</li>\n<li>Is it beneficial to have the interfaces and abstract classes for each layer in their own assemblies?</li>\n<li><strong>MOST IMPORTANTLY</strong> - Is it beneficial to have an \"Entities\" assembly for both the business and data layers? My concern here is that if you include the classes that will be generated by LINQ to SQL inside the data access components, then a given entity will be represented in three different places in the code base. Obviously tools like AutoMapper may be able to help, but I'm still not 100%. The reason that I have them broken apart like this is to A - Enforce a strict-layered architecture and B - Promote a looser coupling between layers and minimize breakage when changes to the business domain behind each entity occur. However, I'd like to get some guidance from people who are much more seasoned in architecture than I am.</li>\n</ol>\n\n<p>If you could answer my questions or point me in the right direction I'd be most grateful. Thanks.</p>\n\n<hr>\n\n<p>EDIT:\nWanted to include some additional details that seem to be more pertinent after reading Baboon's answer. The database tables are also an unholy mess and are quasi-relational, at best. However, I'm not allowed to fully rearchitect the database and do a data clean-up: the furthest down to the core I can go is to create new stored procs and start deprecating the old ones. That's why I'm leaning toward having entities defined explicitly in the data layer--to try to use the classes generated by LINQ to SQL (or any other ORM) as data entities just doesn't seem feasible.</p>\n    ","a":"\n<p>I actually just started the same thing, so hopefully this will help or at least generate more comments and even help for myself :)</p>\n\n<blockquote>\n  <p><strong>1. Are my naming conventions for each module and its respective assembly following standard conventions, or is there a different way I should be going about this?</strong></p>\n</blockquote>\n\n<p>According to <a href=\"http://msdn.microsoft.com/en-us/library/ms229026.aspx\">MSDN Names of Namespaces</a>, this seems to be ok.  They lay it out as:</p>\n\n<p><code>&lt;Company&gt;.(&lt;Product&gt;|&lt;Technology&gt;)[.&lt;Feature&gt;][.&lt;Subnamespace&gt;]</code> <br>\n<code>For example, Microsoft.WindowsMobile.DirectX.</code></p>\n\n<blockquote>\n  <p><strong>2.Is it beneficial to break apart the business and data layers into multiple assemblies?</strong></p>\n</blockquote>\n\n<p>I definitely think its beneficial to break apart the business and data layers into multiple assemblies.  However, in my solution, I've create just two assemblies (DataLayer and BusinessLayer).  The other details like <code>Interfaces</code>, <code>Workflows</code>, etc I would create directories for under each assembly.  I dont think you need to split them up at that level.</p>\n\n<blockquote>\n  <p><strong>3.Is it beneficial to have the interfaces and abstract classes for each layer in their own assemblies?</strong></p>\n</blockquote>\n\n<p>Kind of goes along with the above comments.</p>\n\n<blockquote>\n  <p><strong>4.Is it beneficial to have an \"Entities\" assembly for both the business and data layers?</strong></p>\n</blockquote>\n\n<p>Yes.  I would say that your data entities might not map directly to what your business model will be.  When storing the data to a database or other medium, you might need to change things around to have it play nice.  The entities that you expose to your service layer should be useable for the UI.  The entities you use for you Data Access Layer should be useable for you storage medium. AutoMapper is definitely your friend and can help with mapping as you mentioned. So this is how it shapes up:</p>\n\n<p><img src=\"http://i.msdn.microsoft.com/dynimg/IC350997.png\" alt=\"Service Layer Details\"></p>\n    "},{"t":"Good resources to learn about Event Driven Architecture","l":"http://stackoverflow.com/questions/2652181/good-resources-to-learn-about-event-driven-architecture","q":"\n\n<p>Looking for books, blogs, web sites or videos.</p>\n\n<p>At the moment I am getting a lot of value from the blogs of Udi Dahan and Greg Young, but I was wondering if there are any other experts out there worth listening to?</p>\n    ","a":"\n<p>Here are the sources that I used for my study into EDA. </p>\n\n<p>SOA, EDA, BPM and CEP are all Complementary (David Luckhamm)\n<a href=\"http://complexevents.com/2007/04/30/soa-eda-bpm-and-cep-are-all-complementary/soa-eda-bpm-and-cep-are-all-complementary/\" rel=\"nofollow\">http://complexevents.com/2007/04/30/soa-eda-bpm-and-cep-are-all-complementary/soa-eda-bpm-and-cep-are-all-complementary/</a></p>\n\n<p>The Growing Role of Events in Enterprise Applications (W. Roy Schulte / Gartner)\n<a href=\"http://www.gartner.com/DisplayDocument?doc_cd=116129\" rel=\"nofollow\">http://www.gartner.com/DisplayDocument?doc_cd=116129</a></p>\n\n<p>Event Driven Architecture Overview (Brenda M. Michelson)\n<a href=\"http://www.omg.org/soa/Uploaded%20Docs/EDA/bda2-2-06cc.pdf\" rel=\"nofollow\">http://www.omg.org/soa/Uploaded%20Docs/EDA/bda2-2-06cc.pdf</a></p>\n\n<p>Complex Event Processing in the Real World (Oracle)\n<a href=\"http://www.oracle.com/technetwork/middleware/event-driven-architecture/overview/complex-event-processing-whitepaper-130966.pdf\" rel=\"nofollow\">http://www.oracle.com/technetwork/middleware/event-driven-architecture/overview/complex-event-processing-whitepaper-130966.pdf</a></p>\n\n<p>Event Driven SOA: A Better Way to SOA (Tibco)\n<a href=\"http://www.tibco.jp/multimedia/wp-event-driven-soa_tcm52-803.pdf\" rel=\"nofollow\">http://www.tibco.jp/multimedia/wp-event-driven-soa_tcm52-803.pdf</a></p>\n\n<p>Site of David Luckham\n<a href=\"http://www.complexevents.com/\" rel=\"nofollow\">http://www.complexevents.com/</a></p>\n    "},{"t":"Simulating relations in MongoDB","l":"http://stackoverflow.com/questions/3013027/simulating-relations-in-mongodb","q":"\n\n<p>Being one of the most popular NoSQL solutions MongoDB has most of the advantages of this approach. But one issue I'm still struggling with is how reflect object relations in NoSQL data store, specifically - MongoDB.</p>\n\n<p>For example, let's consider a simple data model: User, Post and Comment. It is clear to me that comments have no value on their own and thus become embedded objects for Posts. But when it comes to users - that becomes tricky because User is an entity on its own, not coupled with Post. Now in case I need to list posts with user full names and links to profiles on a web page, I would need to have a list of posts and information about posts authors (name and id at least).</p>\n\n<p>I see 2 possible solutions here:</p>\n\n<ol>\n<li>De-normalize the data in a way that each post entry contains its author's ID and full name (and any other user attributes I might need when listing posts). This way I would make querying for the data really simple but wheneve user updates his/her profile I would need to update all the posts by the user as well. But then I need to also store user attributes in the comments objects which means that updating user profile essentially requires me to update all the posts that have at least one comment by the user unless I want to store comments in a separate collections.</li>\n<li>Only store user ID in the post object and run 2 queries: one to get a list of posts and another one to get list of users where user id is in the list of post authors. This requires  2 queries and extra processing in my application code to map users to the posts.</li>\n</ol>\n\n<p>I'm sure I'm not the first one facing this issue but unfortunately I have not found any best practices on this topic so far. Opinions?</p>\n    ","a":"\n<p>Both are valid solutions, the advantage of solution 1 is that you can show a page like this with retrieving only one document from the db. Users don't update their profile very often and you can update all posts and embedded comments async after a user profile is changed. You can index the posts and embedded comments on userid so the update should be fast. Updating in mongodb is very speedy because mongodb does an update-in-place and you can't rollback or commit so mongodb doesn't have to log the changes. </p>\n\n<p>However users on sites like stackoverflow also have a reputation and this reputation changes a lot more than their profile. </p>\n\n<p>Solution 2 requires the retrieving of more documents per page, however you can use the $in operator with a list of userid's (userid of post+userid's of comments) so you only need two \"selects statements\".  </p>\n    "},{"t":"Structuring projects & dependencies of large winforms applications in C#","l":"http://stackoverflow.com/questions/152053/structuring-projects-dependencies-of-large-winforms-applications-in-c-sharp","q":"\n\n<p><strong>UPDATE:</strong><br>\nThis is one of my most-visited questions, and yet I still haven't really found a satisfactory solution for my project. One idea I read in an answer to another question is to create a tool which can build solutions 'on the fly' for projects that you pick from a list. I have yet to try that though.</p>\n\n<hr>\n\n<p>How do you structure a very large application?</p>\n\n<ul>\n<li>Multiple smallish projects/assemblies in one big solution? </li>\n<li>A few big projects?</li>\n<li>One solution per project?</li>\n</ul>\n\n<p>And how do you manage dependencies in the case where you don't have one solution.\nNote: I'm looking for advice based on experience, not answers you found on Google (I can do that myself).</p>\n\n<p>I'm currently working on an application which has upward of 80 dlls, each in its own solution. Managing the dependencies is almost a full time job. There is a custom in-house 'source control' with added functionality for copying dependency dlls all over the place. Seems like a sub-optimum solution to me, but is there a better way? Working on a solution with 80 projects would be pretty rough in practice, I fear.</p>\n\n<p>(Context: winforms, not web)</p>\n\n<p>EDIT: <em>(If you think this is a different question, leave me a comment)</em></p>\n\n<p>It seems to me that there are interdependencies between:</p>\n\n<ul>\n<li>Project/Solution structure for an application</li>\n<li>Folder/File structure</li>\n<li>Branch structure for source control (if you use branching)</li>\n</ul>\n\n<p>But I have great difficulty separating these out to consider them individually, if that is even possible.</p>\n\n<p><em>I have asked another related question <a href=\"http://stackoverflow.com/questions/177338/what-do-you-do-about-references-when-unloading-a-project-in-visual-studio\">here</a>.</em></p>\n    ","a":"\n<p><strong>Source Control</strong></p>\n\n<p>We have 20 or 30 projects being built into 4 or 5 discrete solutions. We are using Subversion for SCM.</p>\n\n<p>1) We have one tree in SVN containing all the projects organised logically by namespace and project name. There is a .sln at the root that will build them all, but that is not a requirement. </p>\n\n<p>2) For each actual solution we have a new trunks folder in SVN with SVN:External references to all the required projects so that they get updated from their locations under the main tree. </p>\n\n<p>3) In each solution is the .sln file plus a few other required files, plus any code that is unique to that solution and not shared across solutions.</p>\n\n<p>Having many smaller projects is a bit of a pain at times (for example the TortoiseSVN update messages get messy with all those external links) but does have the huge advantage that dependancies are not allowed to be circular, so our UI projects depend on the BO projects but the BO projects cannot reference the UI (and nor should they!).</p>\n\n<p><strong>Architecture</strong>\nWe have completely switched over to using <a href=\"http://msdn.microsoft.com/en-us/library/bb266334.aspx\" rel=\"nofollow\">MS SCSF and CAB enterprise</a> pattern to manage the way our various projects combine and interact in a Win Forms interface. I am unsure if you have the same problems (multiple modules need to share space in a common forms environment) but if you do then this may well bring some sanity and convention to how you architect and assemble your solutions.</p>\n\n<p>I mention that because SCSF tends to merge BO and UI type functions into the same module, whereas previously we maintained a strict 3 level policy:</p>\n\n<p>FW - Framework code. Code whose function relates to software concerns.\nBO - Business Objects. Code whose function relates to problem domain concerns.\nUI - Code which relates to the UI.</p>\n\n<p>In that scenario dependancies are strictly UI -&gt; BO -&gt; FW</p>\n\n<p>We have found that we can maintain that structure even while using SCSF generated modules so all is good in the world :-)</p>\n    "},{"t":"iPhone Compiler Fails: No architectures to compile for","l":"http://stackoverflow.com/questions/3549478/iphone-compiler-fails-no-architectures-to-compile-for","q":"\n\n<p>Hey guys, I'm trying to implement this in my iPhone app: <a href=\"http://code.google.com/p/core-plot/downloads/detail?name=alpharelease_0.1.zip&amp;can=2&amp;q=&amp;sort=-uploaded\">http://code.google.com/p/core-plot/downloads/detail?name=alpharelease_0.1.zip&amp;can=2&amp;q=&amp;sort=-uploaded</a> . I figured I'd first try to run the sample they provide. I'm attempting to open and compile the project located in /Source/examples/CPTestApp-iPhone/ . It says my base SDK was missing right off of the bat, so I edited the Project settings and the Active Target to use the iOS4 SDK, which I've done before for samples and had work. I'm not sure what to do. I'm running one of the newest Unibody Macbooks, with 10.6.4.</p>\n\n<p>Here is my full error:</p>\n\n<pre><code>// - start - //\n\nCheck dependencies\n\n[BEROR]No architectures to compile for (ONLY_ACTIVE_ARCH=YES, active arch=i386, VALID_ARCHS=armv6 armv7).\n\n// - end - //\n</code></pre>\n\n<p>Thoughts? </p>\n\n<p>Thanks! </p>\n\n<ul>\n<li>Josh</li>\n</ul>\n    ","a":"\n<p>Try this:</p>\n\n<p><strong>Project Build Settings:</strong> </p>\n\n<ul>\n<li>Architectures: Standard (armv6 armv7)</li>\n<li>Base SDK: Latest iOS Build Active</li>\n<li>Architectures Only: Checked Valid</li>\n<li>Architectures: armv6 armv7</li>\n</ul>\n\n<p>Delete any sub settings in the Architecture build setting.</p>\n\n<p><strong>Target Build Settings:</strong></p>\n\n<ul>\n<li>Same at project settings.</li>\n</ul>\n\n<p><strong>Frameworks</strong>\nAdd the SystemConfiguration.framework to your project. - Not sure why this had any impact.</p>\n\n<p>Clean all targets.\nBuild for the simulator.</p>\n\n<p>The long explanation for this can be found on our blog: <a href=\"http://longweekendmobile.com/2010/06/15/fixing-the-missing-required-architecture-arm-in-file-when-developing-for-ipad/\">http://longweekendmobile.com/2010/06/15/fixing-the-missing-required-architecture-arm-in-file-when-developing-for-ipad/</a></p>\n    "},{"t":"Difference between a “coroutine” and a “thread”?","l":"http://stackoverflow.com/questions/1934715/difference-between-a-coroutine-and-a-thread","q":"\n\n<p>What are the differences between a \"coroutine\" and a \"thread\"?</p>\n    ","a":"\n<p>Coroutines are a form of sequential processing: only one is executing at any given time (just like subroutines AKA procedures AKA functions -- they just pass the baton among each other more fluidly;-).  </p>\n\n<p>Threads are (at least conceptually) a form of concurrent processing: multiple threads may be executing at any given time.  (Traditionally, on single-CPU, single-core machines, that concurrency was simulated with some help from the OS -- nowadays, since so many machines are multi-CPU and/or multi-core, threads will <em>de facto</em> be executing simulaneously, not just \"conceptually\";-).</p>\n    "},{"t":"How do get clean URLs like Stackoverflow?","l":"http://stackoverflow.com/questions/1035251/how-do-get-clean-urls-like-stackoverflow","q":"\n\n<p>On some .NET driven sites URLs don't end with asp.net page names, like default.aspx, instead they use a pattern <a href=\"http://sitename.com\">http://sitename.com</a> or <a href=\"http://sitename.com/subdirectory/subdirectory\">http://sitename.com/subdirectory/subdirectory</a>. The site is mapped as sub directories off the root, ie. /tags, /users, /badges, the URLs would be /tags, /users, /badges respectively.</p>\n\n<p>StackOverflow, to use a specific example, uses question URLs of the form <a href=\"http://stackoverflow.com/questions/1035251/how-do-get-clean-urls-like-stackoverflow\">http://stackoverflow.com/questions/1035251/how-do-get-clean-urls-like-stackoverflow</a>. Which is great way to optimize the page for search engines.</p>\n\n<p>Is this implemented using HTTP handlers? Is the GET request filtered based on path and the whole response is formed in the handler itself based on the question id? Anyone else care to speculate?</p>\n    ","a":"\n<p>It's ASP.Net MVC, which has the .Net Routing more or less built in.  The Routing is available for non MVC projects as well, though</p>\n\n<p><a href=\"http://msdn.microsoft.com/en-us/library/cc668201.aspx\" rel=\"nofollow\">http://msdn.microsoft.com/en-us/library/cc668201.aspx</a></p>\n\n<p>It's just a .dll you can drop in your bin folder.  Basically it uses regular expressions to match your URL's to pages/templates.</p>\n    "},{"t":"Explain the different tiers of 2 tier & 3 tier architecture? [closed]","l":"http://stackoverflow.com/questions/2199176/explain-the-different-tiers-of-2-tier-3-tier-architecture","q":"\n\n<p>I am not able to understand which elements are called as first tier, second tier &amp; third tier &amp; where they reside. Can they reside on same machine or different machine. Which tier reside on which machine?  How we can identify a particular application as a 2 tier application or 3 tier application. Please explain with example</p>\n    ","a":"\n<p><a href=\"http://en.wikipedia.org/wiki/Multitier_architecture\">Wikipedia</a> explains it better then I could</p>\n\n<p>From the article - Top is 1st Tier:\n<img src=\"http://upload.wikimedia.org/wikipedia/commons/5/51/Overview_of_a_three-tier_application_vectorVersion.svg\" alt=\"alt text\"></p>\n    "},{"t":"Difference between event handlers and callbacks","l":"http://stackoverflow.com/questions/2069763/difference-between-event-handlers-and-callbacks","q":"\n\n<p>Can someone please explain to me what is the difference between an event handler and a callback function?</p>\n    ","a":"\n<p>An event handler is a type of callback. It's called whenever an event occurs. The term is usually used in terms of user interfaces where events are things like moving the mouse, clicking something and so on.</p>\n    "},{"t":"API Design: HTTP Basic Authentication vs API Token","l":"http://stackoverflow.com/questions/4968009/api-design-http-basic-authentication-vs-api-token","q":"\n\n<p>I'm currently creating an authentication system on front of a public web API for a web application. Given that each user account has an API key and each request must be authenticated, I have two alternatives:</p>\n\n<ol>\n<li><p>Using an HTTP Basic Authentication, <a href=\"http://developer.github.com/guides/basics-of-authentication/\">like GitHub does</a>.</p>\n\n<p>Requests must be sent to the URL</p>\n\n<pre><code>http://api.example.com/resource/id\nwith basic authentication\nusername: token\npassword: the api key\n</code></pre></li>\n<li><p>Passing the API Token as querystring parameter.</p>\n\n<p>Requests must be sent to the URL</p>\n\n<pre><code>http://api.example.com/resource/id?token=api_key\n</code></pre></li>\n</ol>\n\n<p>There's also a third option which is passing the token within the URI, but I honestly don't like that solution.</p>\n\n<p>Which solution would you adopt and why?</p>\n    ","a":"\n<p>I think that HTTP Basic Auth should be ok but just for really simple needs.</p>\n\n<p>The complete (and final) solution IMHO is to implement an <strong>OAuth</strong> provider.\nIt's not complex, it's a simple protocoll and gives to you a lot's of flexibility.\nIn addition it seems to be the current trend as many big players implements it and it is supported from many many libraries</p>\n    "},{"t":"Lift, Play! or BlueEyes (with a bunch of Javascript Frameworks)","l":"http://stackoverflow.com/questions/9219255/lift-play-or-blueeyes-with-a-bunch-of-javascript-frameworks","q":"\n\n<p>I find myself in a bit of a conundrum. I'm building a new, modern, web-based application and not only do I have to pick a technology, I have to pick an architecture. I think it is fair to say that these days its a tough choice because we have more options than we did even 5 years ago.</p>\n\n<p>First things first, I've made the decision that Scala will be the server-side language. I have my reasons, and this is not a Scala versus XYZ post - that choice has been made. I've also sucummed to the fact that we're on the web, in the cloud, so I'm not even going to try and get away from Javascript.  Maybe I will with CoffeeScript, but I will be writing Browser-hosted code.</p>\n\n<p>Now, assuming Scala, most people would probably jump to either <a href=\"http://www.playframework.org/2.0\">Play!</a> or <a href=\"http://liftweb.net/\">Lift</a>. Probably Play! given it's <a href=\"http://blog.typesafe.com/typesafe-stack-adds-play-framework\">endorsement from Typesafe</a>, but I think I have another more important question that needs answering first. What's the <strong>architecture</strong>? If I want a very rich client, do I really need more than a simple stateless service layer based on the fact that we'll have a tonne of Javascript anyway? I'm not sure it'll be a single-page webapp, but is something like <a href=\"https://github.com/jdegoes/blueeyes#readme\">BlueEyes</a> potentially the right choice? Lift and Play! are much more heavyweight in that they take on much more responsibility. They generate the HTML and for these frameworks, the browser is pretty dumb. Things like routing, validation, Ajax and Comet support are all server-side concerns. Because the browser is more capable today, rich, interactive features are normally implemented by generating and injecting Javascript from the server.</p>\n\n<p>My question boils down to this. Do I go with a traditional Lift/Play! framework where the server takes on both the client and server responsibility or do I go with a rich client + REST-style service layer where the client takes a more prominent role in the application? An architecture where the client deals with routing, validation, binding, etc. I'm seeing frameworks like <a href=\"http://knockoutjs.com/\">KnockOut.js</a>, <a href=\"http://sammyjs.org/\">Sammy.js</a>, <a href=\"http://sproutcore.com/\">Sproutcore</a>, <a href=\"http://documentcloud.github.com/backbone/\">Backbone.js</a>,... I'm not going to list them all but suffice to say that they all take on some of these framework features from a client-side perspective.</p>\n\n<p>If I choose Play!, am I giving up some of that rich UI? What about situations where I want to provide service API's for integration/mashup/mobile purposes? How would Play! help me here? Clearly BlueEyes plays well here. I think I need a service layer regardless.</p>\n\n<p>If I choose BlueEyes, what does my client code look like? How many of these Javascript-based frameworks do I need to give me what I need? I still want most of my business-logic in my service layer, but routing, binding.. all that UI stuff would be a concern of the client.</p>\n\n<p>I'm not sure there is a right or wrong answer, but I think this community can probably point me in the right direction.</p>\n\n<p>I also posted this to my blog at <a href=\"http://www.andyczerwonka.com/picking-a-web-technology-isnt-as-easy-as-it-u-45228\">http://www.andyczerwonka.com/picking-a-web-technology-isnt-as-easy-as-it-u-45228</a></p>\n    ","a":"\n<p>The Play 2.0 Beta contains a sample application that is exactly what you are looking for (ZenContacts).\nIts server side is just a bunch of restful interfaces while its client side leverages coffeescript etc. to build a rich user interface. </p>\n    "},{"t":"Javascript Architecture/Application Structure Best Practices?","l":"http://stackoverflow.com/questions/5400132/javascript-architecture-application-structure-best-practices","q":"\n\n<p>Do these exist?</p>\n\n<p>I've been a slave to big strongly typed OO languages (Java &amp; C#) for many years and am a devotee of Martin Fowler and his ilk. Javascript, due to it's loosely typed and functional nature seems to not lend itself to the idioms I am used to. </p>\n\n<p>What are the best practices for organizing a javascript rich client? I am interested in everything from where to keep your code, (one file or multiple files) to MVC patterns to gang of four patterns to layering. </p>\n\n<p>Not putting stuff in the Global namespace seems to be the only consensus. </p>\n\n<p>I am using JQuery as the \"Extended API.\" </p>\n    ","a":"\n<p>I like to use a sort of MVC client side architecture.</p>\n\n<ul>\n<li>I have a page CONTROLLER </li>\n<li>The DOM is my VIEW </li>\n<li>The server is my MODEL</li>\n</ul>\n\n<p>Typically I create a singleton page controller class (with supporting classes off that is needed) that controls the ajax calls and view binding.</p>\n\n<pre><code>var pageXController = {\n  init: function(param) {\n    pageXController.wireEvents();\n    // something else can go here\n  },\n\n  wireEvents : function() {\n    // Wire up page events\n  }\n\n  // Reactive methods from page events\n  // Callbacks, etc\n  methodX : function() {}\n}\n\n$(document).ready( function() {\n  // gather params from querystring, server injection, etc\n  pageXController.init(someparams);\n});\n</code></pre>\n\n<p>I should also add here that your MODEL in this case is your DTO's (Data Transfer Objects) which are optimised to the problem they solve. This is NOT your domain model.</p>\n    "},{"t":"What is the concept behind R.java?","l":"http://stackoverflow.com/questions/10004906/what-is-the-concept-behind-r-java","q":"\n\n<p>In android R.java is used to provide access to resources defined in XML files.\nTo access the resource we need to invoke <code>findViewById()</code> method passing in the id of the resource to be fetched.</p>\n\n<p>This is similar to Spring where beans are defined in a XML context and are fetched by using application context. <code>context.getBean(\"beanId\")</code></p>\n\n<p>This provides loose coupling since the beans are defined externally and could be changed without making modifications to the code.</p>\n\n<p>This has me confused. Though what Android does looks similar to spring, what advantage does it offer?</p>\n\n<blockquote>\n  <ol>\n  <li>What is the point of having an intermediate R.java anyway? Couldn't we just acquire resources directly from XML by use of a resource\n  reader/application context. e.g. <code>findViewById(\"resourceId\")</code></li>\n  <li>There isn't any loose coupling. Since references in R.java get auto-generated how could one delete a resource and put in a new one?</li>\n  <li>What design pattern does it follow(if there is one)?</li>\n  <li>Wouldn't it be better to have resources injected using IOC (like Roboguice)? Why did then google decide to give us such\n  a wierd way of working with resources?</li>\n  </ol>\n</blockquote>\n\n<p>Pardon my ignorance. I'm a newbie Java developer trying too many things at once. :-)\nThanks for all the feedback.</p>\n    ","a":"\n<p><em>android.R.java</em> is not just where <em>XML</em> ids are stored. It also contains access to resources - such as drawables, layouts, strings, arrays, and basically anything you can declare in resources.</p>\n\n<p>Personally I find that it is useful when using Eclipse. I can simply type <code>findViewById(R.id.</code> and Eclipse will show a tooltip with a list of options to choose from. </p>\n\n<p>However at a platform level, I would say that the hardcoded id variables help prevent errors when using Strings to identify resources -- something that can be debuggable while programming (or during compilation, rather than runtime).</p>\n    "},{"t":"examples of DCI architecture? [closed]","l":"http://stackoverflow.com/questions/3879348/examples-of-dci-architecture","q":"\n\n<p>I've been trying to understand <a href=\"http://www.infoq.com/news/2009/05/dci-coplien-reenskau\">DCI</a> architecture by reading <a href=\"http://www.leansoftwarearchitecture.com/\">lean software architecture</a>. I feel like I need to see some more examples to crystalize my understanding of it, but I've only been able to find ones which are variations of the <a href=\"http://horsdal.blogspot.com/2009/05/dci-in-c.html\">money transfer between accounts</a> case that is worked through in the book. </p>\n\n<p>If there are any out there on the web, let me know. Alternatively if you've created an good example yourself that isn't on the web, you could post it here. </p>\n\n<p>Any language will do.</p>\n    ","a":"\n<p>I am not sure, if you had look at some of these literature on the web.\nI am listing them down for reference:</p>\n\n<ul>\n<li><a href=\"http://folk.uio.no/trygver/2008/commonsense.pdf\">http://folk.uio.no/trygver/2008/commonsense.pdf</a></li>\n<li><a href=\"http://www.artima.com/articles/dci_vision.html\">http://www.artima.com/articles/dci_vision.html</a></li>\n<li><a href=\"http://pettermahlen.com/2010/09/10/dci-architecture-good-not-great-or-both/\">http://pettermahlen.com/2010/09/10/dci-architecture-good-not-great-or-both/</a> </li>\n<li><a href=\"http://groups.google.com/group/object-composition/\">http://groups.google.com/group/object-composition/</a></li>\n<li><a href=\"http://www.jroller.com/sebastianKuebeck/entry/james_coplien_s_talk_on\">http://www.jroller.com/sebastianKuebeck/entry/james_coplien_s_talk_on</a></li>\n<li><a href=\"http://www.infoq.com/presentations/The-DCI-Architecture\">http://www.infoq.com/presentations/The-DCI-Architecture</a></li>\n</ul>\n\n<p>And the following discusses the application using an example in scala</p>\n\n<ul>\n<li><a href=\"http://sadekdrobi.com/2009/06/10/dci-in-real-world-domain-context-and-interaction-with-scala-in-a-real-world-project/#more-638\">http://sadekdrobi.com/2009/06/10/dci-in-real-world-domain-context-and-interaction-with-scala-in-a-real-world-project/#more-638</a></li>\n</ul>\n    "},{"t":"Can I refactor to Model View Query Handler?","l":"http://stackoverflow.com/questions/19833120/can-i-refactor-to-model-view-query-handler","q":"\n\n<p>In our MVC application all of our read actions as a paramter take a query which implements:</p>\n\n<pre><code>public interface IQuery&lt;out TResponse&gt; { }\n</code></pre>\n\n<p>Within the action the query is passed to a bus which locates a handler and returns a view model. So controllers now look something like this:</p>\n\n<pre><code>   public ActionResult Edit(DetailsQuery query)\n    {\n        var model = mediator.Request(query);\n        return View(model);\n    }\n</code></pre>\n\n<p>Effectively just passing queries to our mediator and returning the result. We have hundreds of actions that look like this. There is the odd action that does something conditional (which I would leave as they are) but the rest are just the same boilerplate again and again. We have over hundred different queries</p>\n\n<p>How can I refactor this to something more explicit?  I guess moving to a Model View Query Handler rather than the boilerplate controller action that just hands off query to the bus and returns model to View. </p>\n\n<p>What extension points should I look at in MVC? Effectively instead of having to write the action handler - just have some automatic way of wiring together strongly typed query and getting back the correct ViewModel.</p>\n\n<p>If I can? Should I? I just don't like seeing hundreds of actions that all look the same.</p>\n    ","a":"\n<p>First, thanks for the link to the post <a href=\"http://lostechies.com/jimmybogard/2013/10/29/put-your-controllers-on-a-diet-gets-and-queries/\">\"Put your controllers on a diet: GETs and queries\"</a>. My code example uses types from it.</p>\n\n<p>My solution <strong>also involves usage of action filters</strong> as point to inject generic behaviour.</p>\n\n<p>Controller is simple enough and looks like @Kambiz Shahim's:</p>\n\n<pre><code>[QueryFilter]\npublic class ConferenceController : Controller\n{\n    public ActionResult Index(IndexQuery query)\n    {\n        return View();\n    }\n\n    public ViewResult Show(ShowQuery query)\n    {\n        return View();\n    }\n\n    public ActionResult Edit(EditQuery query)\n    {\n        return View();\n    }\n}\n</code></pre>\n\n<p>Working on <code>QueryFilterAttribute</code> I realised that <strong><code>IMediator</code> and its implementation can be omitted. It is enough to know type of query to resolve an instance of <code>IQueryHandler&lt;,&gt;</code> via IoC.</strong></p>\n\n<p>In my example <a href=\"http://docs.castleproject.org/Windsor.MainPage.ashx\">Castle Windsor</a> and implementation of <a href=\"http://blog.ploeh.dk/2010/02/03/ServiceLocatorisanAnti-Pattern/\">'Service Locator'</a> pattern are used.</p>\n\n<pre><code>public class QueryFilterAttribute : ActionFilterAttribute\n{\n    public override void OnActionExecuting(ActionExecutingContext filterContext)\n    {\n        base.OnActionExecuting(filterContext);\n\n        object query = filterContext.ActionParameters[\"query\"];\n        Type queryType = query.GetType();\n        Type modelType = queryType.GetInterfaces()[0].GetGenericArguments()[0];\n\n        var handlerType = typeof(IQueryHandler&lt;,&gt;).MakeGenericType(queryType, modelType);\n\n        // Here you should resolve your IQueryHandler&lt;,&gt; using IoC\n        // 'Service Locator' pattern is used as quick-and-dirty solution to show that code works.\n        var handler = ComponentLocator.GetComponent(handlerType) as IQueryHandler;\n\n        var model = handler.Handle(query);\n        filterContext.Controller.ViewData.Model = model;\n    }\n}\n</code></pre>\n\n<p><code>IQueryHandler</code> interface is added to avoid working with Reflection</p>\n\n<pre><code>/// &lt;summary&gt;\n/// All derived handlers can be refactored using generics. But in the real world handling logic can be completely different.\n/// &lt;/summary&gt;\n/// &lt;typeparam name=\"TQuery\"&gt;The type of the query.&lt;/typeparam&gt;\n/// &lt;typeparam name=\"TResponse\"&gt;The type of the response.&lt;/typeparam&gt;\npublic interface IQueryHandler&lt;in TQuery, out TResponse&gt; : IQueryHandler\n    where TQuery : IQuery&lt;TResponse&gt;\n{\n    TResponse Handle(TQuery query);\n}\n\n/// &lt;summary&gt;\n/// This interface is used in order to invoke 'Handle' for any query type.\n/// &lt;/summary&gt;\npublic interface IQueryHandler\n{\n    object Handle(object query);\n}\n\n/// &lt;summary&gt;\n/// Implements 'Handle' of 'IQueryHandler' interface explicitly to restrict its invocation.\n/// &lt;/summary&gt;\n/// &lt;typeparam name=\"TQuery\"&gt;The type of the query.&lt;/typeparam&gt;\n/// &lt;typeparam name=\"TResponse\"&gt;The type of the response.&lt;/typeparam&gt;\npublic abstract class QueryHandlerBase&lt;TQuery, TResponse&gt; : IQueryHandler&lt;TQuery, TResponse&gt;\n    where TQuery : IQuery&lt;TResponse&gt;\n{\n    public abstract TResponse Handle(TQuery query);\n\n    object IQueryHandler.Handle(object query)\n    {\n        return Handle((TQuery)query);\n    }\n}\n</code></pre>\n\n<p>Types should be registered <code>in Global.asax.cs</code></p>\n\n<pre><code>        container.Register(Component.For&lt;ISession&gt;().ImplementedBy&lt;FakeSession&gt;());\n        container.Register(\n            Classes.FromThisAssembly()\n                .BasedOn(typeof(IQueryHandler&lt;,&gt;))\n                .WithService.Base()\n                .LifestylePerWebRequest());\n</code></pre>\n\n<p>There is a <a href=\"https://gist.github.com/ilyapalkin/c82904208bd529814713\"><strong>link to gist on github</strong></a> with all code.</p>\n    "},{"t":"What is the difference between framework and architecture?","l":"http://stackoverflow.com/questions/2190625/what-is-the-difference-between-framework-and-architecture","q":"\n\n<p>I would like to know the difference between framework and architecture.<br>\nfor example: <code>dotnetnuke</code> is the framework and <code>mvc</code> is the architecture.</p>\n\n<p>so if we take both of this as a example, can anyone tell me difference between them?<br>\nWant to know which one is using when and where?<br>\nWhich is good in terms of user requirement satisfaction?</p>\n    ","a":"\n<p>Let me illustrate the difference.</p>\n\n<p>Framework:</p>\n\n<p><img src=\"http://www.senstonhomes.com/wp-content/uploads/2012/02/diy-woodworking-tools-1.1-800x8001.jpg\" alt=\"Framework\"></p>\n\n<p>Architecture:</p>\n\n<p><img src=\"http://chestofbooks.com/home-improvement/woodworking/Ira-S-Griffith/Courses-Woodwork-Mechanical-Drawing/images/Plate-17-Bird-house-Mechanical-Drawing-39.png\" alt=\"Architecture\"></p>\n    "},{"t":"Good Architecture Interview Questions [closed]","l":"http://stackoverflow.com/questions/816258/good-architecture-interview-questions","q":"\n\n<p>What are some good questions to ask in an interview to see how much the applicant knows about architecture?</p>\n    ","a":"\n<p>Architecture is one of those things that isn't simply a trivia question (e.g., design pattern uses) and is a lot more subjective than other interview topics. There often isn't a single correct architecture so that makes it trickier to evaluate someone. The most you can get is an idea of how the interviewee thinks. </p>\n\n<p>I would suggest that you describe to the interviewee a complex product or part of a product that you (the interviewer) are most intimately familiar with.  Then ask him to think of how he would architect it and explain his reasoning, and then focus on specific decisions and ask questions.</p>\n\n<p>Of course, only do this if:</p>\n\n<ul>\n<li>You are open to hearing other designs that are not your own.</li>\n<li>You are able to take potential\ncriticisms and acknowledge that your\nown design might be imperfect</li>\n</ul>\n\n<p>An added bonus is that you would see how you might handle disagreements if he is hired.</p>\n\n<p>An alternative approach if your product has ever been rearchitected is to describe the architecture of the old version and ask the interviewee how he would rearchitect it. If the result is close to the current architecture, it is likelier that the candidate would be a good fit with the style and mindset of your group.  </p>\n    "},{"t":"Does a software architect have a role in agile, esp. Scrum?","l":"http://stackoverflow.com/questions/177764/does-a-software-architect-have-a-role-in-agile-esp-scrum","q":"\n\n<p>I'm reading the book \"The Software Architect's Profession\" by Marc and Laura Sewell (<a href=\"http://rads.stackoverflow.com/amzn/click/0130607967\">Amazon link</a>) and it got me wondering whether a software architect is a part of the old non-agile BDUF approach.</p>\n\n<p>Is there a place for software architects in an agile approach? I'm especially interested in Scrum.</p>\n\n<p>BTW I currently am the Unix Application Architect for a major company.</p>\n\n<p>cheers,</p>\n\n<p>Rob</p>\n    ","a":"\n<p>Sure.</p>\n\n<p>Remember - agile isn't a 'bring me a rock' approach.  There are still requirements, still a design and still a need for a solid architecture.</p>\n\n<p>When you are building a product or product line and employing Scrum or some other agile approach to managing your project, one of the key ideas is developing a short iteration cycle, prioritizing the backlog of tasks to accomplish, determining what is going to be in iteration A, B, C, etc.  There is where an architect can really be valuable.  Having someone with a clear idea of how X, Y and Z all will fit together can make your Scrum iterations that much more productive.</p>\n    "},{"t":"Benefits of an enterprise service bus","l":"http://stackoverflow.com/questions/2023130/benefits-of-an-enterprise-service-bus","q":"\n\n<p><strong>Where can I find some information on the uses and benefits of an enterprise service bus (ESB)?</strong></p>\n\n<p>I am looking for information about:</p>\n\n<ol>\n<li>the kinds of problems and ESB helps to solve</li>\n<li>the alternatives to an ESB - and the tradeoffs in selecting between them</li>\n<li>what you need to do as a developer to build ESB-compatible systems</li>\n</ol>\n\n<p>I'm looking for a finer level of detail than just Wikipedia or online marketing brochures from vendors. Ideally, some example code would help to clarify what's involved in taking advantage of an ESB. Information from a .NET or Java perspective would be the most useful.</p>\n\n<p>Thanks.</p>\n    ","a":"\n<p>I'd suggest <a href=\"http://blogs.mulesoft.com/dev/mule-dev/to-esb-or-not-to-esb/\" rel=\"nofollow\">To ESB or not to ESB</a> to start with, written by the creator of <a href=\"http://www.mulesoft.org\" rel=\"nofollow\">Mule</a>.</p>\n    "},{"t":"Web API Authentication best practice","l":"http://stackoverflow.com/questions/12222527/web-api-authentication-best-practice","q":"\n\n<p>Which one is the best authentication approach for an Web API, considering that the data security is essential and the ASP.NET application runs on Azure?</p>\n    ","a":"\n<p>When dealing with authentication and securing your Web API I recommend you follow the guidelines set by Dominick Baier. There might be no better expert on ASP.NET identity management in the world.</p>\n\n<p>You can find his blog at <a href=\"http://leastprivilege.com/\">http://leastprivilege.com/</a> and a great Web API Identity package at Nuget, Thinktecture.IdentityModel - <a href=\"http://nuget.org/packages/Thinktecture.IdentityModel\">http://nuget.org/packages/Thinktecture.IdentityModel</a>\nAs with most of the good open source libraries, since all the functionality is available for your for free, there is no need to reinvent the wheel.</p>\n\n<p>This is a top-to-bottom identity &amp; access control library for .NET 4.0/WIF and .NET 4.5 (including support for MVC and Web API).</p>\n\n<p>If you want to learn more about securing your Web API, you should also watch this video <a href=\"http://vimeo.com/43603474\">http://vimeo.com/43603474</a> - Dominick's talk from NDC Oslo 2012.</p>\n    "},{"t":"What are the advantages and disadvantages of plug-in based architecture?","l":"http://stackoverflow.com/questions/2818415/what-are-the-advantages-and-disadvantages-of-plug-in-based-architecture","q":"\n\n<p>I want to do the architectural design for a software that can be used integrate various third party software’s (executable) under one platform. </p>\n\n<p>Standard project types will be added to the platform by default. The project type defines the way in which the different software will be executed and their input and output files.</p>\n\n<p>The user can customize the available standard project type and that will be added to the platform as new project type which defines new custom execution flow.</p>\n\n<p>Also it should support easy extension and customization of the features. I read that plug-in based architecture supports both. </p>\n\n<p>What are the advantages and disadvantages of plug-in based architecture? Do we have any better architecture which can be used for this kind of scenario?</p>\n\n<p>Thanks in advance:)</p>\n    ","a":"\n<p>The benefits of a pluggable system are</p>\n\n<ul>\n<li>extensibility: the application can be dynamically extended to include new features.</li>\n<li>parallel development: since features can be implemented as separate components, they can be developed in parallel by different teams.</li>\n<li>clear development direction: since the plugin framework ideally provides a well-defined interface and documentation for plugin writers, developers have a clear roadmap for development.</li>\n<li>simplicity: a plugin typically has one function, and so developers have a single focus</li>\n</ul>\n\n<p>But some of these strengths are also weaknesses:</p>\n\n<ul>\n<li>extensibility: does the plugin interface anticipate the ways plugin writers what to extend the app, or does it restrict extension. Designing extensibility to meet all use cases often takes several iterations, or extremely good requirements analysis.</li>\n<li>maintainability: the provider of the plugin framework not only has to make sure the plugin interface satisfies indented use cases, is clear and well documented, but also that it can evolve. Managing versions and backwards compatibility with existing plugins can be very hard. Hard enough that many practical implementations don't bother, and push the onus on plugin writers to update their plugins with each version.</li>\n<li>complexity: although each plugin works when tested alone, interactions between plugins can cause new problems, with bugs appearing only with certain combinations of plugins.</li>\n<li>testing: testing plugins can be difficult if the plugin system does not provide some form of mock plugin runner for testing, which is sometimes not possible, and testing is only available by running the plugin for real, which slows down development.</li>\n<li>artifical separation: a plugin typically has a single focus, but what constitues a single focus is set by the plugin api provider. If a plugin writer finds he needs a plugin that can reasonably do 2 things (as defined by the plugin api) in close tandem, he may end up having to implement two plugins and find ways of providing communication between them that is not presently provided by the api. He's then having to work around or against the plugin framework.</li>\n</ul>\n\n<p>Designing a good plugin environment has many of the same challenges as designing a good library. If you are producing both the environment and the plugins yourself, then it's not so bad since you can update all the plugins as the environment evolves, but if the plugin api is open to all, then it requires careful planning and execution to get the design right to avoid too many plugin rewrites as the environment evolves.</p>\n\n<p>\"<a href=\"http://en.wikipedia.org/wiki/Second-system_effect\">Second-system syndrome</a>\" described by Fred Brooks advocates that the second system developed is often excessively generic, aiming for ultimate flexibility, sometimes producing a \"platform within a platform\"/\"<a href=\"http://en.wikipedia.org/wiki/Inner-platform_effect\">inner platform effect</a>\". A pluggable design is often seen as a way out when requirements are non-existent or underspecified. To compensate, the software is made as flexible as possible to try to handle \"whatever comes along\". </p>\n\n<p>Appologies if this paints a dreary picture - pluggable systems can be fantastic and offer a lot of strengths, but they come at a high price. Before diving into a pluggable system, it's prudent to draw up requirements for all the plugins that you will need to cover the functionality required. This will then help you decide if the pluggable design is worth the effort, or some simpler approach would serve equally well.</p>\n    "},{"t":"Extreme Sharding: One SQLite Database Per User","l":"http://stackoverflow.com/questions/128919/extreme-sharding-one-sqlite-database-per-user","q":"\n\n<p>I'm working on a web app that is somewhere between an email service and a social network.  I feel it has the potential to grow really big in the future, so I'm concerned about scalability.</p>\n\n<p>Instead of using one centralized MySQL/InnoDB database and then partitioning it when that time comes, I've decided to create a separate SQLite database for each active user: one active user per 'shard'.</p>\n\n<p>That way backing up the database would be as easy as copying each user's <em>small</em> database file to a remote location once a day.</p>\n\n<p>Scaling up will be as easy as adding extra hard disks to store the new files.</p>\n\n<p>When the app grows beyond a single server I can link the servers together at the filesystem level using GlusterFS and run the app unchanged, or rig up a simple SQLite proxy system that will allow each server to manipulate sqlite files in adjacent servers.</p>\n\n<p>Concurrency issues will be minimal because each HTTP request will only touch one or two database files at a time, out of thousands, and SQLite only blocks on reads anyway.</p>\n\n<p>I'm betting that this approach will allow my app to scale gracefully and support lots of cool and <em>unique</em> features. Am I betting wrong?  Am I missing anything?</p>\n\n<p><strong>UPDATE</strong> I decided to go with a less extreme solution, which is working fine so far.  I'm using a fixed number of shards - 256 sqlite databases, to be precise.  Each user is assigned and bound to a random shard by a simple hash function.  </p>\n\n<p>Most features of my app require access to just one or two shards per request, but there is one in particular that requires the execution of a simple query on 10 to 100 different shards out of 256, depending on the user.  Tests indicate it would take about 0.02 seconds, or less, if all the data is cached in RAM.  I think I can live with that!</p>\n\n<p><strong>UPDATE 2.0</strong> I ported the app to MySQL/InnoDB and was able to get about the same performance for regular requests, but for that one request that requires shard walking, innodb is 4-5 times faster.  For this reason, and other reason, I'm dropping this architecture, but I hope someone somewhere finds a use for it...thanks.</p>\n    ","a":"\n<p>The place where this will fail is if you have to do what's called \"shard walking\" - which is finding out all the data across a bunch of different users. That particular kind of \"query\" will have to be done programmatically, asking each of the SQLite databases in turn - and will very likely be the slowest aspect of your site. It's a common issue in any system where data has been \"sharded\" into separate databases.</p>\n\n<p>If all the of the data is self-contained to the user, then this should scale pretty well - the key to making this an effective design is to know how the data is likely going to be used and if data from one person will be interacting with data from another (in your context).</p>\n\n<p>You may also need to watch out for file system resources - SQLite is great, awesome, fast, etc - but you do get some caching and writing benefits when using a \"standard database\" (i.e. MySQL, PostgreSQL, etc) because of how they're designed. In your proposed design, you'll be missing out on some of that.</p>\n    "},{"t":"Desktop Applications: Architectural Frameworks?","l":"http://stackoverflow.com/questions/150403/desktop-applications-architectural-frameworks","q":"\n\n<p>I'm wondering if there are any architectural frameworks out there to create desktop or standalone applications, in Java or C# for instance. It seems that there are tons of them available for web applications but I can't find many good resources on frameworks or architectural best-practices for desktop development.</p>\n\n<p>Ideally I would like to know if there is any source code available of desktop applications that would be considered to have a good architecture or are built with a certain framework.</p>\n    ","a":"\n<p>While not directly related to desktop applications if you are looking for decent source code for well written projects I asked a similar question:  </p>\n\n<p><a href=\"http://stackoverflow.com/questions/143088/open-source-c-projects-that-have-extremely-high-code-quality-to-learn-from\">Open source C# projects that have extremely high code quality to learn from.</a></p>\n\n<p>People gave some pretty good suggestions there:</p>\n\n<blockquote>\n  <ul>\n  <li>Scott Hanselman's <a href=\"http://www.hanselman.com/blog/CategoryView.aspx?category=Source+Code\">The Weekly Source Code</a> series (usually\n  managed C#)</li>\n  <li>Code written by <a href=\"http://msdn.microsoft.com/en-us/practices/default.aspx\">Microsoft Patterns &amp; Practices</a> team.</li>\n  <li><a href=\"http://www.codeplex.com/SharpDevelop\">SharpDevelop</a> (written in C#)</li>\n  <li><a href=\"http://www.go-mono.com/mono-downloads/download.html/\">Mono</a> (most of the framework in C#)</li>\n  <li><a href=\"http://paint.net\">Paint.Net</a> (written in C#)</li>\n  <li><a href=\"http://www.hibernate.org/428.html\">NHibernate</a> (written in C#)</li>\n  <li><a href=\"http://www.castleproject.org/\">The Castle Project</a> (written in C#)</li>\n  <li><a href=\"http://www.codeplex.com/xunit\">xUnit</a> (written in C#)</li>\n  <li><a href=\"http://referencesource.microsoft.com/netframework.aspx\">.Net Framework Source Code</a></li>\n  </ul>\n</blockquote>\n    "},{"t":"Why is a CPU branch instruction slow?","l":"http://stackoverflow.com/questions/9820319/why-is-a-cpu-branch-instruction-slow","q":"\n\n<p>Since I started programming, I have read in every place to avoid wasteful branches at all costs.</p>\n\n<p>That's fine, although none of the articles explained why I should do this. What exactly happens when the <a href=\"http://en.wikipedia.org/wiki/Central_processing_unit\">CPU</a> decodes a branch instruction and decides to do a jump? And what is the \"thing\" that makes it slower than other instructions (like addition)?</p>\n    ","a":"\n<p>A branch instruction is not inherently slower than any other instruction.</p>\n\n<p>However, the reason you heard that branches should avoided is because modern CPUs follow a <a href=\"http://en.wikipedia.org/wiki/Instruction_pipeline\"><em>pipeline architecture</em></a>.  This means that there are multiple sequential instructions being executed simultaneously.  But the pipeline can only be fully utilised if it's able to read the next instruction from memory on every cycle, which in turn means it needs to know <em>which</em> instruction to read. </p>\n\n<p>On a <em>conditional</em> branch, it usually doesn't know ahead of time which path will be taken.  So when this happens, the CPU has to stall until the decision has been resolved, and throws away everything in the pipeline that's behind the branch instruction.  This lowers utilisation, and therefore performance.</p>\n\n<p>This is the reason that things like <a href=\"http://en.wikipedia.org/wiki/Branch_prediction\"><em>branch prediction</em></a> and <a href=\"http://en.wikipedia.org/wiki/Branch_delay_slot\"><em>branch delay slots</em></a> exist.</p>\n    "},{"t":"Certification/Course for software designer/architecture [closed]","l":"http://stackoverflow.com/questions/4405560/certification-course-for-software-designer-architecture","q":"\n\n<p>Please excuse me if this is a dupe. </p>\n\n<p>After being a software developer for 7+ years, I think it is time for me to take my programming to the next level. I am thinking in terms of designer or an architecture.</p>\n\n<p>Is there a certification/Course available for designer/architecture? I do agree that a certification/course will not make me a good designer/architecture, but it will go on my resume. IMO It will also provide me a platform for me to dig deeper. </p>\n\n<p>Please advise me a Certification or a Course for software designer/architecture</p>\n    ","a":"\n<p>Part of the question, you already answered that Certification is not the only criteria to become a better architecture or designer. You must have real architectural experience by designing some real world application.</p>\n\n<p>I think, you can start by </p>\n\n<p>1- Designing a component from ground 0 this may be in your current project, a module, a small application.</p>\n\n<p>2- Thinking in terms of more efficient Algorithms, design procedure, patterns</p>\n\n<p>3- Be in touch with latest technology, platform etc.</p>\n\n<p>4- Learning more deployment patterns.</p>\n\n<p>5- Learning more about data storage and retrival systems.</p>\n\n<p>6- Start participating in forums, Q&amp;A sites like SO</p>\n\n<p>7- Start writing small technical papers.</p>\n\n<p>there are more points beyond the ones mentioned above but these points are surely a starting point for the long way journey to be an architect.</p>\n\n<p>Plus, work under a senior architect / architect as a Techinal Lead or Junior Architect will also act as a boost.</p>\n\n<p>And in the last, there are certain certifications by the industory leaders like Microsoft, IBM, and others. One of the certification which i know is </p>\n\n<p><strong>MCA (Micorsoft Certiifed Architect)</strong></p>\n\n<p>But this certification  has some predefined criterias like (Min 10 Yrs work ex etc..)</p>\n    "},{"t":"How strictly do you follow the n-tier architecture and separation of concerns between the layers in your projects?","l":"http://stackoverflow.com/questions/533311/how-strictly-do-you-follow-the-n-tier-architecture-and-separation-of-concerns-be","q":"\n\n<p>I suppose most of the developers have an idea of multi-layer architecture. We have DAL (Data access layer), we have BLL (business logic layer) and somewhere near the end of the road we have our UI. If you have a project which somehow follows these principles, do you keep (or at least try) to keep/put the things where they conceptually belong? I'm especially interested in big company applications where you work together with many other people. Clearly you can do whatever you want with your private toy project, invent any kind of an architecture and stick to it. It is not so easy with big projects where lots of people contributed to the software or overall mess.</p>\n\n<p>For example, I happened to see things like UI components going directly to the database to fetch some \"missing\" extra data which BL does not supply, also both UI and BL working with low level elements like table fields where in my opinion they should delegate these operations to the lower level namely DAL. It was especially sad when after discussing the things with the senior developer guy I saw he didn't see a problem with this at all.</p>\n\n<p>We can of course assume me and whoever shares my point of view are just being perfectionists, but I clearly saw a very disadvantegous consequence in that it took me prolonged periods of time in some of my tasks to trace all the \"parallel\" routes that the data is travelling to and from the database and to identify whoever and in which way may now be affected by the new functionality I implemented. The way I see it, these are increased further development / maintenance costs overweighting some savings when someone decided to quickly hack the stuff and close the task as soon as possible.</p>\n\n<p>Are you projects \"pure\" or they abandoned the idea of keeping the clear line between layers a long time ago? If you still keeping it right, how do you deal with colleagues who do not understand these things or don't care about them just building \"custom\" solutions and hacking hacks all the time? Or at some point in time you stopped fighting with the windmill and accepted it as your punishment?.\nEDIT: Somewhat surprised that not many people got interested in the problem. Is that the sign the most do not care?</p>\n    ","a":"\n<p>The more complicated our application gets, the more important separation of concerns becomes.</p>\n\n<p>At 100 klocs, the application was one big blob, as much business code in form classes as anywhere else and calls into form methods from the business classes. With much wailing and gnashing of teeth, we separated out the business logic from the display logic. Any class that needed to notify the user of its progress raised an event that was sunk by the UI. And, for a while, all was right with the world.</p>\n\n<p>Around 200 klocs, we added a data layer. The architecture of our application was such that most of our data was processed as soon as it came in and immediately discarded. Most configuration information was stored in the third-party application with which ours shared a symbiotic relationship. But, settings were starting to accumulate in all sorts of odd corners. We wound up with three configuration management systems, all intricately woven into the business logic. With an extensive rewrite, we were able to separate out the configuration information into its own layer and the handling of streaming data into another layer.</p>\n\n<p>Near the 250 kloc line, we decided to end our relationship with the third-party vendor and make our application stand alone. We began a massive rewrite and, for the first time, added an actual database to our application. Because we had clear lines between streaming information, data storage, and business logic, this was a fairly seamless integration.</p>\n\n<p>Now, approaching 500 klocs, we're moving the application to a grid-based architecture. Not only will the UI be separated from the business logic on a different computer, the actual computation of the quotes and orders that the application sends out will be load balanced and spread out to maximize efficiency. This would be impossible without an n-tier architecture.</p>\n\n<p>At each stage of growth, we were either aided by a clean separation or hindered by our own muddle of communication, data, business, and UI. There probably hasn't been a more important concern than that separation in the creation of this application.</p>\n    "},{"t":"DDD, Anti Corruption layer, how-to?","l":"http://stackoverflow.com/questions/909264/ddd-anti-corruption-layer-how-to","q":"\n\n<p>At the moment, we have to build an application which is based on a legacy one.  Code for that old application should be thrown away and rewritten, but as it usually goes - instead of rewriting it, we need to base something new on it. Recently, we decided to go the DomainDrivenDesign path.  So -- anti corruption layer could be a solution for our problems. As far as I understand, this way it should be possible to gradually rewrite the old application.  </p>\n\n<p>But -- I can't find any good example. I would appreciate <strong>ANY</strong> information.</p>\n    ","a":"\n<p>In my particular implementation, EmployeeAccessService is called by a Repository. It's really a facade into the Anti-corruption layer. It delegates to the EmployeeAccessAdapter. The adapter fetches an object from the legacy model (which it gets from EmployeeAccessFacade),then passes it to the EmployeeAccessTranslator to transform the object from the legacy model to the domain object in my application's model.</p>\n\n<p>See <a href=\"http://www.troygeek.com/static/ac-layer.gif\" rel=\"nofollow\">http://www.troygeek.com/static/ac-layer.gif</a> for a class diagram (sorry, new user so I couldn't include the image directly).</p>\n\n<p><strong>EmployeeAccessService</strong></p>\n\n<pre><code>public Employee findEmployee(String empID){\n    return adapter.findEmployee(empID);\n}\n</code></pre>\n\n<p><strong>EmployeeAccessAdapter</strong></p>\n\n<pre><code>public Employee findEmployee(String empID){\n    EmployeeAccessContainer container = facade.findEmployeeAccess(empID);\n    return translator.translate(container);\n}\n</code></pre>\n\n<p><strong>EmployeeAccessTranslator</strong></p>\n\n<pre><code>public Employee translate(EmployeeAccessContainer container){\n    Employee emp = null;\n    if (container != null) {\n        employee = new Employee();\n        employee.setEmpID(idPrefix + container.getEmployeeDTO().getEmpID());\n        ...(more complex mappings)\n</code></pre>\n    "},{"t":"What should be included in an Application Architecture checklist?","l":"http://stackoverflow.com/questions/929133/what-should-be-included-in-an-application-architecture-checklist","q":"\n\n<p>I'm trying to come up with a checklist or set of questions/criteria to assess and evaluate proposed or emergent architectures (perform architectural reviews).  What are the most important questions you ask when trying to plan, assess or review an architecture?  </p>\n\n<p>I know this is a large topic so I'd like to constrain it to a single end-to-end system and not the architecture for an entire organization.</p>\n\n<p><em>Code Complete</em> provides a decent starting point:</p>\n\n<blockquote>\n  <p>Architecture</p>\n  \n  <ul>\n  <li>Is the overall organization of the program clear, including a good\n  architectural overview and\n  justification?</li>\n  <li>Are modules well defined, including their functionality and\n  their interfaces to other modules?</li>\n  <li>Are all the functions listed in the requirements covered sensibly, by\n  neither too many or too few modules?</li>\n  <li>Is the architecture designed to accommodate likely changes?</li>\n  <li>Are necessary buy-vs.-build decisions included?</li>\n  <li>Does the architecture describe how reused code will be made to conform to\n  other architectural objectives?</li>\n  <li>Are all the major data structures hidden behind access routines?</li>\n  <li>Is the database organization and content justified?</li>\n  <li>Are all key algorithms described and justified?</li>\n  <li>Are all major objects described and justified?</li>\n  <li>Is a strategy for handling user input described?</li>\n  <li>Is a strategy for handling I/O described and justified?</li>\n  <li>Are key aspects of the user interface defined?</li>\n  <li>Is the user interface modularized so that changes in it won't affect the\n  rest of the program?</li>\n  <li>Are memory-use estimates and a strategy for memory management\n  described and justified?</li>\n  <li>Does the architecture set space and speed budgets for each module?</li>\n  <li>Is a strategy for handling strings described, and are character-string\n  storage estimates provided?</li>\n  <li>Is a coherent error-handling strategy provided?</li>\n  <li>Are error messages managed as a set to present a clean user interface?</li>\n  <li>Is a level of robustness specified?</li>\n  <li>Is any part over- or under-architected? Are expectations in\n  this area set out explicitly?</li>\n  <li>Are the major system goals clearly stated?</li>\n  <li>Does the whole architecture hang together conceptually?</li>\n  <li>Is the top-level design independent of the machine and\n  language that will be used to\n  implement it?</li>\n  <li>Are the motivations for all major decisions provided?</li>\n  <li>Are you, as a programmer who will implement the system, comfortable with\n  the architecture?</li>\n  </ul>\n</blockquote>\n\n<p>I'm looking for practical knowledge with examples, e.g., what were the most painful points in an architecture you've created?  </p>\n    ","a":"\n<p>Based on my research, here are some architectural review checklists I've found that do this question a little more justice, and provide some background on what an architecture review is.  (Seems to be a bit of confusion about it here.)  </p>\n\n<p>Each of these potential candidates include a number of different categories.  The overall importance of these categories will vary somewhat depending on business needs.  IMHO, that's OK.  It's much less costly to ask another question when going through a checklist for a review and rule it out than it is to miss a question or category entirely because it didn't seem important enough to include on a checklist initially.</p>\n\n<ul>\n<li>\"<a href=\"http://www.codeproject.com/KB/architecture/SWArchitectureReview.aspx\">Software architecture review guidelines</a>\" by Alexander Nowak</li>\n<li>\"<a href=\"http://www.win.tue.nl/~wstomv/edu/2im24+2im25/add.html\">Review Checklist for Architectural Design Document[s]</a>\" by Tom Verhoeff</li>\n<li>\"<a href=\"http://msdn.microsoft.com/en-us/library/aa302332.aspx\">Checklist: Architecture and Design Review</a>\" from Microsoft patterns &amp; practices Developer Center</li>\n<li>\"<a href=\"http://it.toolbox.com/blogs/enterprise-solutions/conceptual-architecture-checklist-22364\">Conceptual Architecture Checklist</a>\" by Craig Borysowich </li>\n<li>\"<a href=\"http://apparch.codeplex.com/Wiki/View.aspx?title=Checklist%20-%20Architecture%20and%20Design&amp;referringTitle=Home\">App Arch Guide 2.0 Knowledge Base: Checklist - Architecture and Design</a>\" by J.D. Meier, Alex Homer, et al. (found via Peter Stuer's link) </li>\n<li>\"<a href=\"http://www.opengroup.org/architecture/togaf9-doc/arch/chap48.html#tag_49_05\">TOGAF Architecture Compliance Review Checklists</a>\" from the Open Group</li>\n<li>\"<a href=\"http://architects.dzone.com/news/architecture-review-process\">Architecture Review Process</a>\" by Ricky Ho</li>\n</ul>\n\n<p>There also appears to be a white-paper written on this topic, although I have not read it.  It attempts to answer this question over the course of about 11 pages.</p>\n\n<ul>\n<li><a href=\"http://ieeexplore.ieee.org/xpl/freeabs_all.jsp?tp=&amp;arnumber=1407824&amp;isnumber=30525\">Architecture reviews: practice and experience</a> by Maranzano, Rozsypal, et al.</li>\n</ul>\n\n<p>Additionally a colleague recommended a set of books from Springer, though I have not checked any of these out myself:</p>\n\n<ul>\n<li><a href=\"http://www.springer.com/series/8371?detailsPage=titles\">The Enterprise Engineering Series</a>   from Springer</li>\n</ul>\n    "},{"t":"How to implement ASP.NET membership provider in my domain model","l":"http://stackoverflow.com/questions/811137/how-to-implement-asp-net-membership-provider-in-my-domain-model","q":"\n\n<p>In a website, I need to integrate membership and authentication. So I want to use the functionality of ASP.NET Membership, but I have other custom stuff, that a \"user\" has to do. </p>\n\n<p>So I am sitting here with my pencil and paper, drawing lines for my domain model... And how can I best utilize the ASP.Net membership, but extend it to fill my needs?</p>\n\n<p>Should I create a class that inherits from a MembershipUser and extend it with my own properties and methods (and save this in a seperate table). Or should I let the MembershipUser be a property on my custom User/Client object?</p>\n\n<p>What would be a good solid way to do this?</p>\n    ","a":"\n<p>I've thought about it and there are 2 ways that seem appropriate (of course there are more ways to make it work).</p>\n\n<h2>Custom Membership Provider</h2>\n\n<p>You change the membership provider to use your own and use your User object to store all the information.</p>\n\n<p>The problem with this one is that it involves a lot of re-implementation of things that are already well handled by Asp.Net. The good thing is that you have a single User object with all the details.</p>\n\n<h2>Link from a Membership User to your User</h2>\n\n<p>With this method, you would use the original Membership provider to handle the user name and password, but you link your own User object with this one with something like the user name by using a service for example.</p>\n\n<p>It's really easy to set up, you just need to create a service that would be used like this:</p>\n\n<pre><code>string userName = \"Jon Skeet\";\nUser user = new UserManagementServices().GetUserByUserName(userName);\n</code></pre>\n    "},{"t":"Does Android castrate the ARM's Jazelle technology?","l":"http://stackoverflow.com/questions/1153076/does-android-castrate-the-arms-jazelle-technology","q":"\n\n<p>The justification that I've seen for shall we say \"Bastardizing\" the Java bytecodes in Android was performance.  (I suspect there is another reason.)  However by changing the byte codes haven't they made hardware acceleration technologies such as Jazelle moot, and thus actually degraded the performance available for a Mobile Java platform?</p>\n\n<p>It appears counter intuitive to me knowing that the target platform is a ARM based mobile platform.  While it MIGHT give you better performance on other CPU architectures it seems to spit in the face of ARM and Jazelle.</p>\n\n<p>What sort of quantitative effect does it have on Java performance?</p>\n\n<p>Does it actually improve performance, and if so how?</p>\n\n<p>What's the effect on other platforms? (i.e. x86,mips,yadda,yadda,yadda...)</p>\n    ","a":"\n<p>Yes Dalvik makes Jazelle useless. The only question is was Jazelle useful to begin with or is it 90% marketing hype?  A good JIT or AOT(ahead of Time) compiler tends to give much better performance than trying to use specialized instructions. The register based approach of Dalvik might be faster than a traditional java bytecode interpreter but if the difference in minor between that of an interpreter and that of a JIT. Hopefully one of the next versions of Android has a JIT.</p>\n\n<p>It takes ~5-10 years to write a good virtual machine with state of the art garbage collectors and optimizers. Sun (and Microsoft) have spent those years. Google hasn't. Hopefully they will keep investing in it so that one day Android Java code isn't a 90% slower than it should be.</p>\n    "},{"t":"RESTful Authorization","l":"http://stackoverflow.com/questions/1408571/restful-authorization","q":"\n\n<p>I'm building a community-based site in Rails for the members of a real-world organization. I'm trying to adhere to the best practices of RESTful design, and most of it is more or less by-the-book. The issue that's making my brain run in neat RESTful circles is that of authorization. <em>Authentication</em> is an easy, long-solved problem with widely-accepted RESTful solutions, but RESTful authorization seems to be a bit of a black art. I'm trying to find the approach that will provide the most general and flexible framework for controlling access to resources while being as simple as possible, all while conforming to a RESTful architecture. (Also, a pony.)</p>\n\n<p>Considerations:</p>\n\n<ol>\n<li>I need to control access to a variety of resources, such as Users, Pages, Posts, et cetera.</li>\n<li>Authorization for a given resource must be finer-grained than simple CRUD.</li>\n<li>I wish to allow myself and others to edit the authorization rules from within the application.</li>\n<li>Authorization rules should be allowed to depend on predicates, such as (conceptually) Owner(User, Resource) or Locked(Topic)</li>\n</ol>\n\n<p>Consideration (2) is the one that concerns me the most. There seems to be an impedance mismatch between my conception of permissions and the RESTful conception of actions. For example, take Posts (as in a message board). REST dictates the existence of four operations on the Post resource: Create, Read, Update, and Delete. It's simple to say that a user should be able to Update his own Posts, but only certain users (or roles, or groups) should be permitted to Lock them. The traditional way to represent locking is within the state of the Post, but that leads to the smell that a User under the same conditions may or may not be able to Update a Post depending on the (completely valid) values he supplies. It seems clear to me that there are really two different actions to change the state of the Post, and to shoehorn them is merely to disguise a violation of RESTful principles.</p>\n\n<p>(I should note that this problem is quite distinct from the problem of an Update failing due to <em>invalid or inconsistent</em> data—a lock request from an unprivileged user is in principle quite valid, simply disallowed.)</p>\n\n<blockquote>\n  <p><em>Isn't decomposition another word for rot?</em></p>\n</blockquote>\n\n<p>This may be overcome by decomposing the Post: a Lock is a subresource of a particular post, and to Create or Destroy one may then have separate permissions. This solution has the ring of REST to it, but is brings with it both theoretical and practical difficulties. If I factor out locks, then what about other attributes? Suppose I decide, in a fit of caprice, that only a member of Administrator should be allowed to modify the Post's title? A simple change in authorization would then require a restructuring of the database to accommodate it! This is not much of a solution. To allow for this kind of flexibility under a strategy of decomposition would require that every attribute be a resource. This presents a bit of a dilemma. My implicit assumption has been that a resource is represented in the database as a table. Under this assumption, a resource for every attribute means a table for every attribute. Clearly, this is not practical. However, to remove this assumption presents an impedance mismatch between tables and resources, which could open up its own can of worms. To use this approach would require far more in-depth consideration than I have given it. For one thing, users reasonably expect to be able to edit multiple attributes at once. Where does the request go? To the smallest resource that contains all attributes? To each individual resource in parallel? To the moon?</p>\n\n<blockquote>\n  <p><em>Some of these things are not like the others…</em></p>\n</blockquote>\n\n<p>Suppose then that I do not decompose attributes. The alternative then seems to be defining a set of privileges for each resource. At this point, however, the homogeneity of REST is lost. In order to define access rules for a resource, the system must have specific knowledge of that resource's capabilities. Furthermore, it is now impossible to generically propagate permissions to descendant resources—even if a child resource had a privilege of the same name, there's no inherent semantic connection between the privileges. Defining a REST-like set of standard privileges seems to me to be the worst of both worlds, so I's be stuck with a separate permissions hierarchy for each type of resource.</p>\n\n<blockquote>\n  <p><em>Well, we did do the nose. And the hat. But it's a resource!</em></p>\n</blockquote>\n\n<p>One suggestion I've seen that mitigates some of the disadvantages of the above approach is to define permissions as create/delete on <em>resources</em> and read/write on <em>attributes</em>. This system is a compromise between attributes-as-resources and privileges-per-resource: one is still left with only CRUD, but for the purposes of authorization, Read and Update pertain to attributes, which could be thought of as pseudo-resources. This provides many of the practical benefits of the attributes-as-resources approach, although the conceptual integrity is, to a certain extent, compromised. Permissions could still propagate from resource to resource and from resource to pseudo-resource, but never from a pseudo-resource. I have not fully explored the ramifications of this strategy, but it seems as though it may be promising. It occurs to me that such a system would best function as an integral part of the Model. In Rails, for example, it could be a retrofit of <code>ActiveRecord</code>. This seems rather drastic to me, but authorization is such a fundamental cross-cutting concern that this may be justified.</p>\n\n<blockquote>\n  <p><em>Oh, and don't forget about the pony</em></p>\n</blockquote>\n\n<p>All of this ignores the issue of predicative permissions. Obviously, a User should be able to edit his own Posts, but no one else's. Equally obviously, the admin-written permissions table should not have separate records for each user. This is hardly an uncommon requirement—the trick is making it generic. I think that all of the functionality I need could be gained by making only the <em>rules</em> predicative, so that the applicability of the rule could be decided quickly and immediately. A rule \"<code>allow User write Post where Author(User, Post)</code>\" would translate to \"<code>for all User, Post such that Author(User, Post), allow User write Post</code>\", and \"<code>deny all write Post where Locked(Post)</code>\" to \"<code>for all Post such that Locked(Post), deny all write Post</code>\". (It would be <em>grand</em> if all such predicates could be expressed in terms of one User and one Resource.) The conceptually resultant \"final\" rules would be non-predicative. This raises the question of how to implement such a system. The predicates should be members of the Model classes, but I'm not sure how one could refer to them gracefully in the context of the rules. To do so safely would require some sort of reflection. Here again I have a feeling that this would require a retrofit of the Model implementation.</p>\n\n<blockquote>\n  <p><em>How do you spell that again?</em></p>\n</blockquote>\n\n<p>The final question is how to best represent these authorization rules as data. A database table might do the trick, with enum columns for allow/deny and C/R/U/D (or perhaps CRUD bits? or perhaps {C, R, U, D} × {allow, deny, inherit}?), and a resource column with a path. Perhaps, as a convenience, an \"inherit\" bit. I'm at a loss as far as predicates. Separate table? Certainly lots of caching to prevent it from being <em>too</em> ungodly slow.</p>\n\n<hr>\n\n<p>I guess that this is a lot to ask for. I tried to do my homework before asking the question, but at this point I really need an outside perspective. I'd appreciate any input that any of y'all might have on the problem.</p>\n    ","a":"\n<p>Sorry I don't have time to do this question justice, but it is nice to see some well thought out questions on SO.\nHere are some comments:</p>\n\n<p>Don't fall into the trap of mapping the HTTP verbs to CRUD.  Yes GET and DELETE map pretty cleanly, but PUT can do Create and Update (but complete replacement only) and POST is a wildcard verb.  POST is really to handle everything that does not fit into GET, PUT and \nDELETE.  </p>\n\n<p>Using attributes to represent an object's status is only one approach to state management.  I am guessing you can imagine what the following request might do:</p>\n\n<pre><code>POST /LockedPosts?url=/Post/2010\n</code></pre>\n\n<p>A subresource is also a valid approach to manage the current state of a resource.  I would not feel obliged to treat a resource's \"state\" attributes and its \"data\" attributes in  a consistent manner.</p>\n\n<p>Attempting to map resources directly to tables is going to seriously constrain you.  Don't forget that when you follow the REST constraints you suddenly are very limited in the verbs you have available.  You need to be able to make up for that in being creative in the resources that you use.  Limiting yourself to one resource equals one table will severely limit the functionality of your end application.  </p>\n\n<p>We regularly see Rails, ASP.NET MVC and WCF Rest users posting questions here on StackOverflow about how do certain things within the constraints of REST.  The problem is often not a constraint of REST but in the limitations of the framework in its support for RESTful applications.  I think it is essential to first find a RESTful solution to a problem and then see if that can be mapped back to your framework of choice.</p>\n\n<p>As far as creating a permissions model that exists at a finer grain than the resource itself.  Remember that one of the key REST constrains is hypermedia.  Hypermedia can be used for more than just finding related entities, it can also be used to represent valid/permitted state transitions.  If you return a representation than contains embedded links, conditionally based on permissions, then you can control what actions can be  performed by who.  i.e. If a user has permissions to unlock POST 342 then you could return the following link embedded in the representation:</p>\n\n<pre><code>&lt;Link href=\"/UnlockedPosts?url=/Post/342\" method=\"POST\"/&gt;\n</code></pre>\n\n<p>If they don't have that permission, then don't return the link.  </p>\n\n<p>I think one of your difficulties here is that you are trying to chew too big of a problem at once.  I think you need to look at the RESTful interface that you are trying to expose to the client as a distinct problem from how you are going to manage the permissions and predicates in order to manage authorization in your domain model.  </p>\n\n<p>I realize that I haven't directly answered any of your questions, but hopefully I've provided some viewpoints that may help in some way.</p>\n    "},{"t":"How do I abstract the domain layer from the persistence layer in Scala","l":"http://stackoverflow.com/questions/11542153/how-do-i-abstract-the-domain-layer-from-the-persistence-layer-in-scala","q":"\n\n<p>UPDATE:\nI've edited the title and added this text to better explain what I'm trying to achieve: I'm trying to create a new application from the ground up, but don't want the business layer to know about the persistence layer, in the same way one would not want the business layer to know about a REST API layer. Below is an example of a persistence layer that I would like to use. I'm looking for good advice on integrating with this i.e. I need help with the design/architecture to cleanly split the responsibilities between business logic and persistence logic. Maybe a concept along the line of marshalling and unmarshalling of persistence objects to domain objects.</p>\n\n<p>From a SLICK (a.k.a. ScalaQuery) <a href=\"https://github.com/slick/slick/blob/01251edbc7f970f29f3a471d7eee27460e6846cf/src/test/scala/scala/slick/test/ql/ForeignKeyTest.scala#L177\">test example</a>, this is how you create a many-to-many database relationship. This will create 3 tables: a, b and a_to_b, where a_to_b keeps links of rows in table a and b.</p>\n\n<pre><code>object A extends Table[(Int, String)](\"a\") {\n  def id = column[Int](\"id\", O.PrimaryKey)\n  def s = column[String](\"s\")\n  def * = id ~ s\n  def bs = AToB.filter(_.aId === id).flatMap(_.bFK)\n}\n\nobject B extends Table[(Int, String)](\"b\") {\n  def id = column[Int](\"id\", O.PrimaryKey)\n  def s = column[String](\"s\")\n  def * = id ~ s\n  def as = AToB.filter(_.bId === id).flatMap(_.aFK)\n}\n\nobject AToB extends Table[(Int, Int)](\"a_to_b\") {\n  def aId = column[Int](\"a\")\n  def bId = column[Int](\"b\")\n  def * = aId ~ bId\n  def aFK = foreignKey(\"a_fk\", aId, A)(a =&gt; a.id)\n  def bFK = foreignKey(\"b_fk\", bId, B)(b =&gt; b.id)\n}\n\n(A.ddl ++ B.ddl ++ AToB.ddl).create\nA.insertAll(1 -&gt; \"a\", 2 -&gt; \"b\", 3 -&gt; \"c\")\nB.insertAll(1 -&gt; \"x\", 2 -&gt; \"y\", 3 -&gt; \"z\")\nAToB.insertAll(1 -&gt; 1, 1 -&gt; 2, 2 -&gt; 2, 2 -&gt; 3)\n\nval q1 = for {\n  a &lt;- A if a.id &gt;= 2\n  b &lt;- a.bs\n} yield (a.s, b.s)\nq1.foreach(x =&gt; println(\" \"+x))\nassertEquals(Set((\"b\",\"y\"), (\"b\",\"z\")), q1.list.toSet)\n</code></pre>\n\n<p>As my <em>next</em> step, I would like to take this up one level (I still want to use SLICK but wrap it nicely), to working with objects. So in pseudo code it would be great to do something like:</p>\n\n<pre><code>objectOfTypeA.save()\nobjectOfTypeB.save()\nlinkAtoB.save(ojectOfTypeA, objectOfTypeB)\n</code></pre>\n\n<p>Or, something like that. I have my ideas on how I might approach this in Java, but I'm starting to realize that some of my object-oriented ideas from pure OO languages are starting to fail me. Can anyone please give me some pointers as to how approach this problem in Scala.</p>\n\n<p>For example: Do I create simple objects that just wrap or extend the table objects, and then include these (composition) into another class that manages them?</p>\n\n<p>Any ideas, guidance, example (please), that will help me better approach this problem as a designer and coder will be greatly appreciated.</p>\n    ","a":"\n<p>A good solution for simple persistence requirements is the ActiveRecord pattern: <a href=\"http://en.wikipedia.org/wiki/Active_record_pattern\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Active_record_pattern</a> . This is implemented in Ruby and in Play! framework 1.2, and you can easily implement it in Scala in a stand-alone application</p>\n\n<p>The only requirement is to have a singleton DB or a singleton service to get a reference to the DB you require. I personally would go for an implementation based on the following:</p>\n\n<ul>\n<li>A generic trait ActiveRecord</li>\n<li>A generic typeclass ActiveRecordHandler</li>\n</ul>\n\n<p>Exploiting the power of implicits, you could obtain an amazing syntax:</p>\n\n<pre><code>trait ActiveRecordHandler[T]{\n\n  def save(t:T):T\n\n  def delete[A&lt;:Serializable](primaryKey:A):Option[T]\n\n  def find(query:String):Traversable[T]\n}\n\nobject ActiveRecordHandler {\n  // Note that an implicit val inside an object with the same name as the trait \n  // is  one of the way to have the implicit in scope.\n  implicit val myClassHandler = new ActiveRecordHandler[MyClass] {\n\n    def save(myClass:MyClass) = myClass\n\n    def delete[A &lt;: Serializable](primaryKey: A) = None\n\n    def find(query: String) = List(MyClass(\"hello\"),MyClass(\"goodbye\"))\n  }\n}\n\ntrait ActiveRecord[RecordType] {\n  self:RecordType=&gt;\n\n\n  def save(implicit activeRecordHandler:ActiveRecordHandler[RecordType]):RecordType = activeRecordHandler.save(this)\n\n  def delete[A&lt;:Serializable](primaryKey:A)(implicit activeRecordHandler:ActiveRecordHandler[RecordType]):Option[RecordType] = activeRecordHandler.delete(primaryKey)\n}\n\ncase class MyClass(name:String) extends ActiveRecord[MyClass] \n\nobject MyClass {\n  def main(args:Array[String]) = {\n    MyClass(\"10\").save\n  }\n}\n</code></pre>\n\n<p>With such a solution, you only need your class to extends ActiveRecord[T] and have an implicit ActiveRecordHandler[T] to handle this.</p>\n\n<p>There is actually also an implementation: <a href=\"https://github.com/aselab/scala-activerecord\" rel=\"nofollow\">https://github.com/aselab/scala-activerecord</a> which is based on similar idea, but instead of making the ActiveRecord having an abstract type, it declares a generic companion object.</p>\n\n<hr>\n\n<p>A general but very important comment on the ActiveRecord pattern is that it helps meet simple requirements in terms of persistence, but cannot deal with more complex requirements: for example is when you want to persist multiple objects under the same transaction. </p>\n\n<p>If your application requires more complex persistence logic, the best approach is to introduce a persistence service which exposes only a limited set of functions to the client classes, for example </p>\n\n<p><code>def persist(objectsofTypeA:Traversable[A],objectsOfTypeB:Traversable[B])</code></p>\n\n<p>Please also note that according to your application complexity, you might want to expose this logic in different fashions:</p>\n\n<ul>\n<li>as a singleton object in the case your application is simple, and you do not want your persistence logic to be pluggable</li>\n<li>through a singleton object which acts as a sort as a \"application context\", so that in your application at startup you can decide which persistence logic you want to use.</li>\n<li>with some sort of lookup service pattern, if your application is distributed.</li>\n</ul>\n    "},{"t":"What is the difference between an MVC Model object, a domain object and a DTO","l":"http://stackoverflow.com/questions/3853749/what-is-the-difference-between-an-mvc-model-object-a-domain-object-and-a-dto","q":"\n\n<p>What is the difference between a MVC Model object, a domain object and a DTO?</p>\n\n<p>My understanding is:</p>\n\n<p>MVC Model object:</p>\n\n<p>Models the data to be displayed by a corresponding view. As such may not map directly on to a domain object, i.e. may include data from one or more domain objects.</p>\n\n<ol>\n<li>Client side</li>\n<li>May contain business logic, e.g. validation, calculated properties, etc</li>\n<li>No persistence related methods</li>\n</ol>\n\n<p>Domain object:</p>\n\n<p>Object that models a real world object in the problem domain like Reservation, Customer, ORder, etc. Used to persists data.</p>\n\n<ol>\n<li>Server side</li>\n<li>No business logic</li>\n</ol>\n\n<p>DTO (Data Transfer Object):</p>\n\n<p>An object used to transfer data between layers when the layers are in separate processes, e.g. from a DB to a client app. Allows a single transaction across the wire rather than multiple calls. A DTO contains just data and accessor methods, no logic. The data is for a particular DB transaction so may not may directly on to a domain object, i.e. may include data from one or more domain objects.</p>\n\n<ol>\n<li>Used on both sides as passed between layers</li>\n<li>No business logic</li>\n<li>No persistence related methods</li>\n</ol>\n\n<p>So to the questions:</p>\n\n<p>(1) Is my understanding correct? Am I missing some key points?</p>\n\n<p>(2) Are there any reasons not to use Domain objects as the MVC Model assuming that the Model objects do not require extra business logic?</p>\n\n<p>(3) Are there any reasons not to use DTOs as the MVC Model assuming that the Model objects do not require extra business logic?</p>\n\n<p>Thanks.</p>\n\n<p>Tim</p>\n    ","a":"\n<p>The Domain and DTO can also be your \"model\" objects - you can have a view to render the details of the \"Customer\" domain object. </p>\n\n<p>A domain object can have business logic to enforce the properties of the domain entity. validation is one such case. The domain object by itself does not contain persistence related methods, but it can have meta-data (like annotations) to support persistence</p>\n\n<p>the POJO programming model makes it possible to use the same object as your domain, DTO and model objects - essentially, you will not be implemented any extraneous interfaces that will only apply to one layer but does not apply to others. </p>\n    "},{"t":"Is UML still seen as a viable way of documenting a software design?","l":"http://stackoverflow.com/questions/925786/is-uml-still-seen-as-a-viable-way-of-documenting-a-software-design","q":"\n\n<p>Is UML still seen as a viable way of a documenting a software design?</p>\n\n<p>Extra points for references that back up any claims :)</p>\n    ","a":"\n<p>I am responding to the new version of the question which speaks to UML as a documentation tool.  I will try and role in UML as a communication tool as well, because they are one in the same.</p>\n\n<p><strong>Context:</strong>  This perspective is driven of my daily job as an Architect having to design across hundreds of systems/software, 10,000 hour+ efforts, and maintaining consistent documentation and practices for a portfolio of systems.  This means that I have had to grapple with documentation quality, consistency, and definition many times.</p>\n\n<p><strong>Summary:</strong> What else is there?  Sure you can discuss levels of documentation, is UML really better than reading code for conditional logic?  Likely not, but on a whole there is no real alternative if the problem space is large enough.</p>\n\n<p>If UML is nothing else it <strong>is</strong> for documentation and communication.  \"UML Distilled\" written by Martin Fowler, which is nearly the defacto standard for UML books, carries this opinion.  Fowler, if I read correctly, believes UMLs primary use is for communication, which documentation is, just the static kind.  Not so much low level specs and code generation.</p>\n\n<p>IBM, Borland, Microsoft, and Eclipse support UML with large complex tools.  Many other smaller or targeted vendors also provide UML tools.  I am not aware of a more accepted/implemented diagram/modeling standard out there.</p>\n\n<p>Additionally consider the alternatives, what diagram notation is more common?  Why not use what most people know.  Most colleges/university if they teach any diagramming or modelling use UML.  Other than some flow or conditional logic diagram styles there is not much else out there, well documented and standardized.</p>\n\n<p>Standard notation is even more critical that what most people know.  In large projects you can't always read the code, talk to the person that wrote it, or ask the business partner what they wanted again.  This is where standards are key.  Inconsistent usage will cause confusion, and it really will if people are allowed to invent or add to the symbols in an informal way.  Additionally, you don't want to create a document and always have to explain what you meant.</p>\n\n<p>Never invent unless you have too, which is the most likely alternative to UML.  Think about every time a new person joins the team or company.  What does a box mean, arrow?  Can this arrow connect to this triangle in this direction, and what does it mean?  You basically have to invent a domain specific language/model.  So you need a training presentation, tutorials, examples, review work, schedule training sessions, maintain the invented documentation method etc.  Then of course you switch out-task partners, or hire a new person and you have to do it all over again.  Let people focus on learning the systems not your documentation method, or if the have to make it transferable knowledge or skill like UML.  Let the experts focus on coding and designing, not inventing a documentation/diagram standard.</p>\n\n<p><strong>To all the UML critics</strong>  I do not live in a ivory tower or glass bubble, I have to live with hundreds of different documentation methods everyday as people invent them or I am looking at the next vendor technology.  UML is <strong>not</strong> perfect, but it is the most common, is good enough, and not trivially replaceable.  </p>\n\n<p>Valid additional questions:</p>\n\n<ul>\n<li>What should I document visually with UML, where can code comments take over?</li>\n<li>What span or aspects are more important?</li>\n<li>What might be a consistent set of artifacts that work for my kind of systems or applications?  (This is a critical question if you work in an enterprise with hundreds of applications/systems)</li>\n<li>Where do we store the documentation and make it searchable and discoverable.</li>\n</ul>\n    "},{"t":"How to build large applications","l":"http://stackoverflow.com/questions/473797/how-to-build-large-applications","q":"\n\n<p>I think I've become quite good at the basics of programming (for a variety of languages).  I can write a *good** line of code.   I can write a <em>good</em> method.  I can write a <em>good</em> class. I can write a <em>good</em> group of classes.  I can write <em>good</em> small or medium application.</p>\n\n<p>I do not however know how to build a <em>good</em> large application.  Particularly in the case where multiple technologies are involved and more are likely to become involved with time.  Say a project with a large web front-end, a large server back-end that connects to some other integration back-end and finally a large and complex database.  Oh, I've been involved in a few of these applications and I could build one I'm sure. I'm not so sure however that it could qualify as \"good\".  </p>\n\n<p>My question is thus for a reference to a book or other good source of reading where I could learn how to distribute and organize code and data for general large projects.  For example, would I want to layer things very strictly or would I want to encapsulate it independent units instead.  Would I want to try to keep most of the logic in the same pool, or should it just be distributed as it seems most logical when adding whatever feature I'm adding.  </p>\n\n<p>I've seen lots of general principals on these issues (e.g. No spaghetti code, meatball code...) and read a few excellent articles that discuss the matter but I've never encountered a source which would lead me to concrete <strong>practical</strong> knowledge.  I realize the difficultly of the question and so I'd be happy to just hear about the readings that others have found to help them in their quest for such knowledge.</p>\n\n<p>As always, thank you for your replies.</p>\n\n<blockquote>\n  <p>****Given the debated nature of the definition of \"good\" code, the term \"good\" in this context won't be defined (it means whatever you think it ought to mean).</p>\n</blockquote>\n    ","a":"\n<p>As programmers, we like to believe we are smart people, so it's hard to admit that something is too big and complex to even think about all at once.  But for a large-scale software project it's true, and the sooner you acknowledge your <strong>finite brain capacity</strong> and start coming up with ways to simplify the problem, the better off you'll be.</p>\n\n<p>The other main thing to realise is that you will spend most of your time <strong>changing existing code</strong>.  Building the initial codebase is just the honeymoon period -- you need to design your code with the idea in mind that, 6 months later you will be sitting in front of it trying to solve some problem without a clue how this particular module works, even though you wrote it yourself.</p>\n\n<p>So, what can we do?</p>\n\n<p><strong>Minimise coupling</strong> between unrelated parts of your code.  Code is going to change over time in ways you can't anticipate -- there will be showstopper problems integrating with unfamiliar products, requirements changes -- and those will cause ripple-on changes.  If you have established stable interfaces and coded to them, you can make any changes you need in the implementation without those changes affecting code that uses the interface.  You need to <strong>spend time and effort</strong> developing interfaces that will stand the test of time -- if an interface needs to change too, you're back to square one.</p>\n\n<p><strong>Establish automated tests</strong> that you can use for regression testing.  Yes, it's a lot of work up front.  But it will pay off in the future when you can make a change, run the tests, and establish that <em>it still works</em> without that anxious feeling of wondering if everything will fall over if you commit your latest change to source control.</p>\n\n<p><strong>Lay off the tricky stuff.</strong>  Every now and then I see some clever C++ template trick and think, \"Wow!  That's just what my code needs!\"  But the truth is, the decrease in how readable and readily understandable the code becomes is often simply not worth the increased genericity.  If you're someone like me whose natural inclination is to try to solve every problem in as general a manner as possible, you need to learn to restrain it until you actually come across the <em>need</em> for that general solution.  If that <em>need</em> arises, you might have to rewrite some code -- it's no big deal.</p>\n    "},{"t":"What Design Patterns are used on iOS other than MVC?","l":"http://stackoverflow.com/questions/12436497/what-design-patterns-are-used-on-ios-other-than-mvc","q":"\n\n<p>I need to know the design patterns we use in iPhone development other then MVC.</p>\n\n<p>Please reply with any sample explanation or example of code snippet.</p>\n\n<p>Thanks. </p>\n    ","a":"\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW32\">Abstract Factory</a></h2>\n\n<p>The Abstract Factory pattern provides an interface for creating families of related or dependent objects without specifying their concrete classes. The client is decoupled from any of the specifics of the concrete object obtained from the factory.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW35\">Adapter</a></h2>\n\n<p>The Adapter design pattern converts the interface of a class into another interface that clients expect. Adapter lets classes work together that couldn’t otherwise because of incompatible interfaces. It decouples the client from the class of the targeted object.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW25\">Chain of Responsibility</a></h2>\n\n<p>The Chain of Responsibility design pattern decouples the sender of a request from its receiver by giving more than one object a chance to handle the request. The pattern chains the receiving objects together and passes the request along the chain until an object handles it. Each object in the chain either handles the request or passes it to the next object in the chain.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW14\">Command</a></h2>\n\n<p>The Command design pattern encapsulates a request as an object, thereby letting you parameterize clients with different requests, queue or log requests, and support undoable operations. The request object binds together one or more actions on a specific receiver. The Command pattern separates an object making a request from the objects that receive and execute that request.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW15\">Composite</a></h2>\n\n<p>The Composite design pattern composes related objects into tree structures to represent part-whole hierarchies. The pattern lets clients treat individual objects and compositions of objects uniformly. The Composite pattern is part of the Model-View-Controller aggregate pattern.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW43\">Decorator</a></h2>\n\n<p>The Decorator design pattern attaches additional responsibilities to an object dynamically. Decorators provide a flexible alternative to subclassing for extending functionality. As does subclassing, adaptation of the Decorator pattern allows you to incorporate new behavior without modifying existing code. Decorators wrap an object of the class whose behavior they extend. They implement the same interface as the object they wrap and add their own behavior either before or after delegating a task to the wrapped object. The Decorator pattern expresses the design principle that classes should be open to extension but closed to modification.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW47\">Facade</a></h2>\n\n<p>The Facade design pattern provides a unified interface to a set of interfaces in a subsystem. The pattern defines a higher-level interface that makes the subsystem easier to use by reducing complexity and hiding the communication and dependencies between subsystems.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW50\">Iterator</a></h2>\n\n<p>The Iterator design pattern provides a way to access the elements of an aggregate object (that is, a collection) sequentially without exposing its underlying representation. The Iterator pattern transfers the responsibility for accessing and traversing the elements of a collection from the collection itself to an iterator object. The Iterator defines an interface for accessing collection elements and keeps track of the current element. Different iterators can carry out different traversal policies.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW28\">Mediator</a></h2>\n\n<p>The Mediator design pattern defines an object that encapsulates how a set of objects interact. Mediator promotes loose coupling by keeping objects from referring to each other explicitly, and it lets you vary their interaction independently. These objects can thus remain more reusable.\nA \"mediator object” in this pattern centralizes complex communication and control logic between objects in a system. These objects tell the mediator object when their state changes and, in turn, respond to requests from the mediator object.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW54\">Memento</a></h2>\n\n<p>The Memento pattern captures and externalizes an object’s internal state—without violating encapsulation—so that the object can be restored to this state later. The Memento pattern keeps the important state of a key object external from that object to maintain cohesion.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW20\">Observer</a></h2>\n\n<p>The Observer design pattern defines a one-to-many dependency between objects so that when one object changes state, all its dependents are notified and updated automatically. The Observer pattern is essentially a publish-and-subscribe model in which the subject and its observers are loosely coupled. Communication can take place between the observing and observed objects without either needing to know much about the other.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW17\">Proxy</a></h2>\n\n<p>The Proxy design pattern provides a surrogate, or placeholder, for another object in order to control access to that other object. You use this pattern to create a representative, or proxy, object that controls access to another object, which may be remote, expensive to create, or in need of securing. This pattern is structurally similar to the Decorator pattern but it serves a different purpose; Decorator adds behavior to an object whereas Proxy controls access to an object.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW106\">Receptionist</a></h2>\n\n<p>The Receptionist design pattern addresses the general problem of redirecting an event occurring in one execution context of an application to another execution context for handling. It is a hybrid pattern. Although it doesn’t appear in the “Gang of Four” book, it combines elements of the Command, Memo, and Proxy design patterns described in that book. It is also a variant of the Trampoline pattern (which also doesn’t appear in the book); in this pattern, an event initially is received by a trampoline object, so-called because it immediately bounces, or redirects, the event to a target object for handling.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW66\">Singleton</a></h2>\n\n<p>The Singleton design pattern ensures a class only has one instance, and provides a global point of access to it. The class keeps track of its sole instance and ensures that no other instance can be created. Singleton classes are appropriate for situations where it makes sense for a single object to provide access to a global resource.</p>\n\n<h2><a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW26\">Template Method</a></h2>\n\n<p>The Template Method design pattern defines the skeleton of an algorithm in an operation, deferring some steps to subclasses. The Template Method pattern lets subclasses redefine certain steps of an algorithm without changing the algorithm’s structure.</p>\n\n<p><strong>Source:</strong> <a href=\"http://developer.apple.com/library/mac/documentation/Cocoa/Conceptual/CocoaFundamentals/CocoaDesignPatterns/CocoaDesignPatterns.html#//apple_ref/doc/uid/TP40002974-CH6-SW6\">Cocoa Design Patterns</a>.</p>\n    "},{"t":"Examples of open source high quality, well designed python software? [closed]","l":"http://stackoverflow.com/questions/736154/examples-of-open-source-high-quality-well-designed-python-software","q":"\n\n<p>I am looking for a well-engineered, well-built python application that could serve as a guideline to demonstrate best practices relating to software development in general, and more specifically in python. (Note that software in other languages would also be welcome provided they are of good quality and could serve as models of good architecture).</p>\n    ","a":"\n<ul>\n<li><a href=\"http://twistedmatrix.com/trac/\" rel=\"nofollow\">Twisted</a></li>\n<li><a href=\"http://www.djangoproject.com/\" rel=\"nofollow\">Django</a></li>\n<li><a href=\"http://www.selenic.com/mercurial/wiki/\" rel=\"nofollow\">Mercurial</a></li>\n<li><a href=\"http://elisa.fluendo.com/\" rel=\"nofollow\">Elisa</a></li>\n</ul>\n\n<p>Not completely sure about the latter two, but Twisted and Django are both very well written/organised/documented</p>\n    "},{"t":"What is domain logic?","l":"http://stackoverflow.com/questions/360860/what-is-domain-logic","q":"\n\n<p>What is domain logic?  The Wikipedia page for domain logic redirects to business logic.  Are they the same thing, and, if not, how do they differ?</p>\n    ","a":"\n<p>The domain is what you are modelling.</p>\n\n<p>If you are modelling a business problem, they are the same thing.</p>\n\n<p>If you are modelling something else, physics for instance, there is probably no business logic in your system, but the physics parts are still domain logic.</p>\n    "},{"t":"What is the cost of a function call?","l":"http://stackoverflow.com/questions/94794/what-is-the-cost-of-a-function-call","q":"\n\n<p>Compared to </p>\n\n<ul>\n<li>Simple memory access</li>\n<li>Disk access</li>\n<li>Memory access on another computer(on the same network)</li>\n<li>Disk access on another computer(on the same network)</li>\n</ul>\n\n<p>in C++ on windows.</p>\n    ","a":"\n<p>relative timings (shouldn't be off by more than a factor of 100 ;-)</p>\n\n<ul>\n<li>memory-access in cache = 1</li>\n<li>function call/return in cache = 2</li>\n<li>memory-access out of cache = 10 .. 300</li>\n<li>disk access = 1000 .. 1e8 (amortized depends upon the number of bytes transferred)\n<ul>\n<li>depending mostly upon seek times</li>\n<li>the transfer itself can be pretty fast</li>\n<li>involves at least a few thousand ops, since the user/system threshold must be crossed at least twice; an I/O request must be scheduled, the result must be written back; possibly buffers are allocated...</li>\n</ul></li>\n<li>network calls = 1000 .. 1e9 (amortized depends upon the number of bytes transferred)\n<ul>\n<li>same argument as with disk i/o</li>\n<li>the raw transfer speed can be quite high, but some process on the other computer must do the actual work</li>\n</ul></li>\n</ul>\n    "},{"t":"How to manage multiple clients with slightly different business rules?","l":"http://stackoverflow.com/questions/1662464/how-to-manage-multiple-clients-with-slightly-different-business-rules","q":"\n\n<p>We have written a software package for a particular niche industry.  This package has been pretty successful, to the extent that we have signed up several different clients in the industry, who use us as a hosted solution provider, and many others are knocking on our doors.  If we achieve the kind of success that we're aiming for, we will have literally hundreds of clients, each with their own web site hosted on our servers.</p>\n\n<p>Trouble is, each client comes in with their own little customizations and tweaks that they need for their own local circumstances and conditions, often (but not always) based on local state or even county legislation or bureaucracy.  So while probably 90-95% of the system is the same across all clients, we're going to have to build and support these little customizations.</p>\n\n<p>Moreover, the system is still very much a work in progress.  There are enhancements and bug fixes happening continually on the core system that need to be applied across all clients.</p>\n\n<p>We are writing code in .NET (ASP, C#), MS-SQL 2005 is our DB server, and we're using <a href=\"http://sourcegear.com\">SourceGear Vault</a> as our source control system.  I have worked with branching in Vault before, and it's great if you only need to keep 2 or 3 branches synchronized - but we're looking at maintaining hundreds of branches, which is just unthinkable.</p>\n\n<p>My question is: <strong>How do you recommend we manage all this?</strong></p>\n\n<p>I expect answers will be addressing things like object architecture, web server architecture, source control management, developer teams etc.  I have a few ideas of my own, but I have no real experience in managing something like this, and I'd really appreciate hearing from people who have done this sort of thing before.</p>\n\n<p>Thanks!</p>\n    ","a":"\n<p>I would recommend <strong>against</strong> maintaining separate code branches <em>per customer</em>.  This is a nightmare to maintain working code against your Core.</p>\n\n<p>I do recommend you do implement the <a href=\"http://www.dofactory.com/patterns/patternstrategy.aspx\">Strategy Pattern</a> and cover your \"customer customizations\" with automated tests (e.g. Unit &amp; Functional) whenever you are changing your Core.</p>\n\n<p><strong>UPDATE:</strong></p>\n\n<p>I recommend that before you get <em>too many customers,</em> you need to establish a system of creating and updating each of their websites.  How involved you get is going to be balanced by your current revenue stream of course, but you should have an end in mind.</p>\n\n<p>For example, when you just signed up Customer X (hopefully all via the web), their website will be created in XX minutes and send the customer an email stating it's ready.</p>\n\n<p>You definitely want to setup a <em>Continuous Integration (CI)</em> environment.  <a href=\"http://www.jetbrains.com/teamcity/\">TeamCity</a> is a great tool, and free.</p>\n\n<p>With this in place, you'll be able to check your updates in a staging environment and can then apply those patches across your production instances.</p>\n\n<p><strong>Bottom Line:</strong> Once you get over a handful of customers, you need to start thinking about automating your operations and your deployment as yet another <strong>application</strong> to itself.</p>\n\n<p><strong>UPDATE:</strong> This <a href=\"http://www.modernperlbooks.com/mt/2009/03/shooting-yourself-in-the-foot-with-customer-branches.html\">post</a> highlights the negative effects of branching per customer.</p>\n    "},{"t":"If SOA is dead, what's replacing it? [closed]","l":"http://stackoverflow.com/questions/936400/if-soa-is-dead-whats-replacing-it","q":"\n\n<p>Please forgive me if this question is dense.</p>\n\n<p><em>Background:</em> We have several internal applications that integrate at the database.  We are looking at how to break that up, and it seems like moving to an architecture where each application exposes its functionality through services, instead of calling other apps' databases, makes the most sense.  This seems like a service-oriented architecture to me.\nAs I look around for info on getting started with a service-oriented architecture, I see a lot of talk around this article: <a href=\"http://apsblog.burtongroup.com/2009/01/soa-is-dead-long-live-services.html\">SOA Is Dead; Long Live Services</a>.  And I also see this from Martin Fowler &amp; Jim Webber: <a href=\"http://www.infoq.com/presentations/soa-without-esb\">Does My Bus Look Big In This?</a>.</p>\n\n<p><em>Question:</em> </p>\n\n<ul>\n<li>Is SOA dead, or just the buzz around it?</li>\n<li>What is the best way to start on a service-oriented architecture so that it can stay as thin and simple as possible?</li>\n</ul>\n    ","a":"\n<p>SOA is a clever idea, but an enormous hype around it made people writing \"SOA IS NOW DEAD\". This is not true, just as sentence \"Structural programming is dead everybody do OOP now!\" is also not always true: sometimes structural code is the only option, but the decision should be made on evaluation, and not on hype.\nThe same is true when talking about SOA: sometimes you will need SOA, sometimes you will need services.</p>\n    "},{"t":"How do you know when you need a BPM solution?","l":"http://stackoverflow.com/questions/4869734/how-do-you-know-when-you-need-a-bpm-solution","q":"\n\n<p>My customer is looking for a Business Process Management (BPM) solution. What they need is simple document routing and an approval system. What are the drivers for implementing a BPM system? What is the threshold where a developer should suggest implementing a BPM solution vs. a workflow tool or custom development?</p>\n\n<p>When does jBPM fit? When does a state machine built into an app fit? What problems should exist that determine that you need to go with a solution similar to jBPM?</p>\n\n<p>I am looking for some real world examples of \"we tried to build the solution ourselves, but ended up going with AquaLogic/jBPM/Lombardi because of <strong><em>_</em></strong>\". Please fill in the blank.</p>\n    ","a":"\n<p>I wrote a workflow engine, because my employer wanted to own the IP, modeled after jBPM. Now the reason you use such a tool, instead of creating your own finite state machine, is accommodating changes without altering persistence and supporting edge cases of workflow processes as I'll explain. </p>\n\n<h1>Accommodating Changes Without Altering Persistence</h1>\n\n<p>Your typical, or perhaps better to call it \"naive\", finite state machine implementation features a set of database tables tightly coupled to the data managed and the process it flows through. There might be a way to keep past versions and track who took what action during the process as well. Where this runs into problems changes to data and process structure. Then those tightly coupled tables need to be altered to reflect the new structure and may not be backwardly compatible with the old. </p>\n\n<p>A workflow engine overcomes this challenge in two ways, by using serialization to represent the data and process, and abstracting integration points, in particular security. The serialization aspect means data and process can move together through the system. This allows data instances of the same type to follow completely different processes to the point the process can altered at runtime, by adding a new state for instance. And none of this requires changing the underlying storage. </p>\n\n<p>Integration points are means of injecting algorithms into the process and ties to authentication stores (i.e. users who must take action). Injected algorithms might include determinations of whether or not a state is completed, whereas authentication stores example is LDAP. </p>\n\n<p>Now the tradeoff is difficult search. For instance, because data is serialized, it's usually not possible to query historical information - other than retrieve the records, deserialize and analyze using code. </p>\n\n<h1>Edge Cases</h1>\n\n<p>The other aspect of a workflow tool is the experience embedded into its design and functionality that you will likely not consider rolling your own and may live to regret when you do need it. The two cases the come to my mind are timed tasks and parallel execution paths. </p>\n\n<p>Timed tasks are assigning an actor responsibility for data after a certain duration has passed. For instance, say a press release is writ and submitted for approval, and then sits for a week without review. What you probably want your system to do is identify that lingering document and draw attention of the appropriate parties. </p>\n\n<p>Parallel execution paths are uncommon in my experience (Content Management Systems), but are still a situation that arises often enough. It's the idea that a given piece of data is sent down two different paths of review or processing, only to be recombined at some later point. This type of problem requires having useful merging algorithms and the ability to represent the data multiply simultaneously. Weaving that into a homespun solution after the fact is much trickier than it may seem, especially if you want to keep track of historical data. </p>\n\n<h1>Conclusion</h1>\n\n<p>If your system is not likely to change, rolling your own may be an easier solution, particularly if changes can break old information. But if you suspect you have a need for that type of durability or will experience some of these uncommon but thorny scenarios, a workflow tool provides a lot more flexibility and insurance that you won't paint yourself into a corner as the data and business processes change. </p>\n    "},{"t":"How should I architect my iPhone app to talk to my website?","l":"http://stackoverflow.com/questions/3943597/how-should-i-architect-my-iphone-app-to-talk-to-my-website","q":"\n\n<p>I'm planning my first iPhone app and I'd like to get some inputs as to how to build it, right from the start. The iPhone app is being built to be paired with a public facing web  application that is already built in PHP.</p>\n\n<p>I'd like the web platform to be central (data is housed in a mySQL database), and have the \niPhone clients talk to it and use REST'ful methods to perform the functions of the site \n(fetching latest content, posting content, voting, account management as examples).</p>\n\n<p>I'd like the clients to get a local copy of the data in a SQLite database, but refresh to get the latest version of the feed (similar to the Twitter app).</p>\n\n<p>Couple of thoughts I have right now:</p>\n\n<ul>\n<li><p>Use something like ASIHTTPRequest to send/recieve data to PHP files on the server listening for requests</p></li>\n<li><p>JSON - would I be better off to send the GET/POSTS to a PHP that returns JSON objects, and work with some sort of wrapper that manages the data and communicates changes to the local SQLite database?</p></li>\n<li><p>Am I totally off in how I should be building this thing to communicate with the web? Is \nthere a best practice for this?</p></li>\n</ul>\n\n<p>I'd really appreciate any input on how you would architect this sort of a setup.</p>\n\n<p>Thank you,</p>\n\n<p><strong>EDIT</strong>: After reading my own post again, I know it sounds like a Twitter client, but it is NOT, although it has similar features/structure of a Twitter type setup. Thanks!</p>\n    ","a":"\n<p>As you already outlined in your plan, XML and REST are a great way to communicate with a web application. I want to suggest few details about how to actually design and build it, or what you should keep in mind.</p>\n\n<p>First of all, I believe it's important to stick with MVC. I've seen people creating HTTP connections in view-controllers, controllers being NSXMLParser's delegate, controllers containing data in member variables. I've even seen UITableCells establishing HTTP connections. Don't do it!</p>\n\n<p>Your model and its basic manipulation code should be as much extracted from user interface as possible. As you already have created the model in your web-application, try to recreate the entities in your iPhone project. Don't be afraid of having some simple methods in entity classes, but do not make them use external resources, especially tcp connections. As an example of methods in entity class you might have methods that formats data in specific ways (dates as an example, or returning fullname as concatenation of firstname and surname), or you can even have a method like <code>- (void)update</code> that would act as a wrapper to call class responsible to update the model.</p>\n\n<p>Create another class for updating the model - fetching the XMLs from web-app. Do not even consider using synchronous connections, not even from a dedicated thread. Asynchronous connections with delegate is the way to go. Sometimes multiple requests need to be made to get all required data. You might want to create some kind of state-machine to keep the information about in which stage of downloading you are, and progress from stage to stage, skipping to the end if error occurs, re-executing from failed stage after some moments.</p>\n\n<p>Download data somewhere temporarily, and first when you have it all, make a switch and update user interface. This helps responsiveness during launching the app - user gets to work immediately with data stored locally, while the update mechanism is downloading the new data.</p>\n\n<p>If you need to download lots of files, try to download them simultaneously, if dependencies between files allow for that. This involves creating a connection per request, probably delegate instance for each of them. You can of course have only one delegate instance for all of those connections, but it gets a bit more complex to track the data. Downloading simultaneously might decrease latency considerably, making the mechanism much faster for the user.</p>\n\n<p>To save the time and bandwidth, consider using HTTP's <code>If-Modified-Since</code> and/or <code>ETag</code> headers. Remember the time or tag when you requested the data the last time, and next time send it in HTTP's header. Your web-application should return HTTP code 304 if content has not been changed. iPhone app should react on this code accordingly in <code>connection:didReceiveResponse:</code>.</p>\n\n<p>Create a dedicated class to parse the XML and update the model. You can use NSXMLParser, but if your files are not huge I strongly recommend TouchXML, it's such a pleasure to work with XML as document (it also supports XPath), instead of an event based API. You can use this parser also when files are downloaded to check their validity - re-download if parsing fails. That's when dedicated class for parsing comes handy.</p>\n\n<p>If your dataset is not huge, if you do not need to persist downloaded data on iPhone forever, you probably don't need to store them in SQLite database, you can simply store them in XML format - just a simple caching. That at least might be the way for a twitter app. It gets easier that way, but for bigger data sets XML consumes lots of memory and processing power - in that case SQLite is better.</p>\n\n<p>I'd suggest using Core Data, but you mention this is your first iPhone app, so I suggest you don't use it. Yet.</p>\n\n<p>Do not forget about multitasking - your app can go to sleep in the middle of download, you need to cancel connections, and cleanup your update mechanisms. On app's wake-up you might want to resume the update.</p>\n\n<p>Regarding the view part of the application - use Interface Builder. It might be painful in the beginning, but it pays off in the long run.</p>\n\n<p>View controllers are the glue between model and views. Do not store data in there. Think twice about what to implement where, and who should call it.</p>\n\n<p>This is not related to architecture of the app, but I want to remind that Objective-C is very expressive language. Code should read much like a sentence. Extend classes with protocols. As an example the other day I needed first line of a string. Sure, you can write a one-liner where you find first occurrence of a new-line, and get a substring from beginning till there. But it doesn't look right. I've added <code>- (NSString*)firstLine</code> into my NSString's protocol. Code looks so much better this way, it doesn't need any comments.</p>\n\n<p>There are lots of things to consider in both architecture and design of any project, they both should go hand in hand. If one is causing trouble to the other, you need to adapt. Nothing is written in stone.</p>\n    "},{"t":"Choosing a distributed shared memory solution","l":"http://stackoverflow.com/questions/3045164/choosing-a-distributed-shared-memory-solution","q":"\n\n<p>I have a task to build a prototype for a massively scalable distributed shared memory (DSM) app. The prototype would only serve as a proof-of-concept, but I want to spend my time most effectively by picking the components which would be used in the real solution later on.</p>\n\n<p>The aim of this solution is to take data input from an external source, churn it and make the result available for a number of frontends. Those \"frontends\" would just take the data from the cache and serve it without extra processing. The amount of frontend hits on this data can literally be millions per second.</p>\n\n<p>The data itself is very volatile; it can (and does) change quite rapidly. However the frontends should see \"old\" data until the newest has been processed and cached. The processing and writing is done by a single (redundant) node while other nodes only read the data. In other words: no read-through behaviour.</p>\n\n<p>I was looking into solutions like <a href=\"http://memcached.org\">memcached</a> however this particular one doesn't fulfil <strong>all</strong> our requirements which are listed below:</p>\n\n<ol>\n<li>The solution must at least have <strong>Java client API</strong> which is reasonably well maintained as the rest of app is written in Java and we are seasoned Java developers;</li>\n<li>The solution must be totally <strong>elastic</strong>: it should be possible to add new nodes without restarting other nodes in the cluster;</li>\n<li>The solution must be able to handle <strong>failover</strong>. Yes, I realize this means some overhead, but the overall served data size isn't big (1G max) so this shouldn't be a problem. By \"failover\" I mean seamless execution without hardcoding/changing server IP address(es) like in memcached clients when a node goes down;</li>\n<li>Ideally it should be possible to specify the degree of data overlapping (e.g. how many copies of the same data should be stored in the DSM cluster);</li>\n<li>There is no need to permanently store all the data but there might be a need of post-processing of some of the data (e.g. serialization to the DB).</li>\n<li><strong>Price</strong>. Obviously we prefer free/open source but we're happy to pay a reasonable amount if a solution is worth it. In any way, paid 24hr/day support contract is a must.</li>\n<li>The whole thing has to be hosted in <strong>our data centers</strong> so SaaS offerings like Amazon SimpleDB are out of scope. We would only consider this if no other options would be available.</li>\n<li>Ideally the solution would be <em>strictly consistent</em> (as in CAP); however, <em>eventual consistence</em> can be considered as an option.</li>\n</ol>\n\n<p>Thanks in advance for any ideas.</p>\n    ","a":"\n<p>Have a look at <a href=\"http://www.hazelcast.com\">Hazelcast</a>. It is pure Java, open source (Apache license) highly scalable in-memory data grid product. It does offer 7X24 support. And it does solve all of your problems I tried to explain each of them below:</p>\n\n<ol>\n<li>It has a native Java Client.  </li>\n<li>It is 100% dynamic. Add and remove nodes dynamically. No need to change anything. </li>\n<li>Again everything is dynamic.</li>\n<li>You can configure number of backup nodes. </li>\n<li>Hazelcast support persistency.</li>\n<li>Everything that Hazelcast offers is free(open source) and it does offer enterprise level support.</li>\n<li>Hazelcast is single jar file. super easy to use. Just add jar to your classpath. Have a look at screen cast in main page.</li>\n<li>Hazelcast is strictly consistent. You can never read stale data. </li>\n</ol>\n    "},{"t":"Monopoly game in OOD?","l":"http://stackoverflow.com/questions/4576271/monopoly-game-in-ood","q":"\n\n<p>I found this interesting blog post via CodingHorror: <a href=\"http://weblog.raganwald.com/2006/06/my-favourite-interview-question.html\">My Favorite Interview Question</a>. In a nutshell, he talks about the object-oriented design challenges of designing the game of Monopoly, with an emphasis on how to model the rules of the game. For example, \"If a player owns Baltic Avenue, can she add a house to it?\"</p>\n\n<p>Interestingly, near the bottom of the post, he then writes:</p>\n\n<blockquote>\n  <p>You can probably save yourself a lot of interview time. Instead of all this hoopla, ask the candidate to describe when they have actually used the Strategy, Visitor, and Command patterns outside of a framework.)</p>\n</blockquote>\n\n<p>...which probably means that you can use design patterns to model the rules of the game (see above). Has anybody ever done this? Designed the game of Monopoly using design patterns? If so, how did it work out?</p>\n    ","a":"\n<p>Here's how I would design Monopoly.  I've taken the liberty of assuming a dynamically-typed language since that makes everything easier.  Ruby specifically.</p>\n\n<p>You have a simple <code>Game</code> object that's mostly a wrapper around an <code>Array</code> of size 40, plus some convenience methods.  The <code>Game</code> object also tracks the number of available <code>houses</code> and <code>hotels</code> and the two stacks of Chance and Community Chest cards.  A few convenience methods like <code>current_turn</code> and <code>next_turn!</code> are provided — both return a <code>Player</code> object; <code>next_turn!</code> increments the turn index, wrapping to 0 if necessary.</p>\n\n<p>All locations the player can land on must inherit from a superclass of <code>Property</code>.  The <code>Property</code> class defines a few common things like <code>rent</code>, <code>owner</code>, <code>set</code>, <code>houses</code>, <code>purchasable?</code>, and <code>upgradeable?</code>.  The <code>rent</code> and <code>owner</code> properties may be <code>nil</code>.  The <code>set</code> property returns an <code>Array</code> containing all properties within the group.  The <code>set</code> property may vary in size from 1 to 4.  The <code>houses</code> property represents a hotel as 5 'houses'.</p>\n\n<p>The <code>Game</code> object has an <code>Array</code> of <code>Player</code> objects, each with fields like <code>position</code> (an integer from 0 to 39), <code>money</code> (no upper bound — the bank technically never 'runs out of money'), <code>get_out_of_jail_frees</code>, and <code>in_jail?</code> (since position is insufficient for this).  The <code>Game</code> object also has an index to track whose turn it is.</p>\n\n<p>Property-specific rules are all encoded within their respective subclasses.  So, for instance, the implementation of <code>rent</code> on a <code>Railroad</code> would be:</p>\n\n<pre><code>def rent\n  owned_count = self.set.select { |rr| rr.owner == self.owner }.size\n  return 25 * 2 ** (owned_count - 1)\nend\n</code></pre>\n\n<p>Chance and Community Chest cards can be simply implemented with a bunch of closures that takes a game and a player object as parameters.  For instance:</p>\n\n<pre><code># Second place in a beauty contest\nCOMMUNITY_CHEST_CARDS &lt;&lt; lambda do |game, player|\n  player.money += 10\nend\n\n# Advance token to Boardwalk\nCHANCE_CARDS &lt;&lt; lambda do |game, player|\n  game.advance_token!(player, 39)\nend\n\n# Advance token to nearest railroad, pay double\nCHANCE_CARDS &lt;&lt; lambda do |game, player|\n  new_position = [5, 15, 25, 35].detect do |p|\n    p &gt; player.position\n  end || 5\n  game.advance_token!(player, new_position)\n  # Pay rent again, no-op if unowned\n  game.properties[new_position].pay_rent!(player)\nend\n</code></pre>\n\n<p>And so on.  The <code>advance_token!</code> method obviously handles things like passing go.</p>\n\n<p>Obviously, there are more details — it's a fairly complicated game, but hopefully this gives you the right idea.  It'd certainly be more than sufficient for an interview.</p>\n\n<h2>Update</h2>\n\n<p>House rules could be switched on or off by adding a <code>house_rules</code> <code>Array</code> to the <code>Game</code> object.  This would allow the <code>FreeParking</code> property to be implemented like this:</p>\n\n<pre><code>class Game\n  def house_rules\n    @house_rules ||= []\n  end\n\n  def kitty\n    # Initialize the kitty to $500.\n    @kitty ||= 500\n  end\n\n  def kitty=(new_kitty)\n    @kitty = new_kitty\n  end\nend\n\nclass FreeParking &lt; Property\n  def rent\n    if self.game.house_rules.include?(:free_parking_kitty)\n      # Give the player the contents of the kitty, and then reset it to zero.\n      return -(_, self.game.kitty = self.game.kitty, 0)[0]\n    else\n      return 0\n    end\n  end\nend\n</code></pre>\n    "},{"t":"Is “Dying is Awesome” preferred?","l":"http://stackoverflow.com/questions/576532/is-dying-is-awesome-preferred","q":"\n\n<p>Recently I attended Jeffrey Richter's training courses about .NET. He mentions one strategy of coding \"Dying is awesome\". That is, don't write \"catch (Exception ex)\" even at the root of program or event loop. If some exception thrown that is not handled, just let the process die. </p>\n\n<p>I'm not sure this is right. Personally, I prefer to have a \"<code>try {...} catch(Exception ex) {log and try to recover}</code>\" to wrap at the top level of execution. Actually, ASP.NET doesn't die if any exception is throw from asXx. If it does die for exception, then one silver-bullet request can silence the whole service.</p>\n\n<p>What do you think?</p>\n    ","a":"\n<p>I think it depends on what kind of app you are running and what the consequences of 'dying' are.  For many client apps, dying is awesome.  For servers, often not so much (and swallow-and-log is appropriate).  There's no one-size-fits-all solution.</p>\n    "},{"t":"Apple Mach-O Linker Errors (20) - Undefined symbols for architecture armv7","l":"http://stackoverflow.com/questions/9931510/apple-mach-o-linker-errors-20-undefined-symbols-for-architecture-armv7","q":"\n\n<p>I received these errors after I added \" -all_load \" in the \"Other Linker Flags\" build setting once I added \"libPusher-combined.a\" and its header files. I followed the <a href=\"https://github.com/lukeredpath/libPusher/wiki/Adding-libPusher-to-your-project\">instructions</a> exactly up to the part of typing in \"-all_load\" (under \"Using a pre-compiled static library\" in the \"Adding to your iOS Project\", but I ended up getting 20 Mach-O Linker errors. :/ Could anyone please help me with this?</p>\n\n<p>Here are the errors:</p>\n\n<pre><code>Undefined symbols for architecture armv7:\n \"_utf8_nextCharSafeBody\", referenced from:\n  -[SRWebSocket _pumpScanner] in libPusher-combined.a(SRWebSocket.o)\n \"_SCError\", referenced from:\n  -[Reachability startNotifier] in libPusher-combined.a(Reachability.o)\n \"_utf8_countTrailBytes\", referenced from:\n  -[SRWebSocket _pumpScanner] in libPusher-combined.a(SRWebSocket.o)\n \"_SCNetworkReachabilitySetDispatchQueue\", referenced from:\n  -[Reachability startNotifier] in libPusher-combined.a(Reachability.o)\n  -[Reachability stopNotifier] in libPusher-combined.a(Reachability.o)\n \"_kCFHTTPVersion1_1\", referenced from:\n  -[SRWebSocket didConnect] in libPusher-combined.a(SRWebSocket.o)\n\"_CFHTTPMessageIsHeaderComplete\", referenced from:\n  ___30-[SRWebSocket _readHTTPHeader]_block_invoke_0 in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageCreateRequest\", referenced from:\n  -[SRWebSocket didConnect] in libPusher-combined.a(SRWebSocket.o)\n \"_SCNetworkReachabilityCreateWithAddress\", referenced from:\n  +[Reachability reachabilityWithAddress:] in libPusher-combined.a(Reachability.o)\n \"_SCErrorString\", referenced from:\n  -[Reachability startNotifier] in libPusher-combined.a(Reachability.o)\n \"_SCNetworkReachabilityCreateWithName\", referenced from:\n  +[Reachability reachabilityWithHostname:] in libPusher-combined.a(Reachability.o)\n \"_CFHTTPMessageCopyAllHeaderFields\", referenced from:\n  ___30-[SRWebSocket _readHTTPHeader]_block_invoke_0 in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageGetResponseStatusCode\", referenced from:\n  -[SRWebSocket _HTTPHeadersDidFinish] in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageSetHeaderFieldValue\", referenced from:\n  -[SRWebSocket didConnect] in libPusher-combined.a(SRWebSocket.o)\n  ___25-[SRWebSocket didConnect]_block_invoke_0 in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageCreateEmpty\", referenced from:\n  -[SRWebSocket _readHTTPHeader] in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageCopySerializedMessage\", referenced from:\n  -[SRWebSocket didConnect] in libPusher-combined.a(SRWebSocket.o)\n \"_SCNetworkReachabilitySetCallback\", referenced from:\n  -[Reachability startNotifier] in libPusher-combined.a(Reachability.o)\n  -[Reachability stopNotifier] in libPusher-combined.a(Reachability.o)\n \"_SCNetworkReachabilityGetFlags\", referenced from:\n  -[Reachability isReachable] in libPusher-combined.a(Reachability.o)\n  -[Reachability isReachableViaWWAN] in libPusher-combined.a(Reachability.o)\n  -[Reachability isReachableViaWiFi] in libPusher-combined.a(Reachability.o)\n  -[Reachability connectionRequired] in libPusher-combined.a(Reachability.o)\n  -[Reachability isConnectionOnDemand] in libPusher-combined.a(Reachability.o)\n  -[Reachability isInterventionRequired] in libPusher-combined.a(Reachability.o)\n  -[Reachability reachabilityFlags] in libPusher-combined.a(Reachability.o)\n  ...\n \"_CFHTTPMessageCopyHeaderFieldValue\", referenced from:\n  -[SRWebSocket _checkHandshake:] in libPusher-combined.a(SRWebSocket.o)\n \"_CFHTTPMessageAppendBytes\", referenced from:\n  ___30-[SRWebSocket _readHTTPHeader]_block_invoke_0 in libPusher-combined.a(SRWebSocket.o)\nld: symbol(s) not found for architecture armv7\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\n</code></pre>\n\n<p>If you need more information, just ask. I hope that I'm not giving too much trouble. Thanks in advance.</p>\n    ","a":"\n<p>Can you check out in your target-&gt;Build Phase. whether these files exist there or not ? and if you are running for simulator then first you need to make a build for simulator of that library whatever i guess you are using SRWebSocket library. Just open that project and just make a build for simulator and copy the files from build folder and then add to your project and do the same for the device if you are running your app on device.</p>\n    "},{"t":"Should the data access layer contain business logic?","l":"http://stackoverflow.com/questions/601151/should-the-data-access-layer-contain-business-logic","q":"\n\n<p>I've seen a trend to move business logic out of the data access layer (stored procedures, LINQ, etc.) and into a business logic component layer (like C# objects).  </p>\n\n<p>Is this considered the \"right\" way to do things these days?  If so, does this mean that some database developer positions may be eliminated in favor of more middle-tier coding positions?  (i.e. more c# code rather than more long stored procedures.)</p>\n    ","a":"\n<p>Data access logic belongs in the data access layer, business logic belongs in the business layer. I don't see how mixing the two could ever be considered a good idea from a design standpoint.</p>\n    "},{"t":"Always check malloc'ed memory?","l":"http://stackoverflow.com/questions/1941323/always-check-malloced-memory","q":"\n\n<p>I often catch myself doing the following (in non-critical components):</p>\n\n<pre><code>some_small_struct *ptr=(some_small_struct *) malloc(sizeof(some_small_struct));\nptr-&gt;some_member= ...;\n</code></pre>\n\n<p>In words, I allocate dynamically memory for a small structure and I use it directly without checking the malloc'ed pointer.  I understand there is always a chance that the program won't get the memory it asks for (duh!) but consider the following:</p>\n\n<blockquote>\n  <p>If the program can't even get some memory for a small structure off the\n  heap, maybe there are much bigger problems looming and it doesn't matter after all.</p>\n</blockquote>\n\n<p>Furthermore, what if handling the null pointer exacerbates the precarious situation even more?? (e.g. trying to log the condition calls even more non-existing resources etc.)</p>\n\n<p>Is my reasoning sane (enough) ?</p>\n\n<p><strong>Updated</strong>:</p>\n\n<ol>\n<li>A \"safe_malloc\" function can be useful when debugging and might be useful otherwise</li>\n<li><code>+X</code> access can hide the root cause of a NULL pointer</li>\n<li>On Linux, \"optimistic memory allocation\" can shadow loomin OOM (Out-Of-Memory) conditions</li>\n</ol>\n    ","a":"\n<p>Depends on the platform. For instance, on Linux (by default) it does not make much sense to check for NULL:</p>\n\n<p><a href=\"http://linux.die.net/man/3/malloc\">http://linux.die.net/man/3/malloc</a></p>\n\n<blockquote>\n  <p>By default, Linux follows an optimistic memory allocation strategy. This means that when malloc() returns non-NULL there is no guarantee that the memory really is available. This is a really bad bug. In case it turns out that the system is out of memory, one or more processes will be killed by the infamous OOM killer.</p>\n</blockquote>\n    "},{"t":"What does scalability mean to you?","l":"http://stackoverflow.com/questions/214246/what-does-scalability-mean-to-you","q":"\n\n<p>I posted a <a href=\"http://stackoverflow.com/questions/214233/how-scalable-is-linq\">similar question</a> on how scalable linq is. There were so many different views on what scalability actually meant in some recent conversations, so it has sparked me to ask this question as well. What does scalability mean to you?</p>\n    ","a":"\n<p>I look at scalability from two perspectives:</p>\n\n<p><strong>Scaling Up</strong></p>\n\n<p>If I add more RAM to the box that something is running on, how much additional performance and capacity do I gain? If one application I have can handle 300 more connections and runs 15% faster when I add 2 GB of RAM to my server and another application can only handle 100 more connections and runs 5% faster, application A is clearly more scalable.</p>\n\n<p><strong>Scaling Out</strong></p>\n\n<p>Now, if I add more boxes to my set up, how much additional performance and capacity do I gain? Can I set up web front ends to handle more client traffic? If so, is there a linear increase? If I add 3 boxes, can I get 3x more users accessing my site? Can I add more databases to distribute the data load? Can I scale up multithreading? If I can easily add a machine to my network to add capacity to my application, then it is scalable.</p>\n\n<p>This, by the way, is one of the primary drives of n-tier.</p>\n    "},{"t":"What am I not understanding about REST?","l":"http://stackoverflow.com/questions/343288/what-am-i-not-understanding-about-rest","q":"\n\n<p>I'm building a framework and want developers who build with it to have the ability to allow parts of it to both share data with other sites and allow other sites to add/edit/delete data.</p>\n\n<p>For example, if someone makes a site that has book reviews, authors, quotes, code examples, comments, etc. the developer could make e.g. \"book reviews\" read-only for other sites and \"comments\" readable by other sites and writable by certain sites/users. The idea is to use the framework to build applications that can easily be interconnected with other applications.</p>\n\n<p>I envision enabling all interaction with the site via POST and GET which would look something like this:</p>\n\n<ul>\n<li><strong>/books.php?category=ruby</strong> (returns an XML collection of books about ruby)</li>\n<li><strong>/books.php?id=23</strong> (returns the XML for a specific book)</li>\n<li><strong>/books.php?action=add&amp;title=AdvancedRuby&amp;description=....&amp;securityId=923847203487</strong></li>\n<li><strong>/books.php?action=delete&amp;id=342&amp;securityId=923847203487</strong></li>\n</ul>\n\n<p>Other applications could also \"discover and consume\" what a certain site has to offer by doing this:</p>\n\n<ul>\n<li><strong>/discover.php</strong> (returns XML of all public classes and actions available)</li>\n</ul>\n\n<p>Really this is all I need to enable the framework to be a way for developers to quickly create loosely connected sites.</p>\n\n<p><strong>What I want to know is, before I begin implementing this, are there significant/interesting parts of REST that I do not yet understand which I should be building into the framework</strong>, e.g.:</p>\n\n<ul>\n<li>REST requires GET, POST, PUT and DELETE. Why would I ever need \"PUT\" and \"DELETE\"? Am I locking myself out from taking advantage of some standard if I dont' use these?</li>\n<li>My \"discover.php\" file functions similarly to a WSDL file in web services. I am surprised in descriptions of REST there seems to be no standardized way of discovering the services that a RESTful service offers, or is there?</li>\n<li>If a client website tries to e.g. add a book to a server website and does not get any \"success\" response back, it would simply try again until it got a response. The server website would simply not add the same book twice. This is my understanding of data integrity in REST, is there more to it than this?</li>\n<li><p>eventually I want to have multiple sites that have the same rich classes e.g. \"BookReview\" so that a client site would be able to execute code such as this:</p>\n\n<p><strong>$bookReview = new BookReview(\"http://www.example.com/books.php?id=23\");\n$book-&gt;informAuthor(\"a comment about your book review was posted on our site...\");</strong></p></li>\n</ul>\n\n<p>and the server site would send an e-mail off to the author of that review.\nIs this type of type interaction a component of the RESTful philosophy or is REST simply the exchange of data via XML, JSON?</p>\n    ","a":"\n<p><strong>Am I locking myself out from taking advantage of some standard if I dont' use these?</strong></p>\n\n<p>You are yourself locking out from the HTTP standard. Of course you can use GET parameters to do the same thing. It's just not REST then, but something RPC-Like. </p>\n\n<p>May I suggest the book <a href=\"http://rads.stackoverflow.com/amzn/click/0596529260\">RESTful Web Services</a> by Leonard Richardson and Sam Ruby? It's quite fun to read and shows differences between the different approaches.</p>\n\n<p>To answer your questions in a bit more detail: It's up to you to decide which way you go. In theory you can do all the same stuff with both RESTful and RPC-like approaches. With RESTful you use the underlaying HTTP protocol to be <em>the</em> protocol. With RPC you use HTTP just as a means of transportation and hide the work orders somewhere in the transported data. That leads to (unrequired) overhead.</p>\n\n<p>Just look at two of your examples:</p>\n\n<ul>\n<li><strong>/books.php?action=add&amp;title=AdvancedRuby&amp;description=....&amp;securityId=923847203487</strong></li>\n<li><strong>/books.php?action=delete&amp;id=342&amp;securityId=923847203487</strong>\n<ul>\n<li>There's POST and PUT or DELETE, why have action=add and action=delete?</li>\n<li>There's HTTP authentication. Why invent a - possibly less secure - securityId?</li>\n<li>BTW: You shouldn't allow changes to data via GET. That's just something that shouldn't be done (another topic, though ;) )</li>\n</ul></li>\n</ul>\n    "},{"t":"Java Application Architecture Guide","l":"http://stackoverflow.com/questions/647922/java-application-architecture-guide","q":"\n\n<p>Is there a Java Application Architecture Guide that is a counterpart of this: <a href=\"http://www.codeplex.com/AppArchGuide\">http://www.codeplex.com/AppArchGuide</a> ?</p>\n    ","a":"\n<p>The following should be helpful to you</p>\n\n<ol>\n<li><a href=\"http://www.corej2eepatterns.com/Patterns2ndEd/index.htm\">Core J2EE Patterns</a></li>\n<li><a href=\"http://rads.stackoverflow.com/amzn/click/0321130006\">Effective Enterprise Java</a></li>\n<li><a href=\"http://rads.stackoverflow.com/amzn/click/0321127420\">Patterns of Enterprise Application Architecture</a></li>\n<li><a href=\"http://oreilly.com/catalog/9780596007126/\">Head First Design Patterns</a></li>\n<li><a href=\"http://java.sun.com/reference/blueprints/\">J2EE Blueprints</a></li>\n<li><a href=\"http://rads.stackoverflow.com/amzn/click/0130449164\">Sun Certified Enterprise Architect, Study Guide</a></li>\n</ol>\n\n<p>Although, having had a quick glance at the document from codeplex, I can tell you that probably 70-80% of what is in there, applies to Java as well.</p>\n    "},{"t":"What is the technology behind wechat, whatsapp and other messenger apps? [closed]","l":"http://stackoverflow.com/questions/19640703/what-is-the-technology-behind-wechat-whatsapp-and-other-messenger-apps","q":"\n\n<p>I am eager to know about the architecture of different messenger apps. Are they use any generic protocol/architecture?</p>\n    ","a":"\n<p>To my knowledge, Ejabberd (<a href=\"http://www.ejabberd.im/\">http://www.ejabberd.im/</a>) is the parent, this is XMPP server which provide quite good features of open source, Whatsapp uses some modified version of this, facebook messaging also uses a modified version of this. Some more chat applications likes Samsung's ChatOn, Nimbuzz messenger all use ejabberd based ones and Erlang solutions also have modified version of this ejabberd which they claim to be highly scalable and well tested with more performance improvements and renamed as MongooseIM. </p>\n\n<p>Ejabberd is the server which has most of the featured implemented when compared to other. Since it is build in Erlang it is highly scalable horizontally. </p>\n    "},{"t":"Is Backbone.js only for single page applications?","l":"http://stackoverflow.com/questions/7876764/is-backbone-js-only-for-single-page-applications","q":"\n\n<p>I'm searching for a simple architecture for my UI that will have some basic javascript functions in like: select all checkbox's, image crop, some pop-ups and some other plugins.</p>\n\n<p>I found this article: <a href=\"http://weblog.bocoup.com/organizing-your-backbone-js-application-with-modules\">Organizing Your Backbone.js Application With Modules</a></p>\n\n<p>My application is not a SPA (Single Page Application). I want to know if Backbone.js with jQuery will help me even if my application is not a SPA.</p>\n    ","a":"\n<p>The strength of Backbone is really in its ability to manage many models (even complex ones) and keep the rendered page in sync with their current values. It provides an interface to getter/setter functions so that the changing of a model value (there are many different flavors of \"change\") will call render on the corresponding view and the page will correctly reflect the underlying models. Furthermore, it provides interfaces to saving, paging, and routing actions on models.</p>\n\n<p>I have used Backbone extensively for both SPA's (where it shines) as well as more traditional, multiple page applications. It has no special support for UI and DOM manipulation, but combined with jQuery/Prototype/Zepto it manages <em>their</em> rendering/manipulation.</p>\n\n<p>Basically, backbone works best to untangle elaborate chains of rendering logic and model updating. If you feel that your application has a lot of view elements that need to stay in sync with models that the client will be updating on the page, Backbone is a wonderful solution. If you just need to select and manipulate DOM elements, it's overkill. jQuery alone can handle that.</p>\n    "},{"t":"Branch target prediction in conjunction with branch prediction?","l":"http://stackoverflow.com/questions/21787457/branch-target-prediction-in-conjunction-with-branch-prediction","q":"\n\n<p>EDIT: My confusion arises because surely by predicting which branch is taken, you are effectively doing the target prediction too??</p>\n\n<p>This question is intrinsically linked to my first question on the topic:</p>\n\n<p><a href=\"http://stackoverflow.com/questions/21608874/branch-prediction-vs-branch-target-prediction\">branch prediction vs branch target prediction</a></p>\n\n<p>Looking at the accepted answer:</p>\n\n<blockquote>\n  <h2>Unconditional branch, fixed target</h2>\n  \n  <ul>\n  <li>Infinite loop</li>\n  <li><code>goto</code> statement</li>\n  <li><code>break</code> or <code>continue</code> statement</li>\n  <li>End of the 'then' clause of an <code>if/else</code> statement (to jump past the <code>else</code> clause)</li>\n  <li>Non-virtual function call</li>\n  </ul>\n  \n  <h2>Unconditional branch, variable target</h2>\n  \n  <ul>\n  <li>Returning from a function</li>\n  <li>Virtual function call</li>\n  <li>Function pointer call</li>\n  <li><code>switch</code> statement (if compiled into a jump table)</li>\n  </ul>\n  \n  <h2>Conditional branch, fixed target</h2>\n  \n  <ul>\n  <li><code>if</code> statement</li>\n  <li><code>switch</code> statement (if compiled into a series of <code>if/else</code> statements)</li>\n  <li>Loop condition tests</li>\n  <li>The <code>&amp;&amp;</code> and <code>||</code> operators</li>\n  <li>The ternary <code>?:</code> operator</li>\n  </ul>\n  \n  <h2>Conditional branch, variable target</h2>\n  \n  <ul>\n  <li>Less likely to show up under normal conditions, but the compiler may synthesize one as an optimization, combining two of the above cases. \n  For example, on x86, the compiler may optimize code like <code>if\n  (condition) { obj-&gt;VirtualFunctionCall(); }</code> into a conditional\n  indirect jump like <code>jne *%eax</code> if it appears at the end of a function\n  due to tail call optimization.</li>\n  </ul>\n</blockquote>\n\n<p>If I have the following code:</p>\n\n<pre><code>if(something){\n    //a\n}\nelse{\n    //b\n}\n</code></pre>\n\n<p>(BP = \"Branch Prediction\" and BTP = \"Branch Target Prediction\")</p>\n\n<p>Its pretty obvious BP is used to evaluate the conditional <code>something</code>. However I am trying to understand whether BTP is also involved in determine what happens in branch <code>a</code>. Does BTP also happen to determine the address of the code located at branch <code>a</code>/<code>b</code>, depending on the result of the BP?</p>\n\n<p>I ask becase on this wikipedia page (<a href=\"http://en.wikipedia.org/wiki/Branch_target_predictor\">http://en.wikipedia.org/wiki/Branch_target_predictor</a>):</p>\n\n<blockquote>\n  <p>In computer architecture, a branch target predictor is the part of a\n  processor that predicts the target of a taken conditional branch or an\n  unconditional branch instruction before the target of the branch\n  instruction is computed by the execution unit of the processor.</p>\n</blockquote>\n\n<p>it suggests BTP is used to predict the target after the conditional has been predicted. </p>\n\n<p><strong>1) Could somebody clarify the above please?</strong></p>\n\n<p>A second related question- how do BP and BTP differ in the way they interact with the fetch/decode/execute/write-back pipeline of the CPU? Does BP begin at the fetch or decode stage? After the execution stage of the conditional code we can check whether the prediction was correct and update the branch prediction cache. </p>\n\n<p><strong>2) How does BTP work with regards to the fetch/decode/execute/write-back CPU stages?</strong></p>\n    ","a":"\n<p>Do read along with the Intel optimization manual, current download location <a href=\"http://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-optimization-manual.pdf\">is here</a>.  When stale (they move stuff around all the time) then search the Intel site for \"Architectures optimization manual\".  Keep in mind the info there is fairly generic, they disclose only as much as needed to allow writing efficient code.  Branch prediction implementation details are considered a trade secret and <em>do</em> change between architectures.  Search the manual for \"branch prediction\" to find references, it is fairly spread among the chapters.</p>\n\n<p>I'll give a summary of what's found in the manual, adding details where appropriate:</p>\n\n<p>Branch prediction is the job of the BPU unit in the core (Branch Prediction Unit).  Roughly correlates to \"BP\" in your question.  It contains several sub-units:</p>\n\n<ul>\n<li><p>The branch history table.  This table keeps track of previously taken <em>conditional</em> branches and is consulted by the predictor to decide if a branch is likely to be taken.  Is is fed with entries by the instruction retirement unit, the one that knows whether the branch was actually taken.  This is the sub-unit that has changed the most as the architectures improved, getting deeper and smarter as more real estate became available.</p></li>\n<li><p>The BTB, Branch Target Buffer.  This buffer stores the target address of a previously taken indirect jump or call.  This correlates to \"BTP\" in your question.  The manual does not state whether the buffer can store multiple targets per address, indexed by the history table, I consider it likely for later architectures.</p></li>\n<li><p>The Return Stack Buffer.  This buffer acts a \"shadow\" stack, storing the return address for CALL instructions, making the target of a RET instruction available with a high degree of confidence without the processor having to rely on the BTB, unlikely to be as effective for calls.  It is documented to be 16 levels deep.</p></li>\n</ul>\n\n<p>Bullet 2) in a bit difficult to answer accurately, the manual only talks about the \"Front End\" and does not break down the details of the pipeline.  Appropriate enough, it is heavily architecture dependent.  The diagram in section 2.2.5 is possibly illustrative.  The execution trace cache plays a role, it stores previously decoded instructions so is the primary source of BPU consultations.  Otherwise right after the instruction translator (aka decoder).</p>\n    "},{"t":"What should be the considerations for choosing SQL/NoSQL?","l":"http://stackoverflow.com/questions/2440079/what-should-be-the-considerations-for-choosing-sql-nosql","q":"\n\n<p>Target application is a medium-sized website built to support several hundred to several thousand users an hour, with an option to scale above that. Data model is rather simple, and caching potential is pretty high (~10:1 ratio of read to edit actions).</p>\n\n<p>What should be the considerations when coming to choose between a relational, SQL-based datastore to a NoSQL option (such as HBase and Cassandra)?</p>\n    ","a":"\n<p>To me, you don't have any particular problem to solve. If you need ACIDity, use a database; if you don't, then it doesn't matter. At the end just build your app. And let me quote <a href=\"http://bjclark.me/2009/08/04/nosql-if-only-it-was-that-easy/\">NoSQL: If Only It Was That Easy</a>:</p>\n\n<blockquote>\n  <p>The real thing to point out is that if you are being held back from making something super awesome because you can’t choose a database, you are doing it wrong. If you know mysql, just used it. Optimize when you actually need to. Use it like a k/v store, use it like a rdbms, but for god sake, build your killer app! None of this will matter to most apps. Facebook still uses MySQL, a lot. Wikipedia uses MySQL, a lot. FriendFeed uses MySQL, a lot. NoSQL is a great tool, but it’s certainly not going to be your competitive edge, it’s not going to make your app hot, and most of all, your users won’t give a shit about any of this.</p>\n</blockquote>\n    "},{"t":"Why don't stacks grow upwards (for security)?","l":"http://stackoverflow.com/questions/2744502/why-dont-stacks-grow-upwards-for-security","q":"\n\n<p>This is related to the question <a href=\"http://stackoverflow.com/questions/2035568/why-do-stacks-typically-grow-downwards\">'Why do stacks typically grow downwards?'</a>, but more from a security point of view.  I'm generally referring to x86.</p>\n\n<p>It strikes me as odd that the stack would grow downwards, when buffers are usually written to upwards in memory.  For example a typical C++ string has its end at a higher memory address than the beginning.</p>\n\n<p>This means that if there's a buffer overflow you're overwriting further up the call stack, which I understand is a security risk, since it opens the possibility of changing return addresses and local variable contents.</p>\n\n<p>If the stack grew upwards in memory, wouldn't buffer overflows simply run in to dead memory?  Would this improve security?  If so, why hasn't it been done?  What about x64, do those stacks grow upwards and if not why not?</p>\n    ","a":"\n<p>Technically this is OS/CPU dependant, but typically this is because the stack and heap grow in opposite directions and from opposite ends of the address space.  </p>\n\n<p>This arrangement gives you the most flexibility to split/allocate memory between the heap and the stack without causing them to collide.  If they were both to grow in the same direction, then you would need to have a starting address for the stack that would put a hard limit the maximum size of the heap (and a hard limit on the size of the stack)</p>\n\n<p>ETA:</p>\n\n<p>Found an <a href=\"http://en.wikipedia.org/wiki/Stack_buffer_overflow#Stacks_that_grow_up\">interesting piece on wikipedia</a> about why making a stack grow upwards does not necessarily prevent stack overflows - it just makes them work a bit differently.</p>\n    "},{"t":"ASP.NET Web Site + Windows Forms App + WCF Service: Client Credentials","l":"http://stackoverflow.com/questions/345414/asp-net-web-site-windows-forms-app-wcf-service-client-credentials","q":"\n\n<p>Let's say that I'm considering designing a WCF service whose primary purpose is to provide broad services that can be used by three disparate applications: a public-facing Web site, an internal Windows Forms application, and a wireless mobile device. The purpose of the service is twofold: (1) to consolidate code related to business processes in a central location and (2) to lock down access to the legacy database, finally and once and for all hiding it behind one suite of services. </p>\n\n<p>Currently, each of the three applications has its own persistence and domain layers with slightly different views of the same database. Instead of all three applications talking to the database, they would talk to the WCF service, enabling new features from some clients (the mobile picker can't currently trigger processes to send e-mail, obviously) and centralizing notification systems (instead of a scheduled task polling the database every five minutes for new orders, just ping the overhead paging system when the <code>AcceptNewOrder()</code> service method is invoked by one of these clients). All in all, this sounds pretty sane so far.</p>\n\n<p>In terms of overall design, however, I'm stumped when it comes to security. The Windows Forms application currently just uses Windows principals; employees are stored in Active Directory, and upon application startup, they can login as the current Windows user (in which case no password is required) or they can supply their domain name and password. The mobile client doesn't have any concept of a user; its connection to the database is a hardcoded string. And the Web site has thousands of users stored in the legacy database. So how do I implement the identity model and configure the WCF endpoints to deal with this?</p>\n\n<p>In terms of the Windows Forms application, this is no great issue: the WCF proxy can be initiated once and can hang around in memory, so I only need the client credentials once (and can prompt for them again if the proxy ever faults). The mobile client can just be special cased and use an X509 certificate for authentication against the WCF service. But what do I do about the Web site?</p>\n\n<p>In the Web site's case, anonymous access to some services is allowed. And for the services that require authentication in the hypothetical \"Customer\" role, I obviously don't want to have to authenticate them on each and every request for two reasons:</p>\n\n<ul>\n<li>I need their username and password each time. Storing this pair of information pretty much anywhere--the session, an encrypted cookie, the moon--seems like a bad idea.</li>\n<li>I would have to hit the users table in the database for each request. Ouch.</li>\n</ul>\n\n<p>The only solution that I can come up with is to treat the Web site as a trusted subsystem. The WCF service expects a particular X509 certificate from the Web site. The Web site, using Forms Authentication internally (which invokes an <code>AuthenticateCustomer()</code> method on the service that returns a boolean result), can add an additional claim to the list of credentials, something like \"joe@example.com is logged in as a customer.\" Then somehow a custom IIdentity object and IPrincipal could be constructed on the service with that claim, the WCF service being confident that the Web site has properly authenticated the customer (it will know that the claim hasn't been tampered with, at least, because it'll know the Web site's certificate ahead of time).</p>\n\n<p>With all of that in place, the WCF service code would be able to say things like <code>[PrincipalPermission.Demand(Role=MyRoles.Customer)]</code> or <code>[PrincipalPermission.Demand(Role=MyRoles.Manager)]</code>, and the <code>Thread.CurrentPrincipal</code> would have something that represented a user (an e-mail address for a customer or a distinguished name for an employee, both of them useful for logging and auditing).</p>\n\n<p>In other words, two different endpoints would exist for each service: one that accepted well-known client X509 certificates (for the mobile devices and the Web site), and one that accept Windows users (for the employees).</p>\n\n<p>Sorry this is so long. So the question is: Does any of this make sense? Does the proposed solution make sense? And am I making this too complicated?</p>\n    ","a":"\n<p>Well, I reckon that I'll take a stab at my own question now that I've spent a few hours playing with various approaches.</p>\n\n<p>My first approach was to set up certificate-based authentication between the WCF service and the public-facing Web site (the Web site is a consumer/client of the service). A few test certs generated with <code>makecert</code>, plop them into the <code>Personal</code>, <code>Trusted People</code>, and <code>Trusted Root Certification Authorities</code> (because I couldn't be bothered to generate real ones against our domain's certificate services), some config file modifications, and great, we're all set.</p>\n\n<p>To prevent the Web site from having to maintain username and password information for users, the idea is that once a user is logged into the Web site via Forms Authentication, the Web site can pass just the username (accessible via <code>HttpContext.Current.User.Identity.Name</code>) as an optional <code>UserNameSecurityToken</code> in addition to the <code>X509CertificateSecurityToken</code> that is actually used to secure the message. If the optional username security token is found, then the WCF service would say \"Hey, this trusted subsystem says that this user is properly authenticated, so let me set up a <code>MyCustomPrincipal</code> for that user and install it on the current thread so that actual service code can inspect this.\" If it wasn't, then an anonymous version of <code>MyCustomPrincipal</code> would be installed.</p>\n\n<p>So off I went for five hours trying to implement this, and with the help of <a href=\"http://www.leastprivilege.com/UserNameSupportingTokenInWCF.aspx\">various</a> <a href=\"http://weblogs.asp.net/cibrax/archive/2008/01/22/authenticating-users-with-supporting-tokens-in-wcf.aspx\">blogs</a>, I was able to do it. (I spent most of my time debugging a problem where I had every single configuration and supporting class correct, and then installed my custom authorizations <em>after</em> I started the host, not before, so none of my effort was actually taking effect. Some days I hate computers.) I had a <code>TrustedSubsystemAuthorizationPolicy</code> that did the X509 certificate validation, installing an anonymous <code>MyCustomPrincipal</code>, a <code>TrustedSubsystemImpersonationAuthorizationPolicy</code> that accepted a username token with a blank password and installed a customer-role <code>MyCustomPrincipal</code> if it saw that the anonymous trusted subsystem principal was already installed, and a <code>UserNameAuthorizationPolicy</code> which did regular username and password based validation for the other endpoints where X509 certificates aren't being used. It worked, and it was wonderful.</p>\n\n<p>But.</p>\n\n<p>The stab-myself-in-the-eyeballs moment came when I was fiddling with the generated client proxy code that the Web site would use to talk to this service. Specifying the <code>UserName</code> on the <code>ClientCredentials</code> property of the generated <code>ClientBase&lt;T&gt;</code> object was easy enough. But the main problem is that credentials are specific to a <code>ChannelFactory</code>, not a particular method invocation.</p>\n\n<p>You see, new()ing up a WCF client proxy is <a href=\"http://weblogs.asp.net/pglavich/archive/2007/05/07/wcf-client-channel-pool-improved-client-performance.aspx\">more expensive</a> than <a href=\"http://caught-in-a-web.blogspot.com/2008/05/increasing-wcf-client-applications.html\">you might think</a>. I wrote a quick-and-dirty app to test performance myself: both new()ing up a new proxy and calling a method ten times took about 6 seconds whereas new()ing up a proxy once and calling only the method 10 times cost about 3/5ths of one second. That is just a depressing performance difference.</p>\n\n<p>So I can just implement a pool or a cache for the client proxy, right? Well, no, it's not easily worked around: the client credentials information is at the channel factory level because it might be used to secure the transport, not just the message, and some bindings keep an actual transport open between service calls. Since client credentials are unique to the proxy object, this means that I would have to have a unique cached instance for each user currently on the Web site. That's potentially a lot of proxy objects sitting in memory, and pretty @#$@# close to the problem that I was trying to avoid in the first place! And since I have to touch the <code>Endpoint</code> property anyway to set up the binding for the optional supporting username token, I can't take advantage of the <a href=\"http://blogs.msdn.com/wenlong/archive/2007/10/27/performance-improvement-of-wcf-client-proxy-creation-and-best-practices.aspx\">automatic channel factory caching</a> that Microsoft added \"for free\" in .NET 3.5.</p>\n\n<p>Back to the drawing board: my second approach, and the one that I think that I'll end up using for now, is to stick with the X509 certificate security between the client Web site and the WCF service. I'll just send a custom \"UserName\" SOAP header in my messages, and the WCF service can inspect that SOAP header, determine if it came from a trusted subsystem such as the Web site, and if so, install a <code>MyCustomPrincipal</code> in a similar manner as before.</p>\n\n<p><a href=\"http://www.codeproject.com/KB/WCF/AutomaticCultureFlow.aspx\">Codeproject</a> and <a href=\"http://weblogs.asp.net/paolopia/archive/2008/02/25/handling-custom-soap-headers-via-wcf-behaviors.aspx\">random people on Google</a> are wonderful things to have because they helped me get this up and running quickly, even after <a href=\"http://nayyeri.net/blog/configuration-error-for-custom-behavior-extensions-in-wcf/\">running into a weird WCF bug when it comes to custom endpoint behaviors in configuration</a>. By implementing message inspectors on the client side and the service side--one to add the UserName header, and one to read it and install the correct principal--this code is in one place where I can simply forget about it. Since I don't have to touch the <code>Endpoint</code> property, I get the built-in channel factory caching for free. And since the <code>ClientCredentials</code> are the same for any user accessing the Web site (indeed, they are always the X509 certificate -- only the value of the UserName header within the message itself changes), adding client proxy caching or a proxy pool is much more trivial.</p>\n\n<p>So that's what I ended up doing. Actual service code in the WCF service can do things like</p>\n\n<pre><code>\n    // Scenario 1: X509Cert + custom UserName header yields for a Web site customer ...\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.Identity.Name); // prints out, say, \"joe@example.com\"\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.IsInRole(MyRoles.Customer)); // prints out \"True\"\n\n    // Scenario 2: My custom UserNameSecurityToken authentication yields for an employee ...\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.Identity.Name); // prints out, say, CN=Nick,DC=example, DC=com\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.IsInRole(MyRoles.Employee)); // prints out \"True\"\n\n    // Scenario 3: Web site doesn't pass in a UserName header ...\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.Identity.Name); // prints out nothing\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.IsInRole(MyRoles.Guest)); // prints out \"True\"\n    Console.WriteLine(\"{0}\", Thread.CurrentPrincipal.IsInRole(MyRoles.Customer)); // prints out \"False\"\n</code></pre>\n\n<p>It doesn't matter how these people got authenticated, or that some are living in SQL server or that some are living in Active Directory: <code>PrincipalPermission.Demand</code> and logging for auditing purposes is now a snap.</p>\n\n<p>I hope this helps some poor soul in the future.</p>\n    "},{"t":"WCF: MessageContract, DataContract … Confused?","l":"http://stackoverflow.com/questions/673638/wcf-messagecontract-datacontract-confused","q":"\n\n<p>I'm writing my first WCF service. I decided to write the service just as a DLL to begin with and then aspect the WCF stuff on afterwards which is where I am now.</p>\n\n<p>I was advised by the arcitect that I should stick to a specific format for message objects which I have done. However I've used Interfaces, complex types and lists thereof in my message objects. I'm coming to adding the attributes on and I'm getting a bit confused.</p>\n\n<p>Here's a show example of my code.</p>\n\n<pre><code>[ServiceContract]\npublic interface MyServiceContract\n{\n     [OperationContract]\n     MyMethodResponseMessage MyMethod(MyMethodRequestMessage request);\n}\n\npublic class MyService : MyServiceContract\n{\n    public MyMethodResponseMessage MyMethod(MyMethodRequestMessage request)\n    {\n        //Do things\n    }\n}\n\n//Messages\n[MessageContract]\npublic class MyMethodResponseMessage \n{\n    [MessageBodyMember]\n    public MyMethodResponse Body { get; set; }\n}\n\n[DataContract]\npublic class MyMethodResponse\n{\n    [DataMember]\n    public IMyComplexTypeItem { get; set; }\n\n    [DataMember]\n    public List&lt;IMyComplexType&gt; Items { get; set; }\n\n    [DataMember]\n    public bool Success { get; set; }\n}\n\n//DTO    \npublic interface IMyComplexType \n{\n    [DataMember]\n    string Identity { get; set; }\n}\n\n[DataContract]\npublic class MyComplexType1 : IMyComplexType\n{\n     [DataMember]\n     public virtual string Identity\n}\n</code></pre>\n\n<p>Can anyone comment on the correctness in the use of MessageContract, DataContract, DataMember and Serializable etc? Any pointers or glaring mistakes?</p>\n\n<p>Also which serializer is the best one to use? and what is the best strategy to ensure I get well formed XML from this so that other clients can consume my service easily?</p>\n    ","a":"\n<p>Re the request/response - a <code>[DataContract]</code> would work just as well. One of the advantages of message-contracts is that you can set privacy against members, but in many cases this isn't necessary. In such cases, I prefer to keep the contract as simple as possible, just as a data-contract.</p>\n\n<p>Re which serializer - that is largely a factor of the configuration. By default over http, for example, it will be <code>DataContractSerializer</code>.</p>\n\n<p>I'm not sure, however, that the list of <code>IMyComplexType</code> is going to work very well. You could try, but generally it wants concrete types. Note that with base-classes you can use <code>[KnownType]</code> to specify the allowed sub-types.</p>\n\n<p>Note that unlike <code>XmlSerializer</code>, it is not a requirement for collection members to have setters - although you might need to add an <code>OnDeserializing</code> callback method to initialize the list if you do that (WCF doesn't call constructors).</p>\n\n<p>Aside: you can also use <a href=\"http://code.google.com/p/protobuf-net/\">protobuf-net</a> with data-contracts and WCF (as long as they have an explicit Order); this is more densely packed than the regular xml. It has no support for message-contracts at the moment, though.</p>\n    "},{"t":"What is the best architecture for tracking field changes on objects?","l":"http://stackoverflow.com/questions/2135096/what-is-the-best-architecture-for-tracking-field-changes-on-objects","q":"\n\n<p>We have a web application that is built on top of a SQL database. Several different types of objects can have comments added to them, and some of these objects need field-level tracking, similar to how field changes are tracked on most issue-tracking systems (such as status, assignment, priority).  We'd like to show who the change is by, what the previous value was, and what the new value is.</p>\n\n<p>At a pure design level, it would be most straightforward to track each change from any object in a generic table, with columns for the object type, object primary key, primary key of the user that made the change, the field name, and the old and new values. In our case, these would also optionally have a comment ID if the user entered a comment when making the changes.</p>\n\n<p>However, with how quickly this data can grow, is this the best architecture? What are some methods commonly employed to add this type of functionality to an already large-scale application?</p>\n\n<p>[<strong>Edit</strong>]  I'm starting a bounty on this question mainly because I'd like to find out in particular what is the best architecture in terms of handling scale very well. Tom H.'s answer is informative, but the recommended solution seems to be fairly size-inefficient (a new row for every new state of an object, even if many columns did not change) and not possible given the requirement that we must be able to track changes to user-created fields as well.  In particular, I'm likely to accept an answer that can explain how a common issue-tracking system (JIRA or similar) has implemented this.</p>\n    ","a":"\n<p>There are several options available to you for this. You could have audit tables which basically mirror the base tables but also include a change date/time, change type and user. These can be updated through a trigger. This solution is typically better for behind the scenes auditing (IMO) though, rather than to solve an application-specific requirement.</p>\n\n<p>The second option is as you've described. You can have a generic table that holds each individual change with a type code to show which attribute was changed. I personally don't like this solution as it prevents the use of check constraints on the columns and can also prevent foreign key constraints.</p>\n\n<p>The third option (which would be my initial choice with the information given) would be to have a separate historical change table which is updated through the application and includes the PK for each table as well as the column(s) which you would be tracking. It's slightly different from the first option in that the application would be responsible for updating the table as needed. I prefer this over the first option in your case because you really have a business requirement that you're trying to solve, not a back-end technical requirement like auditing. By putting the logic in the application you have a bit more flexibility. Maybe some changes you don't want to track because they're maintenance updates, etc.</p>\n\n<p>With the third option you can either have the \"current\" data in the base table or you can have each column that is kept historically in the historical table only. You would then need to look at the latest row to get the current state for the object. I prefer that because it avoids the problem of duplicate data in your database or having to look at multiple tables for the same data.</p>\n\n<p>So, you might have:</p>\n\n<p>Problem_Ticket (ticket_id, ticket_name)\nProblem_Ticket_History (ticket_id, change_datetime, description, comment, username)</p>\n\n<p>Alternatively, you could use:</p>\n\n<p>Problem_Ticket (ticket_id, ticket_name)\nProblem_Ticket_Comments (ticket_id, change_datetime, comment, username)\nProblem_Ticket_Statuses (ticket_id, change_datetime, status_id, username)</p>\n    "},{"t":"Validating app, application is missing Architecture armv7","l":"http://stackoverflow.com/questions/12487689/validating-app-application-is-missing-architecture-armv7","q":"\n\n<p>When I'm updating my first iOS app , I have 2 problems validating them,</p>\n\n<pre><code>*iPhone/iPod Touch:application executable is missing a required architecture. \nAt least one of the following architecture(s) must be present: armv7\n\n*Unable to extract entitlements from application: (null)\n</code></pre>\n\n<p>The Info.plist and build settings are all the defaults, the only thing I changed is the code signing Identity debug and release to my distribution provisioning profile, with the app ID and Bundle Id identically.</p>\n    ","a":"\n<p>This happened to me when i had my iphone 5 connected and built my archive.  when i disconnected my iPhone and built my archive, it went through fine.</p>\n    "},{"t":"How well does .NET scale?","l":"http://stackoverflow.com/questions/54864/how-well-does-net-scale","q":"\n\n<p>(I'll begin by making it clear, I am not a .NET developer and am not tied to any other environment.)</p>\n\n<p>Recently, I heard that the London Stock Exchange went down for an entire day. I've also heard that the software was written in .NET. Up to this point they would experience performance hits on busy days. People seem to be blaming .NET. </p>\n\n<p>I don't want to debate the story, but it brought to mind the question of just how does .NET scale? How big is too big for .NET?</p>\n    ","a":"\n<p>Honestly, I think it boils down to code optimization, apart from just the infrastructure. </p>\n\n<p>In <a href=\"http://blog.stackoverflow.com/2008/08/podcast-19/\">StackOverflow Podcast 19</a>, Jeff discussed about how they had to tweak SQL Server to handle the kinds of loads StackOverflow has; notice that it was not .NET that needed tweaking here.</p>\n\n<p>One also has to note that <a href=\"http://weblogs.asp.net/scottgu/archive/2006/03/25/Handling-1.5-Billion-Page-Views-Per-Day-Using-ASP.NET-2.0.aspx\">MySpace.com, one of the most massive social networks out there, runs on ASP.NET</a>.</p>\n\n<p>The MySpace use of ASP.NET alone is a testament to its scalability. It will boil down to how developers will write their applications in such a way that best leverages that capability.</p>\n    "},{"t":"Why use Abstract factory pattern in C#","l":"http://stackoverflow.com/questions/10513086/why-use-abstract-factory-pattern-in-c-sharp","q":"\n\n<p>Most of the definition says: </p>\n\n<blockquote>\n  <p>An abstract factory provides an\n  interface for creating families of\n  related objects without specifying\n  their concrete classes</p>\n</blockquote>\n\n<p>What is the use of Abstract Factory Pattern as we can achieve the task via creating object of concrete class itself. Why do we have a factory method that creates object of Concrete class?  </p>\n\n<p>Please provide me any real life example where I must implement abstractFactory pattern? </p>\n    ","a":"\n<p>First of all, I would suggest you to read about the Abstract Factory pattern, for example <a href=\"http://en.wikipedia.org/wiki/Abstract_factory_pattern\">here</a>. Now I will try to explain why you would use this pattern.</p>\n\n<p>Normally, if you use the Factory pattern, you will create objects in a Factory. The problem arises when you have multiple implementation of a given class (or classes). Now, those multiple implementations are grouped. You will use the <code>Abstract Factory pattern</code> when you have a factory, but you would like to group the creating of objects per group.</p>\n\n<p>Okay, above explanation might not be completely clear, so I will give you an example.</p>\n\n<p>Let's say you have a class library with data agents. Data agents provide you methods to access and store different data. Of course, there are multiple ways of storing your data. For example: in a database, in XML file, over a service, . For each of these possible ways, you would like to have data agents. Now the problem is, you don't want that someone uses the DataAgentA for XML files together with DataAgentB for database (let's assume that we have entities A and B). The user should use only one storage engine.</p>\n\n<p>Let me introduce you the Abstract Factory pattern.</p>\n\n<p>You will make sure that users cannot directly instantiate your Data Agents, but they will have to get these data agents out of a factory. (An extra advantage is, that when you use for example a database (EF), you can do internal wiring to make sure your Data Agents use the same context, etc.) How do we accomplish this? We set the constructor of our data agents to ´internal´. Apart from that, we create different factories for each storage engine. Now, since those factories all do the same, we also have these interfaced (just like our data agents, since they all have to do the same, right!?).</p>\n\n<p>Below we have our interfaces. Basically this is the factory pattern, but only now instead of about <em>classes</em>, we are talking about <em>interfaces</em>.</p>\n\n<pre><code>public interface IAgentA \n{\n    // Add some methods here!\n}\n\npublic interface IAgentB\n{\n    // Add some methods here!\n}\n\npublic interface IAgentFactory\n{\n    IAgentA CreateAgentA();\n    IAgentB CreateAgentB();\n}\n</code></pre>\n\n<p>Now for the two agents, we have two possible implementations, one for XML and one for database storage (again: this is an example, you can have as many implementation types as you want). Those implementations would look like this (see below). Please note that I made the constructor <code>internal</code>! This is needed for the part that comes after this code block.</p>\n\n<pre><code>public class AgentA_Xml : IAgentA\n{\n    internal AgentA_Xml()\n    { /* Construction here */}\n\n    // IAgentA method implementations\n}\n\npublic class AgentB_Xml : IAgentB\n{\n    internal AgentB_Xml()\n    { /* Construction here */}\n\n    // IAgentB method implementations\n}\n\n\npublic class AgentA_Database : IAgentA\n{\n    internal AgentA_Database()\n    { /* Construction here */}\n\n    // IAgentA method implementations\n}\n\npublic class AgentB_Database : IAgentB\n{\n    internal AgentB_Database()\n    { /* Construction here */}\n\n    // IAgentB method implementations\n}\n</code></pre>\n\n<p>Now as the constructors are internal. This causes that you cannot instantiate those classes outside the assembly, which is generally what you do with these kind of cases. Now we have to create our factories.</p>\n\n<pre><code>public class XMLAgentFactory : IAgentFactory\n{\n    public IAgentA CreateAgentA()\n    {\n        return new AgentA_Xml();\n    }\n\n    public IAgentB CreateAgentB()\n    {\n        return new AgentB_Xml();\n    }\n}\n\n\npublic class DatabaseAgentFactory : IAgentFactory\n{\n    public IAgentA CreateAgentA()\n    {\n        return new AgentA_Database();\n    }\n\n    public IAgentB CreateAgentB()\n    {\n        return new AgentB_Database();\n    }\n}\n</code></pre>\n\n<p>Since both factories implement the <code>IAgentFactory</code> interface, the user can easily change of <code>AgentFactory</code> implementation (if he, in this case, wants to use a different storage engine) without having to change any other code he wrote (against the agents), as long as he programmed against the interfaces (obviously).</p>\n\n<p>Above explanation hopefully answers your questions (1) and (2).</p>\n\n<blockquote>\n  <ol>\n  <li>Good example for Abstract factory pattern in C#? </li>\n  <li>and what are advantages of Abstract factory pattern in c#?</li>\n  </ol>\n</blockquote>\n\n<p>Answering your question (3).</p>\n\n<blockquote>\n  <ol>\n  <li>How use C# generics with Abstract factory pattern?</li>\n  </ol>\n</blockquote>\n\n<p>You can still use generics, this doesn't change any bit when you use an Abstract Factory pattern. Of course, you will have to create generic factory methods (the create methods), but that shouldn't be any problem.</p>\n\n<p>Answering your question (4).</p>\n\n<blockquote>\n  <ol>\n  <li>How does unit test with Abstract factory pattern?</li>\n  </ol>\n</blockquote>\n\n<p>Just the same as you would unit test any other class. Only one thing will be different.</p>\n\n<p>Since you probably also want to test the constructor of your classes (and maybe other internal methods), you need to make the internal constructors (methods) visible to your unit test project (and you don't want to change the <code>internal</code> to <code>public</code>). This is easily done by adding the following line to your <code>AssemblyInfo.cs</code> file of your project (the project where your factory and classes are in):</p>\n\n<pre><code>[assembly: System.Runtime.CompilerServices.InternalsVisibleTo(\"My.UnitTest.Namespace\")]\n</code></pre>\n\n<p>You can find more information (and remarks) about the InternalsVisibleTo attribute on <a href=\"http://msdn.microsoft.com/en-us/library/system.runtime.compilerservices.internalsvisibletoattribute.aspx\"><strong>MSDN</strong></a>.</p>\n\n<p>I hope this kind of answers your question.</p>\n    "},{"t":"Arguments of using WCF/OData as access layer instead of EF/L2S/nHibernate directly","l":"http://stackoverflow.com/questions/2498796/arguments-of-using-wcf-odata-as-access-layer-instead-of-ef-l2s-nhibernate-direct","q":"\n\n<p>We develop mostly low traffic but highly specialized web applications. Normally we use L2S, EF or nHibernate as access layer and then throws Asp.Net MVC to it and in which for normal crud operations we query the ISession/DataContext directly but for more advanced functions/side effects we put it in a some kind of service layer. </p>\n\n<p>Now, i was think about publishing the data through OData (WCF Data Service) and query that from the controllers (or even from jQuery when the a good template engine shows up) and publish the service operations through a WCF service (or as custom methods on the WCF Data Service?). What advantages/disadvantages does this architecture poses? </p>\n\n<p>Do I gain something except higher complexity and latency? Better separations of concerns (or is it just a illusion)? </p>\n\n<p><strong>Edit:</strong>\nCan it be a good idea to create a complete ajax driven solution with eg. <a href=\"http://www.silverlight.net/getstarted/riaservices/\">WCF RIA Services</a>? Or do one loose too much flexibility? Feels like you can completely dispatch your views from your logic then, heck, one should be able to just write pure HTML, not even a asp.net MVC should be needed? but i guess there's a lot of new problems arising? </p>\n    ","a":"\n<p>As TomTom mentions, you don't want to pay the cost of loopback for OData when within a process. If you have direct line-of-sight to your database and it's your own application's database, then there is no reason to put WCF Data Services in the middle. I would continue to use one of the other options you mentioned (L2S, EF, nHibernate). </p>\n\n<p>Now, if you need to expose data over your http endpoint for other applications to consume, or even for your own application if you have some jQuery code in the client that needs to access data from the server, then definitely an OData endpoint may help and WCF Data Services is the simplest way to create one.</p>\n    "},{"t":"Django role based views?","l":"http://stackoverflow.com/questions/1546670/django-role-based-views","q":"\n\n<p>I'm looking for some input on how others would architect this. I'm going to provide class (django group) based views. </p>\n\n<p>For example, a user's group will determine what views/templates he or she will have access to. I'm thinking of perhaps storing paths to view functions in a table to determine what a user's link bar will consist of. Filter specifications can also be stored to determine what rows will fill these templates. </p>\n\n<p>A good example is a hospital nursing units. Nurses at one unit need not see the entire hospital's patients. They only need to see their patients. Doctors on the same unit need only to see those patients as well, but they should have access to much greater functionality.</p>\n\n<p>Has this been done via some third party application? And how would you approach this problem?</p>\n\n<p>Thanks,\nPete</p>\n    ","a":"\n<p>Django already has a groups and permissions system, which may be sufficient for your purpose.</p>\n\n<p><a href=\"http://docs.djangoproject.com/en/dev/topics/auth/\">http://docs.djangoproject.com/en/dev/topics/auth/</a></p>\n\n<p>Generally in your code you check if a user has a permission. A user has his own permissions and those of the groups he belongs to. You can administer this pretty easily from the admin console.</p>\n\n<p>There are two parts you need to look at.</p>\n\n<ol>\n<li>Check that a user requesting a page\nhas permission to do so.</li>\n<li>Only display links to the user if he\nhas the permission.</li>\n</ol>\n\n<p>For 1. you can check permissions in a decorator as such:</p>\n\n<pre><code>from django.contrib.auth.decorators import permission_required\n\n@permission_required('polls.can_vote')\ndef some_view(request):\n</code></pre>\n\n<p>For 2. the currently logged-in user's permissions are stored in the template variable {{ perms }}. This code checks the same permission as above.</p>\n\n<pre><code>{% if perms.polls.can_vote %}\n    &lt;a href=\"/vote\"&gt;vote&lt;/a&gt;\n{% endif %}\n</code></pre>\n\n<p>To generate a list of links you can iterate over user.get_all_permissions() and fetch the links (or function that generates the link) from a dict:</p>\n\n<pre><code>def more_elaborate_list_of_links_for_a_perm(user):\n    return [\"/link1\", ...]\n\n_LINKS = {\n        'polls.can_vote' : lambda u: [\"/user/specific/link/\" + u.id],\n        'polls.can_close': lambda u: ['/static/link/1', 'static/link/2'],\n        'polls.can_open' : more_elaborate_list_of_links_for_a_perm\n    }\n\ndef gen_links(user):\n    userlinks = []\n    perms = user.get_all_permissions()\n    #get_all_permissions also gets permissions for users groups\n    for p in perms:\n        if _LINKS.has_key(p):\n            userlinks.extend(_LINKS[p](user))\n\n    return userlinks\n</code></pre>\n\n<p>There are probably many other approaches.</p>\n    "},{"t":"How does Trello show history so quickly?","l":"http://stackoverflow.com/questions/10505431/how-does-trello-show-history-so-quickly","q":"\n\n<p>Trello shows a historial log of everything that any user has done since the board's inception. Likewise, if you click on a specific card it shows the history of anything anyone has done related to that card. </p>\n\n<p>Keeping track of every change/addition/deletion that is kept indefinitely must collect a ton of data and also potentially bottleneck on writing to the history trail log (assuming it is written immediately to a data store of sorts). I mean, it isn't like they are storing everything in log files spread across 1000's of servers that they only collect and parse when they need to find something -- they are displaying all of this info all the time. </p>\n\n<p>I know this isn't the only service that provides something like this, but how would you go about architecting such a system?</p>\n    ","a":"\n<p>I'm on the Trello team. We use an Actions collection in our MongoDB instance, with a compound index on the ids of the models to which it refers (a Card is a model, and so is a Member) and the date when the action was performed. No fancy caching or anything, except inasmuch as the index and recently used documents are kept in memory by the DB. Actions is by far our biggest collection.</p>\n\n<p>It is worth mentioning that most of the data needed to display an action is stored denormalized in the action document, so that speeds things up considerably.</p>\n    "},{"t":"When does multiple inheritance come in handy?","l":"http://stackoverflow.com/questions/31478542/when-does-multiple-inheritance-come-in-handy","q":"\n\n<p>Can you provide some real-world examples when problem can be more easily addressed using multiple inheritance rather than using composition or other alternatives?</p>\n\n<p>When should one use multiple inheritance?</p>\n\n<p>Why do some languages support multiple inheritance (C++, Python) and others don't (Java, Ruby)? I mean - based on what factors do creators of programming languages decide to include support for MI or not.</p>\n    ","a":"\n<p>Multiple inheritance is mostly used for integration purposes, i.e. when you need an object that implements all the required functionality of the classes it derives from. Whether this amounts to a \"better\" solution than possible alternatives, is a matter of debate or taste, so you're probably lucky that this question wasn't closed as primarily opinion-based.</p>\n\n<p>With regard to examples, </p>\n\n<ul>\n<li>this article on <a href=\"https://rhettinger.wordpress.com/2011/05/26/super-considered-super/\">using Python's super() for multiple\ninheritance</a>\nshows an example of implementation sharing. You can't have this with\ninterfaces or composition,</li>\n<li>a similar example is explained on the <a href=\"https://en.wikipedia.org/wiki/Multiple_inheritance\">Wikipedia page on multiple inheritance</a> for deriving <code>Button</code> from <code>Rectangle</code> and <code>Clickable</code> (it also has a long list of languages supporting MI),</li>\n<li>an answer to a previous question <a href=\"http://stackoverflow.com/a/31178549/3098550\">for good MI examples</a> points to <code>Observable</code> and the like, which at least Bertrand Meyer claims to be cleaner implemented with MI than without (hence you're also lucky that this question didn't get closed as a duplicate).</li>\n</ul>\n\n<p>From personal experience, multiple inheritance can be quite helpful, but it can also be a big problem easily. The Wikipedia page discusses the <em>Diamond</em> problem to some extent: it boils down to the question what should happen if two or more base classes provide an implementation of some method. Languages need to define / implement a way to deal with this, typically by defining some method resolution order (e.g. <a href=\"https://www.python.org/download/releases/2.3/mro/\">Python's mro</a>).</p>\n\n<p>The conflict potential increases, of course, with the number of base classes and the number of methods. I had a case once where the framework (implemented in Python) we were using employed multiple inheritance of a handful of base classes for some class we had derived from. We could then happily override an inherited method without being aware of it. </p>\n\n<p>Multiple inheritance, while sometimes useful, can be seen as a violation of the <a href=\"https://en.wikipedia.org/wiki/Single_responsibility_principle\">Single responsibility principle</a>: by definition, a class deriving from multiple base classes will behave like either class. It's hence also quite likely that from a data modelling perspective, the <a href=\"https://en.wikipedia.org/wiki/Liskov_substitution_principle\">Liskov substitution principle</a> is also violated.</p>\n\n<p>So, I believe that creators of programming languages might recognize that multiple inheritance is seen as not free of conceptual issues and might require substantial implementation effort while providing only limited added value over other solutions -- but that's just my personal guess.</p>\n    "},{"t":"What do i need to create a RESTful API Server in Java?","l":"http://stackoverflow.com/questions/9943445/what-do-i-need-to-create-a-restful-api-server-in-java","q":"\n\n<p>I would like to build my own RESTful API Server and i have no idea what i need for that.</p>\n\n<p>I'll tell you a bit about the project:</p>\n\n<p>On a Webservice (www.mysite.com/) users can register and manage there account and so on. But they also can use the RESTful API (mysite.com/api/...) and can do there pretty much the same via REST.</p>\n\n<p>What is a good way to realize that ? Do i need to use jetty or something similar ?\nShould i split webservice and restful api ? what i a good architecture for that ?</p>\n\n<p>Thanks :)</p>\n    ","a":"\n<p>you can use Spring controller for build a restful server. You can run it on tomcat or jetty doesn't matter.</p>\n\n<p>check this url : <a href=\"http://static.springsource.org/spring/docs/3.0.0.M3/spring-framework-reference/html/ch18s02.html\">http://static.springsource.org/spring/docs/3.0.0.M3/spring-framework-reference/html/ch18s02.html</a></p>\n    "},{"t":"Getting up to speed on modern architecture","l":"http://stackoverflow.com/questions/2644290/getting-up-to-speed-on-modern-architecture","q":"\n\n<p>I don't have any formal qualifications in computer science, rather I taught myself classic ASP back in the days of the dotcom boom and managed to get myself a job and my career developed from there. I was a confident and, I think, pretty good programmer in ASP 3 but as others have observed one of the problems with classic ASP was that it did a very good job of hiding the nitty-gritty of http so you could become quite competent as a programmer on the basis of relatively poor understanding of the technology you were working with.</p>\n\n<p>When I changed on to .NET at first I treated it like classic ASP, developing stand-alone applications as individual websites simply because I didn't know any better at the time. I moved jobs at this point and spent the next several years working on a single site whose architecture relied heavily on custom objects: in other words I gained a lot of experience working with .NET as a middle-tier development tool using a quite old-fashioned approach to OO design along the lines of the classic \"car\" class example that's so often used to teach OO. Breaking down programs into blocks of functionality and basing your classes and methods around that. Although we worked under an Agile approach to manage the work the whole setup was classic client/server stuff. That suited me and I gradually got to grips with .NET and started using it far more in the manner that it should be, and I began to see the power inherent in the technology and precisely why it was so much better than good old ASP 3.</p>\n\n<p>In my latest job I have found myself suddenly dropped in at the deep end with two quite young, skilled and very cutting-edge programmers. They've built a site architecture which is modelling along a lot of stuff which is new to me and which, in truth I'm having a lot of trouble understanding. The application is built on a cloud computing model with multi-tenancy and the architecture is all loosely coupled using a lot of interfaces, factories and the like. They use nHibernate a lot too. Shortly after I joined, both these guys left and I'm now supposedly the senior developer on a system whose technology and architecture I don't really understand and I have no-one to ask questions of.</p>\n\n<p>Except you, the internet.</p>\n\n<p>Frankly I feel like I've been pitched in at the deep end and I'm sinking. I'm not sure if this is because I lack the educational background to understand this stuff, if I'm simply not mathematically minded enough for modern computing (my maths was never great - my approach to design is often to simply debug until it works, then refactor until it looks neat), or whether I've simply been presented with too much of too radical a nature at once. But the only way to find out which it is is to try and learn it.</p>\n\n<p>So can anyone suggest some good places to start? Good books, tutorials or blogs? I've found a lot of internet material simply presupposes a level of understanding that I just don't have.</p>\n\n<p>Your advice is much appreciated. Help a middle-aged, stuck in the mud developer get enthusastic again!</p>\n\n<p>Please!</p>\n    ","a":"\n<p><strong>Sitting on the Beach - Preparation</strong></p>\n\n<p>Make a list of everything you don't understand. At the final stage, this list shall be your checklist. \nClear your mind – get yourself to a fresh start, \"forget\" all the confusing details you already know about your architecture.\nDig up every document created by the original architects.\nGet the documentations for every technology used in your project.\nMake coffee. </p>\n\n<p><strong>Floating - Managing Complexity</strong></p>\n\n<p>To float, you need to manage complexity. If you don't deal with complexity properly, you'll dive into details when there's absolutely no need, and you won't know how and where to stop, sinking right into the bottom and drowning. </p>\n\n<blockquote>\n  <p>\"My approach to design is often to\n  simply debug until it works, then\n  refactor until it looks neat\"</p>\n</blockquote>\n\n<p>I think I used to be just like you. I developed solutions by starting from scratch and adding one piece at a time, eventually containing a complex structure inside my head. I didn't plan the architecture, I didn't separate design and implementation, I just coded, debugged, refactored. It worked: since complexity grew slowly, I had no trouble understanding the architecture that emerged.</p>\n\n<p>This approach simply isn't good enough when \"inheriting\" a complex architecture planned by others; you cannot swallow the entire structure at once - because there are too many details, and you cannot randomly swallow little bits - because you won't understand how they all relate to each other and you'll never get to see the big picture.</p>\n\n<p>Software is a puzzle of complexity management. There are very big pieces, sometimes referred to as \"subsystems\", which compose the big picture. Each of these is composed of smaller pieces, which in turn are also composed of smaller pieces. When you look at the code, all you see is the tiniest pieces. So forget about the code itself for now, at least until you see all the bigger pieces. </p>\n\n<p><strong>Swimming – Mapping the Architecture</strong></p>\n\n<p>The first step towards floating is seeing the big pieces. To do that, you need maps. The map to the biggest pieces is the highest-level architecture. If the original architects left you with no such map, you'll have to create it by yourself. Just like it is impossible to map a region from inside a valley, you cannot map your architecture from low-level details. You need to stand at the top of a mountain to get a 360-degrees-view of all the valleys, hills and paths. You need to map your architecture from the top.  </p>\n\n<p>After you have this top-level map, you should get maps for the parts composing it - just like you create an un-detailed map of an entire region, and then create separate detailed maps of sub-regions. A map should describe the different subsystems. At the very least, it should describe the responsibilities of each subsystem, its external interface, and how it interacts with other subsystems.</p>\n\n<p><strong>Diving – Managing the Details</strong></p>\n\n<p>There is this principle in diving which says you shouldn't move between depths too fast, because of the changes in pressure. This principle holds. When you move from dealing with one subsystem into dealing with one of its internal subsystems, make sure you only dive into the next level of complexity/abstraction. Let your mind handle one tier at a time. </p>\n\n<p>Separate concepts, patterns, interfaces and implementations. nHibernate is an Object-Relational Mapping (ORM) solution. Thus, before you deal with the details of nHibernate itself, you need to make sure you understand the general concept of ORMs and their place in the world. Factory is a design-pattern, so before you deal with Factory you should understand what design-patterns are and what their role is.</p>\n\n<p>Technologies raise and fall, but concepts remain. Once you get the concepts, it really doesn't matter much – on an architectural level – how these concepts are manifested. </p>\n\n<p>The fact that your architecture is loosely-coupled is actually a good thing, because it means you can understand the role of one subsystem without the need to know much about other subsystems. The fact your architecture makes use of interfaces is also good – it means you can learn how elements interact with each other without learning how they work internally. </p>\n\n<p><strong>Waterskiing – Acquiring Distilled Knowledge</strong>  </p>\n\n<p>There is one book that I think is a \"must-read\": Code Complete by Steve McConnell. It changed my professional life.</p>\n\n<hr>\n\n<p>I hope that this post managed to help you in some way and isn't a complete waste of your time.</p>\n    "},{"t":"Tools to produce & manage specifications/requirements (not ticket trackers)","l":"http://stackoverflow.com/questions/4187927/tools-to-produce-manage-specifications-requirements-not-ticket-trackers","q":"\n\n<p>I'm interested if there are any websites or software out there to aid in initial project design, and then management of the project's design over time as features are implmented, bugs are found, etc...  My design will include requirements (functional &amp; non-functional), use cases, and basic database schema design.</p>\n\n<p>Most sought-after feature:</p>\n\n<ul>\n<li>Being able to define requirements and track their changes over time (i.e. how is version 1.5 different than 1.0?)</li>\n</ul>\n\n<p>Nice-to-haves:</p>\n\n<ul>\n<li>Being able to collaborate with other project managers and the team when putting together the specifications</li>\n</ul>\n\n<p>What I'm <em>not</em> looking for:</p>\n\n<ul>\n<li>Ticket trackers (JIRA, fogbugz, etc...)</li>\n<li>Software version control systems</li>\n<li>Wikis (unless they are built with requirements management in mind)</li>\n</ul>\n\n<p>Thanks.</p>\n    ","a":"\n<p>[Edit : based on revised question]</p>\n\n<blockquote>\n  <p>Requirement Management Tools</p>\n</blockquote>\n\n<p>Most requirement management tools work on textual and diagrammatic end artifacts. For version control, I prefer to use a DVCS like Mercurial. How ever the tool must provide traceability. </p>\n\n<p>I have used Rational tools and many others and my personal experience has not been very good at all. I have spent more time dealing with the tool than using it for other productive means.</p>\n\n<p>Some of the products that caters for this requirement:</p>\n\n<ol>\n<li><strong>Rational</strong> Requisite Pro and IBM Rational DOORS (heavy, costly and not to my liking) </li>\n<li>Web based requirement management tool: <a href=\"http://code.google.com/p/django-req/\"><strong>django-req</strong></a></li>\n<li>A promising free opensource tool <a href=\"http://www.flonatel.de/index.php?id=9\"><strong>rmtoo</strong></a> </li>\n</ol>\n\n<blockquote>\n  <p>Design Tools</p>\n</blockquote>\n\n<p>There are various <strong>design documentation tools</strong> that targets specific type of design and outputs different design artifacts. Say <a href=\"http://www.aquafold.com/docs-er-diagram.html\">Entity Relationship Tool</a>. You will have to check out what you need.</p>\n\n<p>UML tools are very helpful and are the good way to document use cases.</p>\n\n<ol>\n<li>UML based diagramming tool <a href=\"http://www.yworks.com/en/index.html\"><strong>yED</strong></a>. </li>\n<li>A UML based modelling tool <a href=\"http://staruml.sourceforge.net/en/\"><strong>StarUML</strong></a> </li>\n<li>This is my favourite : <a href=\"http://argouml.tigris.org/\"><strong>argouml</strong></a></li>\n</ol>\n\n<p>People can get creative with the tools they use for design purposes.</p>\n\n<ol>\n<li><a href=\"http://www.developer.com/design/article.php/3469181\">Using mind map</a></li>\n<li><a href=\"http://en.wikipedia.org/wiki/List_of_Unified_Modeling_Language_tools\">Uml is still a prevalent design tool</a></li>\n</ol>\n\n<blockquote>\n  <p>Database design tool</p>\n</blockquote>\n\n<ol>\n<li><a href=\"http://ondras.zarovi.cz/sql/demo/\"><strong>SQL Designer</strong></a> does a good job    </li>\n<li>Check out the free : <a href=\"http://www.fabforce.net/dbdesigner4/\"><strong>dbdesigner4</strong></a></li>\n<li><a href=\"http://wb.mysql.com/\"><strong>MySql Workbench</strong></a> </li>\n<li><a href=\"http://www.sqlpower.ca/page/architect\"><strong>SQL Power Architect</strong></a> is very promising.</li>\n</ol>\n\n<blockquote>\n  <p>Project management</p>\n</blockquote>\n\n<p>There are <a href=\"http://basecamphq.com/\"><strong>plethora of tools</strong></a> that can do project management including the MS tool that you mentioned. You only need to search them in google. </p>\n\n<ul>\n<li>I have enjoyed using <a href=\"http://faces.homeip.net/\"><strong>faces</strong></a> and is my favorite.</li>\n<li><a href=\"http://www.ganttproject.biz/\"><strong>ganttproject</strong></a> </li>\n<li><a href=\"http://www.jxproject.com/\"><strong>jxproject</strong></a> </li>\n<li><a href=\"http://www.dotproject.net/\"><strong>dotproject</strong></a> is a good open source tool. </li>\n<li><a href=\"http://www.openworkbench.org/\"><strong>openworkbench</strong></a> considers itself an alternative to MS Project.</li>\n<li><a href=\"http://www.projectpier.org/\">projectpier</a>, <a href=\"http://projecthq.org/\">projecthq</a> </li>\n</ul>\n\n<blockquote>\n  <p>collaborative software development</p>\n</blockquote>\n\n<p>For collaborative software development, there are many was like google code, <a href=\"http://bitbucket.org/\">bitbucket</a> , <a href=\"http://www.collab.net/\">collabnet</a> ...</p>\n    "},{"t":"How do I create a single makefile for both 32- and 64-bit?","l":"http://stackoverflow.com/questions/4096173/how-do-i-create-a-single-makefile-for-both-32-and-64-bit","q":"\n\n<p>I have a <code>makefile</code> that works transparently for Linux (<code>x86_64</code>) and OS X Intel (<code>x86_64</code>). This uses 64-bit specific GCC options.</p>\n\n<p>Is there a way to adjust the makefile so that I could build for 32-bit and 64-bit OS X PPC (<code>ppc</code>, <code>ppc64</code>) without having to maintain separate, arch-specific makefiles — perhaps something like a pre-processor directive that can determine the architecture before building?</p>\n    ","a":"\n<pre><code>ARCH := $(shell getconf LONG_BIT)\n\nCPP_FLAGS_32 := -D32_BIT ...  Some 32 specific compiler flags ...\nCPP_FLAGS_64 := -D64_BIT\n\nCPP_FLAGS := $(CPP_FLAGS_$(ARCH))  ... all the other flags ...\n</code></pre>\n    "},{"t":"Best Design for a User/Role Management System?","l":"http://stackoverflow.com/questions/300359/best-design-for-a-user-role-management-system","q":"\n\n<p>Here's a software design question I've encountered several times and have never found an ideal solution for (I'm also dealing with it now again.)</p>\n\n<p>Many applications need some form of user/role management.  You have base users, groups that these users can belong to (not limited to just one), roles and permissions they have, organizational units, and a whole bunch of properties and other features that are project-specific.</p>\n\n<p>My question is, what ways do people know of and/or have experience with to design and build a really dynamic, flexible user management system?  Are there any design patterns you know of that really help?</p>\n    ","a":"\n<p>You should adapt your design because every organization is different. \n<a href=\"http://en.wikipedia.org/wiki/Role-based_access_control\" rel=\"nofollow\">Check this page</a>, you can see a pattern for role-based administration.</p>\n    "},{"t":"If 'Architect' is a dirty word - what's the alternative; when not everyone can actually design a good interface!","l":"http://stackoverflow.com/questions/2453649/if-architect-is-a-dirty-word-whats-the-alternative-when-not-everyone-can-a","q":"\n\n<p>Now - I'm a developer first and foremost; but whenever I sit down to work on a big project with lots of interlinking components and areas, I will forward-plan my interfaces, base classes etc as best I can - putting on my Architect hat.</p>\n\n<p>For a few weeks I've been doing this for a huge project - designing whole swathes of interfaces etc for a business-wide platform that we're developing.</p>\n\n<p>The basic structure is a couple of big projects that consists of service and data interfaces, with some basic implementations of all of these.  On their own, these assemblies are useless though, as they are simply intended intended as a scaffold on which to build a business-specific implementation (we have a lot of businesses).  Therefore, the design of the core platform is absolutely crucial, since consumers of the system are not intended to know which implementation they are actually using.</p>\n\n<p>In the past it's not worked so well, but after a few proof-of-concepts and R&amp;D projects this new platform is now growing nicely and is already proving itself.</p>\n\n<p>Then somebody else gets involved in the project - he's a TDD man who sees code-level architecture as an irrelevance and is definitely from the camp that 'architect' is a dirty word - I should add that our working relationship is very good despite this :)</p>\n\n<p>He's open about the fact that he can't architect in advance and obviously TDD really helps him because it allows him to evolve his systems over time.  That I get, and totally understand; but it means that his coding style, basically, doesn't seem to be able to honour the architecture that I've been putting in place.</p>\n\n<p>Now don't get me wrong - he's an awesome coder; but the other day he needed to extend one of his components (an implementation of a core interface) to bring in an extra implementation-specific dependency; and in doing so he extended the core interface as well as his implementation (he uses ReSharper), thus breaking the independence of the whole interface.</p>\n\n<p>When I pointed out his error to him, he was dismayed.  Being test-first, all that mattered to him was that he'd made his tests pass, and just said 'well, I need that dependency, so can't we put it in?'.</p>\n\n<p>Of course we <em>could</em> put it in, but I was frustrated that he couldn't see that refactoring the generic interface to incorporate an implementation-specific feature was just wrong!  But it is all very Charlie Brown to him (you know the sound the adults make when they're talking to the children) - as far as he's concerned we don't need to worry about it because we can always refactor.</p>\n\n<p>The problem is, the culture of test-write-refactor is all very well and good - but not when you're dealing with a platform that is going to be shared out among so many projects that you could never get them all in one place to make the refactorings work.  In my opinion, sometimes you actually have to think about what you're doing, and not just let nature take its course.</p>\n\n<p>Am I simply fulfilling the role of Architect as a dirty word here?  I believe that architecture is important and should be thought about before code gets written; unless it's a particularly small project.  But when you're working in a team of people who don't think that way, or even <em>can't</em> think that way how can you actually get this across?</p>\n\n<p>Is it a case of simply making the architecture off-limits to changes by other people?  I don't want to start having bloody committees just to be able to grow the system; but equally I don't want to be the only one responsible for it all.</p>\n\n<p>Do you think the architect role is a waste of time? Is it at odds with TDD and other practises?  Can this mix of different practises be made to work, or should I just be a lot less precious (and in so doing allow a generic platform become useless!)?</p>\n\n<p>Or do I just lay down the law?</p>\n\n<p>Any ideas/experiences/views gratefully received.</p>\n\n<p><strong>UPDATE</strong></p>\n\n<p>At the time of accepting the answer, I'd like to point out that all of the answers provided are excellent - I've chosen the one relating to communication because I feel that as the lead on this particular project, I have to communicate what I want; and at the same time the team must communicate back if they feel it's wrong.</p>\n\n<p>Certainly, though, it's good to get clarification that there's no reason for the development practise (i.e. TDD etc) to interfere with the role of an architect.</p>\n    ","a":"\n<p><strong>Communication / Design Goals</strong></p>\n\n<p>The developers really need to undersand the project's <strong>design goals</strong>. As an architect (and developer) it's your role to ensure that the communication of these goals is clear and they're understood by everybody in the team.</p>\n\n<p>You summarized why there is this particular design goal of your question very well here - that's what they need to understand:</p>\n\n<blockquote>\n  <p>The problem is, the culture of\n  test-write-refactor is all very well\n  and good - but not when you're dealing\n  with a platform that is going to be\n  shared out among so many projects that\n  you could never get them all in one\n  place to make the refactorings work.\n  In my opinion, sometimes you actually\n  have to think about what you're doing,\n  and not just let nature take its\n  course.</p>\n</blockquote>\n\n<p>So you need to discuss this with him and other developers until everybody is on the same page. <strong>Communication</strong> is key here.</p>\n    "},{"t":"Android Architecture Design - How to do it right?","l":"http://stackoverflow.com/questions/5093457/android-architecture-design-how-to-do-it-right","q":"\n\n<p>how does a good architecture for an android app look like? Should all the \"work/business logic\" been done in a background service and the Activity communicates just with the service to query/fetch data from somewhere (local/distant)?</p>\n\n<p>Would you implement the \"service\" that the Activity calls as a real Android-service? Or a POJO-Singleton that does the work (perhaps using background threads). Or instantiate background threads in your activity for time-consuming actions (query a webservice).</p>\n\n<p>How do you abstract your data access the right way? Would you use a ContentProvider to access/abstract your data? How/From where should it be queried? Activity? Service? ..?</p>\n\n<p>I've tried to search for a good app architecture design, but I only found how the Android architecture looks like, not how an Android app should look like. </p>\n\n<p>So what's your opinion about that? What components of an Android application should communicate which each other to ensure best extensibility/encapsulation,...?</p>\n    ","a":"\n<p>There's no one answer to this question.  Good OO design isn't Android specific.  I'd say that the rule is - if the framework gives you a high level object (such as Service in the case of Android) that fits your use case, use it.  If you find yourself making POJO implementations of the same things you get for free with the framework, go with the framework.</p>\n\n<p>As far as separation of concerns, this is standard OO stuff.  Don't put anything in your Activity classes that isn't the job of the Activity.  Over-stuffing the Activity with methods and properties that the Activity needs but aren't really the job of the Activity is bad - makes the intention of your Activity hard to understand.</p>\n\n<p>I usually separate stuff into sub-packages in my apps.</p>\n\n<ul>\n<li>com.myname.myproject.app - base classes, global application functionality</li>\n<li>com.myname.myproject.net - network stuff, network related utils</li>\n<li>com.myname.myproject.data - db helpers, providers, etc</li>\n<li>com.myname.myproject.model - object model</li>\n</ul>\n\n<p>etc.</p>\n\n<p>As far as communication within your app...</p>\n\n<p>I always have a custom Application class that I register in the manifest.  This way, when I have controllers and helpers that need to be a \"single instance\", I don't have to do all that crazy thread safe singleton stuff...I just keep one global copy of.</p>\n\n<p><a href=\"http://code.google.com/p/roboguice/\">RoboGuice</a> is a dependency injection framework that makes this even easier to accomplish...definitely worth looking into.  If this interests you, the Google Group for RoboGuice is great and is constantly filled with the creators of the framework who can basically answer anything you need.</p>\n\n<p>As far as in-app communication, I use my single instance Controller and State classes to hold state and do common tasks, and I usually use BroadcastIntents to communicate back to Activities from Services</p>\n    "},{"t":"How would I implement separate databases for reading and writing operations?","l":"http://stackoverflow.com/questions/2914664/how-would-i-implement-separate-databases-for-reading-and-writing-operations","q":"\n\n<p>I am interested in implementing an architecture that has two databases one for read operations and the other for writes. I have never implemented something like this and have always built single database, highly normalised systems so I am not quite sure where to begin. I have a few parts to this question. <br><br>\n<b>1. What would be a good resource to find out more about this architecture?</b><br>\n<b>2. Is it just a question of replicating between two identical schemas, or would your schemas differ depending on the operations, would normalisation vary too?</b><br>\n<b>3. How do you insure that data written to one database is immediately available for reading from the second?</b></p>\n\n<p><br>\nAny further help, tips, resources would be appreciated. Thanks.</p>\n\n<p><b>EDIT</b><br>\nAfter some research I have found this article which I found very informative for those interested..</p>\n\n<p><a href=\"http://www.codefutures.com/database-sharding/\">http://www.codefutures.com/database-sharding/</a></p>\n\n<p>I found this highscalability <a href=\"http://highscalability.com/plentyoffish-architecture\">article</a> very informative</p>\n    ","a":"\n<p>I'm not a specialist but the <strong>read/write master database and read-only slaves</strong> pattern is a \"common\" pattern, especially for big applications doing mostly read accesses or data warehouses:</p>\n\n<ul>\n<li>it allows to scale (you add more read-only slaves if required)</li>\n<li>it allows to tune the databases differently (for either efficient reads or efficient writes)</li>\n</ul>\n\n<blockquote>\n  <p>What would be a good resource to find out more about this architecture?</p>\n</blockquote>\n\n<p>There are good resources available on the Internet. For example:</p>\n\n<ul>\n<li><a href=\"http://highscalability.com/\">Highscalability.com</a> has good examples (e.g. <a href=\"http://highscalability.com/wikimedia-architecture\">Wikimedia architecture</a>, the <a href=\"http://highscalability.com/blog/category/master-slave\">master-slave</a> category,...)</li>\n<li><a href=\"http://www.slideshare.net/directi/handling-data-in-mega-scale-systems\">Handling Data in Mega Scale Systems</a> (starting from slide 29)</li>\n<li><a href=\"http://uni-svishtov.academia.edu/AsenBozhikov/Papers/82526/MySQL-Scale-Out-approach-for-better-performance-and-scalability-as-a-key-factor-for-Wikipedia%E2%80%99s-growth\">MySQL Scale-Out approach for better performance and scalability as a key factor for Wikipedia’s growth</a></li>\n<li><a href=\"http://www.postgresql.org/docs/8.2/static/high-availability.html\">Chapter 24. High Availability and Load Balancing</a> in PostgreSQL documentation</li>\n<li><a href=\"http://dev.mysql.com/doc/refman/5.1/en/replication.html\">Chapter 16. Replication</a> in MySQL documentation</li>\n<li><a href=\"http://www.google.com/search?q=read%2Fwrite+master+database+and+read-only+slaves\">http://www.google.com/search?q=read%2Fwrite+master+database+and+read-only+slaves</a></li>\n</ul>\n\n<blockquote>\n  <p>Is it just a question of replicating between two identical schemas, or would your schemas differ depending on the operations, would normalisation vary too?</p>\n</blockquote>\n\n<p>I'm not sure - I'm eager to read answers from experts - but I think the schemas are identical in traditional replication scenari (the tuning may be different though). Maybe people are doing more exotic things but I wonder if they rely on database replication in that case, it sounds more like \"real-time ETL\".</p>\n\n<blockquote>\n  <p>How do you insure that data written to one database is immediately available for reading from the second?</p>\n</blockquote>\n\n<p>I guess you would need <em>synchronous replication</em> for that (which is of course slower than asynchronous). While some databases do support this mode, not all do AFAIK. But have a look at <a href=\"http://serverfault.com/questions/58829/how-to-keep-multiple-read-write-db-servers-in-sync\">this answer</a> or <a href=\"http://stackoverflow.com/questions/12946/database-replication-2-servers-master-database-and-the-2nd-is-read-only\">this one</a> for SQL Server.</p>\n    "},{"t":"Modularizing web applications","l":"http://stackoverflow.com/questions/2360632/modularizing-web-applications","q":"\n\n<p>I was wondering how big companies tend to modularize components on their page. Facebook is a good example:</p>\n\n<blockquote>\n  <p>There's a team working on Search that\n  has its own CSS, javascript, html,\n  etc.. </p>\n  \n  <p>There's a team working on the news\n  feed that has its own CSS, javascript,\n  html, etc...</p>\n  \n  <p>... And the list goes on</p>\n</blockquote>\n\n<p>They cannot all be aware of what everyone is naming their div tags and whatnot, so what's the controller(?) doing to hook all these components in on the final page??</p>\n\n<p><em>Note: This doesn't just apply to facebook - any company that has separate teams working on separate components has some logic that helps them out.</em></p>\n\n<p><strong>EDIT: Thanks all for the responses, unfortunately I still haven't really found what I'm looking for - when you check out the source code (granted its minified), the divs have UIDs, my guess is that there is a compilation process that runs through and makes each of the components unique, renaming divs and css rules.. any ideas?</strong></p>\n\n<p><strong>EDIT 2: Thanks all for contributing your thoughts - the bounty went to the highest upvoted answer. The question was designed to be vague- I think it led to a really interesting discussion. As I improve my build process, I will contribute my own thoughts and experiences.</strong></p>\n\n<p>Thanks all!\nMatt Mueller</p>\n    ","a":"\n<p>Web development definitely brings some organizational challenge. HTML/CSS is not exactly the dream environment for splitting work. It is very important to define certain rules and strictly follow them.</p>\n\n<p>My personal tactic I have come to is to prefix the names in shared sources (like CSS or markup components) with some module suffix. If you keep to the strategy, it will uniquify the names globally.</p>\n\n<p>For example:</p>\n\n<p>instead of</p>\n\n<pre><code>div.question_title\ndiv.question_body\n</code></pre>\n\n<p>you could use</p>\n\n<pre><code>div.so_question_title\ndiv.so_question_body\n\ndiv.su_question_title\ndiv.su_question_body\n</code></pre>\n\n<p>Also agree with teams on some shared data like colors of the color scheme. Define them somewhere globally and reuse them everywhere.</p>\n\n<p>Another issue arrives when teams are working on different parts of the same page. Here if you're developing a page component, you may find one day something is broken because the guys working on the page itself changed something and changes propagated down the element hierarchy.</p>\n\n<p>For example, if you define a CSS style in this manner:</p>\n\n<pre><code>div.main_news *\n{\n    /* ... */\n}\n</code></pre>\n\n<p>it would be asking for trouble. I suggest that you have at as a rule to define CSS styles with the <em>minimum possible scope</em> which is sufficient for some technique to work.</p>\n\n<p>One possible workaround: each submodule firstly resets all the styles for its top-level hierarchy element, like:</p>\n\n<pre><code>div.news_container\n{\n    /* Reset styles */\n}\n</code></pre>\n\n<p>so that you can now work on the module resting assured the changes in some parent elements would be stopped at your perimeter.</p>\n\n<p>UPDATE: Regarding divs with UIDs. If you mean Facebook, I'm not sure what UIDs you are referring to. Only hidden inputs have some long cryptic IDs as their values (main page, not logged in), but this is likely the result of the framework automatically generating these values for some reason. I once wrote some code (for ASP.NET MVC) for Html helpers to generate unique IDs application-wide (I wanted to bind checkboxes with labels by IDs completely automatically and transparently for me). Another case could be that a stateful event-driven framework (such as ASP.NET WebForms) has unique IDs generated server side as a requirement to support its operation. Each control has to have some unique ID so that it is possible to know on the server side which element raised an event on a page. Also some WYSIWYG editors would add auto IDs to elements when you drag them and drop to a form.</p>\n\n<p>This all aside, it is of course possible to have some pre-build script to go over the code and inject unique IDs into markup and CSS code portions. But you really need to know exactly what and why you are doing this. I'm personally of the opinion this \"uniquization\" in general can be achieved manually by enforcing some simple rules in a team, while some work can of course be automatized, like what I described above.</p>\n    "},{"t":"Call graph of the whole application","l":"http://stackoverflow.com/questions/2161613/call-graph-of-the-whole-application","q":"\n\n<p>Is there a non-toyish tool that can create a call graph of the whole application? I don't mean just getting a picture or drawing call graph by means of pointing method-by-method.</p>\n\n<p>I need a call graph, which is accessible programmatically, i.e. the tool should flush it to a file in text mode (e.g. XML) or build the call graph in memory (which becomes problematic for large application). A call graph built in a DB would be great.</p>\n\n<p>Both static and dynamic call graphs are in demand; though static one is a little more interesting, the fact that it is overapproximated is acceptable.</p>\n\n<p>I have tried Soot so far. However, it is not able to handle even medium-size projects like FreeCol (java sources are available). Soot depletes 1.5GB of memory on that project, and then JVM crashes, as described here: <a href=\"http://www.sable.mcgill.ca/pipermail/soot-list/2008-July/001828.html\">http://www.sable.mcgill.ca/pipermail/soot-list/2008-July/001828.html</a></p>\n\n<p>Could anyone suggest a tool to generate a call graph, as described above? Java or .NET languages are ok.</p>\n\n<p>Best regards,\nSarge</p>\n    ","a":"\n<p>Our <a href=\"http://www.semanticdesigns.com/Products/DMS/DMSToolkit.html\" rel=\"nofollow\">DMS Software Reengineering Toolkit</a> can construct global call graphs for C, Java, and COBOL.\nThese are computed as an in-memory data structure, and can then be walked to collect arbitrary other facts.   (You could export it to some other tool to walk over it, but for a big call graph the time and effort to export would dominate the time to just analyze it, so we tend not to export it. YMMV.). </p>\n\n<p>It is relatively easy to extract call-graph information from a statement of the abstract form of \"CALL X(...)\", because the target X is right there in the code at the call site. Indirect (virtual or method calls) are problematic in that the actual call targets are not trivially in the code at the call site, but in fact are scattered around the entire system and worse, controlled by runtime conditionals. In the absence of any additional information, a call graph constructor has to assume an indirect call can go to any target with a matching signature; this introduces lots of false-positive call arcs in the graph.</p>\n\n<p>DMS uses a (conservative) global points-to analysis as part of the call-graph extraction process, to determine where such indirect calls go, while minimizing false-positives.\nSee <a href=\"http://www.semanticdesigns.com/Products/DMS/FlowAnalysis.html\" rel=\"nofollow\">Flow analysis and call graphs</a> for more examples of what DMS can extract, and a sample graph extracted from a system of 250,000 functions.</p>\n    "},{"t":".net n-tier identity & authorization in service architecture","l":"http://stackoverflow.com/questions/5044585/net-n-tier-identity-authorization-in-service-architecture","q":"\n\n<p>I'm building an application where the requirements seem standard issue (at least to me)... I have a Web.UI based on asp .net mvc &amp; clients from iphone, andriod &amp; blackberry.</p>\n\n<p>So the sensible thing to do is to move all my business logic into a services layer that can be accesses over http. This services layer must accept requests with a user context (identity) and in some nice way perform authorization consistently no matter which type of client is communicating with it (I hope?).</p>\n\n<p>Over a year a go I did a 3 month gig that employed W.I.F. (Windows Identity Foundation) in a hybrid on-premises &amp; cloud architecture. I liked it. The 3 things that struck a chord were (1) externalizing authentication and not caring how it was done, (2) removing authorization logic from business logic, (3) Claims based authorization.</p>\n\n<p>Over the last year I've heard and watch all about Rest Services the 'new cool hippy way of doing things'. So I though great, let's try that. After I started to play around &amp; get coding, I started getting really confused (and subsequently read for about 10 hours yesterday without writing another line of c#). I'm still confused about all the SOAP vs REST, WS.* vs Http, SAML vs SWT babble. I don't really want this thread to be about that because there is enough of that speak on stackoverflow, but I feel like I've got a choice between two camps, when it doesn't really feel like I want one or the other but bits from each?</p>\n\n<p>To me the 3 points I mentioned above about WIF don't seem like concepts that should be tied to WS.* ? But I'm getting the feeling that they, or at least how WIF comes at the moment makes them, without some expert tweaking (e.g. I came across this post only written a few days ago - <a href=\"http://zamd.net/2011/02/08/using-simple-web-token-swt-with-wif/\" rel=\"nofollow\">http://zamd.net/2011/02/08/using-simple-web-token-swt-with-wif/</a>).</p>\n\n<p>The other areas I don't know much about is are my clients (iphone, andriod, blackberry) capable of playing with WIF, is it the same STS that throws a SAML token to them and they behave just like a browser and pass it back in a header just like any other client? Yes I'm going to have to find out, but if this is a deal breaker with W.I.F and I find out straight after posting this, then at least I can focus away from it.</p>\n\n<p>Finally to throw one more thing in the mix. I don't really want to think about any of this. I want to use a 3rd party authentication / identity provider - <a href=\"http://www.janrain.com/products/engage\" rel=\"nofollow\">http://www.janrain.com/products/engage</a> - which I believe uses OpenID. Can this fit into W.I.F. or do I just create a new SAML token from the OpenID and use WIF from that moment on.</p>\n\n<p>I guess at the end of this babble, I want to come back to where I started because it's getting more and more complicated the more questions I ask and the more options I consider.</p>\n\n<p>Is having a services layer (on WCF) that talks to different non-.net clients that requires identity context and authorization so strange? If you've build something like this, how did you approach it?</p>\n    ","a":"\n<p>When you have many devices, one way to get the same solution working across all of them, is to target the lowest common denominator.</p>\n\n<p>Assuming that all your clients support cookies. One way of doing this would:</p>\n\n<ul>\n<li>Have an authentication system based on a cookie.</li>\n<li>Cache all authorisation information on the server side, linked to a session or key in the cookie</li>\n<li>For each request check the authorization</li>\n</ul>\n\n<p>Not quite as elegant as using SAML tokens, but it does work cross platform / devices.</p>\n\n<p>IPhone supports cookies <a href=\"http://support.apple.com/kb/HT1675\" rel=\"nofollow\">http://support.apple.com/kb/HT1675</a></p>\n\n<p>Blackberry supports cookies <a href=\"http://docs.blackberry.com/en/developers/deliverables/11844/feature_cookie_storage_438273_11.jsp\" rel=\"nofollow\">http://docs.blackberry.com/en/developers/deliverables/11844/feature_cookie_storage_438273_11.jsp</a></p>\n    "},{"t":"Is my reputation system secure?","l":"http://stackoverflow.com/questions/621344/is-my-reputation-system-secure","q":"\n\n<p>BOUNTY: To get bounty either show me how to play the system, or explain why you think it's impossible to play it.</p>\n\n<p>I'm developing a reputation system for a site that allows you to start your own blog of sorts, and to comment and have favorites etc.</p>\n\n<p>I aim for a very short ruleset that is easy to understand for the users and can't be \"played\". Note: when I write \"answers\", I mean <em>answers to comments</em>, which is\nthe equivalent of Stack Overflow's <em>comments to answers</em>.</p>\n\n<ol>\n<li>To create an account you need one Mojo. Without it you can only answer other people's comments.</li>\n<li>When you have an account, you get one Mojo a day.</li>\n<li>Each day you can only post as many posts and comments as you have Mojo. You can answer as many comments as you like. You don't lose Mojo when you post.</li>\n<li>You can give one Mojo to someone who has less, but only once to each person.</li>\n<li>Alternatively, you can burn one Mojo to take one Mojo away from someone who has less, but only once.</li>\n<li>You can't have your Mojo back.</li>\n</ol>\n\n<p>The site is supposed to be invite-only, but non-members can answer member's comments, and maybe they'll be able to start their own blogs too, I'm not sure yet. The idea is for a system based mainly on seniority, where power can be transferred between users only in a very limited manner so basically there's no way to inflate your reputation (Mojo only flows down.)</p>\n\n<p>Giving and taking Mojo is supposed to be an act on the level of marking someone as a friend or as an enemy. </p>\n\n<p>I don't want Mojo itself to be a motivator for people to be part of the community. I want them to use it to influence how other people behave on site. By burning someone with your Mojo you effectively limit how much they can post on the site. By giving someone Mojo you allow them to express more.</p>\n\n<p>I'm also planning to add ways to get extra Mojo, like \"Post of the Day\" or \"Favorite Blog of the Week\" contests with prizes of around 3-10 Mojo. But one of my main goals is to avoid inflation.</p>\n    ","a":"\n<p>Here are some consequences of your design. These may or may not be what you intended, but I point them out so that you're aware of them.</p>\n\n<ul>\n<li><p>A very Mojo-ful user who has been mostly quiet is not going to care at all about stepping on some toes, because they have a huge bank of Mojo from which to draw. This seems to go against your goal of limiting negative behavior.</p></li>\n<li><p>Likewise, users who contribute absolutely nothing to your site still get Mojo just by virtue of having an account. But an otherwise valuable contributor who makes one off-color post that's disliked by the community will be silenced until he has enough Mojo to post again.</p></li>\n<li><p>If someone has something very valuable to contribute, he has to make sure to have \"reserve Mojo\" at all times -- that is, he must ensure that he isn't at his posting limit. If he doesn't, he might lose the opportunity to say something useful that would earn him more Mojo.</p></li>\n<li><p>The rate at which people can accrue Mojo is limited by the size of the community. If there are few people who are handing out Mojo, pretty soon they won't be able to hand out Mojo anymore, since there won't be anyone left who hasn't already received Mojo from them.</p></li>\n<li><p>The oldest users will effectively become an invincible cabal whose ideas may define and shape your site. Since you can only reduce someone else's Mojo if they have fewer Mojo than you, these users can make statements your community vehemently disagrees with and have their Mojo ratings remain intact.</p></li>\n<li><p>In general, by restricting the supply of Mojo, you have created an economic system in which people will probably be more hesitant to contribute to a discussion. They will need to more carefully weigh what they say, since a post that is disliked by the community may prevent them from speaking further if they get too much negative Mojo.</p></li>\n</ul>\n\n<p></p><hr><p></p>\n\n<h3>Playing the system</h3>\n\n<blockquote>\n  <p>Either show me how to play the system, or explain why you think it's impossible to play it.</p>\n</blockquote>\n\n<p>Suppose we define \"playing the system\" as \"artificially changing the value or quantity of one's Mojo in ways you didn't intend\". I would say your system is safe from artificial <em>inflation</em> of Mojo, but at the cost of stifling discussion that would have otherwise taken place. You must be able to make the following guarantees:</p>\n\n<ul>\n<li><em>Flow condition.</em> Mojo only \"flows down\"; it is not possible for a lower-ranked user to transfer Mojo to a higher-ranked user.</li>\n<li><em>Creation condition.</em> It is difficult for users to take actions which can generate their own Mojo. Also, it is either impossible to make new accounts, or they carry such a heavy penalty that no one will want to do it.</li>\n</ul>\n\n<p>For example, if you cannot satisfy the creation condition, then malicious early users will simply make an army of new accounts. They keep a number of these new accounts in reserve, quietly accruing Mojo. They then use them as a \"bury brigade\" to drain Mojo of factions or ideas they disagree with. Although they will lose Mojo when they do so, the collective Mojo of the bury brigade will be constant as long as they don't go hitman on more than a single hated foe per day.</p>\n\n<p>This is clearly not what you intended.</p>\n\n<h3>Artificial deflation</h3>\n\n<p>However, your system is not safe from artificial <em>deflation</em> of Mojo. To see why, imagine that users stream into your site to accept their invitations. Imagine a user, Mallory, with <em>k</em> Mojo points. Because Mojo can only flow down, there is no way for a user with <em>k</em> or fewer Mojo points can express their disagreement with Mallory. Only users with <em>k+1</em> or more Mojo can do so.</p>\n\n<p>Mallory's reign of terror will continue unchecked unless there are enough users with <em>k+1</em> or higher Mojo. In fact, if Mallory is an early enough user, there may not be any users who have the power to reduce her Mojo. Indeed, because you've artificially made Mojo scarce, they may not <em>want</em> to burn a Mojo to express their opinion, given how precious each Mojo point is -- since that also weakens them and makes <em>their</em> opinions more vulnerable to attack.</p>\n\n<p>In short, if there are enough (or maybe even just a few) Mallorys, you will be reduced to playing traffic cop and cleaning up after Mallorys instead of improving your site. The system can no longer be self-policing. Each Mojo point has now become worth much more than before, because people will see from the example of Mallory and her ilk that it is better not to burn a Mojo to open oneself to attack. Thus, Mojo deflation.</p>\n\n<p>This is also clearly not what you intended.</p>\n    "},{"t":"A potentially dangerous Request.Form value was detected from the client","l":"http://stackoverflow.com/questions/9130186/a-potentially-dangerous-request-form-value-was-detected-from-the-client","q":"\n\n<p>I have this issue. I have tried everything. ValidateRequest=\"false\".. and decoding and encoding html.. etc. etc..</p>\n\n<p>What I need is a popup box (so im using ModalPopupExtender) to present to a user where people can type in xml settings and click ok/cancel button to close the popup and save. </p>\n\n<p>However i keep on getting this error \"A potentially dangerous Request.Form value was detected from the client\".. </p>\n\n<p>Here is my test code below (quick example of my scenario and error)..</p>\n\n<pre><code>&lt;%@ Page Language=\"C#\" AutoEventWireup=\"true\" CodeBehind=\"WebForm1.aspx.cs\" Inherits=\"WebApplication1.WebForm1\"\n    ValidateRequest=\"false\" %&gt;\n\n&lt;%@ Register Assembly=\"AjaxControlToolkit\" Namespace=\"AjaxControlToolkit\" TagPrefix=\"cc1\" %&gt;\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\"&gt;\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\"&gt;\n&lt;head runat=\"server\"&gt;\n    &lt;title&gt;&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;form id=\"form1\" runat=\"server\"&gt;\n    &lt;asp:ScriptManager ID=\"ScriptManager1\" runat=\"server\"&gt;\n    &lt;/asp:ScriptManager&gt;\n    &lt;div&gt;\n        &lt;asp:Panel ID=\"Popup\" runat=\"server\" Width=\"800px\" Style=\"display: none;\"&gt;\n            &lt;asp:LinkButton ID=\"Display\" runat=\"server\" Style=\"display: none;\" OnClick=\"Display_Click\" /&gt;\n            &lt;cc1:ModalPopupExtender ID=\"ModalPopupExtender\" runat=\"server\" TargetControlID=\"Display\"\n                PopupControlID=\"Popup\" DropShadow=\"false\" Y=\"10\" /&gt;\n            &lt;div id=\"Item\"&gt;\n                &lt;div class=\"Item\"&gt;\n                    &lt;table width=\"100%\"&gt;\n                        &lt;tr&gt;                                \n                            &lt;td&gt;\n                                &lt;textarea id=\"txtAreaValue\" cols=\"35\" rows=\"6\" style=\"resize: none;\" runat=\"server\" /&gt;\n                            &lt;/td&gt;\n                        &lt;/tr&gt;\n                        &lt;tr&gt;                                \n                            &lt;td&gt;\n                                &lt;asp:Button ID=\"btnOk\" Text=\"Ok\" SkinID=\"default\" Width=\"50px\" runat=\"server\" /&gt;\n                                &lt;asp:Button ID=\"btnCancel\" Text=\"Cancel\" SkinID=\"default\" Width=\"50px\" OnClick=\"BtnCancel_Click\"\n                                    runat=\"server\" /&gt;\n                            &lt;/td&gt;\n                        &lt;/tr&gt;\n                    &lt;/table&gt;\n                &lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/asp:Panel&gt;\n    &lt;/div&gt;\n    &lt;/form&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>\n\n<p>Code Behind:</p>\n\n<pre><code>using System;\nusing System.Collections.Generic;\nusing System.Linq;\nusing System.Web;\nusing System.Web.UI;\nusing System.Web.UI.WebControls;\n\nnamespace WebApplication1\n{\n    public partial class WebForm1 : System.Web.UI.Page\n    {\n        protected void Page_Load(object sender, EventArgs e)\n        {\n            ModalPopupExtender.Show();\n            string str = \"&lt;?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\"?&gt;&lt;XmlConfig xmlns:xsi=\\\"http://www.w3.org/2001/XMLSchema-instance\\\" xmlns:xsd=\\\"http://www.w3.org/2001/XMLSchema\\\"&gt; &lt;XmlConfig Type=\\\"TEST\\\" DefiningXpath=\\\"/PERSON/NAME\\\"&gt;&lt;Index Name=\\\"Name\\\" XPath=\\\"/PERSON/NAME/VALUE\\\" Type=\\\"String\\\" /&gt;&lt;Index Name=\\\"Id\\\" XPath=\\\"/PERSON/NAME/ID\\\" Type=\\\"String\\\" /&gt; &lt;/XmlConfig&gt;&lt;/XmlConfig&gt;\";\n\n            txtAreaValue.InnerText = str;\n        }\n\n        protected void Display_Click(object sender, EventArgs e)\n        {\n            //Shows the Item detail Edit box\n            ModalPopupExtender.Show();\n        }\n\n        protected void BtnCancel_Click(object sender, EventArgs e)\n        {\n            ModalPopupExtender.Hide();\n        }\n    }\n}\n</code></pre>\n\n<p>To run the code.. Add ref to AjaxControltoolkit.dll and then run and you will see the textarea being populated with xml. Click on the cancel button and this causes the error. Please can anyone help me?</p>\n    ","a":"\n<p>Use</p>\n\n<pre><code>&lt;httpRuntime requestValidationMode=\"2.0\" /&gt;\n</code></pre>\n\n<p>in your web.config (keeping any attributes you already have on that element, if it's already there). ASP.NET4.0 ignores <code>ValidateRequest</code> otherwise.</p>\n\n<p>And, of course, do make sure that you take necessary measures to protect against genuinely dangerous requests, now that it's not being done for you.</p>\n\n<p>Edit: A great way of doing this is to create your own class derived from <code>RequestValidator</code>, and using the 4.0 behaviour, but with that as the class that does the checking.</p>\n    "},{"t":"What tools (free) do you use to design software [closed]","l":"http://stackoverflow.com/questions/974019/what-tools-free-do-you-use-to-design-software","q":"\n\n<p>What tools do you use to speed up documenting application design.\nNamely, creating wireframes, flowcharts. What other methods do you find essential .</p>\n\n<p>Is the general consensus that use cases are vital, or is a good functional  spec document easier and quicker</p>\n    ","a":"\n<p><a href=\"http://argouml.tigris.org/\" rel=\"nofollow\">ArgoUML</a> has been my friend for many years when it comes to drawing UML. ArgoUML is a <em>tool</em> and you're asking about <em>both</em> tools and the <em>processes</em> used (i.e. \"which artifacts do you create with the tools). We generally stick to user stories (agile project) and do not make \"classical\" use cases and use case documents. </p>\n    "},{"t":"Where I can find a detailed comparison of Java XML frameworks?","l":"http://stackoverflow.com/questions/3855324/where-i-can-find-a-detailed-comparison-of-java-xml-frameworks","q":"\n\n<p>I'm trying to choose an XML-processing framework for my Java projects, and I'm lost in names.. XOM, JDOM, etc. Where I can find a detailed comparison of all popular Java XML frameworks?</p>\n    ","a":"\n<p>As Blaise pointed out stick with the standards. But there are multiple standards created over the period to solve different problems/usecases. Which one to choose completely depends upon your requirement. I hope the below comparison can help you choose the right one.</p>\n\n<p>Now there are <strong>two things</strong> you have to choose. <strong>API</strong> and the <strong>implementations of the API</strong> (there are many)</p>\n\n<h2>API</h2>\n\n<p><strong>SAX: Pros</strong></p>\n\n<ul>\n<li>event based</li>\n<li>memory efficient</li>\n<li>faster than DOM</li>\n<li>supports schema validation</li>\n</ul>\n\n<p><strong>SAX: Cons</strong></p>\n\n<ul>\n<li>No object model, you have to tap into\nthe events and create your self</li>\n<li>Single parse of the xml and can only\ngo forward</li>\n<li>read only api</li>\n<li>no xpath support</li>\n<li>little bit harder to use</li>\n</ul>\n\n<p><strong>DOM: Pros</strong></p>\n\n<ul>\n<li>in-memory object model</li>\n<li>preserves element order</li>\n<li>bi-directional</li>\n<li>read and write api</li>\n<li>xml MANIPULATION</li>\n<li>simple to use</li>\n<li>supports schema validation</li>\n</ul>\n\n<p><strong>DOM: Cons</strong></p>\n\n<ul>\n<li>memory hog for larger XML documents\n(typically used for XML documents\nless than 10 mb)</li>\n<li>slower</li>\n<li>generic model i.e. you work with Nodes</li>\n</ul>\n\n<p><strong>Stax: Pros</strong></p>\n\n<ul>\n<li>Best of SAX and DOM i.e. Ease of DOM\nand efficiency of SAX</li>\n<li>memory efficient</li>\n<li>Pull model</li>\n<li>read and write api</li>\n<li><a href=\"http://tutorials.jenkov.com/java-xml/sax-vs-stax.html\">supports subparsing</a></li>\n<li>can read multiple documents same time\nin one single thread</li>\n<li>parallel processing of XML is easier</li>\n</ul>\n\n<p><strong>Stax: Cons</strong></p>\n\n<ul>\n<li>no schema validation support (as far\nas I remember, not sure if they have\nadded it now)</li>\n<li>can only go forward like sax</li>\n<li>no xml MANIPULATION</li>\n</ul>\n\n<p><strong>JAXB: Pros</strong></p>\n\n<ul>\n<li>allows you to access and process XML\ndata without having to know XML</li>\n<li>bi-directional</li>\n<li>more memory efficient than DOM</li>\n<li>SAX and DOM are generic parsers where\nas JAXB creates a parser specific to\nyour XML Schmea</li>\n<li>data conversion: JAXB can convert xml\nto java types</li>\n<li>supports XML MANIPULATION via object\nAPI</li>\n</ul>\n\n<p><strong>JAXB: Cons</strong></p>\n\n<ul>\n<li>can only parse valid XML</li>\n</ul>\n\n<p><strong>Trax:</strong> For transforming XML from 1 form to another form using XSLT</p>\n\n<h2>Implementations</h2>\n\n<p>SAX, DOM, Stax, JAXB are just specifications. There are many <a href=\"http://www.edankert.com/jaxpimplementations.html\">open source and commercial implementations of these specifications</a>. Most of the time you can just stick with what comes with JDK or your application server. But sometimes you need to use a different implementation that provided by default. And this is where you can appreciate the <a href=\"http://jaxp.java.net/\">JAXP wrapper api</a>. <strong>JAXP</strong> allows you to switch implementations through configuration without the need to modify your code. It also provides a parser/spec independent api for parsing, transformation, validation and querying XML documents.</p>\n\n<p><strong>Performance and other comparisons of various implementations</strong></p>\n\n<ul>\n<li>Stax:\n<a href=\"http://java.sun.com/performance/reference/whitepapers/StAX-1_0.pdf\">http://java.sun.com/performance/reference/whitepapers/StAX-1_0.pdf</a></li>\n<li>Most of the API:\n<a href=\"http://www.ibm.com/developerworks/xml/library/x-databdopt2/\">http://www.ibm.com/developerworks/xml/library/x-databdopt2/</a></li>\n<li>JAXB versus XmlBeans discussion on SO: <a href=\"http://stackoverflow.com/questions/1362030/jaxb-vs-apache-xmlbeans\">JAXB vs Apache XMLBeans</a></li>\n<li><a href=\"http://www.ibm.com/developerworks/xml/library/x-injava/\">http://www.ibm.com/developerworks/xml/library/x-injava/</a></li>\n</ul>\n\n<hr>\n\n<p>Now standards are good but once in a while you encounter this crazy usecase where you have to support parsing of XML document that is <strong>100 gigabytes</strong> of size or you need <strong>ultra fast</strong> processing of XML (may be your are implementing a XML parser chip) and this is when you need to dump the standards and look for a different way of doing things. Its about using the right tool for the right job! And this is where I suggest you to have a look at <a href=\"http://vtd-xml.sourceforge.net/\"><strong>vtd-xml</strong></a></p>\n\n<p>During the initial days of SAX and DOM, people wanted simpler API's than provided by either of them. <a href=\"http://www.jdom.org/\">JDOM</a>, <a href=\"http://www.dom4j.org/\">dom4j</a>, <a href=\"http://xmlbeans.apache.org/\">XmlBeans</a>, <a href=\"http://jibx.sourceforge.net/\">JiBX</a>, <a href=\"http://www.castor.org/\">Castor</a> are the ones I know that became popular.</p>\n    "},{"t":"Recommended location for document storage - in database or elsewhere?","l":"http://stackoverflow.com/questions/512262/recommended-location-for-document-storage-in-database-or-elsewhere","q":"\n\n<p><strong>Background:</strong>  </p>\n\n<p>We have an in house document storage system that was implemented long ago.  For whatever reason, using the database as the storage mechanism for the documents was chosen.</p>\n\n<p><strong>My question is this:</strong>  </p>\n\n<p>What is the best practice for storing documents?  What are the alternatives? What are the pros and cons?  <em>Answers do not have to be technology or platform specific, it is more of a general best practice question.</em></p>\n\n<p><strong>My Thoughts:</strong></p>\n\n<p>Databases are not meant for document storage.  File Systems or 3rd party Document Management systems may be of better use.  Document Storage in Databases is expensive.  Operations are slow.  Are these logic assumptions?  Perhaps this is best, but in my mind, we have better alternatives.  Could oracle BFILE's (links to document on NAS or SAN) be better than BLOB / CLOB?</p>\n\n<p><strong>Details:</strong></p>\n\n<ul>\n<li>Documents are various types (pdf, word, xml)</li>\n<li>The Middle Tier code is written in .net 2.0 / c#</li>\n<li>Documents are stored in a Oracle 10g database in BLOB with compression (NAS Storage)</li>\n<li>File sizes rage </li>\n<li>The number of document is growing drastically and has no signs of slowing down</li>\n<li>Inserts is typically is in the hunderds per hour during peak</li>\n<li>Retreival is typically in the thousands per hour during peak</li>\n<li>NAS storage and SAN storage is available</li>\n</ul>\n\n<p><strong><em>UPDATE (from questions below):</em></strong></p>\n\n<ul>\n<li>my background is development</li>\n<li>there is associated meta-data about the files stored next to file in the database</li>\n</ul>\n    ","a":"\n<p>The only limit to storing documents in the database is technological. </p>\n\n<p>A <a href=\"http://en.wikipedia.org/wiki/Relational_database\" rel=\"nofollow\">relation database</a> is meant to be the persistent store of the mission critical data of an enterprise. How well it can perform that function varies from database to database and system to system, of course. But <em>ideally</em> the <a href=\"http://en.wikipedia.org/wiki/ACID\" rel=\"nofollow\">ACID</a> properties of a <a href=\"http://en.wikipedia.org/wiki/Relational_model\" rel=\"nofollow\">relational database</a> are <strong>intended</strong> to make it the store of all <a href=\"http://en.wikipedia.org/wiki/Enterprise_Data_Management\" rel=\"nofollow\">enterprise data</a>. The file system, revision controller systems and other local store storage systems might have specific advantages but they are not designed for enterprise data storage as such. </p>\n\n<p>If the documents you are storing qualify as enterprise data - if they are used persistently through-out the enterprise - then it is logical to keep them in the database. If you are having problems with storing in the database, perhaps a DBA can find a better solution. You might even have to move them out of the database for performance reasons but I don't think you should move them out of the database for best-practices reasons. </p>\n\n<p>Of course, if the documents aren't enterprise data, if they're only used for one application, say, then moving them out of the database would also make sense. </p>\n    "},{"t":"Implementing a Message Bus architecture","l":"http://stackoverflow.com/questions/722675/implementing-a-message-bus-architecture","q":"\n\n<p>I'm currently doing analysis and design for a new message bus architecture in my company.  I have tried MSMQ to do something like this in the past and it works well and was thinking of doing the same thing again for this project but using WCF as the API instead of using the System.Messaging API.  Has anyone had experience with MSMQ in WCF?  Is it easier to use then the System.Messaging API?  What would be some benefits of using WCF over System.Messaging or vice versa?</p>\n    ","a":"\n<p>IMHO, with so many good, flexible and proven bus architectures to choose from (<a href=\"http://www.nservicebus.com/\">NServiceBus</a>, <a href=\"http://code.google.com/p/masstransit/\">Mass Transit</a>, <a href=\"http://ayende.com/blog/tags/rhino-service-bus\">Rhino Service Bus</a>), implementing your own would be a big <a href=\"http://en.wikipedia.org/wiki/Not_Invented_Here\">NIH</a>. It's not a trivial task.</p>\n\n<p>Udi describes it very well in <a href=\"http://tech.groups.yahoo.com/group/nservicebus/message/712\">this message</a>.</p>\n    "},{"t":"Service layer and controller: who takes care of what?","l":"http://stackoverflow.com/questions/3885675/service-layer-and-controller-who-takes-care-of-what","q":"\n\n<p>In class we're now learning how to build up a Spring application, even though spring isn't directly involved, we learned how to make the interfaces for DAO and service layer objects. </p>\n\n<p>Please correct me if I'm wrong:\nDAO layer is pretty abstract: it just contains the CRUD operations and is further used to read data.(ie: get all objects, get specific objects, etc)</p>\n\n<p>Service layer: contains services to create things, and delete things, this is where business logic should be. </p>\n\n<p>Now all of this makes sense in the service layer; except \"updating\" objects. Do you just put a \"update\" function that just saves the object in your database? Or do you need to define the logic there as well? This is where my confusion is as, my understanding is objects in Spring are just POJO's. Now then who validates the data? </p>\n\n<p>Let's say I have an Object \"child\"\nit has:<code>Name</code>, <code>SurName</code>, <code>Gender</code>, <code>Photo</code>, <code>Birthdate</code>\nfields.\nhow would I name the services? Or would you just let the controller take care of validation, which doesn't seem right to me. On the other hand it wouldn't seem right either to delegate every setter that needs to be called to the service layer.</p>\n\n<p>So just basically: help me with how to define saving your objects via the service layer.</p>\n    ","a":"\n<p>If you wish to have controllers be able to persist changes to a <code>Child</code> object, then traditionally you would have a method in the service named something like <code>ChildService.update(Child newchild)</code>, which will handle calling the correct DAOs to persist the new version of this Child.</p>\n\n<p>Controllers are free to ask the service for a Child, change the fields around (conceivably based on some user input) - a sane design would have the Controller doing some work with the Child POJO and then asking the Service to persist the change. The model POJO should know nothing about a controller, service, or DAO but just simply hold data as you suggest - certainly you would not want every call to <code>setName()</code> or <code>setGender()</code> to automatically result in a database update.</p>\n\n<p>Instead, the controller and/or service should acquire a <code>Child</code> object, do whatever work it needs to the object in it's unit of work, and then ask a Service (and then the DAO) to persist the changes.</p>\n\n<p>Validation can take place in several layers - the Controller might want to validate any input from the web user, and the Service may want to validate that it has a valid <code>Child</code> object before it persists it. It especially makes sense to have some level of validation in both layers in case you want to re-use this Service in other capacities - such as exposing a REST interface, a different front-end, etc.</p>\n    "},{"t":"Software that “Phones Home”; good? bad? Evil? What notice does one give? How to? [closed]","l":"http://stackoverflow.com/questions/235879/software-that-phones-home-good-bad-evil-what-notice-does-one-give-how-to","q":"\n\n<p><strong>PHONE HOME</strong></p>\n\n<p>Everybody wants to now and then. ...What about software when it grows up and becomes a mature product? Shouldn't it be an adult and live in its new home quietly? Or, should it show some affection from whence it came?...</p>\n\n<p>I've heard some say they'd rip out from the platters any bits that try and communicate without their say so. I've also noticed a large number of products that now routinely ask for permission to send statistical use information. And there are many levels in between.</p>\n\n<p>I'm sitting on the fence. </p>\n\n<p>There’s a long paragraphs explanation of how this question came to me, but for all our sakes, I wrote then deleted it. Suffice to say, I’m Chief Scientist, an officer of the company <em>and</em> head of our development efforts; this is a really big deal and I’m looking for insight from the programming community as I'm not getting any useful feedback here...</p>\n\n<p>The biggest argument for <strong>PHONE HOME</strong> is that some involved fear there is likely to be serious attempts to cheat the contract(s) and if the software occasionally phoned home it would help detect cheating (for which there are penalties).</p>\n\n<p>Other pro arguments are that it can provide usage statistics and perhaps detect when updates are appropriate.</p>\n\n<p>The biggest argument against is that it’s offensive.</p>\n\n<p>I also haven’t a clue how I would architect this. Clearly, everything calling home all the time is not going to fly. There are a half dozen major products and some will run 24 X 7 X 365.24 and some will be up and down like a frigen yo-yo, yet some data on all of them would be nice - Local repository?</p>\n\n<p>Then there’s connection strategy – a mail message, while convenient, may be a bad call because it can be more obtrusive (perhaps). Then, a simple TCP ssh call may not be so great, either.</p>\n\n<p>So, how about it? If you’re pro, please tell me why. If you’re against, why also. Examples of \"doing it right?\" Contractual text you like somewhere - or hate?</p>\n\n<p>Next, IF we decide to do it, how should we do it – how would YOU do it? Why?</p>\n\n<p>Frankly, I’m <em>profoundly</em> torn. I hate such things in general, but as an officer of the company, I have to acknowledge above my own feelings, there’s potentially a lot of money on the table here, and being offended may not be a good argument.</p>\n\n<p>Thanks for your thoughts.</p>\n    ","a":"\n<p>Informed consent, where informed means that the type, frequency and content of the information you'll be sending is told to the client is truly the only reasonable option, else you start closely resembling a malware author. People will find out and will dislike you a lot if you tried to pull it off sneakily. You probably can and should present it as a means to improve the service though, everybody likes software that reports bugs by itself.</p>\n\n<p>This means you cannot rely on this to be your cheat detection mechanism, but, given that there's a lot of money on the table, you may be able to contractually put some random inspections. For instance you could register locally the data you'd otherwise send and go look at it in the inspections. I don't think you are forced to declare you'll be locally registering usage information (IANAL, YMMV, WTF, BBQ)</p>\n    "},{"t":"What is DCI and how can it fit with Rails?","l":"http://stackoverflow.com/questions/9677916/what-is-dci-and-how-can-it-fit-with-rails","q":"\n\n<p>A recent debate with a co-worker about different approaches to design and code the models in a Rails application brought me across <a href=\"http://andrzejonsoftware.blogspot.com/2011/02/dci-and-rails.html\">DCI in the context of Rails</a>.</p>\n\n<p>However, I just can't seem to wrap my head around that entire concept, even after going over <a href=\"https://github.com/anachronistic/DCI-Rails-Example\">this example application</a>.</p>\n\n<p>Currently, I tend to just go more or less \"<a href=\"http://pragprog.com/book/rails3/agile-web-development-with-rails\">by the book</a>\" when writing a Rails app.</p>\n\n<p>So there are a few things I'd like to ask --</p>\n\n<ul>\n<li>What is DCI and what are its advantages when implemented alongside MVC over plain old MVC (and vanilla ActiveRecord in Rails) ?</li>\n<li>And how can it be implemented in Rails (or in other words, <em>what's with all the modules</em>) ?</li>\n</ul>\n\n<p><strong>Edit</strong></p>\n\n<p>I'd like to even further expand my question in the context of RoR - is another level of abstraction between the models and the controllers in Rails recommended? How widespread is it in different-scale applications?</p>\n    ","a":"\n<p>DCI is a paradigm and hence much more than a way to design an application. It's a way to think about modelling as well as structuring code. One of the important parts of DCI is keeping what the system is (the domain model) and what the system does (functionality) apart. DCI is not a different approach to solving the same problem as MVC so your first question can't really be answered. You can use MVC and DCI simultaneously which is no coincidence since Trygve Renskaug is the father of both MVC and DCI. He recently answered a <a href=\"http://groups.google.com/group/object-composition/browse_thread/thread/ce934f6fd3e7cc90/d38ccb6fd523e05f?show_docid=d38ccb6fd523e05f&amp;pli=1\" rel=\"nofollow\">similar question</a> to this on the google group 'object-composition'.</p>\n\n<p>The example you've linked to violates some of the basic ideas such as keeping roles private to the contexts and I couldn't actually find a single context either but that could be due to spending only a short time browsing the code.</p>\n\n<p>I don't know RoR my self so I can't give you an RoR example but if you go to <a href=\"http://fullOO.info/Examples/\" rel=\"nofollow\">fullOO</a> you'll find examples written in different languages including both Ruby and Marvin the first language designed for DCI.</p>\n\n<p><strong>EDIT</strong> There's no simply answer to the question \"What is DCI\" DCI is a paradigm, just like OOP is a paradigm. They both have the same roots and answering the above question is as complicated as answering \"What is object orientented programming\". Things are even more complicated by the fact that DCI is object oriented and OOP in all the major OO languages is actually class oriented and not object oriented. DCI aims at producing code where the interaction between <em>objects</em> at run time is visible in the code at compile time and in more general terms tries to mkae it easier to reason about the run time behavior from reading the code. The <a href=\"http://fullOO.info/Examples/\" rel=\"nofollow\">site</a> I've linked to above is devoted to explaining what DCI is all about and also lists examples in a number of languages. Ruby being one of them</p>\n\n<p><strong>EDIT</strong> There's a <a href=\"http://clean-ruby.com/\" rel=\"nofollow\">book</a> on ruby and DCI on it's way. The author is pretty active on object-composition and insightfull</p>\n    "},{"t":"To implement a property or to implement a subclass","l":"http://stackoverflow.com/questions/6008534/to-implement-a-property-or-to-implement-a-subclass","q":"\n\n<p>I've got a class called <code>List_Field</code> that, as the name suggests, builds list input fields. These list input fields allow users to select a single item per list.</p>\n\n<p>I want to be able to build list input fields that would allow users to select multiple items per list, so I have the following dilemma:</p>\n\n<p>Should I do that through implementing a <code>multiple_choice_allowed</code> property into the existing <code>List_Field</code> property, or should I implement a <code>Multiple_Choice_List_Field</code> subclass of the <code>List_Field</code> class?</p>\n\n<p>What's the engineering principle that I should follow when confronted with dilemmas like this one?</p>\n    ","a":"\n<p>Take a look at the <a href=\"http://butunclebob.com/ArticleS.UncleBob.PrinciplesOfOod\" rel=\"nofollow\">SOLID principles</a>. They'll help you in your designs. In particular, the single responsibility principle will tell you not to mix the two concerns in one class, and the Liskov substitution principle will tell you not to create subclasses that break the contract of superclasses, like what you're also proposing.</p>\n\n<p>So what would be the solution in your case? You could create an abstract base class that would be agnostic to the type of selection and then create 2 subclasses, one for single selection and another for multiple selection.</p>\n    "},{"t":"How to become a technical architect? [closed]","l":"http://stackoverflow.com/questions/4243066/how-to-become-a-technical-architect","q":"\n\n<p>I have spent more than 3 years into dotnet (C#) programming and now want to look into the framework / design stuffs.</p>\n\n<p>I have decided to become a good architect in future. I know that for this I need to work hard. I am ready to do so.</p>\n\n<p>What I do not know is how to start with?</p>\n\n<p>Could you people be kind enough in order to help me in getting the right stepping stone.</p>\n\n<p>Thanks</p>\n    ","a":"\n<p>Update: the two links are both broken, I will try and find some replacement content but in the meantime this page has a list of different architect types, FWIW: <a href=\"http://en.wikipedia.org/wiki/Systems_architect\" rel=\"nofollow\">http://en.wikipedia.org/wiki/Systems_architect</a></p>\n\n<p>~~~~~~~~~~~~~~~~~~~~~~~~~~~</p>\n\n<p>It depends what you call \"<a href=\"http://en.wikipedia.org/wiki/Technical_architect\" rel=\"nofollow\">Technical Architect</a>\", as well as where you want to go.\nAlso, your experience (as far as you've described it) is programming / software related, so the term \"Technical Architecture\" might not be exactly what you're after.</p>\n\n<p>As I understand it, a Technical Architect is concerned more with standards are so forth, as opposed to a Software Architect which who would deal more with code and design patterns.</p>\n\n<p>My general advice to you is this:</p>\n\n<ul>\n<li>Research: read books, articles, blogs and (most importantly)...</li>\n<li>Interaction: talk with actual architects about what it is they do and how they got there.   Sure you can ask questions on forums like this, but a deep thorough discussion is what you're after - and not just one or two.  One way of doing this is to...</li>\n<li>Join a local architects forum or community group in your area, or attend the odd talk.  Big conferences like Tech Ed will have an architectuire track - so keep an eye out for interesting topics.</li>\n<li>Bide you Time: I landed the formal title of \"Solutions Architect\" after 8 years in software development, which is probably on the fast side; so prepare yourself for a long but \"deep\" journey.</li>\n<li>In terms of domain do you want to stay in software or move into infrastructure? Security specialist perhaps?  The only way to know is to get your hands dirty on a few of them; and having a lot of little bits of wide experience (such as in infrastructure, security, data) does nicely augment a deep \"center of gravity\" in something like software architecture.</li>\n</ul>\n\n<p>Things to consider on the way:</p>\n\n<ul>\n<li>Being an architect isn't just about coming up with technical solutions to technical probelms, it's also (at least half) about \"soft skills\"...</li>\n<li>Leading development teams / project teams, advising project managers; they'll be looking to you for guidance.</li>\n<li>Resolving ambiguity, dealing with conflicting needs. analysis of business problems, etc.</li>\n<li>Thinking outside the square and asking (re-asking) the basic questions, e.g: Question: \"What's the best way to do X?\", Your Answer: \"Why do X in the first place?\"</li>\n</ul>\n\n<p>FYI, \"<a href=\"http://www.morphological.geek.nz/blogs/postsByTag.aspx?t=Aspiring%20Architects\" rel=\"nofollow\">Aspiring Architects</a>\" is a favourite topic of mine.</p>\n    "},{"t":"Fat Models, skinny ViewModels and dumb Views, the best MVVM approach?","l":"http://stackoverflow.com/questions/852441/fat-models-skinny-viewmodels-and-dumb-views-the-best-mvvm-approach","q":"\n\n<p>Through generous help on <a href=\"http://stackoverflow.com/questions/851595\">this question</a>, I put together the following MVVM structure which displays the changes of a model in real time in XAML (current date/time), very nice.</p>\n\n<blockquote>\n  <p>A cool advantage of this set up is\n  that when you look at your view <em>in\n  design mode</em> of Visual Studio or\n  Blend, <em>you see the time ticking by</em>,\n  which means that <em>at design time you\n  have access to live data from your\n  model.</em></p>\n</blockquote>\n\n<p>In the process of getting this to work, I was surprised to see <strong>most of the bulk move from my ViewModel into my Model</strong>, including implementation of INotifyPropertyChange. Another change is that I <strong>no longer bind to <em>properties</em> on the ViewModel but to <em>methods</em></strong>. </p>\n\n<p>So currently this is my favorite flavor of MVVM:</p>\n\n<ol>\n<li><p>View is dumb: </p>\n\n<ul>\n<li>one ObjectDataProvider for each object you need from your model</li>\n<li>each ObjectDataProvider maps to a method on the ViewModel (not a property)</li>\n<li>no x:Name properties in XAML elements</li>\n</ul></li>\n<li><p>ViewModel is skinny:</p>\n\n<ul>\n<li>the only thing in your ViewModel are the <em>methods</em> to which your view binds</li>\n</ul></li>\n<li><p>Model is fat:</p>\n\n<ul>\n<li>the model implements INotifyPropertyChanged on each of its properties.</li>\n<li>for every method on your ViewModel (e.g. GetCurrentCustomer) there is a corresponding <em>singleton method</em> in your Model (e.g. GetCurrentCustomer).</li>\n<li>the model takes care of any real time threading functionality as in this example</li>\n</ul></li>\n</ol>\n\n<p><strong>Questions:</strong></p>\n\n<ol>\n<li>Those of you who have been implementing MVVM in real scenarios, is this the basic structure you have also settled upon, and if not, how does yours vary?</li>\n<li>How would you extend this to include routed commands and routed events?</li>\n</ol>\n\n<p><em>The following code will work if you just copy the XAML and code behind into a new WPF project.</em></p>\n\n<p><strong>XAML:</strong></p>\n\n<pre><code>&lt;Window x:Class=\"TestBinding99382.Window1\"\n    xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\"\n    xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\"\n    xmlns:local=\"clr-namespace:TestBinding99382\"\n    Title=\"Window1\" Height=\"300\" Width=\"300\"&gt;\n\n    &lt;Window.Resources&gt;\n        &lt;ObjectDataProvider \n             x:Key=\"DataSourceCustomer\" \n             ObjectType=\"{x:Type local:ShowCustomerViewModel}\" \n                        MethodName=\"GetCurrentCustomer\"/&gt;\n    &lt;/Window.Resources&gt;\n\n    &lt;DockPanel DataContext=\"{StaticResource DataSourceCustomer}\"&gt;\n        &lt;StackPanel DockPanel.Dock=\"Top\" Orientation=\"Horizontal\"&gt;\n            &lt;TextBlock Text=\"{Binding Path=FirstName}\"/&gt;\n            &lt;TextBlock Text=\" \"/&gt;\n            &lt;TextBlock Text=\"{Binding Path=LastName}\"/&gt;\n        &lt;/StackPanel&gt;\n        &lt;StackPanel DockPanel.Dock=\"Top\" Orientation=\"Horizontal\"&gt;\n            &lt;TextBlock Text=\"{Binding Path=TimeOfMostRecentActivity}\"/&gt;\n        &lt;/StackPanel&gt;\n\n    &lt;/DockPanel&gt;\n&lt;/Window&gt;\n</code></pre>\n\n<p><strong>Code Behind:</strong></p>\n\n<pre><code>using System.Windows;\nusing System.ComponentModel;\nusing System;\nusing System.Threading;\n\nnamespace TestBinding99382\n{\n    public partial class Window1 : Window\n    {\n        public Window1()\n        {\n            InitializeComponent();\n        }\n    }\n\n    //view model\n    public class ShowCustomerViewModel\n    {\n        public Customer GetCurrentCustomer() {\n            return Customer.GetCurrentCustomer();\n        }\n    }\n\n    //model\n    public class Customer : INotifyPropertyChanged\n    {\n        private string _firstName;\n        private string _lastName;\n        private DateTime _timeOfMostRecentActivity;\n        private static Customer _currentCustomer;\n        private Timer _timer;\n\n        public string FirstName\n        {\n            get\n            {\n                return _firstName;\n            }\n            set\n            {\n                _firstName = value;\n                this.RaisePropertyChanged(\"FirstName\");\n            }\n        }\n\n        public string LastName\n        {\n            get\n            {\n                return _lastName;\n            }\n            set\n            {\n                _lastName = value;\n                this.RaisePropertyChanged(\"LastName\");\n            }\n        }\n\n        public DateTime TimeOfMostRecentActivity\n        {\n            get\n            {\n                return _timeOfMostRecentActivity;\n            }\n            set\n            {\n                _timeOfMostRecentActivity = value;\n                this.RaisePropertyChanged(\"TimeOfMostRecentActivity\");\n            }\n        }\n\n        public Customer()\n        {\n            _timer = new Timer(UpdateDateTime, null, 0, 1000);\n        }\n\n        private void UpdateDateTime(object state)\n        {\n            TimeOfMostRecentActivity = DateTime.Now;\n        }\n\n        public static Customer GetCurrentCustomer()\n        {\n            if (_currentCustomer == null)\n            {\n                _currentCustomer = new Customer \n                     {  FirstName = \"Jim\"\n                        , LastName = \"Smith\"\n                        , TimeOfMostRecentActivity = DateTime.Now \n                     };\n            }\n            return _currentCustomer;\n        }\n\n        //INotifyPropertyChanged implementation\n        public event PropertyChangedEventHandler PropertyChanged;\n        private void RaisePropertyChanged(string property)\n        {\n            if (PropertyChanged != null)\n            {\n                PropertyChanged(this, new PropertyChangedEventArgs(property));\n            }\n        }\n    }\n}\n</code></pre>\n    ","a":"\n<p>Here's my opinion, for what it's worth :</p>\n\n<p>I don't really agree with the approach you suggest (except for the dumb view). In real life, you will often have to use an existing model : it could be legacy code that you don't have the time (or will) to change, or even a library for which you don't have the code. In my opinion, the model should be completely unaware of the way it will be displayed, and should be easily usable in a non-WPF application. So it doesn't have to implement any specific interface like <code>INotifyPropertyChanged</code> of <code>INotifyCollectionChanged</code> to make it usable in MVVM. I think that all the logic related to UI should reside in the ViewModel.</p>\n\n<p>Regarding <code>RoutedEvents</code> and <code>RoutedCommands</code>, they are not really suitable for use with the MVVM pattern. I usually try to use as little <code>RoutedEvents</code> as possible, and no <code>RoutedCommands</code> at all. Instead, my ViewModels expose <code>RelayCommand</code> properties that I bind to the UI in XAML (see <a href=\"http://msdn.microsoft.com/en-us/magazine/dd419663.aspx\">this article</a> by Josh Smith for details on <code>RelayCommand</code>). When I really need to handle events for some control, I use attached behaviors to map the events to ViewModel commands (have a look at <a href=\"http://marlongrech.wordpress.com/2008/12/13/attachedcommandbehavior-v2-aka-acb/\">Marlon Grech's implementation</a>)</p>\n\n<p>So, in summary :</p>\n\n<ul>\n<li>Dumb View</li>\n<li>Big and smart ViewModel</li>\n<li>Any model you want or have to use</li>\n</ul>\n\n<p>Of course it's just my approach, and it may not be the best, but I feel quite comfortable with it ;)</p>\n    "},{"t":"Managing SQLite Connections in Android","l":"http://stackoverflow.com/questions/5156113/managing-sqlite-connections-in-android","q":"\n\n<p>I have a (hopefully) quick question regarding handling SQLite database connections in Android. I have an app that is composed, naturally, of several activities. I have no trouble creating/updating/querying the database, as I've created a single, dedicated class to handle that work via SQLiteOpenHelper, etc.</p>\n\n<p>My question is this: since these activities all share this same database, is this usually implemented as a single, static member, or should each activity own its own connection? My concern of course is the cost of re-connecting to the database in each activity.</p>\n\n<p>Or, put another way, is there any reason not to just store a singleton instance?</p>\n\n<p>I'm also wondering if there's something going on behind the scenes similar to .NET's connection pooling to reduce the cost of opening connections.</p>\n\n<p>Thanks in advance!</p>\n    ","a":"\n<p>Connection opening in SQLite is about 0.2ms. </p>\n\n<p>The best practice tells us to open and close the connection each time we need one. </p>\n    "},{"t":"Mysql VIEWS vs. PHP query","l":"http://stackoverflow.com/questions/4426919/mysql-views-vs-php-query","q":"\n\n<p>I am working on a web application which involves create list of Restaurants in various lists like \"Joe's must visit places\". Now for each Restaurant and list, I have display on website which calculates</p>\n\n<ul>\n<li>Calculating popularity of a Restaurant</li>\n<li>Popularity of a list</li>\n<li>Number of lists a Restaurant is present in</li>\n</ul>\n\n<p>Currently I am using MySQL statements in PHP for this but planning to switch to MySQL VIEWS and do a simple select statement in PHP...</p>\n\n<p>my question is,\n<strong>What is Advantage/Disadvantage of using VIEWS over writing sql queries in PHP?</strong></p>\n    ","a":"\n<p>Using views adds a <strong>level of abstraction</strong> : you may later change the structure of your tables, and you will not have to change the code that displays the information about the lists, because you will still be querying the view (the view definition may change, though).</p>\n\n<p>The main difference is that views are updated after each insertion, such that the data is \"ready\" whenever you query the view, whereas using your custom query will have MySQL compute everything each time (there is some caching, of course).</p>\n\n<p>The bottom line is that if your lists are updated less frenquently than they are viewed, you will see some gains in performance in using views.</p>\n    "},{"t":"Alternative “architectural” approaches to javaScript client code?","l":"http://stackoverflow.com/questions/32540/alternative-architectural-approaches-to-javascript-client-code","q":"\n\n<p>How is your javaScript code organized? Does it follow patterns like MVC, or something else? </p>\n\n<p>I've been working on a side project for some time now, and the further I get, the more my webpage has turned into a full-featured application. Right now, I'm sticking with <a href=\"http://jquery.com\">jQuery</a>, however, the logic on the page is growing to a point where some organization, or dare I say it, \"architecture\" is needed. My first approach is \"MVC-ish\":</p>\n\n<ul>\n<li>The 'model' is a JSON tree that gets extended with helpers</li>\n<li>The view is the DOM plus classes that tweak it</li>\n<li>The controller is the object where I connect events handling and kick off view or model manipulation</li>\n</ul>\n\n<p>I'm very interested, however, in how other people have built more substantial javaScript apps. I'm not interested in GWT, or other server-oriented approaches... just in the approach of \"javaScript + &lt;generic web service-y thingy here&gt;\"</p>\n\n<p>Note: earlier I said javaScript \"is not really OO, not really functional\". This, I think, distracted everyone. Let's put it this way, because javaScript is unique in many ways, and I'm coming from a strongly-typed background, I don't want to force paradigms I know but were developed in very different languages.</p>\n    ","a":"\n<p>..but Javascript has many facets that <strong>are</strong> OO.</p>\n\n<p>Consider this:</p>\n\n<pre><code>var Vehicle = jQuery.Class.create({ \n   init: function(name) { this.name = name; } \n});\n\nvar Car = Vehicle.extend({ \n   fillGas: function(){ \n      this.gas = 100; \n   } \n});\n</code></pre>\n\n<p>I've used this technique to create page-level javascript classes that have their own state, this helps keep it contained (and I often identify areas that I can reuse and put into other classes).</p>\n\n<p>This is also especially useful when you have components/server controls that have their own script to execute, but when you might have multiple instances on the same page.  This keeps the state separate.</p>\n    "},{"t":"Is it a good practice to use JMS Temporary Queue for synchronous use?","l":"http://stackoverflow.com/questions/10786636/is-it-a-good-practice-to-use-jms-temporary-queue-for-synchronous-use","q":"\n\n<p>If we use JMS request/reply mechanism using \"Temporary Queue\", will that code be scalable?</p>\n\n<p>As of now, we don't know if we will supporting 100 requests per second, or 1000s of requests per second.</p>\n\n<p>The code below is what I am thinking of implementing. It makes use of JMS in a 'Synchronous' fashion. The key parts are where the 'Consumer' gets created to point a 'Temporary Queue' that was created for this session. I just can't figure out whether using such Temporary Queues is a scalable design.</p>\n\n<pre><code>  destination = session.createQueue(\"queue:///Q1\");\n  producer = session.createProducer(destination);\n  tempDestination = session.createTemporaryQueue();\n  consumer = session.createConsumer(tempDestination);\n\n  long uniqueNumber = System.currentTimeMillis() % 1000;\n  TextMessage message = session\n      .createTextMessage(\"SimpleRequestor: Your lucky number today is \" + uniqueNumber);\n\n  // Set the JMSReplyTo\n  message.setJMSReplyTo(tempDestination);\n\n  // Start the connection\n  connection.start();\n\n  // And, send the request\n  producer.send(message);\n  System.out.println(\"Sent message:\\n\" + message);\n\n  // Now, receive the reply\n  Message receivedMessage = consumer.receive(15000); // in ms or 15 seconds\n  System.out.println(\"\\nReceived message:\\n\" + receivedMessage);\n</code></pre>\n\n<p><strong>Update:</strong></p>\n\n<p>I came across another pattern, see <a href=\"http://codedependents.com/2010/03/04/synchronous-request-response-with-activemq-and-spring/\">this blog</a>\nThe idea is to use 'regular' Queues for both Send and Receive. However for 'Synchronous' calls, in order to get the desired Response (i.e. matching the request), you create a Consumer that listens to the Receive queue using a 'Selector'.</p>\n\n<p>Steps:</p>\n\n<pre><code>    // 1. Create Send and Receive Queue.\n    // 2. Create a msg with a specific ID\n final String correlationId = UUID.randomUUID().toString();\n final TextMessage textMessage = session.createTextMessage( msg );\n textMessage.setJMSCorrelationID( correlationId );\n\n    // 3. Start a consumer that receives using a 'Selector'.\n           consumer = session.createConsumer( replyQueue, \"JMSCorrelationID = '\" + correlationId + \"'\" );\n</code></pre>\n\n<p>So the difference in this pattern is that we don't create a new temp Queue for each new request.\nInstead all responses come to only one queue, but use a 'selector' to make sure each request-thread receives the only the response that is cares about.</p>\n\n<p>I think the downside here is that you have to use a 'selector'. I don't know yet if that is less preferred or more preferred than earlier mentioned pattern. Thoughts? </p>\n    ","a":"\n<p>Regarding the update in  your post - selectors are very efficient if performed on the message headers, like you are doing with the Correlation ID. <a href=\"http://www.springsource.org/spring-integration\">Spring Integration</a> also internally does this for <a href=\"https://github.com/SpringSource/spring-integration/blob/master/spring-integration-jms/src/main/java/org/springframework/integration/jms/JmsOutboundGateway.java\">implementing a JMS Outbound gateway</a>.</p>\n    "},{"t":"Am I just not understanding TDD unit testing (Asp.Net MVC project)?","l":"http://stackoverflow.com/questions/2867798/am-i-just-not-understanding-tdd-unit-testing-asp-net-mvc-project","q":"\n\n<p>I am trying to figure out how to correctly and efficiently unit test my Asp.net MVC project.  When I started on this project I bought the Pro ASP.Net MVC, and with that book I learned about TDD and unit testing.  After seeing the examples, and the fact that I work as a software engineer in QA in my current company, I was amazed at how awesome TDD seemed to be.  So I started working on my project and went gung ho writing unit tests for my database layer, business layer, and controllers.  Everything got a unit test prior to implementation.  At first I thought it was awesome, but then things started to go downhill.</p>\n\n<p>Here are the issues I started encountering:</p>\n\n<ul>\n<li><p>I ended up writing application code in order to make it possible for unit tests to be performed.  I don't mean this in a good way as in my code was broken and I had to fix it so the unit test pass.  I mean that abstracting out the database to a mock database is impossible due to the use of linq for data retrieval (using the generic repository pattern).  </p>\n\n<p>The reason is that with linq-&gt;sql or linq-&gt;entities you can do joins just by doing:</p>\n\n<pre><code>var objs = select p from _container.Projects select p.Objects;\n</code></pre>\n\n<p>However, if you mock the database layer out, in order to have that linq pass the unit test you must change the linq to be</p>\n\n<pre><code>var objs = select p from _container.Projects\n       join o in _container.Objects on o.ProjectId equals p.Id\n       select o;\n</code></pre>\n\n<p>Not only does this mean you are changing your application logic just so you can unit test it, but you are making your code less efficient for the sole purpose of testability, and getting rid of a lot of advantages using an ORM has in the first place.  </p>\n\n<p>Furthermore, since a lot of the IDs for my models are database generated, I proved to have to write additional code to handle the non-database tests since IDs were never generated and I had to still handle those cases for the unit tests to pass, yet they would never occur in real scenarios.</p>\n\n<p>Thus I ended up throwing out my database unit testing.  </p></li>\n<li><p>Writing unit tests for controllers was easy as long as I was returning views.  However, the major part of my application (and the one that would benefit most from unit testing) is a complicated ajax web application.  For various reasons I decided to change the app from returning views to returning JSON with the data I needed.  After this occurred my unit tests became extremely painful to write, as I have not found any good way to write unit tests for non-trivial json.  </p>\n\n<p>After pounding my head and wasting a ton of time trying to find a good way to unit test the JSON, I gave up and deleted all of my controller unit tests (all controller actions are focused on this part of the app so far).</p></li>\n<li><p>So finally I was left with testing the Service layer (BLL).  Right now I am using EF4, however I had this issue with linq-&gt;sql as well.  I chose to do the EF4 model-first approach because to me, it makes sense to do it that way (define my business objects and let the framework figure out how to translate it into the sql backend).  This was fine at the beginning but now it is becoming cumbersome due to relationships.  </p>\n\n<p>For example say I have <code>Project</code>, <code>User</code>, and <code>Object</code> entities.  One Object must be associated to a project, and a project must be associated to a user.  This is not only a database specific rule, these are my business rules as well.  However, say I want to do a unit test that I am able to save an object (for a simple example).  I now have to do the following code just to make sure the save worked:</p>\n\n<pre><code>User usr = new User { Name = \"Me\" };\n_userService.SaveUser(usr);\n\n\nProject prj = new Project { Name = \"Test Project\", Owner = usr };\n_projectService.SaveProject(prj);\n\n\nObject obj = new Object { Name = \"Test Object\" };\n_objectService.SaveObject(obj);\n\n\n// Perform verifications\n</code></pre>\n\n<p>There are many issues with having to do all this just to perform one unit test.  There are several issues with this.  </p>\n\n<p></p><ul>\n<li>For starters, if I add a new dependency, such as all projects must belong to a category, I must go into EVERY single unit test that references a project, add code to save the category then add code to add the category to the project.  This can be a HUGE effort down the road for a very simple business logic change, and yet almost none of the unit tests I will be modifying for this requirement are actually meant to test that feature/requirement.</li>\n<li>If I then add verifications to my SaveProject method, so that projects cannot be saved unless they have a name with at least 5 characters, I then have to go through every Object and Project unit test to make sure that the new requirement doesn't make any unrelated unit tests fail.</li>\n<li>If there is an issue in the <code>UserService.SaveUser()</code> method it will cause all project, and object unit tests to fail and it the cause won't be immediately noticeable without having to dig through the exceptions.</li></ul></li>\n</ul>\n\n<p>Thus I have removed all service layer unit tests from my project.</p>\n\nI could go on and on, but so far I have not seen any way for unit testing to actually help me and not get in my way.  I can see specific cases where I can, and probably will, implement unit tests, such as making sure my data verification methods work correctly, but those cases are few and far between.  Some of my issues can probably be mitigated but not without adding extra layers to my application, and thus making more points of failure just so I can unit test.  <p></p>\n\n<p>Thus I have no unit tests left in my code.  Luckily I heavily use source control so I can get them back if I need but I just don't see the point.  </p>\n\n<p>Everywhere on the internet I see people talking about how great TDD unit tests are, and I'm not just talking about the fanatical people.  The few people who dismiss TDD/Unit tests give bad arguments claiming they are more efficient debugging by hand through the IDE, or that their coding skills are amazing that they don't need it.  I recognize that both of those arguments are utter bullocks, especially for a project that needs to be maintainable by multiple developers, but any valid rebuttals to TDD seem to be few and far between.   </p>\n\n<p>So the point of this post is to ask, am I just not understanding how to use TDD and automatic unit tests?</p>\n    ","a":"\n<p>You may take a look at a <a href=\"http://github.com/darind/samplemvc\" rel=\"nofollow\">sample ASP.NET MVC 2.0 project structure</a> I wrote. It presents some concepts that might get you started on unit testing your controller logic and database. As far as database testing is concerned it is no longer unit tests but integration tests. As you will see in my sample I am using NHibernate which allows me to easily switch to a sample SQLite database that is re-created for each test fixture.</p>\n\n<p>Finally doing unit tests in ASP.NET MVC could be a pain without proper separation of concerns and abstractions and using mocking frameworks and frameworks like <a href=\"http://mvccontrib.codeplex.com/wikipage?title=TestHelper\" rel=\"nofollow\">MVCContrib.TestHelper</a> could make your life easier.</p>\n\n<p><a href=\"http://github.com/darind/samplemvc/blob/master/tests/SampleMvc.Web.Tests/Controllers/UsersControllerTests.cs\" rel=\"nofollow\">Here's a preview</a> of how your controller unit test might look like.</p>\n\n<hr>\n\n<p>UPDATE:</p>\n\n<p>As a response to the comments I think that programming is a concrete task and it is difficult to give an ultimate answer as to how do I unit test my complex business application. In order to be able to test a complex application coupling between the layers should be as weak as possible which could be achieved with interfaces and abstract classes. I agree though that achieving such a weak coupling in a complex application is not a trivial task.</p>\n\n<p>I could give you an advice: if the whole TDD concept is difficult to understand and you see no benefits in it then this is OK. Nobody can prove that TDD is beneficial in all situations. Just try to design your application in such a way that each class has a single responsibility. If you find yourself doing validation of input, SQL data access and exception handling in the same class then you are doing it wrong. Once you achieve this separation you will see that unit testing becomes much easier and you could even come to a stage when unit tests will drive your development :-)</p>\n\n<p>As far as unit testing a <code>JsonResult</code> with <code>MvcContrib.TestHelper</code> this is a concrete question to which I give a concrete answer:</p>\n\n<pre><code>public class MyModel\n{\n    public string MyProperty { get; set; }\n}\n\npublic class HomeController : Controller\n{\n    public ActionResult Index()\n    {\n        return Json(new MyModel { MyProperty = \"value\" });\n    }\n}\n</code></pre>\n\n<p>And the test:</p>\n\n<pre><code>[TestMethod]\npublic void HomeController_Index_Action_Should_Return_Json_Representation_Of_MyModel()\n{\n    // arrange\n    var sut = new HomeController();\n\n    // act\n    var actual = sut.Index();\n\n    // assert\n    actual\n        .AssertResultIs&lt;JsonResult&gt;()\n        .Data\n        .ShouldBe&lt;MyModel&gt;(\"\")\n        .MyProperty\n        .ShouldBe(\"value\");\n}\n</code></pre>\n    "},{"t":"Android: Best practice for keeping data in Memory and Database at same time","l":"http://stackoverflow.com/questions/3679664/android-best-practice-for-keeping-data-in-memory-and-database-at-same-time","q":"\n\n<p>We're designing an Android app that has a lot of data (\"customers\", \"products\", \"orders\"...), and we don't want to query sqlite every time we need some record. We wanna avoid to query database as most as we can, so we decided to keep certain data allways in memory.</p>\n\n<p>Our initial idea is to create 2 simple classes:</p>\n\n<ol>\n<li><p>\"MemoryRecord\": a class that will contain basically an array of objects (string/int/double/datetime/etc...), that are the data from a table record, and all methods to get those data in/out from this array.</p></li>\n<li><p>\"MemoryTable\": a class that will contain basically a Map of [Key,MemoryRecord] and all methods to manipulate this Map and insert/update/delete record into/from database.</p></li>\n</ol>\n\n<p>Those classes will be derived to every kind of table we have in database. Of course that there are other usefull methods not listed above, but they are not important at this point.  </p>\n\n<p>So, when starting app, we will load those tables from SQLite database to memory using those classes, and every time we need to change some data, we will change in memory and post it into database right after.</p>\n\n<p>But, we want some help/advice from you. Can you suggest something more simple or efficient to implement such thing? Or maybe some existing classes that already do it for us?</p>\n\n<p>Thanks in advance.</p>\n\n<p><strong>Update:</strong></p>\n\n<p>I understand what you guys are trying to show me, and I thank you for that. </p>\n\n<p>But, let's say we have a table with 2000 records, and I will to list those records. For each one, I have to query other 30 tables (some of them with 1000 records, others with 10 records) to add additional info in the list, and this while it's \"flying\" (and as you know , we must be very fast at this momment).</p>\n\n<p>Now you'll gonna say: \"just build your main query with all those 'joins', and bring all you need in one step. SQLite can be very fast, if your database is well designed, etc...\". </p>\n\n<p>OK, but this query will become very complicated and sure, even SQLite be very fast, it will be \"too\" slow (2 a 4 seconds, as I confirmed, and this isn't a acceptable time for us). </p>\n\n<p>Another complicator is that, depending of user interaction, we need to \"re-query\" all records, because the tables involved are not the same, and we have to \"re-join\" with another set of tables.</p>\n\n<p>So, an alternative is bring only the main records (this will never change, no matter what user does or wants) with no join (this is very fast!) and query the others tables every time we want some data. Note that on the table with 10 records only, we will fetch the same records many and many times. In this case, it is a wast of time, because no matter fast sqlite be, it will allways be more expensive to query/cursor/fetch/etc... than just grab the record from a kind of \"memory cache\". I want to make clear that we don't plan to keep all data in memory allways, just some tables we query very offten. </p>\n\n<p>And we came to the original question: what is the best way to \"cache\" those records. I really like to focus the discussion on that and not \"why do you need to cache data?\"  </p>\n\n<p>Thanks again.</p>\n    ","a":"\n<p>The vast majority of the apps on the platform (contacts, Email, Gmail, calendar, etc.) do not do this.  Some of these have extremely complicated database schemas with potentially a large amount of data and do not need to do this.  What you are proposing to do is going to cause <em>huge</em> pain for you, with no clear gain.</p>\n\n<p>You should first focus on designing your database and schema to be able to do efficient queries.  There are two main reasons I can think of for database access to be slow:</p>\n\n<ul>\n<li>You have really complicated data schemas.</li>\n<li>You have a very large amount of data.</li>\n</ul>\n\n<p>If you are going to have a lot of data, you can't afford to keep it all in memory anyway, so this is a dead end.  If you have complicated structures, you would benefit in either case with optimizing them to improve performance.  In both cases, your database schema is going to be key to good performance.</p>\n\n<p>Actually optimizing the schema can be a bit a of a black art (and I am no expert on it), but some things to look out for are correctly creating indices on rows you will query, designing joins so they will take efficient paths, etc.  I am sure there are lots of people who can help you with this area.</p>\n\n<p>You could also try looking at the source of some of the platform's databases to get some ideas of how to design for good performance.  For example the Contacts database (especially starting with 2.0) is extremely complicated and has a lot of optimizations to provide good performance on relatively large data and extensible data sets with lots of different kinds of queries.</p>\n\n<p>Update:</p>\n\n<p>Here's a good illustration of how important database optimization is.  In Android's media provider database, a newer version of the platform changed the schema significantly to add some new features.  The upgrade code to modify an existing media database to the new schema could take 8 minutes or more to execute.</p>\n\n<p>An engineer made an optimization that reduced the upgrade time of a real test database from 8 minutes to 8 seconds.  A 60x performance improvement.</p>\n\n<p>What was this optimization?</p>\n\n<p>It was to create a temporary index, at the point of upgrade, on an important column used in the upgrade operations.  (And then delete it when done.)  So this 60x performance improvement comes even though it also includes the time needed to build an index on one of the columns used during upgrading.</p>\n\n<p>SQLite is one of those things where if you know what you are doing it can be remarkably efficient.  And if you don't take care in how you use it, you can end up with wretched performance.  It is a safe bet, though, if you are having performance issues with it that you can fix them by improving how you are using SQLite.</p>\n    "},{"t":"If you are forced to use an Anemic domain model, where do you put your business logic and calculated fields?","l":"http://stackoverflow.com/questions/1933351/if-you-are-forced-to-use-an-anemic-domain-model-where-do-you-put-your-business","q":"\n\n<p>Our current O/RM tool does not really allow for rich domain models, so we are forced to utilize anemic (DTO) entities everywhere.  This has worked fine, but I continue to struggle with where to put basic object-based business logic and calculated fields.</p>\n\n<p>Current layers:</p>\n\n<ul>\n<li>Presentation </li>\n<li>Service </li>\n<li>Repository</li>\n<li>Data/Entity</li>\n</ul>\n\n<p>Our repository layer has most of the basic fetch/validate/save logic, although the service layer does a lot of the more complex validation &amp; saving (since save operations also do logging, checking of permissions, etc).  The problem is where to put code like this:</p>\n\n<pre><code>Decimal CalculateTotal(LineItemEntity li)\n{\n  return li.Quantity * li.Price;\n}\n</code></pre>\n\n<p>or </p>\n\n<pre><code>Decimal CalculateOrderTotal(OrderEntity order)\n{\n  Decimal orderTotal = 0;\n  foreach (LineItemEntity li in order.LineItems)\n  {\n    orderTotal += CalculateTotal(li);\n  }\n  return orderTotal;\n}\n</code></pre>\n\n<p>Any thoughts?</p>\n    ","a":"\n<p>Let's get back to basics:</p>\n\n<h2>Services</h2>\n\n<p>Services come in 3 flavours: <em>Domain Services</em>, <em>Application Services</em>, and <em>Infrastructure Services</em></p>\n\n<ul>\n<li><strong>Domain Services</strong> : Encapsulates business logic that doesn't naturally\nfit within a domain object.  In your case, <em>all</em> of your business logic.</li>\n<li><strong>Application Services</strong> : Used by external consumers to talk to your system </li>\n<li><strong>Infrastructure Services</strong> : Used to abstract technical concerns (e.g.\nMSMQ, email provider, etc)</li>\n</ul>\n\n<h2>Repository</h2>\n\n<p>This is where your data-access and <strong>consistency checks</strong> go. In pure DDD, your <em>Aggregate Roots</em> would be responsible for checking consistency (before persisting any objects).  In your case, you would use checks from your <strong>Domain Services</strong> layer.</p>\n\n<p></p><hr><p></p>\n\n<p>Proposed solution: <strong><em>Split your existing services apart</em></strong></p>\n\n<p>Use a new <strong>Domain Services</strong> layer to encapsulate all logic for your DTOs, and your consistency checks too (using <em>Specifications</em>, maybe?).</p>\n\n<p>Use the <strong>Application Service</strong> to expose the necessary fetch methods (<code>FetchOpenOrdersWithLines</code>), which forward the requests to your <strong>Repository</strong> (and use generics, as Jeremy suggested).  You might also consider using <em>Query Specifications</em> to wrap your queries.</p>\n\n<p>From your <strong>Repository</strong>, use <em>Specifications</em> in your <strong>Domain Services</strong> layer to check object consistency etc before persisting your objects.</p>\n\n<p>You can find supporting info in Evans' book:</p>\n\n<ul>\n<li><em>\"Services and the Isolated Domain Layer\"</em>  (pg 106)</li>\n<li><em>\"Specifications\"</em>  (pg 224)</li>\n<li><em>\"Query Specifications\"</em>  (pg 229)</li>\n</ul>\n    "},{"t":"When to use SOA (Service Oriented Architecture) [closed]","l":"http://stackoverflow.com/questions/969964/when-to-use-soa-service-oriented-architecture","q":"\n\n<p>I had a conversation with one of our architects recently and he summarized his use of SOA as \"The only time we'll use services is when we need async actions otherwise we'll use go direct to the data store\"</p>\n\n<p>I thought about this statement and it seems fairly logical as services work well in a publish subscribe model, but I was wondering in what other scenarios you should be looking to use SOA?</p>\n    ","a":"\n<p>We expose services to our customers because they shouldn't be able to connect to the datasource directly.</p>\n\n<p>We expose services to ourselves because it's easier to spread them over different technologies using WCF. </p>\n\n<p>We expose services because we have different user interfaces for the same datasource. And when we use services we save a third of the work.</p>\n\n<p>It is never only because of the async actions.</p>\n    "},{"t":"Game Architecture","l":"http://stackoverflow.com/questions/5458760/game-architecture","q":"\n\n<p>I have a question about a XNA game I'm making, but it is also a generic question for future games. I'm making a Pong game and I don't know exactly what to update where, so I'll explain better what I mean. I have a class Game, Paddle and Ball and, for example, I want to verify the collisions between the ball with the screen limits or the paddles, but I come across 2 approaches to do this:</p>\n\n<p><strong>Higher Level Approach</strong> - Make paddle and ball properties public and on the Game.Update check for collisions?</p>\n\n<p><strong>Lower Level Approach</strong>- I supply every info I need (the screen limits and paddles info) to the ball class (by parameter, or in a Common public static class) and on the Ball.Update I check for collisions?</p>\n\n<p>I guess my question in a more generic way is:</p>\n\n<p>Does an object need to know how to update and draw itself, even having dependencies from higher levels that somehow are supplied to them?</p>\n\n<p><strong>or</strong></p>\n\n<p>Is better to process it at higher levels in Game.Update or Game.Draw or using Managers to simplify code?</p>\n\n<p>I think this is a game logic model question that applies to every game. I don't know if I made my question clear, if not, feel free to ask.</p>\n    ","a":"\n<p>The difficult part of answering your question is that you're asking both: \"what should I do now, for Pong\" and \"what should I do later, on some generic game\".</p>\n\n<hr>\n\n<p>To make Pong you don't even need Ball and Paddle classes, because they're basically just positions. Just stick something like this in your Game class:</p>\n\n<pre><code>Vector2 ballPosition, ballVelocity;\nfloat leftPaddlePosition, rightPaddlePosition;\n</code></pre>\n\n<p>Then just update and draw them in whatever order suits you in your Game's <code>Update</code> and <code>Draw</code> functions. Easy!</p>\n\n<hr>\n\n<p>But, say you want to create multiple balls, and balls have many properties (position, velocity, rotation, colour, etc): You might want to make a <code>Ball</code> class or struct that you can instance (same goes for the paddles). You could even move some functions into that class where they are self-contained (a <code>Draw</code> function is a good example).</p>\n\n<p>But keep the design concept the same - all of the object-to-object interaction handling (ie: the gameplay) happens in your <code>Game</code> class.</p>\n\n<p>This is all just fine if you have two or three different gameplay elements (or classes).</p>\n\n<hr>\n\n<p>However let's postulate a more complicated game. Let's take the basic pong game, add some pinball elements like mutli-ball and player-controlled flippers. Let's add some elements from Snake, say we have an AI-controlled \"snake\" as well as some pickup objects that either the balls or the snake can hit. And for good measure let's say the paddles can also shoot lasers like in Space Invaders and the laser bolts do different things depending on what they hit.</p>\n\n<p><em>Golly</em> that is a huge mess of interaction! How are we going to cope with it? We can't put it all in Game!</p>\n\n<p>Simple! We make an interface (or an abstract class or a virtual class) that each \"thing\" (or \"actor\") in our game world will derive from. Here is an example:</p>\n\n<pre><code>interface IActor\n{\n    void LoadContent(ContentManager content);\n    void UnloadContent();\n\n    void Think(float seconds);\n    void UpdatePhysics(float seconds);\n\n    void Draw(SpriteBatch spriteBatch);\n\n    void Touched(IActor by);\n\n    Vector2 Position { get; }\n    Rectangle BoundingBox { get; }\n}\n</code></pre>\n\n<p>(This is only an example. There is not \"<em>one true actor interface</em>\" that will work for every game, you will need to design your own. This is why I don't like <code>DrawableGameComponent</code>.)</p>\n\n<p>Having a common interface allows Game to just talk about Actors - instead of needing to know about every single type in your game. It is just left to do the things common to every type - collision detection, drawing, updating, loading, unloading, etc.</p>\n\n<p>Once you're <em>in</em> the actor, you can start worrying about specific types of actor. For example, this might be a method in <code>Paddle</code>:</p>\n\n<pre><code>void Touched(IActor by)\n{\n    if(by is Ball)\n         ((Ball)by).BounceOff(this.BoundingBox);\n    if(by is Snake)\n         ((Snake)by).Kill();\n}\n</code></pre>\n\n<p>Now, I like to make the Ball bounced by the Paddle, but it is really a matter of taste. You could do it the other way around.</p>\n\n<p><strong>In the end you should be able to stick all your actors in a big list that you can simply iterate through in Game.</strong></p>\n\n<p>In practice you might end up having multiple lists of actors of different types for performance or code simplicity reasons. This is ok - but in general try to stick to the principle of Game only knowing about generic actors.</p>\n\n<p>Actors also may want to query what other actors exist for various reasons. So give each actor a reference to Game, and make the list of actors public on Game (there's no need to be super-strict about public/private when you're writing gameplay code and it's your own internal code.)</p>\n\n<hr>\n\n<p>Now, you could even go a step further and have multiple interfaces. For example: one for rendering, one for scripting and AI, one for physics, etc. Then have multiple implementations that can be composed into objects.</p>\n\n<p>This is described in detail in <a href=\"http://cowboyprogramming.com/2007/01/05/evolve-your-heirachy/\">this article</a>. And I've got a simple example in <a href=\"http://stackoverflow.com/a/6719162/165500\">this answer</a>. This is an appropriate next step if you start finding that your single actor interface is starting to turn into more of a \"tree\" of abstract classes.</p>\n    "},{"t":"On OS X, how do I find out what architecture a shared lib is compiled for?","l":"http://stackoverflow.com/questions/3377147/on-os-x-how-do-i-find-out-what-architecture-a-shared-lib-is-compiled-for","q":"\n\n<p>I need to know whether I compiled libjpeg for 32 or 64 bits architecture, but don't know how to find out, is there a command that will let me check?</p>\n    ","a":"\n<p>just type 'file libjpeg.dylib' and you'll get output like the following</p>\n\n<pre><code>libpoll.dylib: Mach-O universal binary with 3 architectures\nlibpoll.dylib (for architecture x86_64): Mach-O 64-bit dynamically linked shared library x86_64\nlibpoll.dylib (for architecture i386): Mach-O dynamically linked shared library i386\nlibpoll.dylib (for architecture ppc7400): Mach-O dynamically linked shared library ppc\n</code></pre>\n    "},{"t":"What's the difference between Architectural Patterns and Architectural Styles?","l":"http://stackoverflow.com/questions/3958316/whats-the-difference-between-architectural-patterns-and-architectural-styles","q":"\n\n<p>In <code>Software Architecture - Foundations, Theory and Practice</code>, I can find definitions for both. The problem is that I don't get what each one of them means in plain english:</p>\n\n<h2>Architectural Pattern.</h2>\n\n<blockquote>\n  <p>An Architectural Pattern is a named\n  collection of architectural design\n  decisions that are applicable to a\n  recurring design problem parameterized\n  to account for different software\n  development contexts in which that\n  problem appears.</p>\n</blockquote>\n\n<h2>Architectural Style.</h2>\n\n<blockquote>\n  <p>An Architectural Style is a named\n  collection of architectural design\n  decisions that (1) are applicable in a\n  given development context, (2)\n  constrain architectural design\n  decisions that are specific to a\n  particular system within that context,\n  and (3) elicit beneficial qualities in\n  each resulting system.</p>\n</blockquote>\n\n<p>So, could anyone clarify in simple english what does each one mean and what are the differences between them?</p>\n    ","a":"\n<p>So here it is:</p>\n\n<p>An Architectural Pattern is a way of solving a recurring architectural problem. MVC, for instance, solves the problem of separating the UI from the model. Senser-Controller-Actuator, is a pattern that will help you with the problem of actuating in face of several input senses. </p>\n\n<p>An Architectural Style, on the other hand, is just a name given to a recurrent Archictural Design. Contrary to a Pattern, it doesn't exist to \"solve\" a problem. </p>\n\n<p>Pipe&amp;filter doesn't solve any specific problem, it's just a way of organizing your code. Client/server, Main program &amp; subroutine and Abstract Data Types / OO, the same.</p>\n\n<p>Also, a single architecture can contain several architectural styles, and each architectural style can make use of several architectural patterns.</p>\n    "},{"t":"Code generators vs. ORMs vs. Stored Procedures","l":"http://stackoverflow.com/questions/76395/code-generators-vs-orms-vs-stored-procedures","q":"\n\n<p>In what domains do each of these software architectures shine or fail?</p>\n\n<p>Which key requirements would prompt you to choose one over the other?</p>\n\n<p>Please assume that you have developers available who can do good object oriented code as well as good database development.</p>\n\n<p>Also, please avoid holy wars :) all three technologies have pros and cons, I'm interested in where is most appropriate to use which.</p>\n    ","a":"\n<p>Every one of these tools provides differing layers of abstraction, along with differing points to override behavior.  These are architecture choices, and all architectural choices depend on trade-offs between technology, control, and organization, both of the application itself and the environment where it will be deployed.</p>\n\n<ul>\n<li><p>If you're dealing with a culture where DBAs 'rule the roost', then a stored-procedure-based architecture will be easier to deploy.  On the other hand, it can be very difficult to manage and version stored procedures.</p></li>\n<li><p>Code generators shine when you use statically-typed languages, because you can catch errors at compile-time instead of at run-time.</p></li>\n<li><p>ORMs are ideal for integration tools, where you may need to deal with different RDBMSes and schemas on an installation-to-installation basis.  Change one map and your application goes from working with PeopleSoft on Oracle to working with Microsoft Dynamics on SQL Server.</p></li>\n</ul>\n\n<p>I've seen applications where Generated Code is used to interface with Stored Procedures, because the stored procedures could be tweaked to get around limitations in the code generator.</p>\n\n<p>Ultimately the only correct answer will depend upon the problem you're trying to solve and the environment where the solution needs to execute.  Anything else is arguing the correct pronunciation of 'potato'.</p>\n    "},{"t":"Design Methodology: use case driven vs. domain driven","l":"http://stackoverflow.com/questions/3173070/design-methodology-use-case-driven-vs-domain-driven","q":"\n\n<p>Just for discussion, to me it seems that 2 different terminologies actually are saying the same thing. Is there any tangible differences between this 2 design approaches?</p>\n    ","a":"\n<p><strong>Use Cases</strong> focus on <em>Users, Actions, and Processes</em>.  This is great from a business perspective, because everyone can see an abstracted view of what the system will provide.</p>\n\n<p><strong>DDD</strong> focuses on creating software that solves problems.  The '<em>Who can solve this?</em>' and the '<em>What process will they follow?</em>' come afterwards.</p>\n\n<p><strong>DDD</strong> really gets to the core problems earlier in the design process, and helps you <strong>structure your solution</strong> (i.e. identifying <em>Entities, Value Objects, Respositories, Domain/Application/Infrastructure services, Bounded Contexts, Specifications, etc</em>).</p>\n\n<p>Use Cases don't cater for this at all, or how to <strong>manage your development</strong> (<em>Anti-Corruption Layers, Separate Ways, etc</em>)</p>\n\n<p>In my experience, DDD offers <strong>more flexibility</strong> (changing requirements anyone?), and provides the foundations for your Use Cases.  Once you've got your <strong>Domain Model</strong> in place, Use Cases can be implemented using <em>Controllers/Workflow Engines/UIs</em> that connect with your Domain Model.  Quite often, I've identified gaps in business requirements just by building Domain Models.</p>\n\n<p>And having attended a talk by Ivar Jacobsen some years ago, I would also say that DDD is better suited to Agile.</p>\n    "},{"t":"Recommendations for 'C' Project Architecture Guidelines?","l":"http://stackoverflow.com/questions/2792422/recommendations-for-c-project-architecture-guidelines","q":"\n\n<p>Now that I got my head wrapped around the 'C' language to a point where I feel proficient enough to write clean code, I'd like to focus my attention on project architecture guidelines.  I'm looking for a good resource that coves the following topics:</p>\n\n<ol>\n<li>How to create an interface that promotes code maintainability and is extensible for future upgrades.</li>\n<li>Library creation guidelines. Example, when should I consider using static vs dynamic libraries.  How to properly design an ABI to cope with either one.</li>\n<li>Header files: what to partition out and when.  Examples on when to use 1:1 vs 1:many .h to .c</li>\n<li>Anything you feel I missed but is important when attempting to architect a new C project.  </li>\n</ol>\n\n<p>Ideally, I'd like to see some example projects ranging from small to large and see how the architecture changes depending on project size, function or customer.</p>\n\n<p>What resource(s) would you recommend for such topics?</p>\n    ","a":"\n<p>Whenever I got serious writing C code, I had to emulate C++ features in it.  The main stuff worth doing is:</p>\n\n<ul>\n<li><p>Think of each module like a class.  The functions you expose in the header are like public methods.  Only put a function in the header if it part of the module's needed interface.</p></li>\n<li><p>Avoid circular module dependencies.  Module A and module B should not call each other.  You can refactor something into a module C to avoid that.</p></li>\n<li><p>Again, following the C++ pattern, if you have a module that can perform the same operations on different instances of data, have a create and delete function in your interface that will return a pointer to struct that is passed back to other functions.  But for the sake of encapsulation, return a void pointer in the public interface and cast to your struct inside of the module.</p></li>\n<li><p>Avoid module-scope variables--the previously described pattern will usually do what you need.  But if you really need module-scope variables, group them under a struct stored in a single module-scope variable called \"m\" or something consistent.  Then in your code whenever you see \"m.variable\" you will know at a glance it is one of the module-scope structs.</p></li>\n<li><p>To avoid header trouble, put #ifndef MY_HEADER_H #define MY_HEADER_H declaration that protects against double including.  The header .h file for your module, should only contain #includes needed FOR THAT HEADER FILE.  The module .c file can have more includes needed for the compiling the module, but don't add those includes into the module header file.  This will save you from a lot of namespace conflicts and order-of-include problems.</p></li>\n</ul>\n    "},{"t":"Overriding the bean defined in parent context in a child context","l":"http://stackoverflow.com/questions/4249978/overriding-the-bean-defined-in-parent-context-in-a-child-context","q":"\n\n<p>Our app has a requirement to support multi-tenancy. Each of the boarded customer might potentially override 1 or more beans or some properties of a bean defined at the core platform level (common code/definitions). I am wondering what is the best way to handle this.</p>\n    ","a":"\n<p>Spring allows you to redefine the same bean name multiple times, and takes the last bean definition processed for a given name to be the one that wins.  So for example, your could have an XML file defining your core beans, and import that in a client-specific XML file, which also redefines some of those beans. It's a bit fragile, though, since there's no mechanism to specifically say \"this bean definition is an override\".</p>\n\n<p>I've found that the cleanest way to handle this is using the <a href=\"http://static.springsource.org/spring/docs/3.0.x/spring-framework-reference/html/beans.html#beans-java\">new <code>@Bean</code>-syntax introduced in Spring 3</a>. Rather than defining beans as XML, you define them in Java. So your core beans would be defined in one <code>@Bean</code>-annotated class, and your client configs would subclass that, and override the appropriate beans. This allows you to use standard java <code>@Override</code> annotations, explicitly indicating that a given bean definition is being overridden.</p>\n    "},{"t":"DTO DAO POCO BO","l":"http://stackoverflow.com/questions/1203377/dto-dao-poco-bo","q":"\n\n<p>Actually i'm pretty confused about this terms and how they relate to each other. A read something about every one of them but i don't uderstant the work flow..</p>\n\n<p>DTO - Data transfer object - object to transport values<br>\nBO Business object - object in domain model. object to make Business logic with<br>\nPOCO - no idea, i've read a definition on wiki but didn't understood anything<br>\nDAO - data access object - object to map the DB table ?   </p>\n\n<p>Could someone please bring some light into it for me ?</p>\n    ","a":"\n<ul>\n<li><strong>DTO</strong>: Data Transfer Object, used to transfer data between loosly coupled services</li>\n<li><strong>POCO</strong>: Plain Old Clr Object, normal CLR object doesn't use any attributes or required inheritance to act as a DAO/DTO</li>\n<li><strong>BO</strong>: Business Object, contains business logic, used in the Business Logic part of your solution</li>\n<li><strong>DAO</strong>: Data Access Object, used to transfer data from your database</li>\n</ul>\n\n<p>So a regular workflow would be to request data from a service, which is sent to your app as a DTO, you convert it to a BO to manipulate it and send it back as a DTO or after converting it to a DAO store it in a database.</p>\n\n<p>You use the different object to separate concerns between the 3 types, a BO doesn't need to know whether it's persisted using a database or a service.</p>\n    "},{"t":"How to test your code on a machine with big-endian architecture?","l":"http://stackoverflow.com/questions/2839087/how-to-test-your-code-on-a-machine-with-big-endian-architecture","q":"\n\n<p>Both <a href=\"http://ideone.com/\"><strong>ideone.com</strong></a> and <a href=\"http://www.codepad.org/\"><strong>codepad.org</strong></a> have <a href=\"http://en.wikipedia.org/wiki/Endianness\"><strong>Little-Endian</strong></a> architechtures.</p>\n\n<p>I want to test my code on some machine with <strong>Big-Endian</strong> architechture (for example - Solaris - which I don't have). Is there some easy way that you know about?</p>\n    ","a":"\n<p>Googling \"big endian online emulator\" lead me to <a href=\"http://pearpc.sourceforge.net/\">PearPC</a>. I assume that if you have the patience you can <a href=\"http://pearpc.sourceforge.net/installlinux.html\">install Mandrake Linux</a>, get gcc, and go party.</p>\n    "},{"t":"Should services always return DTOs, or can they also return domain models?","l":"http://stackoverflow.com/questions/21554977/should-services-always-return-dtos-or-can-they-also-return-domain-models","q":"\n\n<p>I'm (re)designing large-scale application, we use multi-layer architecture based on DDD.</p>\n\n<p>We have MVC with data layer (implementation of repositories), domain layer (definition of domain model and interfaces - repositories, services, unit of work), service layer (implementation of services). So far, we use domain models (mostly entities) accross all layers, and we use DTOs only as view models (in controller, service returns domain model(s) and controller creates view model, which is passed to the view).</p>\n\n<p>I'v read countless articles about using, not using, mapping and passing DTOs. I understand that there's no any definitive answer, but I'm not sure if it's ok or not returning domain models from services to controllers. If I return domain model, it's still never passed to the view, since controller always creates view-specific view model - in this case, it seem legit. On the other hand, it doesn't feel right when domain model leaves business layer (service layer). Sometimes service needs to return data object that wasn't defined in the domain and then we either have to add new object to the domain that isn't mapped, or create POCO object (this is ugly, since some services return domain models, some effectively return DTOs).</p>\n\n<p>The question is - if we strictly use view models, is it ok to return domain models all the way to controllers, or should we always use DTOs for communication with service layer? If so, is it ok to adjust domain models based on what services need? (Frankly I don't think so, since services should consume what domain has.) If we should strictly stick to DTOs, should they be defined in service layer? (I think so.) Sometimes it's clear that we should use DTOs (e.g., when service performs lot of business logic and creates new objects), sometimes it's clear that we should use just domain models (e.g., when Membership service returns anemic User(s) - it seems it wouldn't make much sense to create DTO that is the same as domain model) - but I prefer consistency and good practices.</p>\n\n<p>Article <a href=\"http://stackoverflow.com/questions/12874328/domain-vs-dto-vs-viewmodel-how-and-when-to-use-them\">Domain vs DTO vs ViewModel - How and When to use them?</a> (and also some other articles) is very similar to my problem, but it doesn't answer this question(s). Article <a href=\"http://stackoverflow.com/questions/19932876/should-i-implement-dtos-in-repository-pattern-with-ef\">Should I implement DTOs in repository pattern with EF?</a> is also similar, but it doesn't deal with DDD.</p>\n\n<p>Disclaimer: I don't intend to use any design pattern only because it exists and is fancy, on the other hand, I'd like to use good design patterns and practices also because it helps designing the application as a whole, helps with separation of concerns, even tohugh using particular pattern isn't \"necessary\", at least at the moment.</p>\n\n<p>As always, thank you.</p>\n    ","a":"\n<blockquote>\n  <p><em>it doesn't feel right when domain model leaves business layer (service layer)</em></p>\n</blockquote>\n\n<p>Makes you feel like you are pulling the guts out right? According to Martin Fowler: the Service Layer defines the application's boundery, it encapsulates the domain. In other words it protects the domain.</p>\n\n<blockquote>\n  <p><em>Sometimes service needs to return data object that wasn't defined in the domain</em></p>\n</blockquote>\n\n<p>Can you provide an example of this data object?</p>\n\n<blockquote>\n  <p><em>If we should strictly stick to DTOs, should they be defined in service layer?</em></p>\n</blockquote>\n\n<p>Yes, because the response is part of your service layer. If it is defined \"somewhere else\" then the service layer needs to reference that \"somewhere else\", adding a new layer to your lasagna.</p>\n\n<blockquote>\n  <p><em>is it ok to return domain models all the way to controllers, or should we always use DTOs for communication with service layer?</em></p>\n</blockquote>\n\n<p>A DTO a response/request object, it makes sense if you use it for communication. If you use domain models in your presentation layer (MVC-Controllers/View, WebForms, ConsoleApp), then the presentation layer is tightly coupled to your domain, any changes in the domain requires you to change your controllers, etc, recompilation and everything.</p>\n\n<blockquote>\n  <p><em>it seems it wouldn't make much sense to create DTO that is the same as domain model)</em></p>\n</blockquote>\n\n<p>This is one of the disadvantage of DTO to new eyes. Right now, you are thinking <strong>duplication of code</strong>, but as your project expands then it would make much more sense, specially in a team environment where different teams are assigned to different layers.</p>\n\n<p>DTO might add additional complexity to your application, but so are your layers. DTO is an expensive feature of your system, they don't come free.</p>\n\n<h2>Why use a DTO</h2>\n\n<p>This article provides both advantage and disadvantage of using a DTO,  <a href=\"http://guntherpopp.blogspot.com/2010/09/to-dto-or-not-to-dto.html\">http://guntherpopp.blogspot.com/2010/09/to-dto-or-not-to-dto.html</a></p>\n\n<p>Summary as follows:</p>\n\n<p><strong>When to Use</strong></p>\n\n<ul>\n<li>For large projects. </li>\n<li>Project lifetime is 10 years and above.</li>\n<li>Strategic, mission critical application. </li>\n<li>Large teams (more than 5)</li>\n<li>Developers are distributed geographically. </li>\n<li>The domain and presentation are different. </li>\n<li>Reduce overhead data exchanges (the original purpose of DTO)</li>\n</ul>\n\n<p><strong>When not to Use</strong></p>\n\n<ul>\n<li>Small to mid size project (5 members max)</li>\n<li>Project lifetime is 2 years or so. </li>\n<li>No separate team for GUI, backend, etc.</li>\n</ul>\n\n<p><strong>Arguments Against DTO</strong></p>\n\n<ul>\n<li>Duplication of code. </li>\n<li>Cost of development time, debugging. (use DTO generation tools <a href=\"http://entitiestodtos.codeplex.com/\">http://entitiestodtos.codeplex.com/</a>)</li>\n<li>You must synchronize both models all the time. </li>\n<li>Cost of developement: Additional mapping is necessary. (use auto mappers like <a href=\"https://github.com/AutoMapper/AutoMapper\">https://github.com/AutoMapper/AutoMapper</a>)</li>\n<li><a href=\"http://stackoverflow.com/questions/1440952/why-are-data-transfer-objects-an-anti-pattern\">Why are Data Transfer Objects an anti-pattern?</a></li>\n</ul>\n\n<p><strong>Arguments With DTO</strong></p>\n\n<ul>\n<li>Without DTO, the presentation and the domain is tightly coupled. (This is ok for small projects.)</li>\n<li>Interface/API stability</li>\n<li>May provide optimization for the presentation layer by returning a DTO containing only those attributes that are absolutely required. Using <a href=\"http://stackoverflow.com/questions/21187083/from-where-or-firstordefault-in-linq/21187130#21187130\">linq-projection</a>, you don't have to pull an entire entity.</li>\n<li>To reduce development cost, use code-generating tools</li>\n</ul>\n    "},{"t":"Architecture of a Docker multi-apps server regarding to database","l":"http://stackoverflow.com/questions/19250205/architecture-of-a-docker-multi-apps-server-regarding-to-database","q":"\n\n<p>I have a server running 5 or 6 small Rails apps.  All their attached files are on S3 and they all use MySQL as database. Each app has its own user and runs some thins.  There is an nginx server doing the load balancing and domain routing.</p>\n\n<p>I plan to replace this server by a Docker installation : one server with one container per app, with a nginx in front.</p>\n\n<p>My question is : where would you put the database part ?</p>\n\n<p>I mainly see 4 possibilities :</p>\n\n<p>1) One Mysql server inside of each app container. This seams not to be Docker's philosophy I think. It would require each container's data to be backuped individually.</p>\n\n<p>2) A unique MySQL container for all apps.</p>\n\n<p>3) A standard MySQL installation on the host Docker server.</p>\n\n<p>4) A separate MySQL server for all apps.</p>\n\n<p>What would you do ?</p>\n\n<p>PS : I know Docker is not production ready yet, I plan to use it for staging at the moment and switch if I'm happy with it.</p>\n    ","a":"\n<p>It depends on several factors. Here are some questions to help you to decide.</p>\n\n<ul>\n<li><p>Are the 5-6 apps very similar (i.e., in Docker terms, you could base them on a common image), and are you thinking about deploying more of them, and/or migrating some of them to other servers?</p>\n\n<ul>\n<li><p>YES: then it makes sense to embed the MySQL server in each app, because it will \"stick around\" with the app, with minimal configuration effort.</p></li>\n<li><p>NO: then there is no compelling reason to embed the MySQL server.</p></li>\n</ul></li>\n<li><p>Do you want to be able to scale those apps (i.e. load balance requests for a single app on multiple containers), or to scale the MySQL server (to e.g. a master/slave replicated setup) ?</p>\n\n<ul>\n<li><p>YES: then you cannot embed the MySQL server, otherwise, scaling one tier would scale the other tier, which will lead to though headaches.</p></li>\n<li><p>NO: then nothing prevents you from embedding the MySQL server.</p></li>\n</ul></li>\n<li><p>Do you think that there will be a significant database load on at least one of those apps?</p>\n\n<ul>\n<li><p>YES: then you might want to use separate MySQL servers, because a single app could impede the others.</p></li>\n<li><p>NO: then you can use a single MySQL server.</p></li>\n</ul></li>\n</ul>\n\n<p>Embedding the MySQL server is fine if you want a super-easy-to-deploy setup, where you don't need scalability, but you want to be able to spin up new instances super easily, and you want to be able to move instances around without difficulty.</p>\n\n<p>The most flexible setup is the one where you deploy one app container + one MySQL container for each app. If you want to do that, I would suggest to wait for Docker 0.7, which will implement <em>links</em>, which will let you have a basic service discovery mechanism, so that each app container can easily discover the host/port of its database container.</p>\n\n<p>I wouldn't deploy MySQL on the host; if you want a single MySQL install, you can achieve the same result by running a single MySQL container and running it with <code>-p 3306:3306</code> (it will route the host's <code>3306/tcp</code> port to the MySQL container's <code>3306/tcp</code> port).</p>\n    "},{"t":"DDD - Dependecies between domain model, services and repositories","l":"http://stackoverflow.com/questions/756849/ddd-dependecies-between-domain-model-services-and-repositories","q":"\n\n<p>Just wanted to know how others have layered their architecture.  Say i have my layers as follows:</p>\n\n<p>Domain Layer<br>\n--Product<br>\n--ProductService (Should the imp go into this layer?)<br>\n--IProductService<br>\n--IProductRepository<br></p>\n\n<p>Infrastructure Layer<br>\n--ProductRepository (Imp of IProductRepository in my domain)<br></p>\n\n<p>Now when a new product is created i have a requirement to assign a product id by calling into the ProductService.GetNextProductId() method.  </p>\n\n<p>Because the service has a dependency on the repository i set up the ProductService ctor with an interface of IProductRepository which can be injected later.  something like this:</p>\n\n<pre><code>    public class ProductService : IProductService\n    {\n        private IProductRepository _repository;\n\n        public ProductService(IProductRepository repository)\n        {\n            _repository = repository;\n        }\n\n        public long GetNextProductId()\n        {\n            return _repository.GetNextProductId();\n        }\n    }\n</code></pre>\n\n<p>My issue is that when i use the service in the Product Class i am making reference to the Repository in the ctor when instantiating a new ProductService class.  In DDD its a big no no to have such a reference.  I' am not even sure if my product domain class is being set up correctly to call the service, can someone pls advise:</p>\n\n<pre><code>public class Product : Entity\n    {\n        private ProductService _svc;\n        private IProductRepository _repository;\n\n        public Product(string name, Address address) //It doesnt seem right to put parm for IProductRepository in the ctor?\n            : base(_svc.GetNextProductId) // This is where i pass the id\n        {\n            // where to create an instance of IProductRepository?\n        }\n    }\n</code></pre>\n\n<p>How can i elegantly solve this design issue?  I am open to suggestions from experienced DDD'ers</p>\n\n<p>EDIT:</p>\n\n<p>Thanks for you comments.  I also doubted if the service should be called from the Product Class.  I have not used a factory pattern (yet) as the construction of the object is still simple.  I dont feel it warrants a factory method yet?</p>\n\n<p>I' am confused...Putting the ProductId aside if my Product class needed some other data from a Service e.g GetSystemDateTime() (i know, bad example but trying to demonstrate a non db call) where would this service method be called?  </p>\n\n<p>Services in DDD are logic dumps where the logic is not natrual to the domain object, right?  So How does it glue together?</p>\n    ","a":"\n<p>Your domain model shouldn't have a reference to ProductService nor to IProductRepository. If you create a new Product it has to be created through a factory - the Factory may use ProductService to get a product id.</p>\n\n<p>In fact I'd wrap ProductService with an appropriate interface, such as IProductIdGeneratorService so that you can inject this into the factory using your IoC container.</p>\n    "},{"t":"amd64 fs/gs registers in linux","l":"http://stackoverflow.com/questions/6611346/amd64-fs-gs-registers-in-linux","q":"\n\n<p>On the x86-64 architecture, two registers have a special purpose: FS and GS. In linux 2.6.*, the FS register seem to be used to store thread-local information.</p>\n\n<ul>\n<li>Is that correct?</li>\n<li>What is stored at fs:0? Is there any C structure that describe this content?</li>\n<li>What is then the use of GS?</li>\n</ul>\n    ","a":"\n<p>In x86-64 there are <a href=\"http://lxr.free-electrons.com/source/arch/x86/include/asm/segment.h?v=2.6.39#L170\">3 TLS entries</a>, two of them accesible via <a href=\"http://lxr.free-electrons.com/source/arch/x86/include/asm/segment.h?v=2.6.39#L176\">FS and GS</a>, FS is used internally by glibc (in IA32 apparently <a href=\"http://lxr.free-electrons.com/source/arch/x86/include/asm/segment.h?v=2.6.39#L40\">FS is used by Wine and GS by glibc</a>).</p>\n\n<p>Glibc makes its TLS entry point to a <a href=\"http://fxr.watson.org/fxr/source/nptl/descr.h?v=GLIBC27;im=excerpts#L124\"><code>struct pthread</code></a> that contains some internal structures for threading. Glibc usually refers to a <code>struct pthread</code> variable as <code>pd</code>, presumably for <em>pthread descriptor</em>.</p>\n\n<p>On x86-64, <code>struct pthread</code> starts with a <a href=\"http://fxr.watson.org/fxr/source/nptl/sysdeps/x86_64/tls.h?v=GLIBC27;im=excerpts#L45\"><code>tcbhead_t</code></a> (this depends on the architecture, see the macros <a href=\"http://fxr.watson.org/fxr/ident?v=GLIBC27;im=excerpts;i=TLS_DTV_AT_TP\"><code>TLS_DTV_AT_TP</code></a> and <a href=\"http://fxr.watson.org/fxr/ident?v=GLIBC27;im=excerpts;i=TLS_TCB_AT_TP\"><code>TLS_TCB_AT_TP</code></a>). This Thread Control Block Header, AFAIU, contains some fields that are needed even when there is a single thread. The DTV is the Dynamic Thread Vector, and contains pointers to TLS blocks for DSOs loaded via <code>dlopen()</code>. Before or after the TCB there is a static TLS block for the executable and DSOs linked at (program's) load time. The TCB and DTV are explained pretty well in <a href=\"http://www.akkadia.org/drepper/tls.pdf\">Ulrich Drepper's TLS document</a> (look for the diagrams in chapter 3).</p>\n    "},{"t":"Durandal and ASP.NET MVC conventions","l":"http://stackoverflow.com/questions/15545705/durandal-and-asp-net-mvc-conventions","q":"\n\n<p>I'm currently evaluating <strong>Durandal</strong> for use in an enterprise <strong>ASP.NET MVC</strong> application. </p>\n\n<p>However the default conventions used by Durandal seem to conflict with the MVC conventions I've grown accustomed to.</p>\n\n<p>The HotTowel MVC template by John Papa is great, but this too seems to \"do away\" with MVC conventions in favour of Durandals by putting things in an App folder.</p>\n\n<p>A couple of the issues I have with these conventions are:</p>\n\n<ul>\n<li>Views are potentially split across two locations (/App/views and /Views).</li>\n<li>Scripts are also split across two locations (/App/durandal and /Scripts).</li>\n<li>Views are not in the default MVC locations for the <code>RazorViewEngine</code>.</li>\n</ul>\n\n<p>I would prefer to keep each element contained in the appropriate MVC conventions e.g.</p>\n\n<pre><code>/Controllers/\n---- HomeController\n---- AdminController\n\n/Scripts/    \n---- durandal/    \n---- viewmodels/    \n-------- Home\n-------- Admin\n\n/Views/    \n---- Home    \n---- Admin\n</code></pre>\n\n<p>My questions are:</p>\n\n<ol>\n<li><p>Is it possible to configure Durandal to achieve the above (or something similar)?</p></li>\n<li><p>Is it wise to venture away from the default Durandal conventions?</p></li>\n<li><p>What are the potential issues in doing so?</p></li>\n</ol>\n    ","a":"\n<h2>1. Is it possible to configure Durandal to achieve the above (or something similar)?</h2>\n\n<p>Yes, you can have any folder structure your heart desires. Durandal does not impose any folder structure on your application but it does have a default convention which is completely overridable.  </p>\n\n<p>If you are using Durandals <a href=\"http://durandaljs.com/documentation/Router/\">router</a> then you will want to look into how to configure it to find modules. There are many ways of doing this, I prefer to create my own convention by overriding the <code>router.autoConvertRouteToModuleId</code>. </p>\n\n<p>If you are not using the router plugin then you will have to manage the uris for your modules yourself and this is done by following <a href=\"http://requirejs.org/docs/api.html#jsfiles\">requirejs'</a> convention and using this convention along w/ durandals <a href=\"http://durandaljs.com/documentation/Composition/\">composition</a> module. </p>\n\n<p>Also, you can override how it finds the views to bind to your modules by overriding the <a href=\"http://durandaljs.com/documentation/View-Locator/\">viewlocators</a> convention.  Durandal provides an very simplistic way of structuring small applications right out of the box but if you need to build larger applications then it is recommended you create your own conventions.</p>\n\n<h2>2. Is it wise to venture away from the default Durandal conventions? 3. What are the potential issues in doing so?</h2>\n\n<p>So, there are the conventions of how to discover modules and how to discover views which are completely overridable. And I recommend you do override these and choose a way that suites you best.  But, as for placing durandal inside your scripts folder as you have listed above I dont think its a good idea.  </p>\n\n<p>The reason I dont recommend this is because I see the scripts folder as a place for all your third party scripts that are NON-AMD modules. This is because Durandal also comes with an <a href=\"http://durandaljs.com/documentation/Optimizing-On-Dot-Net/\">optimizer.exe</a> which makes minifying/compressing/uglifying all your html/css/js (amd) files into 1 file.  </p>\n\n<p>If you keep your entire application under an app folder and then have the durandal folder inside your app folder the optimizer just works because it lives inside the app/durandal/amd folder.  So, when you execute it, it will transverse up 2 directories to your app folder and then scan every subfolder to create a <a href=\"http://requirejs.org/docs/optimization.html\">app.build.js</a> requirejs optimization file.. and then it will compress your entire application to one file for you.</p>\n\n<p>This beats having to hand edit an app.build.js file everytime you add a new file to your project.  Sure.. there are other tools out there which can do this too.. but you will have to spend time learning their api and how to configure them.  If you dont feel like devoting the time to learning something like <a href=\"http://gruntjs.com/\">grunt</a> then this optimizer is kick ass.  Personally, I like the ability to just double click something and have my whole application built for me.</p>\n\n<p>As for placing all your third party libraries which are non-amd in a seperate scripts folder I would look into compressing those seperately like using <a href=\"http://www.asp.net/mvc/tutorials/mvc-4/bundling-and-minification\">MVC's bundling</a>.  The reason I would bundle those seperately is because you know those files arnt changing very often and if you bundle those into a seperate js file they can be cached by the browser seperately.  Whereas if your spa is changing, which it it probably will.. then you want the browser to cache that seperately so it only has to re-download your compressed application.</p>\n    "},{"t":"Models, ViewModels, DTOs in MVC 3 application","l":"http://stackoverflow.com/questions/5995140/models-viewmodels-dtos-in-mvc-3-application","q":"\n\n<p>I have a web solution (in VS2010) with two sub-projects:</p>\n\n<ol>\n<li><p><code>Domain</code> which holds the <code>Model</code> classes (mapped to database tables via Entity Framework) and <code>Services</code> which (besides other stuff) are responsible for CRUD operations </p></li>\n<li><p><code>WebUI</code> which references the Domain project</p></li>\n</ol>\n\n<p>For the first pages I've created I have used the Model classes from the Domain project directly as Model in my strongly typed Views because the classes were small and I wanted to display and modify <em>all</em> properties.</p>\n\n<p>Now I have a page which should only work with a small part of all properties of the corresponding Domain Model. I retrieve those properties by using a <em>projection</em> of the query result in my Service class. But I need to <strong>project into a type</strong> - and here come my questions about the solutions I can think of:</p>\n\n<ol>\n<li><p>I introduce <code>ViewModels</code> which live in the <code>WebUI</code> project and expose <code>IQueryables</code> and the <code>EF data context</code> from the service to the WebUI project. Then I could directly project into those ViewModels.</p></li>\n<li><p>If I don't want to expose IQueryables and the EF data context I put the <code>ViewModel</code> classes in the <code>Domain</code> project, then I can return the ViewModels directly as result of the queries and projections from the Service classes.</p></li>\n<li><p>In addition to the <code>ViewModels</code> in the <code>WebUI</code> project I introduce <code>Data transfer objects</code> which move the data from the queries in the Service classes to the <code>ViewModels</code>.</p></li>\n</ol>\n\n<p>Solution 1 and 2 look like the same amount of work and I am inclined to prefer solution 2 to keep all the database concerns in a separate project. But somehow it sounds wrong to have <em>View</em>-Models in the Domain project.</p>\n\n<p>Solution 3 sounds like a lot more work since I have more classes to create and to care about the Model-DTO-ViewModel mapping. I also don't understand what would be the difference between the DTOs and the ViewModels. Aren't the ViewModels exactly the collection of the selected properties of my Model class which I want to display? Wouldn't they contain the same members as the DTOs? Why would I want to differentiate between ViewModels and DTO?</p>\n\n<p>Which of these three solutions is preferable and what are the benefits and downsides? Are there other options?</p>\n\n<p>Thank you for feedback in advance!</p>\n\n<p><strong>Edit</strong> (because I had perhaps a too long wall of text and have been asked for code)</p>\n\n<p>Example: I have a <code>Customer</code> Entity ...</p>\n\n<pre><code>public class Customer\n{\n    public int ID { get; set; }\n    public string Name { get; set; }\n    public City { get; set; }\n    // ... and many more properties\n}\n</code></pre>\n\n<p>... and want to create a View which only shows (and perhaps allows to edit) the <code>Name</code> of customers in a list. In a Service class I extract the data I need for the View via a projection:</p>\n\n<pre><code>public class CustomerService\n{\n    public List&lt;SomeClass1&gt; GetCustomerNameList()\n    {\n        using (var dbContext = new MyDbContext())\n        {\n            return dbContext.Customers\n                .Select(c =&gt; new SomeClass1\n                             {\n                                 ID = c.ID,\n                                 Name = c.Name\n                             })\n                .ToList();\n        }\n    }\n}\n</code></pre>\n\n<p>Then there is a CustomerController with an action method. How should this look like?</p>\n\n<p>Either this way (a) ...</p>\n\n<pre><code>public ActionResult Index()\n{\n    List&lt;SomeClass1&gt; list = _service.GetCustomerNameList();\n    return View(list);\n}\n</code></pre>\n\n<p>... or better this way (b):</p>\n\n<pre><code>public ActionResult Index()\n{\n    List&lt;SomeClass1&gt; list = _service.GetCustomerNameList();\n\n    List&lt;SomeClass2&gt; newList = CreateNewList(list);\n\n    return View(newList);\n}\n</code></pre>\n\n<p>With respect to option 3 above I'd say: <code>SomeClass1</code> (lives in <code>Domain</code> project) is a <strong>DTO</strong> and <code>SomeClass2</code> (lives in <code>WebUI</code> project) is a <strong>ViewModel</strong>.</p>\n\n<p>I am wondering if it ever makes sense to distinguish the two classes. Why wouldn't I always choose option (a) for the controller action (because it's easier)? Are there reasons to introduce the <strong>ViewModel</strong> (<code>SomeClass2</code>) in addition to the <strong>DTO</strong> (<code>SomeClass1</code>)?</p>\n    ","a":"\n<blockquote>\n  <p>introduce ViewModels which live in the\n  WebUI project and expose IQueryables\n  and the EF data context from the\n  service to the WebUI project. Then I\n  could directly project into those\n  ViewModels.</p>\n</blockquote>\n\n<p>The trouble with this is you soon run into problems using EF trying to 'flatten' models. I encountered something similar when I had a <code>CommentViewModel</code> class that looked like this:</p>\n\n<pre><code>public class CommentViewModel\n{\n    public string Content { get; set; }\n    public string DateCreated { get; set; }\n}\n</code></pre>\n\n<p>The following EF4 query projection to the <code>CommentViewModel</code> wouldn't work as the  <a href=\"http://stackoverflow.com/questions/5839388/formatting-date-in-linq-to-entities-query-causes-exception\">couldn't translate the ToString() method into SQL</a>:</p>\n\n<pre><code>var comments = from c in DbSet where c.PostId == postId \n               select new CommentViewModel() \n               { \n                   Content = c.Content,\n                   DateCreated = c.DateCreated.ToShortTimeString() \n               };\n</code></pre>\n\n<p>Using something like Automapper is a good choice, especially if you have a lot of conversions to make. However, you can also create your own converters that basically convert your domain model to your view model. In my case I created my own extension methods to convert my <code>Comment</code> domain model to my <code>CommentViewModel</code> like this:</p>\n\n<pre><code>public static class ViewModelConverters\n{\n    public static CommentViewModel ToCommentViewModel(this Comment comment)\n    {\n        return new CommentViewModel() \n        { \n            Content = comment.Content,\n            DateCreated = comment.DateCreated.ToShortDateString() \n        };\n    }\n\n    public static IEnumerable&lt;CommentViewModel&gt; ToCommentViewModelList(this IEnumerable&lt;Comment&gt; comments)\n    {\n        List&lt;CommentViewModel&gt; commentModels = new List&lt;CommentViewModel&gt;(comments.Count());\n\n        foreach (var c in comments)\n        {\n            commentModels.Add(c.ToCommentViewModel());\n        }\n\n        return commentModels;\n    }\n}\n</code></pre>\n\n<p>Basically what I do is perform a standard EF query to bring back a domain model and then use the extension methods to convert the results to a view model. For example, the following methods illustrate the usage:</p>\n\n<pre><code>public Comment GetComment(int commentId)\n{\n    return CommentRepository.GetById(commentId);\n}\n\npublic CommentViewModel GetCommentViewModel(int commentId)\n{\n    return CommentRepository.GetById(commentId).ToCommentViewModel();\n}\n\npublic IEnumerable&lt;Comment&gt; GetCommentsForPost(int postId)\n{\n    return CommentRepository.GetCommentsForPost(postId);\n}\n\npublic IEnumerable&lt;CommentViewModel&gt; GetCommentViewModelsForPost(int postId)\n{\n    return CommentRepository.GetCommentsForPost(postId).ToCommentViewModelList();\n}\n</code></pre>\n    "},{"t":"How/when/where to include external javascript","l":"http://stackoverflow.com/questions/13954734/how-when-where-to-include-external-javascript","q":"\n\n<p>I'm looking for some advice on the best way to hold my JavaScript (jQuery) functions.</p>\n\n<p>I am developing in MVC/razor and therefore have a layout page.  I include my jQuery library and an external JavaScript file in here so it's available in every single page.</p>\n\n<p>This is working well, but I am now becoming very aware of the fact that I am adding almost 300 lines of JS to EVERY page, where maybe half of that is used in any one of these pages.</p>\n\n<p>One function is not in the external file and instead sits inside the HTML because I need to use variables set in my razor code.  </p>\n\n<p>I have a couple of questions around this arrangement:</p>\n\n<ul>\n<li>Is placing JS inside the HTML generally acceptable when variables set using razor are used? There does not appear to be a clean way of passing a variable into an external js file</li>\n<li>Should I split my functions down in to individual JS files and just include what is needed for each page in the site?</li>\n<li>If I were to split them into multiple files, how would that work with jQuery's <code>(document).ready</code> ? Do I need to use that if all the JavaScript I am including is to be used?</li>\n</ul>\n\n<p>I'm sure this will more a matter of opinion than a black and white answer, but I want to consider all my options before moving on.  Even though it works fine as is, I can't help but feel there is a better/cleaner way.</p>\n    ","a":"\n<p>Remember once a user lands on your homepage and loads the javascript file it will be cached in their browser so subsequent pages will not download the Javascript again.</p>\n\n<p>I would definitely keep the js separate, you could have a snippet on each page that initialise the JS that that particurlar view needs. Put something like the below in the views that need to run JS</p>\n\n<pre><code>$(document).ready(function() {\n    mysite.mypage();\n});\n</code></pre>\n\n<p>Then the function mysite.mypage() can be defined in the external JS file. \n300 lines isnt the end of the world, I would say its probably too early to be worryign about optimisation. </p>\n\n<p>You could always look at minifying that JS file to decrease the size. A quick and easy way to do this is here:</p>\n\n<p><a href=\"http://www.minifyjavascript.com/\">http://www.minifyjavascript.com/</a></p>\n    "},{"t":"Server architecture for a multiplayer game? [closed]","l":"http://stackoverflow.com/questions/632793/server-architecture-for-a-multiplayer-game","q":"\n\n<p>I'm planning to build a small multiplayer game which could be run as a java applet or a flash file in the web browser. I haven't done any server programming before, so I'm wondering what sort of server architecture i should have.</p>\n\n<p>It'll be easy for me to create perl/php files on the server, which the java/flash code contacts to update the player position/actions, etc. But I'm considering whether i should get a dedicated web host, which OS to use, which database, etc. Also, the amount of bandwidth used and scalability is a consideration.</p>\n\n<p>Another option could be using a cloud hosting system (as opposed to a dedicated server), so they would take care of adding additional machines as the game grows. As long as each server ran the core perl/php files for updating the database, it should work fine.</p>\n\n<p>Yet another option could be using Google app engine.</p>\n\n<p>Any thoughts regarding the server architecture, OS/database choice, and whether my method of using perl/php/python scripts for server-side programing is a good one, will be appreciated!</p>\n    ","a":"\n<p>You need to clarify more about the game, and think more about architecture rather than specific implementation details. </p>\n\n<p>The main question is whether your game is going to be in real time, turn based, or long-delay based (e.g., email chess). Another question is whether or not you are going to be freezing the state for subsequent reloads.</p>\n\n<p>I would highly recommend figuring out in advance whether or not all players in the same game are going to be hosted on the same server (e.g., 1000 of 4 player matches compared to 4 matches of 1000 players each). If possible, go with the first and stick everyone who is in the same game under the same server. You will have a hard enough time synchronizing multiple clients to one server, rather than having multiple servers against which players are synchronized. Otherwise, the definition of consistency is problematic.</p>\n\n<p>If possible, have each client communicate with the server and then the server distributing updates to the clients. This way you have one \"official state\", and can do a variety of conflict resolutions, phantoms, etc. Peer to peer gives better performance in faster games (e.g., FPSs) but introduces tons of problems. </p>\n\n<p>I cannot for the life of me see any convincing reason to do this and perl or PHP. Your game is not web based, why write it in a web oriented language? Use good old J2EE for the server, and exchange data with your clients via XML and AJAX. If possible, run a real Java application on clients rather than servlets. You can then benefit from using JMS which will take a huge load off your back by abstracting a lot of the communication details for you.</p>\n    "},{"t":"Game Programming - communication between game objects in 2d","l":"http://stackoverflow.com/questions/1677706/game-programming-communication-between-game-objects-in-2d","q":"\n\n<p>recently I have been trying my hand at coding a game in C#. I'm not using XNA for this, as I thought I would learn more if I coded the game from scratch (although I am using a multimedia engine).</p>\n\n<p>I'm trying to design a 2D RPG game - a bit ambitious I know, however I have a reasonably well understanding of at least the basic parts of the game (ie the 'boiler plate' code), and I've reached a part where I don't know where to go from here.</p>\n\n<p>In the 2D game, you progress through the game via walking around different 'areas'. Once you hit a 'portal tile', you are transported to the next area etc.</p>\n\n<p>I'm having trouble understanding how these area object should be set up. This was my first idea: Each area has a few different collection structures (for example, a visibility quadtree, a collision quadtree, an AI entity List etc). So if I were to add an enemy entity into the game, it would be put into the visibility quadtree, the collision quadtree (because you can collide with entities) and the AI entity list. When the area receives an update request, it tells each of these structures to update themselves, which in turn tell the entities to update themselves. All good, so far.</p>\n\n<p>My question is this: What if this enemy needs to communicate with other objects? For example, it might need to know whether the player was in a certain range of it. Or whether it had been hit by the player. Or where all the collidable objects are in the area (so it could pathfind).</p>\n\n<p>The first (and bad) solution to this problem would be simply to pass each entity a reference to each collection. But this obviously encourages tightly coupled objects, which is not good.</p>\n\n<p>The second solution I came up with was for each entity to be able to query the area, via message structures. So an enemy would be able to say \"Give me a list of each entity within X distance of my position\" and the area would return an answer. However, this would get increasingly difficult as I would have to code more and more possibilities into the area (\"Give me a list of entities that are not within X distance of myself\", \"Give me a list of all entities with health lower than X\" etc).</p>\n\n<p>What I'm looking for is a time tested solution to this problem of inter object communication, and basically how to set up an area. I suppose it would need some kind of messaging system as well, although I'm not sure.</p>\n\n<p>Thanks for reading.</p>\n    ","a":"\n<p>You could look into the <a href=\"http://sourcemaking.com/design_patterns/mediator\" rel=\"nofollow\">Mediator pattern</a>. It would allow you to have low coupling, but yeah, you <em>would</em> have a lot of code in the mediator object(s) to facilitate communication between the other objects. But I think it's either one or the other. And then this is preferable. It would also allow you more freedom to do tricks, like queuing certain update requests and handle the requests at more opportune times, or to do batch processing of a lot of requests instead doing them one by one which would (hypothetically) impose some sort of overhead. </p>\n    "},{"t":"WinRT and .Net Framework","l":"http://stackoverflow.com/questions/7431306/winrt-and-net-framework","q":"\n\n<p>After the WinRT presentation, I'm confused about the role of the .net framework in the Microsoft development stack.</p>\n\n<p>Is it necessary for developing WinRT applications?</p>\n    ","a":"\n<p>As I understand it you can build a WinRT app in 3 ways</p>\n\n<ul>\n<li>.net</li>\n<li>jscript</li>\n<li>unmanged C++</li>\n</ul>\n\n<p>The WinRT \"object\" are ref counted like COM was, however they have good meta data so .net can make them look like .net objects.  (likewise jscript can make them look like jscipt objects)</p>\n\n<p>So .net is not necessary to develop WinRT applications if you wish to use jscript or C++.</p>\n    "},{"t":"How to determine distributed architecture?","l":"http://stackoverflow.com/questions/5832344/how-to-determine-distributed-architecture","q":"\n\n<p>I'm trying to get my head around the thought process when designing a large scale application.</p>\n\n<p>Let's say I have a client who needs a new customer website and he is estimating 40,000 orders per day with an already 25,000 user base. When desiging the application, how do you about determining if a distributed architecutre is needed? Should I use a web farm? etc.</p>\n\n<p>I've mostly build 2 tier (physical) applications in the past and I really want to improve my understanding.</p>\n\n<p>Any insight would be great!</p>\n    ","a":"\n<p>It's going to depend on a lot of other factors than just the number of orders per day. Where will it be hosted? What does that physical architecture look like? What else does the application do besides ecommerce? Does it need to integrate with other applications (besides the payment gateways of course)? Etc.</p>\n\n<p>A simple two tier application in the right cloud hosting environment (say VMware for instance) that can scale dynamically would work just fine for an ecommerce website. A simple two tier application in the right on-premises hosting environment (load balanced web farm) should also work fine for an ecommerce website. It's the difference between scaling up (potentially hidden with virtualization, which ends up being a scale out of sorts) and scaling out (adding more servers).</p>\n\n<p>A distributed architecture would allow you to distribute the system load (say order processing) to 1:M servers that sit (perhaps) behind a load balancer. This is a very common approach, and would also work very well for an ecommerce website.</p>\n\n<p>In my opinion, there isn't one architecture or system design that fits every mold. The closest architecture to fit every mold (again, my opinion) would be a service oriented architecture. If all business processes and logic are services (and designed correctly), then no matter how your requirements change, no matter what your hosting environment looks like or changes to, and no matter what integration requirements you have, your system can handle it with little or no changes.</p>\n    "},{"t":"Should domain events be raised within or outside of a transaction?","l":"http://stackoverflow.com/questions/4691710/should-domain-events-be-raised-within-or-outside-of-a-transaction","q":"\n\n<p>In our application we raise domain events when something changes in the domain model. Some of the tasks that are performed by the event handlers must be done within the same transaction that was used when the event is raised, other tasks must be performed outside of this transaction.</p>\n\n<p>For example,</p>\n\n<p>When an Orderline is added to an Order entity, the OrderLineAdded domain event is raised, one domain event changes the state of the domain model (so must be performed in the same transaction), then when the transaction is completed the UI must be updated.</p>\n\n<p>How would you approach this problem?</p>\n\n<ol>\n<li>Raise two events, one inside the transaction, and one outside of the transaction.</li>\n<li>Raise the event inside of the transaction, but use the event handler to send an Async request to update the UI? </li>\n</ol>\n\n<p>Option 1 seems confusing, since the events names must somehow convey they are in or out of a transaction, but with option 2 handlers of the domain event must always assume that they are called synchronously from within a transaction.</p>\n\n<p>Maybe there is a better approach?</p>\n    ","a":"\n<p>I've had a similar problem. Domain model was publishing events (using the technique Udi Dahan describes <a href=\"http://www.udidahan.com/2009/06/14/domain-events-salvation/\">here</a>). Then I realized that my UI-related handlers are invoked even if something goes wrong and transaction is rolled back later.</p>\n\n<p>To fix this I introduced another role to the system, another kind of event handler. I has <code>ITransactionalEventHadneler</code> and <code>INonTransactionalEventHandler</code>. The former were invoked synchonously immediately in <code>DomainEvents.Publish()</code> method. The latter were queued to be invoked as soon as transaction gets committed (using System.Transactions hooks). The solution worked fine and was quite readable and maintainable.</p>\n    "},{"t":"Azure Storage Table Paging","l":"http://stackoverflow.com/questions/6328042/azure-storage-table-paging","q":"\n\n<p>To implement <strong>simple</strong> paging in Azure Storage in relatively straight forward: <a href=\"http://scottdensmore.typepad.com/blog/2010/04/paging-with-windows-azure-table-storage.html\">Paging with Windows Azure Table Storage</a>. This can be implemented with continuation token functionality. </p>\n\n<p>But.</p>\n\n<p>This is just a start for the serious paging. First problem is <strong>sorting</strong>. You can not do OrderBy in Azure Table. What would be the best solution to overcome this? Pages must be sorted, that's the fact.</p>\n\n<p>Second problem, when come to the paging is to know number of <strong>total pages</strong>, with just continuation token functionality this is not possible. To do at every page \".Count()\" seems to me very inefficient (since partitions could be on multiple servers, for instance).</p>\n\n<p>Third problem is, related to the second, even you can count how many pages you have, how to \"connect\" counted pages to the actuals continuation tokens? This is the biggest mystery for me. <strong>How to get a continuation from the specific table row?</strong></p>\n\n<p>I would be very happy, if correct solution could be provided. I must admit I also have one and I will write it in one of the answers below.</p>\n    ","a":"\n<p>I know this doesn't solve your question in the way you asked for, but still, I do not believe paging should be performed in the way you suggested. What I mean by that is that, since Azure Table Storage does not support the functionallity you require, it may not be a good fit. </p>\n\n<p>I would get the data in a local cache, perform the order and paging in there and be done with it. There is a suggested workaround for this limitation with carefully constructing the rowkey/partitionkey but I would strongly suggest you not follow that.</p>\n\n<pre><code>Blog blog=  new Blog();\n// Note the fixed length of 19 being used since the max tick value is 19 digits long.\nstring rowKeyToUse = string.Format(\"{0:D19}\", \n        DateTime.MaxValue.Ticks - DateTime.UtcNow.Ticks);\nblog.RowKey = rowKeyToUse;\n</code></pre>\n\n<p>So a blog  b1 dated 10/1/2008 10:00:00 AM will have 2521794455999999999 as the RowKey, and b2 dated 10/2/2008 10:00:00 AM will have 2521793591999999999 as the RowKey and hence b2 will preceede b1.</p>\n\n<p>To retrieve all blogs dated after 10/1/2008 10:00:00 AM, we will use the follwing query:</p>\n\n<pre><code>     string rowKeyToUse = string.Format(\"{0:D19}\", \n        DateTime.MaxValue.Ticks - DateTime.UtcNow.Ticks);\nvar blogs = \n    from blog in context.CreateQuery&lt;Blog&gt;(\"Blogs\")\n    where blog.PartitionKey == \"Football\" \n        &amp;&amp; blog.RowKey.CompareTo(rowKeyToUse) &gt; 0\n  select blog;\n</code></pre>\n\n<p>(this has been taken from Windows Azure Table, Dec. 2008 Documents <a href=\"http://www.google.si/url?sa=t&amp;source=web&amp;cd=1&amp;ved=0CBgQhgIwAA&amp;url=http://download.microsoft.com/download/3/B/1/3B170FF4-2354-4B2D-B4DC-8FED5F838F6A/Windows%2520Azure%2520Table%2520-%2520Dec%25202008.docx&amp;ei=NND1TemoNsrfsgbruYHIBg&amp;usg=AFQjCNF9KUQPyH_vDHJsHSNyhnfgljov_A\">provided</a> by Microsoft)</p>\n\n<p>As for counting the number of pages, that's easy, a simply divide operation will do the trick here; as for continuation tokens, one way would be to (upon initial request) \"walk\" on each page and get the continuation token which basically just tells you which row &amp; partition keys come next. But having all of them means you are vulnerable to consistency errors (e.g. if someone posts something into the same table storage). </p>\n\n<p>Personally, I would page based on rowkeys, as I described above, or, if this is a requirement, move to a storage engine that supports it. </p>\n\n<p>To elaborate a bit further, if you know you will have only one \"OrderBy\" clause, you can select all of them, and through some implication, guess what the page boundaries will be. </p>\n\n<p>On a side note, I believe the paging provided is there not to allow paging on the front-end but to alliviate the 1000 result limit. But this are just my $0.02.</p>\n    "},{"t":"Cocoa application architecture on Mac OS X","l":"http://stackoverflow.com/questions/1371165/cocoa-application-architecture-on-mac-os-x","q":"\n\n<p>I'm getting back in to Cocoa development on the Mac after a long stint doing iPhone work. My previous experience with Cocoa on the Mac has just been dinky little tools. I'm looking to build something serious.</p>\n\n<p>Looking at a modern Cocoa application like iPhoto (or Mail or Things or....) many apps use the Single-Window, Source-List based approach. I'm trying to wrap my head around that as best I can because it seems to provide a good experience. However, I'm having a little trouble. Here's how I think it should look, but I'm wondering how others are doing it, and what's really the best way:</p>\n\n<ul>\n<li><p>Starting point of the app is an AppDelegate object which, after launching, creates a Window[Controller?] from a nib, along with setting up its data (from, say CoreData)</p></li>\n<li><p>WindowController loads a window which essentially just has an NSSplitView in it.</p></li>\n<li><p>Left side of the splitview has an NSTableView or NSOutlineView which is set to have the SourceList style.</p></li>\n<li><p>Right side has the main content of the app, depending on which item of the table view is selected.</p></li>\n</ul>\n\n<p>I would assume somewhere (where?) there are NSViewControllers managing each of the different views which will appear in the right side (think how iPhoto has All Photos, Events, Faces, Places, etc. and I imagine they could all appear in different nibs... is this correct?).</p>\n\n<p>Those view controllers are probably bound to the source list on the left.. how does that work (source list is backed by an NSArrayController of NSViewControllers maybe?).</p>\n\n<p>Anyway, those are my thoughts, am I completely off-base or...? I've looked around the web, found this post <a href=\"http://cocoawithlove.com/2008/08/application-design-in-appkit.html\">here</a>, and I've looked at some Apple source code but I can't seem to wrap my head around it. Any guidance would be welcome.</p>\n    ","a":"\n<p>Breaking the views up into separate nibs is mainly good if you're going to swap out some views for others, since you can load them lazily. And yes, in a modern app, you would use NSViewController, or perhaps KTViewController from <a href=\"http://katidev.com/blog/ktuikit/\" rel=\"nofollow\">KTUIKit</a> (see <a href=\"http://katidev.com/blog/2008/04/09/nsviewcontroller-the-new-c-in-mvc-pt-1-of-3/\" rel=\"nofollow\">the posts she co-wrote about NSViewController</a>)</p>\n\n<p>Don't just go running into the arms of the source list, however. A single-window interface can be good for simple apps, but it can quickly become unwieldy when you have many things going on, as they may be better served by breaking them into separate windows; iTunes and Xcode both provide many examples of this (especially the latter, since you can switch it between SWI and MWI).</p>\n\n<p>You need to think about whether a multiple-window or single-window interface would be better for your app. There is no one answer for all apps; it depends entirely on your app, and what you want it to do, and how you want it to look—you (plus the rest of your team, if you have one) are the only one who can answer this question. You may want to do some paper prototyping to do quick experiments in each direction so that you can hold at least fake examples of both UIs up against each other.</p>\n    "},{"t":"What is SEDA (Staged Event Driven Architecture)?","l":"http://stackoverflow.com/questions/3570610/what-is-seda-staged-event-driven-architecture","q":"\n\n<p><a href=\"http://www.eecs.harvard.edu/~mdw/proj/seda/\">SEDA: An Architecture for Highly Concurrent Server Applications</a></p>\n\n<p>\"SEDA is an acronym for <em>staged event-driven architecture</em>, and decomposes a complex, event-driven application into a set of <em>stages</em> connected by <em>queues</em>.\"</p>\n\n<p>I understand that it's an architecture and that there are many implementations of SEDA (see the <a href=\"http://en.wikipedia.org/wiki/Staged_event-driven_architecture\">Wikipedia article</a>). What is a \"stage\"? Can someone give a thorough high-level summary of a staged event-driven architecture, and how it differs from traditional (unstaged?) event driven architectures?</p>\n    ","a":"\n<p>Stage is analog to \"Event\", to simplify the idea, think SEDA as a series of events sending messages between them.</p>\n\n<p>One reason to use this kind of architecture, I think, is that you fragment the logic and can connect it and decouple each event, mainly for high performance services with low latency requirements fits well.</p>\n\n<p>If you use Java TPE, you could monitor the health, throughput, errors, latency of each stage, and quickly find where is the performance bottleneck. And as a nice side effect, with smaller pieces of code, you can easily test them and increment your code coverage (that was my case).</p>\n\n<p>For the record, this is the internal architecture of Cassandra (NoSQL), and Mule ESB (AFAIK).</p>\n\n<p>I recommend to read the original paper (sorry, duplicate link):</p>\n\n<ul>\n<li><a href=\"http://www.eecs.harvard.edu/~mdw/papers/seda-sosp01.pdf\">http://www.eecs.harvard.edu/~mdw/papers/seda-sosp01.pdf</a></li>\n<li><a href=\"http://www.eecs.harvard.edu/~mdw/proj/seda/\">http://www.eecs.harvard.edu/~mdw/proj/seda/</a></li>\n</ul>\n\n<p>Here is a framework I've created to model SEDA for Java EE:  <a href=\"http://code.google.com/p/seide/\">http://code.google.com/p/seide/</a></p>\n    "},{"t":"MVVM: How to handle interaction between nested ViewModels?","l":"http://stackoverflow.com/questions/2576536/mvvm-how-to-handle-interaction-between-nested-viewmodels","q":"\n\n<p>I'm been experimenting with the oft-mentioned MVVM pattern and I've been having a hard time defining clear boundaries in some cases.  In my application, I have a dialog that allows me to create a Connection to a Controller.  There is a ViewModel class for the dialog, which is simple enough.  However, the dialog also hosts an additional control (chosen by a ContentTemplateSelector), which varies depending on the particular type of Controller that's being connected.  This control has its own ViewModel.</p>\n\n<p>The issue I'm encountering is that, when I close the dialog by pressing OK, I need to actually create the requested connection, which requires information captured in the inner Controller-specific ViewModel class.  It's tempting to simply have all of the Controller-specific ViewModel classes implement a common interface that constructs the connection, but should the inner ViewModel really be in charge of this construction?</p>\n\n<p>My general question is: are there are any generally-accepted design patterns for how ViewModels should interact with eachother, particularly when a 'parent' VM needs help from a 'child' VM in order to know what to do?</p>\n\n<hr>\n\n<p>EDIT:</p>\n\n<p>I did come up with a design that's a bit cleaner than I was originally thinking, but I'm still not sure if it's the 'right' way to do this.  I have some back-end services that allow a ContentTemplateSelector to look at a Controller instance and pseudo-magically find a control to display for the connection builder.  What was bugging me about this is that my top-level ViewModel would have to look at the DataContext for the generated control and cast it to an appropriate interface, which seems like a bad idea (why should the View's DataContext have anything to do with creating the connection?)</p>\n\n<p>I wound up with something like this (simplifying):</p>\n\n<pre><code>public interface IController\n{\n    IControllerConnectionBuilder CreateConnectionBuilder();\n}\n\npublic interface IControllerConnectionBuilder\n{\n    ControllerConnection BuildConnection();\n}\n</code></pre>\n\n<p>I have my inner ViewModel class implement IControllerConnectionBuilder and the Controller returns the inner ViewModel.  The top-level ViewModel then visualizes this IControllerConnectionBuilder (via the pseudo-magical mechanism).  It still bothers me a little that it's my inner ViewModel performing the building, but at least now my top-level ViewModel doesn't have to know about the dirty details (it doesn't even know or care that the visualized control is using a ViewModel).</p>\n\n<p>I welcome additional thoughts if there are ways to clean this up further.  It's still not clear to me how much responsibility it's 'okay' for the ViewModel to have.</p>\n    ","a":"\n<p>An option which works well for interaction between viewmodels is to bind directly to <a href=\"http://4-getful.blogspot.com/2010/01/using-observer-to-share-data-between.html\" rel=\"nofollow\">observer</a> classes sitting between the viewmodel classes. </p>\n    "},{"t":"Has anyone used Google Gears in an Enterprise scenario?","l":"http://stackoverflow.com/questions/410959/has-anyone-used-google-gears-in-an-enterprise-scenario","q":"\n\n<p>I want to create an application which will have a client and server components. The client may not be connected to the internet all the time, and hence will have to store data locally and then sync with the server whenever the internet connection is available. The data sync will be both ways: client to server and server to client.</p>\n\n<p>Initially i thought making use of SQL Server Merge replication/Microsoft sync framework for ado.net and creating the client application using C# windows forms.</p>\n\n<p>But Google Gears appears like a very good option, because it works with JavaScript and we just need build a asp.net web application which can then be used both on the client and the server. Plus it is available on Windows mobile 5 and 6, hence available on mobile devices as well.</p>\n\n<p>But has any one used Google Gears in an enterprise scenario? Has any one faced any issues using Google Gears?</p>\n    ","a":"\n<p>Google have put Gears in hibernation mode in favour of HTML5: <a href=\"http://gearsblog.blogspot.com/2010/02/hello-html5.html\" rel=\"nofollow\">http://gearsblog.blogspot.com/2010/02/hello-html5.html</a>.</p>\n    "},{"t":"Best way to secure javascript front end/REST back end architecture web site?","l":"http://stackoverflow.com/questions/8546061/best-way-to-secure-javascript-front-end-rest-back-end-architecture-web-site","q":"\n\n<p>I would like to build the following project:</p>\n\n<ul>\n<li>public REST API back end which can be accessed by any authenticated client</li>\n<li>front end with static files in HTML/CSS/Javascript with Backbone.js jQuery calls to the REST back end</li>\n</ul>\n\n<p>In fact, there are three parties in my architecture : the front end, which is a client of the back end, the back end and the user which wants to authenticate on the front end login page.</p>\n\n<p>What is the best way to secure the three parties involved in this architecture ?</p>\n\n<p>In fact, I believe it is just impossible to do a secure app on the front end if I do everything in javascript, so I intend to delegate the authentication/authorization to a proxy layer on my server front end. What do you think about that ?</p>\n\n<p>I intend to use OAuth to secure my REST back end, but I am not sure if I have to use the 2 or 3 legged implementation. What is the right approach in this case?</p>\n\n<p><strong>UPDATE</strong> : while searching a deep more on SO website, i found this <a href=\"http://stackoverflow.com/questions/4574868/securing-my-rest-api-with-oauth-while-still-allowing-authentication-via-third-pa\">thread</a> which is exactly what i would like to do, except i want to use Java on server side and not DotNet. If i understand well, in fact my web site is like any client of my REST API, except it is the only one which has the right to create new users' accounts. Because, if my REST API is only accessible by OAuth (like Twitter's one), who can perform the user account creation before ? Am i right ?</p>\n    ","a":"\n<p>One major concern with security with this architecture is testing.   Automated tools will have trouble testing this system for common vulnerabilities like SQL Injection,  <a href=\"https://www.owasp.org/index.php/Top_10_2010-A4-Insecure_Direct_Object_References\" rel=\"nofollow\">Direct Object Reference</a>.   A useful tool for testing strange architectures is OWASP's open source <a href=\"https://www.owasp.org/index.php/OWASP_Zed_Attack_Proxy_Project\" rel=\"nofollow\">Zed Attack Proxy</a> or the proprietary BURP proxy.   Testing will be time consuming and requires someone who has a good understanding of web application vulnerabilities. We often refer to these people as <strong>Pentesters</strong>. </p>\n\n<p>A RESTful form of keeping session state is to use an <a href=\"http://en.wikipedia.org/wiki/HMAC\" rel=\"nofollow\">HMAC</a> to protect the values from modification.  However,  this is a misuse of cryptography because it opens the door for attack.  An attacker can brute force the secret key used in your HMAC and then modify values such as his session id or otherwise gain access to another account on the system.  Cryptography should only be used when there is no other option.  This vulnerability is prevented entirely by storing session state in a database,  which isn't RESTful.</p>\n    "},{"t":"Concrete examples on why the 'Anemic Domain Model' is considered an anti-pattern","l":"http://stackoverflow.com/questions/6293981/concrete-examples-on-why-the-anemic-domain-model-is-considered-an-anti-pattern","q":"\n\n<p>I apologize if this is a duplicate, but I couldn't find any concrete examples on the topic in related questions.</p>\n\n<p>After reading <a href=\"http://martinfowler.com/bliki/AnemicDomainModel.html\">Martin Fowler's article on the 'Anemic Domain Model'</a>, I'm left wandering as to why is this considered an anti-pattern. Even does the majority of enterprise developers consider it an anti-pattern, since AFAIK probably 90% of the j2ee applications are designed in an 'anemic' way ?</p>\n\n<p>Can someone recommend further reading on the topic (other than the 'Domain Driven Design' book), or even better, give a concrete examples on how this anti-pattern is affecting application design in a bad way.</p>\n\n<p>Thanks,</p>\n    ","a":"\n<p>Given the following two classes:</p>\n\n<pre><code>class CalculatorBean  \n{  \n    //getters and setters  \n}  \n\nclass CalculatorBeanService  \n{  \n   Number calculate(Number first, Number second);  \n    {  \n       //do calculation  \n    }  \n} \n</code></pre>\n\n<p>If I understand correctly, Fowler is stating that because your <code>CalculatorBean</code> is just a bunch of getters/setters you don't gain any real value from it and if you port that object to another system it will do nothing.  The problem seems that your <code>CalculatorBeanService</code> contains everything that the <code>CalculatorBean</code> should be responsible for.  Which is not the best as now the <code>CalculatorBean</code> delegates all of its responsibility to the <code>CalculatorBeanService</code></p>\n    "},{"t":"Difference between three tier vs. n-tier","l":"http://stackoverflow.com/questions/455555/difference-between-three-tier-vs-n-tier","q":"\n\n<p>I just came across the following sentence:</p>\n\n<blockquote>\n  <p>As the industry has moved from a three\n  tier model to n-tier models, the object relational impedance mismatch has become more prevalent.</p>\n</blockquote>\n\n<p>But I can't find a concise explanation of the difference between three tier and n-tier. I know what three tier is, and I assume n-tier just adds one or more tiers. I'm just not sure what these additional tiers would be. If anyone has a short explanation or simply a good link, that would be much appreciated.</p>\n    ","a":"\n<p>The quote appears to be from this <a href=\"http://www.codeproject.com/KB/showcase/object_relational_mapping.aspx\">codeproject</a> page.  It also seems to do a pretty good job of explaining n-tier to include things like web services, javascript, workflows, etc.  All things that 3-tier models don't necessarily include.</p>\n    "},{"t":"SaaS database design - Multiple Databases? Split?","l":"http://stackoverflow.com/questions/69128/saas-database-design-multiple-databases-split","q":"\n\n<p>I've seen SaaS applications hosted in many different ways. Is it a good idea to split features and modules across multiple databases? For example, putting things like the User table on one DB and feature/app specific tables on another DB and perhaps other commonly shared tables in another DB?</p>\n    ","a":"\n<p>Start with one database. Split data/functionality when project requires it.</p>\n\n<p>Here is what we can learn from LinkedIn:</p>\n\n<ul>\n<li>A single database does not work</li>\n<li>Referential integrity will not be possible</li>\n<li>Any data loss is a problem</li>\n<li>Caching is good even when it's modestly effective</li>\n<li>Never underestimate growth trajectory</li>\n</ul>\n\n<p>Source:</p>\n\n<p><a href=\"http://www.slideshare.net/linkedin/linkedins-communication-architecture\">LinkedIn architecture</a></p>\n\n<p><a href=\"http://www.slideshare.net/linkedin/linked-in-javaone-2008-tech-session-comm\">LinkedIn communication architecture</a></p>\n    "},{"t":"Is there an equivalent to COM on *nix systems ? If not, what was the *nix approach to re-usability?","l":"http://stackoverflow.com/questions/3063321/is-there-an-equivalent-to-com-on-nix-systems-if-not-what-was-the-nix-approa","q":"\n\n<p>I have an understanding of windows COM and the ideas behind it.  I am trying to understand if *nix systems even have an equivalent or why they don't?</p>\n    ","a":"\n<p>The Unix model is built around the idea of lightweight processes that communicate with each other, through sockets, pipes, signals, and command lines.  Historically, Unix didn't have threads (the POSIX thread model is only about 10 years old IIRC), but processes on Unix have always been much cheaper than on Windows, so it was more performant to factor functionality into separate executables than to allow a single program to grow large and monolithic.</p>\n\n<p>In COM, you define binary interfaces that allow shared-memory communication.  COM is tied to an <em>object-oriented</em> paradigm.  In the classic Unix model, you define stream-oriented interfaces that allow communication over pipes, without shared memory.  Conceptually, this is much closer to a <em>functional</em> programming paradigm.</p>\n\n<p>The Unix model encourages making small programs that can be easily coupled together by a lightweight \"shell\", while the COM model encourages making large programs that expose \"components\" that can be reused by other large programs.  It's really an apples-and-oranges comparison, since both models provide benefits and drawbacks for different scenarios.</p>\n\n<p>Of course, modern Unix systems can have COM-like facilities.  Mozilla has XPCOM, a cross-platform framework built on the same principles as COM.  GNOME for a long time used Bonobo, which is conceptually very similar to Microsoft OLE, which was the forerunner to COM.  But recent versions of GNOME have been shifting away from Bonobo in favor of D-Bus, which is more of an event/messaging pattern.</p>\n    "},{"t":"When to use the CQRS design pattern?","l":"http://stackoverflow.com/questions/8820748/when-to-use-the-cqrs-design-pattern","q":"\n\n<p>My team and I have been discussing using the CQRS (Command Query Responsibility Segregation) design pattern and we are still trying to asses the pros and cons of using it. According to: <a href=\"http://martinfowler.com/bliki/CQRS.html\">http://martinfowler.com/bliki/CQRS.html</a> </p>\n\n<blockquote>\n  <p>we haven't seen enough uses of CQRS in the field yet to be confident\n  that we understand its pros and cons</p>\n</blockquote>\n\n<p>So what do you guys think, when does a problem call for using CQRS? </p>\n    ","a":"\n<p>CQRS is not a pattern that encompasses the whole application.</p>\n\n<p>It is a concept that builds on Domain Driven Design (DDD). And an important strategic concept of DDD is the so-called <strong>Bounded Context</strong>. </p>\n\n<p>In a typical application there are multiple bounded contexts, any of which can be implemented the way it makes sense. For instance</p>\n\n<ul>\n<li>User Management -&gt; CRUD</li>\n<li>Invoicing -&gt; CRUD</li>\n<li>Insurance Policy Management (the Core Domain) -&gt; CQRS</li>\n<li>...</li>\n</ul>\n\n<p>This probably doesn't answer your question but it might give a little more insight into the topic. To be honest, I don't think it can be answered at all without considering a project's specifics, and even then there is rarely something like a definite <em>best practice</em>.</p>\n    "},{"t":"Repository, Pipeline, business logic and domain model - how do I fit these together?","l":"http://stackoverflow.com/questions/6074322/repository-pipeline-business-logic-and-domain-model-how-do-i-fit-these-toget","q":"\n\n<p>I'm designing N-tier application and I came across a difficulty which you might have a solution to. Presentation layer is MVC.</p>\n\n<p>My ORM is carried out using LinqToSQL - it's a seperate project which serves repositories.</p>\n\n<p>Each reporsitory has an interface and at least 1 concrete implementation.</p>\n\n<p>Repositories have the following methods: <code>FindAll(), Save(T entity), Delete(int id)</code></p>\n\n<p><code>FindAll()</code> returns     IQueryable of some type, which means that it returns queries to which I can apply filters.</p>\n\n<p>ORM mapping has been carried out using Database First methodology, where tables were created first and then classes were generated by SQL Metal.</p>\n\n<p>I have added a Pipeline layer which works with repositories. It applies further filters to queries. E.g. <code>OrderRepository.FindAll().Where(o =&gt; o.CustomerId == 10)</code> </p>\n\n<p>Pipeline also returns IQueryable of some type, which means that I can pass it further up the layer and do more stuff with it.</p>\n\n<p>At this point I would like to move to the BusinessLogic layer, but I don't want to work with entity models any longer, I want to convert entity model to a domain model. This means that I can add validation to a model and use that model in the presentation layer. Model can't be defined in MVC project as it would be dependant on the presentation layer, so that's a no.</p>\n\n<p>I'm fairly certain that business logic (behaviour) and model must be stored seperate from pipeline, data and presentation layer. The question is where?</p>\n\n<p>For example, a pipeline has three methods:\n1. FindByCustomerId\n2. FindByOrderId\n3. FindBySomethingElse</p>\n\n<p>All these methods return IQueryable of Order. I need to convert this to a domain model, but I don't want to do it per each method as it won't be mainteinable. </p>\n\n<p>I feel that this model is fairly robust and scalable. I just don't see what is the best place for mapping from entities to domain model and vise versa.</p>\n\n<p>Thank you</p>\n    ","a":"\n<p>First of all, if you are applying Domain Driven Design principles here, you must not have BusinessLogic layer in your application. All business logic should live inside your domain model. </p>\n\n<p>But it is quite hard to achieve using LinqToSQL because it does not support inheritance mapping and you would have to deal with partial classes to put business logic into your domain. So I would strongly recommend to consider moving from LinqToSQL to NHibernate or Entity Framework Code First .In this case you also won't have to convert your persistence model into your domain model and vice versa.</p>\n\n<p>If you still want to do conversion, you could take a look at <a href=\"http://automapper.codeplex.com/\">Automapper</a></p>\n    "},{"t":"How ASP .NET MVC architecture fits into the traditional multi layered architecture","l":"http://stackoverflow.com/questions/5990773/how-asp-net-mvc-architecture-fits-into-the-traditional-multi-layered-architectu","q":"\n\n<p>Moving from the traditional way of architecting web applications with a Business Layer, Service Layer, Data Access Layer and a Presentation Layer to the MVC design pattern, I find it difficult to understand how it fits in the old model.</p>\n\n<p>It seems to be that the MVC model itself already has done allot of the separation of concerns that is needed and used to be achieved via a layered architecture. Can someone shed some light on this subject please?</p>\n\n<p><strong>As a reference, below is how I understand it, please share your view on this</strong></p>\n\n<p>MVC Views and Controllers along with View Models -are- <em>Presentation Layer</em></p>\n\n<p>MVC Models - could be - <em>Data Access Layer or Business Layer or even Service Layer</em></p>\n    ","a":"\n<p>I see the <strong>Asp.Net MVC part</strong> only as the <strong>view (or presentation) part</strong> of the whole application.  </p>\n\n<p>I struggled too with the problem how to structure the app in a proper way.<br>\nFollowing the <strong>Onion Architecture</strong> I heard about <strong><a href=\"http://jeffreypalermo.com/blog/the-onion-architecture-part-1/\">here</a></strong> (and especially the image found <a href=\"http://jeffreypalermo.com/blog/the-onion-architecture-part-2/\">here</a>), my solution looks this way:</p>\n\n<ul>\n<li><strong>Project.Core</strong><br>\nBusiness logic/services implementations, entities, interfaces that must be implemented by the other projects (i.e. \"IRepository\", \"IAuthenticationService\",...)  </li>\n<li><strong>Project.Data</strong><br>\nDB connection - in my case NHibernate repositories and entity-mappings go here.\nImplements <em>data</em>-interfaces of Project.Core</li>\n<li><strong>Project.UI.Web</strong><br>\nThe Asp.Net MVC (\"presentation\") project - it wires the whole app together.<br>\nHas implementations for Interfaces in Project.Core and wires them (and those from Project.Data) up with some DI framework like Castle Windsor.</li>\n</ul>\n\n<p>Project.UI.Web follows the following conventions:  </p>\n\n<ul>\n<li>its <strong>models</strong> are only(!) <strong>viewmodels</strong>  </li>\n<li>the <strong>views</strong> consume their <strong>own viewmodel</strong> (one-view-one-viewmodel)  </li>\n<li>the <strong>controllers</strong> just need to <strong>validate</strong> the input, <strong>transforms</strong> it into <strong>domain objects</strong> (as the business logic <strong><em>knows exacly nothing about viewmodels</em></strong>) and <strong>delegate</strong> the real work (business logic) to the business services.</li>\n</ul>\n\n<p><strong>Summary:</strong><br>\nIf you follow this model it's helpful to <strong>focus on Project.Core</strong>: <strong><em>that</em></strong> is the <strong><em>real</em> application</strong>. It doesn't worry about the real persistence of data nor cares about how does it get presented. It's just about \"how-to-do-it\". But it's laying out the rules and contracts (interfaces) the other projects must provide implementations for.</p>\n\n<p>I hope this helps you with how to layout an Asp.Net MVC application!</p>\n\n<p>Lg<br>\nwarappa</p>\n    "},{"t":"What type of architecture is this called?","l":"http://stackoverflow.com/questions/9732747/what-type-of-architecture-is-this-called","q":"\n\n<p>For the web application (ASP.NET MVC) I'm currently developing, we have the following architecture in place:</p>\n\n<ul>\n<li><code>Data Access Layer</code>: Logic for persisting data to an arbitrary db</li>\n<li><code>Domain</code>: The data model</li>\n<li><code>Service Layer</code>: Business logic (e.g. order processing, account management, etc.)</li>\n<li><code>Controller</code>: Consumes services and provides/receives data to/from the View</li>\n<li><code>View</code>: The user interface for the user</li>\n</ul>\n\n<p>In essence, I took the <code>Model</code> and split it up into the <code>DAL</code>, <code>Service Layer</code> and <code>Domain</code>. I felt that stuffing all the logic within the <code>Model</code> made my code overly complicated. Furthermore, I felt that it let me express my business logic cleanly without making the controller do too much work.</p>\n\n<p><strong>My question then is:</strong> What is this type of architecture called?</p>\n\n<p><strong>As a secondary question</strong>: Does this type of architecture make sense? If not, am I doing something wrong?</p>\n    ","a":"\n<p>You are on the right track about DDD depending on how thin / thick the domain &amp; service layers are. DDD says that the knowledge (i.e. business logic) should be crunched into the domain model. Moving data access concerns to the DAL is in line with DDD, but I think moving business logic out into a Services Layer is not. If you have a thin Domain \"data model\" layer (mostly for entities) and a thick Services layer (mostly for \"business logic\"), you may have an <a href=\"http://martinfowler.com/bliki/AnemicDomainModel.html\">anemic domain</a>.</p>\n\n<p>Also, there is technically no \"Service Layer\" in DDD. There may be an \"Application Layer\", but it should be thin, and only be responsible for application flow / managing domain class lifetimes. This is essentially what Controllers do in .NET MVC, manage application flow in the context of web http. </p>\n\n<p>If stuffing all of the  logic within the Model made your code overly complicated, I'd be interested to hear examples of what you mean by \"overly complicated\". You could be correctly modeling a complex domain, or there are chances you could have gone to DDD patterns to uncomplicate things. I would say as you have listed it in your question, the arch is not DDD. I would just call it \"Layered architecture\", but that's because I prefer to use the term \"tier\" only when talking about physical arch. However, your logical architecture is layered.</p>\n\n<p>I really like that Darin linked to Onion arch in his answer. I'm becoming a big fan of it, and I find it's not exclusive to DDD at all. If your code uses dependency injection to solve interface dependencies with runtime implementations, you may have a form of onion arch. For example, do you define any interfaces in your DAL? Are implementations of those interfaces solved at runtime? </p>\n\n<p>Here is an example of an arch I am starting to use in my new projects. It's a combination of onion + DDD:</p>\n\n<ul>\n<li><p><code>API</code> Project/Assembly: generic interfaces, enums, classes, and extension methods used by all other layers. Need not be separate from Domain, but may.</p></li>\n<li><p><code>Domain</code> Project/Assembly: all entities and business logic. Depends on <code>API</code> only. Uses DDD patterns like factory, service, specification, repository, etc. Also contains more domain-specific interfaces which are not defined in the API. </p></li>\n<li><p><code>Impl</code> Project/Assembly: implementations of interfaces defined in <code>API</code> and <code>Domain</code>. This is where the EF DbContext is implemented, as well as things like logging, email sending, etc. All of these implementations are dependency-injected, so technically you could have several Impl projects / assemblies. </p></li>\n<li><p><code>UI</code> Project/Assembly: This is the MVC project. Controllers consume the domain surface directly, and do not go through an application or service layer. Any interface dependencies in factories, services, repositories, etc, are injected into the domain by the controller using MVC IoC (constructor injection). </p></li>\n</ul>\n\n<p>I placed an API layer at the very core but you could combine the API and Domain projects into one. Either way, the big meaty part of the onion is the Domain, and it has internal layering. For example Services may depend on Factories, which depend on Repositories, which depend on Entities.</p>\n\n<p>The Impl project is what you see as the \"Infrastructure\" onion skin in Palermo's diagram. It is at the outer edge along with the UI, and contains no domain-specific knowledge. It knows how to send email, store/retrieve data using EF, etc. If you want, you can have more than 1 of these -- for example 1 Impl for data access, 1 Impl for dealing with mail, etc. </p>\n\n<p>MVC has the Controllers and Views, and concentrates on the UI and web application flow. Anything that requires domain-specific knowledge is delegated out to the domain, and domain classes are constructor injected into the controller. This means any constructor-injected interfaces in domain classes are resolved automatically by the IoC container. </p>\n\n<p>As a final note, programming against interfaces defined in the API and Domain classes means you can unit test the domain project separately from the MVC project. </p>\n    "},{"t":"What's wrong with the architecture of a game object drawing and updating itself?","l":"http://stackoverflow.com/questions/3000525/whats-wrong-with-the-architecture-of-a-game-object-drawing-and-updating-itself","q":"\n\n<p>What are the reasons for and against a game object drawing and updating itself? For example, if you have a game where the player has a position on screen, why not have an all-encompassing class:</p>\n\n<pre><code>public class Player {\n    private int x, y, xVelocity, yVelocity;\n    private Sprite s;\n    //...\n\n    public Player() {\n        // load the sprite here, somehow?\n    }\n\n    public void draw(CustomGraphicsClass g) {\n        g.draw(s, x, y);\n    }\n\n    public void update(long timeElapsed) {\n        x += (xVelocity * timeElapsed);\n        y += (yVelocity * timeElapsed);\n    }\n}\n</code></pre>\n\n<p>What is wrong with this design? What are the downfalls or concerns? How would you better write something like this, or better architect this type of thing in a game?</p>\n\n<p>Also, somewhat connected, how would you implement loading that Sprite image?</p>\n\n<p>And furthermore, how would you then implement collision between two <code>Player</code>s?</p>\n\n<p>(I should probably separate these extra two questions into new questions, huh?)</p>\n    ","a":"\n<p>It couples all of your rendering and logic code together when they have little in common beyond being conceptually tied to the same \"entity\". As your class gets bigger, you can find yourself with a huge monolithic <code>Player</code> that's a nightmare to maintain. Splitting out along domain boundaries (rendering, AI) makes it more manageable without having to give up much since those domains don't have a lot of overlap.</p>\n\n<p>Beyond maintainability, there's some other considerations:</p>\n\n<ol>\n<li><p>If you want to process rendering and AI on different threads, mixing their state into the same class is just begging for nasty multi-threading problems.</p></li>\n<li><p>If you're using a language like C++, highly-coupled classes like this can kill your compile times.</p></li>\n<li><p>Depending on how your code and objects are laid out in memory, splitting objects into separate components for each domain can give you better cache coherency and much better performance.</p></li>\n</ol>\n\n<p>Here's <a href=\"http://gameprogrammingpatterns.com/component.html\">lots more info</a> if you're curious.</p>\n    "},{"t":"Avoid exposing primary keys in the source of a web app?","l":"http://stackoverflow.com/questions/806787/avoid-exposing-primary-keys-in-the-source-of-a-web-app","q":"\n\n<p>I often come across web applications that expose internal database primary keys through forms like select boxes.  And occasionally I see javascript matching against an int or guid magic value that switches the logic.</p>\n\n<p>Is is a best practice to avoid leaking all internal identifiers of rows in your web application to prevent outsiders from understanding too much of your system and possibly using it to exploit your system.  If so what is the best way to solve this problem?</p>\n\n<p>Should you expose some other value to the web app that can be translated back to the primary key?</p>\n\n<p>Thanks</p>\n\n<p><strong>Edit</strong></p>\n\n<p>In a perfect world your application would be 100% secure so it wouldn't matter if you obscured things.  Obviously that's not the case so should we error on the side of caution and not expose this information?</p>\n\n<p>Some have pointed out that Stackoverflow is probably exposing a key in the Url which is probably fine.  However are considerations different for Enterprise Applications?</p>\n    ","a":"\n<p>I disagree with the stance that exposing primary keys is a problem. It can be a problem if you make them visible to users because them they are given meaning outside the system, which is usually what you're trying to avoid.</p>\n\n<p>However to use IDs as the value for combo box list items? Go for it I say. What's the point in doing a translation to and from some intermediate value? You may not have a unique key to use. Such a translation introduces more potential for bugs.</p>\n\n<p>Just don't neglect security.</p>\n\n<p>If say you present the user with 6 items (ID 1 to 6), never assume you'll only get those values back from the user. Someone could try and breach security by sending back ID 7 so you still have to verify that what you get back is allowed.</p>\n\n<p>But avoiding that entirely? No way. No need.</p>\n\n<p>As a comment on another answer says, look at the URL here. That includes what no doubt is the primary key for the question in the SO database. It's entirely fine to expose keys for technical uses.</p>\n\n<p>Also, if you do use some surrogate value instead, that's not necessarily more secure.</p>\n    "},{"t":"Frameworks vs. SDKs","l":"http://stackoverflow.com/questions/424846/frameworks-vs-sdks","q":"\n\n<p>What is the difference between a framework and an SDK?  Take, for example, the MS platform SDK and the .NET framework.  Both have API's, both hide their inner workings, and both provide functionality that may not be quickly/easily accessible otherwise (in other words, they serve a real-world purpose).</p>\n\n<p>So what's the difference?  Is it primarily a marketing game of semantics, or are there actual differences in how developers are expected to interact with the software (and conversely, how the developers can expect the software to behave)?  Is one expected to be higher- or lower-level than the other, etc?</p>\n\n<p>Thanks!</p>\n\n<p>EDIT: This question applies to SDKs and frameworks in general, not just the two mentioned above.</p>\n    ","a":"\n<p>An SDK is expected to offer tools to program against a certain system resource or feature. A Framework not necessarily (although .NET offers a whole set of tools such as the compilers, etc - but these are mandatory for it to work anyways).</p>\n\n<p>So, you could develop a Framework consisting solely of libraries, but if you call it SDK you will be expected to offer something to support development.</p>\n    "},{"t":"Solution: Per application, or per application suite","l":"http://stackoverflow.com/questions/200954/solution-per-application-or-per-application-suite","q":"\n\n<p>Often multiple applications share a large codebase of libraries that change often in development.  In these cases, I prefer to create a solution named after the suite, and include separate projects for each application and the shared libraries.</p>\n\n<p>Is this a good approach?  How do others structure their code bases for things like a suite of applications?</p>\n    ","a":"\n<p>It really depends on your organization's particular needs.  MSDN has a <a href=\"http://msdn.microsoft.com/en-us/library/ee817674.aspx\">good page</a> that goes through the various recommended solution layouts, including:</p>\n\n<ol>\n<li>The Single Solution model (preferred)</li>\n<li>The Partitioned Single Solution model</li>\n<li>The Multi-solution model (Only if strictly necessary)</li>\n</ol>\n\n<p>The <a href=\"http://msdn.microsoft.com/en-us/library/ee817674.aspx\">MSDN page</a> also discusses the pros and cons of each model in more detail so you can decide which one makes sense for you.  :)</p>\n\n<p>In general, for an application suite such as you describe, I would consider the partitioned, single solution model.  There's a single master solution that builds everything, and a number of separate solutions for each individual application within the suite (assuming the applications are of appreciable size).  </p>\n\n<p>If the applications in the suite are small and build quickly (e.g., a suite of command line tools), I might not even generate the separate solution files.  That's really a judgement call we can't make for you.  :)</p>\n    "},{"t":"How does the github website work (architecture)?","l":"http://stackoverflow.com/questions/4892602/how-does-the-github-website-work-architecture","q":"\n\n<p>Github is a truly amazing service. I'm keen to understand what their architecture is like and how they fit the different pieces together; how they store the repositories, how they access those repositories to show file contents, how they handle displaying diffs, etc. Could someone give an overview of the technologies and techniques they use, so I can study them to expand my knowledge and in turn skills?</p>\n    ","a":"\n<p><a href=\"https://github.com/blog/530-how-we-made-github-fast\">This article</a> from the github blog gives a pretty good overview of the architecture based on a drill-down of how client requests are handled. Note that there are some proprietary bits in there that are basically github's trade secrets.</p>\n    "},{"t":"Should I run RavenDB as a windows service or through IIS?","l":"http://stackoverflow.com/questions/8673918/should-i-run-ravendb-as-a-windows-service-or-through-iis","q":"\n\n<p>I am playing with the idea of using RavenDB as the data store for an application that will most likely have an HTML UI, a WebService UI, and server utilities that will access the data as well.  One reason for using RavenDB is the horizontal scaling it offers through replication and sharding.  However, it seems like there are several considerations around running Raven as a windows service or running it through IIS.</p>\n\n<ul>\n<li>Security - Is the Raven service more secure or will using IIS allow me more flexibility to restrict by IP address, .NET Membership, etc.</li>\n<li>Caching - It seems like IIS is the better choice for this feature</li>\n<li>Architecture - Since I would not want any third party to access the data store would it really make sense to expose Raven through IIS. Also, there would be a business layer between Raven and the various UI's and utilities, so involving IIS seems unnecessary and may introduce unneeded complexity.</li>\n<li>Performance - The IIS pipeline probably has more overhead on each request than a windows service</li>\n<li>Scaling - Using IIS is probably more complicated to scale out across multiple servers as opposed to just installing the Raven service with a small batch file</li>\n</ul>\n\n<p><strong>EDITED</strong></p>\n\n<p>I can understand using Raven's Embedded configuration if all you have is a single web client but when you have several different clients, Raven's API needs to be exposed independently to prevent a single client from locking the data files.</p>\n    ","a":"\n<p>Jedatu,\nWe generally host RavenDB inside IIS, it makes some things easier, in particular, management of the server is easier when IIS is taking care of all the activation, etc.\nWe haven't seen any meaningful perf difference, and IIS has nicer options for fine grained management.</p>\n    "}]